{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env variables set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SETUP IS READY\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Choose the dataset name (the dataset should be inside the folder /dataset in csv format)\n",
    "The default dataset is: openml_203ds_datasets_matching\n",
    "\"\"\"\n",
    "dataset_name = \"openml_203ds_datasets_matching\"\n",
    "\n",
    "\"\"\"\n",
    "choose integer number of ratio negative/positive to sample (0 will use all negative pairs)\n",
    "\"\"\"\n",
    "neg_sample = 2\n",
    "\"\"\"\n",
    "Choose one split trategy [\"isolation\",\"random\"] : \n",
    "- random will randomly spread positive node pairs in 80-20 fashion\n",
    "- isolation will isolate 1 node from some topics in test (none pair in train will see these nodes).\n",
    "The positive pairs will be splitted almost in 80-20%, like in the random case.\n",
    "\"\"\"\n",
    "strategy = \"random\"\n",
    "\"\"\"\n",
    "Choose to use the selected strategy to create a new split \n",
    "or reuse a previously created one (useful to repeat exact same experiment)\n",
    "\"\"\"\n",
    "create_new_split = False\n",
    "\n",
    "\"\"\"\n",
    "You can choose to use one of [\"FASTTEXT\",\"BERT\"] as initial word_embedding encoding for the nodes in the datasets\n",
    "\"\"\"\n",
    "word_embedding_encoding = \"FASTTEXT\"\n",
    "\n",
    "\"\"\"\n",
    "These are the default values\n",
    "\n",
    "dataset_name = \"openml_203ds_datasets_matching\"\n",
    "neg_sample = 2\n",
    "strategy = \"random\"\n",
    "create_new_split = False #assumes splitted files exists already\n",
    "word_embedding_encoding = \"FASTTEXT\"\n",
    "\"\"\"\n",
    "print(\"Env variables set\")\n",
    "\n",
    "#import libraries\n",
    "from step3 import step3_gcnsm\n",
    "from step3.step3_gcnsm import confusion_matrix as confusion_matrix\n",
    "from step3.step3_gcnsm import train as train\n",
    "from step3.step3_gcnsm import cross_validation as cross_validation\n",
    "from step3.step3_gcnsm import test_mask, train_mask\n",
    "from step3.step3_gcnsm import g\n",
    "from step3 import step3_gcn_nn_concatenate as gcn_nn\n",
    "from step3 import step3_gcn_loss as gcn_loss\n",
    "from step3 import step3_gcn_training as gcn_training\n",
    "from step3 import step3_plot_results as plot\n",
    "# step3_gcnsm.load_env(ds_name=dataset_name,ns=neg_sample,st=strategy,sp=create_new_split,we=word_embedding_encoding)\n",
    "print(\"\\n SETUP IS READY\")\n",
    "cv_number=\"5-5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_nn.get_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose NN architecture and loss function, then run tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config and run training\n",
    "### NN architectures: \n",
    "\n",
    "{<br>\n",
    "    \"0\": \"Bert_300\", <br>\n",
    "    \"1\": \"Bert_300_300_200\", <br>\n",
    "    \"2\": \"Bert_768\", <br>\n",
    "    \"3\": 'Fasttext2_150', <br>\n",
    "    \"4\": \"Fasttext3GCN_300\" <br>\n",
    "    \"5\": \"Fasttext_150\", <br>\n",
    "    \"6\": \"Fasttext_150_150_100\", <br>\n",
    "    \"7\": \"Fasttext_300\" <br>\n",
    "}\n",
    "### Loss functions: \n",
    "{<br>\n",
    "    \"0\": \"ContrastiveLoss\", <br>\n",
    "    \"1\": \"CosineEmbeddingLoss\", <br>\n",
    "}\n",
    "\n",
    "### Optimizer\n",
    "{<br>\n",
    "    \"adam\" (default)<br>\n",
    "    \"sgd\"<br> \n",
    "}\n",
    "\n",
    "\n",
    "### Loss functions parameters examples: format -> [margin]+[aggregation_function] \n",
    "{<br>\n",
    "    0.9+mean, <br>\n",
    "    0.7+mean, <br>\n",
    "    0.5+mean, <br>\n",
    "    0.3+mean, <br>\n",
    "    0.9+sum, <br>\n",
    "    0.7+sum, <br>\n",
    "    0.5+sum, <br>\n",
    "    0.3+sum, <br>\n",
    "}\n",
    "\n",
    "### batch_splits examples: \n",
    "{<br>\n",
    "    64, <br>\n",
    "    128, <br>\n",
    "}\n",
    "### learning rate examples (lr): \n",
    "{<br>\n",
    "    1e-3, <br>\n",
    "    1e-4, <br>\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #load model from path\n",
    "# training = gcn_training.Training()\n",
    "# training.load_state(path=\"./models/[file_name].pt\")\n",
    "# train(training,iterations=N)\n",
    "\n",
    "# #train new model and specify parameters\n",
    "# training = gcn_training.Training()\n",
    "# training.set_training(\n",
    "#             net_name= gcn_nn.get_option_name(),  #_of_option for NN architecture\n",
    "#             batch_splits= ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "#             lr= , #learning rate for training (e.g. 1e-3 )\n",
    "#             loss_name=gcn_loss.get_option_name(), #_of_option for loss \n",
    "#             loss_parameters= ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "#             optimizer_name= ) #adam or sgd, default adam\n",
    "# train(training,iterations=N)\n",
    "\n",
    "## Print confusion matrix and results using the training object\n",
    "#confusion_matrix(training.net, step3_gcnsm.g, step3_gcnsm.g.ndata['vector'], step3_gcnsm.test_mask,training.loss_name,threshold = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 3\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 2664 Test samples: 198\n",
      "Train positive samples: 1332 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 3\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 2664 Test samples: 198\n",
      "Train positive samples: 1332 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00041, loss_test:0.14495, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:15.012, tt:15.012\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00041, loss_test:0.14282, lr:1.00e-02, fs:0.64360 (r=0.939,p=0.489),  time:13.921, tt:27.841\n",
      "Ep:2, loss:0.00039, loss_test:0.13855, lr:1.00e-02, fs:0.62454 (r=0.848,p=0.494),  time:13.567, tt:40.702\n",
      "Ep:3, loss:0.00036, loss_test:0.13356, lr:1.00e-02, fs:0.58559 (r=0.657,p=0.528),  time:13.616, tt:54.463\n",
      "Ep:4, loss:0.00034, loss_test:0.13546, lr:1.00e-02, fs:0.57297 (r=0.535,p=0.616),  time:13.485, tt:67.427\n",
      "Ep:5, loss:0.00032, loss_test:0.13473, lr:1.00e-02, fs:0.59184 (r=0.586,p=0.598),  time:13.400, tt:80.403\n",
      "Ep:6, loss:0.00031, loss_test:0.13370, lr:1.00e-02, fs:0.57868 (r=0.576,p=0.582),  time:13.341, tt:93.387\n",
      "Ep:7, loss:0.00029, loss_test:0.13629, lr:1.00e-02, fs:0.58427 (r=0.525,p=0.658),  time:13.289, tt:106.310\n",
      "Ep:8, loss:0.00028, loss_test:0.13706, lr:1.00e-02, fs:0.56354 (r=0.515,p=0.622),  time:13.396, tt:120.567\n",
      "Ep:9, loss:0.00027, loss_test:0.14096, lr:1.00e-02, fs:0.54651 (r=0.475,p=0.644),  time:13.387, tt:133.874\n",
      "Ep:10, loss:0.00025, loss_test:0.14052, lr:1.00e-02, fs:0.55814 (r=0.485,p=0.658),  time:13.593, tt:149.521\n",
      "Ep:11, loss:0.00024, loss_test:0.14159, lr:1.00e-02, fs:0.56647 (r=0.495,p=0.662),  time:13.698, tt:164.372\n",
      "Ep:12, loss:0.00023, loss_test:0.13943, lr:9.90e-03, fs:0.57471 (r=0.505,p=0.667),  time:13.766, tt:178.963\n",
      "Ep:13, loss:0.00022, loss_test:0.14053, lr:9.80e-03, fs:0.58480 (r=0.505,p=0.694),  time:13.828, tt:193.588\n",
      "Ep:14, loss:0.00022, loss_test:0.14197, lr:9.70e-03, fs:0.57647 (r=0.495,p=0.690),  time:13.884, tt:208.261\n",
      "Ep:15, loss:0.00021, loss_test:0.14198, lr:9.61e-03, fs:0.55814 (r=0.485,p=0.658),  time:13.942, tt:223.067\n",
      "Ep:16, loss:0.00020, loss_test:0.14102, lr:9.51e-03, fs:0.57143 (r=0.485,p=0.696),  time:13.995, tt:237.909\n",
      "Ep:17, loss:0.00019, loss_test:0.13874, lr:9.41e-03, fs:0.56647 (r=0.495,p=0.662),  time:14.032, tt:252.580\n",
      "Ep:18, loss:0.00019, loss_test:0.13820, lr:9.32e-03, fs:0.59770 (r=0.525,p=0.693),  time:14.067, tt:267.273\n",
      "Ep:19, loss:0.00018, loss_test:0.13568, lr:9.23e-03, fs:0.62637 (r=0.576,p=0.687),  time:14.098, tt:281.965\n",
      "Ep:20, loss:0.00018, loss_test:0.13521, lr:9.14e-03, fs:0.62222 (r=0.566,p=0.691),  time:14.118, tt:296.469\n",
      "Ep:21, loss:0.00017, loss_test:0.13499, lr:9.04e-03, fs:0.63333 (r=0.576,p=0.704),  time:14.144, tt:311.177\n",
      "Ep:22, loss:0.00017, loss_test:0.13287, lr:8.95e-03, fs:0.64481 (r=0.596,p=0.702),  time:14.161, tt:325.701\n",
      "Ep:23, loss:0.00016, loss_test:0.13194, lr:8.86e-03, fs:0.66292 (r=0.596,p=0.747),  time:14.189, tt:340.529\n",
      "Ep:24, loss:0.00016, loss_test:0.13302, lr:8.78e-03, fs:0.65922 (r=0.596,p=0.738),  time:14.197, tt:354.913\n",
      "Ep:25, loss:0.00015, loss_test:0.13146, lr:8.69e-03, fs:0.65556 (r=0.596,p=0.728),  time:14.212, tt:369.520\n",
      "Ep:26, loss:0.00015, loss_test:0.12893, lr:8.60e-03, fs:0.65922 (r=0.596,p=0.738),  time:14.223, tt:384.020\n",
      "Ep:27, loss:0.00015, loss_test:0.13076, lr:8.51e-03, fs:0.65922 (r=0.596,p=0.738),  time:14.241, tt:398.737\n",
      "Ep:28, loss:0.00014, loss_test:0.12875, lr:8.43e-03, fs:0.65922 (r=0.596,p=0.738),  time:14.342, tt:415.909\n",
      "Ep:29, loss:0.00014, loss_test:0.12819, lr:8.35e-03, fs:0.65556 (r=0.596,p=0.728),  time:14.360, tt:430.788\n",
      "Ep:30, loss:0.00014, loss_test:0.12844, lr:8.26e-03, fs:0.66292 (r=0.596,p=0.747),  time:14.370, tt:445.473\n",
      "Ep:31, loss:0.00013, loss_test:0.12630, lr:8.18e-03, fs:0.66292 (r=0.596,p=0.747),  time:14.397, tt:460.709\n",
      "Ep:32, loss:0.00013, loss_test:0.12694, lr:8.10e-03, fs:0.67429 (r=0.596,p=0.776),  time:14.414, tt:475.670\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00013, loss_test:0.12719, lr:8.10e-03, fs:0.67429 (r=0.596,p=0.776),  time:14.428, tt:490.565\n",
      "Ep:34, loss:0.00013, loss_test:0.12488, lr:8.10e-03, fs:0.67045 (r=0.596,p=0.766),  time:14.445, tt:505.564\n",
      "Ep:35, loss:0.00012, loss_test:0.12449, lr:8.10e-03, fs:0.68208 (r=0.596,p=0.797),  time:14.451, tt:520.236\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00012, loss_test:0.12366, lr:8.10e-03, fs:0.68605 (r=0.596,p=0.808),  time:14.465, tt:535.209\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00012, loss_test:0.12394, lr:8.10e-03, fs:0.68208 (r=0.596,p=0.797),  time:14.475, tt:550.045\n",
      "Ep:38, loss:0.00011, loss_test:0.12320, lr:8.10e-03, fs:0.69006 (r=0.596,p=0.819),  time:14.485, tt:564.932\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00011, loss_test:0.12323, lr:8.10e-03, fs:0.68208 (r=0.596,p=0.797),  time:14.489, tt:579.571\n",
      "Ep:40, loss:0.00011, loss_test:0.12158, lr:8.10e-03, fs:0.69006 (r=0.596,p=0.819),  time:14.492, tt:594.175\n",
      "Ep:41, loss:0.00011, loss_test:0.12157, lr:8.10e-03, fs:0.69412 (r=0.596,p=0.831),  time:14.492, tt:608.669\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00010, loss_test:0.12149, lr:8.10e-03, fs:0.69412 (r=0.596,p=0.831),  time:14.497, tt:623.364\n",
      "Ep:43, loss:0.00010, loss_test:0.11953, lr:8.10e-03, fs:0.69822 (r=0.596,p=0.843),  time:14.497, tt:637.848\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00010, loss_test:0.12073, lr:8.10e-03, fs:0.70238 (r=0.596,p=0.855),  time:14.499, tt:652.452\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00010, loss_test:0.11841, lr:8.10e-03, fs:0.69412 (r=0.596,p=0.831),  time:14.503, tt:667.128\n",
      "Ep:46, loss:0.00010, loss_test:0.11980, lr:8.10e-03, fs:0.70238 (r=0.596,p=0.855),  time:14.507, tt:681.830\n",
      "Ep:47, loss:0.00009, loss_test:0.11731, lr:8.10e-03, fs:0.69822 (r=0.596,p=0.843),  time:14.511, tt:696.529\n",
      "Ep:48, loss:0.00009, loss_test:0.11982, lr:8.10e-03, fs:0.70659 (r=0.596,p=0.868),  time:14.515, tt:711.223\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00009, loss_test:0.11615, lr:8.10e-03, fs:0.70588 (r=0.606,p=0.845),  time:14.516, tt:725.802\n",
      "Ep:50, loss:0.00009, loss_test:0.11765, lr:8.10e-03, fs:0.70659 (r=0.596,p=0.868),  time:14.517, tt:740.382\n",
      "Ep:51, loss:0.00009, loss_test:0.11722, lr:8.10e-03, fs:0.70175 (r=0.606,p=0.833),  time:14.522, tt:755.122\n",
      "Ep:52, loss:0.00008, loss_test:0.11680, lr:8.10e-03, fs:0.70659 (r=0.596,p=0.868),  time:14.526, tt:769.903\n",
      "Ep:53, loss:0.00008, loss_test:0.11741, lr:8.10e-03, fs:0.70659 (r=0.596,p=0.868),  time:14.526, tt:784.408\n",
      "Ep:54, loss:0.00008, loss_test:0.11614, lr:8.10e-03, fs:0.71429 (r=0.606,p=0.870),  time:14.529, tt:799.074\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00008, loss_test:0.11765, lr:8.10e-03, fs:0.71084 (r=0.596,p=0.881),  time:14.529, tt:813.610\n",
      "Ep:56, loss:0.00008, loss_test:0.11367, lr:8.10e-03, fs:0.72941 (r=0.626,p=0.873),  time:14.531, tt:828.248\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00008, loss_test:0.11603, lr:8.10e-03, fs:0.71856 (r=0.606,p=0.882),  time:14.536, tt:843.102\n",
      "Ep:58, loss:0.00008, loss_test:0.11440, lr:8.10e-03, fs:0.71429 (r=0.606,p=0.870),  time:14.537, tt:857.694\n",
      "Ep:59, loss:0.00007, loss_test:0.11522, lr:8.10e-03, fs:0.73054 (r=0.616,p=0.897),  time:14.542, tt:872.530\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00007, loss_test:0.11422, lr:8.10e-03, fs:0.72289 (r=0.606,p=0.896),  time:14.542, tt:887.088\n",
      "Ep:61, loss:0.00007, loss_test:0.11547, lr:8.10e-03, fs:0.73054 (r=0.616,p=0.897),  time:14.546, tt:901.854\n",
      "Ep:62, loss:0.00007, loss_test:0.11480, lr:8.10e-03, fs:0.72727 (r=0.606,p=0.909),  time:14.550, tt:916.619\n",
      "Ep:63, loss:0.00007, loss_test:0.11337, lr:8.10e-03, fs:0.73054 (r=0.616,p=0.897),  time:14.550, tt:931.194\n",
      "Ep:64, loss:0.00007, loss_test:0.11403, lr:8.10e-03, fs:0.73494 (r=0.616,p=0.910),  time:14.553, tt:945.939\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:65, loss:0.00007, loss_test:0.11212, lr:8.10e-03, fs:0.73054 (r=0.616,p=0.897),  time:14.553, tt:960.507\n",
      "Ep:66, loss:0.00006, loss_test:0.11498, lr:8.10e-03, fs:0.72727 (r=0.606,p=0.909),  time:14.558, tt:975.404\n",
      "Ep:67, loss:0.00006, loss_test:0.11244, lr:8.10e-03, fs:0.73054 (r=0.616,p=0.897),  time:14.562, tt:990.226\n",
      "Ep:68, loss:0.00006, loss_test:0.11359, lr:8.10e-03, fs:0.72289 (r=0.606,p=0.896),  time:14.564, tt:1004.904\n",
      "Ep:69, loss:0.00006, loss_test:0.11368, lr:8.10e-03, fs:0.72727 (r=0.606,p=0.909),  time:14.563, tt:1019.445\n",
      "Ep:70, loss:0.00006, loss_test:0.11392, lr:8.10e-03, fs:0.73171 (r=0.606,p=0.923),  time:14.565, tt:1034.145\n",
      "Ep:71, loss:0.00006, loss_test:0.11352, lr:8.10e-03, fs:0.72727 (r=0.606,p=0.909),  time:14.569, tt:1048.949\n",
      "Ep:72, loss:0.00006, loss_test:0.11231, lr:8.10e-03, fs:0.73171 (r=0.606,p=0.923),  time:14.573, tt:1063.852\n",
      "Ep:73, loss:0.00005, loss_test:0.11288, lr:8.10e-03, fs:0.72727 (r=0.606,p=0.909),  time:14.574, tt:1078.511\n",
      "Ep:74, loss:0.00005, loss_test:0.11361, lr:8.10e-03, fs:0.73171 (r=0.606,p=0.923),  time:14.577, tt:1093.250\n",
      "Ep:75, loss:0.00005, loss_test:0.11131, lr:8.10e-03, fs:0.72727 (r=0.606,p=0.909),  time:14.575, tt:1107.682\n",
      "Ep:76, loss:0.00005, loss_test:0.11266, lr:8.02e-03, fs:0.74390 (r=0.616,p=0.938),  time:14.627, tt:1126.253\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00005, loss_test:0.11370, lr:8.02e-03, fs:0.73171 (r=0.606,p=0.923),  time:14.625, tt:1140.769\n",
      "Ep:78, loss:0.00005, loss_test:0.11177, lr:8.02e-03, fs:0.73620 (r=0.606,p=0.938),  time:14.627, tt:1155.520\n",
      "Ep:79, loss:0.00005, loss_test:0.11143, lr:8.02e-03, fs:0.73171 (r=0.606,p=0.923),  time:14.628, tt:1170.260\n",
      "Ep:80, loss:0.00005, loss_test:0.11167, lr:8.02e-03, fs:0.75152 (r=0.626,p=0.939),  time:14.627, tt:1184.816\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00005, loss_test:0.11230, lr:8.02e-03, fs:0.73620 (r=0.606,p=0.938),  time:14.631, tt:1199.744\n",
      "Ep:82, loss:0.00004, loss_test:0.11008, lr:8.02e-03, fs:0.74074 (r=0.606,p=0.952),  time:14.629, tt:1214.208\n",
      "Ep:83, loss:0.00004, loss_test:0.11320, lr:8.02e-03, fs:0.75152 (r=0.626,p=0.939),  time:14.632, tt:1229.071\n",
      "Ep:84, loss:0.00004, loss_test:0.11105, lr:8.02e-03, fs:0.74847 (r=0.616,p=0.953),  time:14.634, tt:1243.867\n",
      "Ep:85, loss:0.00004, loss_test:0.11182, lr:8.02e-03, fs:0.74847 (r=0.616,p=0.953),  time:14.638, tt:1258.889\n",
      "Ep:86, loss:0.00004, loss_test:0.11187, lr:8.02e-03, fs:0.74847 (r=0.616,p=0.953),  time:14.641, tt:1273.737\n",
      "Ep:87, loss:0.00004, loss_test:0.11106, lr:8.02e-03, fs:0.75610 (r=0.626,p=0.954),  time:14.639, tt:1288.268\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00004, loss_test:0.10987, lr:8.02e-03, fs:0.76074 (r=0.626,p=0.969),  time:14.641, tt:1303.043\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00004, loss_test:0.11031, lr:8.02e-03, fs:0.75610 (r=0.626,p=0.954),  time:14.640, tt:1317.610\n",
      "Ep:90, loss:0.00004, loss_test:0.11162, lr:8.02e-03, fs:0.75610 (r=0.626,p=0.954),  time:14.642, tt:1332.387\n",
      "Ep:91, loss:0.00004, loss_test:0.11015, lr:8.02e-03, fs:0.75610 (r=0.626,p=0.954),  time:14.642, tt:1347.079\n",
      "Ep:92, loss:0.00003, loss_test:0.10929, lr:8.02e-03, fs:0.75610 (r=0.626,p=0.954),  time:14.643, tt:1361.798\n",
      "Ep:93, loss:0.00003, loss_test:0.11124, lr:8.02e-03, fs:0.75610 (r=0.626,p=0.954),  time:14.644, tt:1376.539\n",
      "Ep:94, loss:0.00003, loss_test:0.10984, lr:8.02e-03, fs:0.75610 (r=0.626,p=0.954),  time:14.645, tt:1391.282\n",
      "Ep:95, loss:0.00003, loss_test:0.10991, lr:8.02e-03, fs:0.75610 (r=0.626,p=0.954),  time:14.646, tt:1406.054\n",
      "Ep:96, loss:0.00003, loss_test:0.11037, lr:8.02e-03, fs:0.75610 (r=0.626,p=0.954),  time:14.647, tt:1420.751\n",
      "Ep:97, loss:0.00003, loss_test:0.10952, lr:8.02e-03, fs:0.75610 (r=0.626,p=0.954),  time:14.646, tt:1435.335\n",
      "Ep:98, loss:0.00003, loss_test:0.10913, lr:8.02e-03, fs:0.75610 (r=0.626,p=0.954),  time:14.646, tt:1449.967\n",
      "Ep:99, loss:0.00003, loss_test:0.11015, lr:8.02e-03, fs:0.76074 (r=0.626,p=0.969),  time:14.646, tt:1464.635\n",
      "Ep:100, loss:0.00003, loss_test:0.11013, lr:7.94e-03, fs:0.75610 (r=0.626,p=0.954),  time:14.648, tt:1479.457\n",
      "Ep:101, loss:0.00003, loss_test:0.11035, lr:7.86e-03, fs:0.76074 (r=0.626,p=0.969),  time:14.648, tt:1494.139\n",
      "Ep:102, loss:0.00003, loss_test:0.11040, lr:7.78e-03, fs:0.76074 (r=0.626,p=0.969),  time:14.650, tt:1508.907\n",
      "Ep:103, loss:0.00003, loss_test:0.10891, lr:7.70e-03, fs:0.76074 (r=0.626,p=0.969),  time:14.650, tt:1523.642\n",
      "Ep:104, loss:0.00003, loss_test:0.10964, lr:7.62e-03, fs:0.76074 (r=0.626,p=0.969),  time:14.649, tt:1538.110\n",
      "Ep:105, loss:0.00003, loss_test:0.10917, lr:7.55e-03, fs:0.76074 (r=0.626,p=0.969),  time:14.648, tt:1552.712\n",
      "Ep:106, loss:0.00002, loss_test:0.11162, lr:7.47e-03, fs:0.76074 (r=0.626,p=0.969),  time:14.650, tt:1567.567\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=3,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 2048: \n",
      "Ep:0, loss:0.00014, loss_test:0.14520, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.256, tt:26.256\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00014, loss_test:0.14456, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.226, tt:58.452\n",
      "Ep:2, loss:0.00014, loss_test:0.14350, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.257, tt:90.771\n",
      "Ep:3, loss:0.00014, loss_test:0.14185, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.144, tt:120.575\n",
      "Ep:4, loss:0.00014, loss_test:0.13927, lr:1.00e-02, fs:0.65306 (r=0.970,p=0.492),  time:30.199, tt:150.993\n",
      "Ep:5, loss:0.00013, loss_test:0.13508, lr:1.00e-02, fs:0.64111 (r=0.929,p=0.489),  time:30.594, tt:183.567\n",
      "Ep:6, loss:0.00013, loss_test:0.12795, lr:1.00e-02, fs:0.65414 (r=0.879,p=0.521),  time:30.829, tt:215.801\n",
      "Ep:7, loss:0.00012, loss_test:0.11924, lr:1.00e-02, fs:0.66079 (r=0.758,p=0.586),  time:30.905, tt:247.237\n",
      "Ep:8, loss:0.00011, loss_test:0.11499, lr:1.00e-02, fs:0.66986 (r=0.707,p=0.636),  time:31.037, tt:279.333\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00011, loss_test:0.11216, lr:1.00e-02, fs:0.69159 (r=0.747,p=0.643),  time:31.163, tt:311.630\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00011, loss_test:0.11096, lr:1.00e-02, fs:0.70320 (r=0.778,p=0.642),  time:31.404, tt:345.439\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00011, loss_test:0.10789, lr:1.00e-02, fs:0.69767 (r=0.758,p=0.647),  time:31.518, tt:378.220\n",
      "Ep:12, loss:0.00010, loss_test:0.10447, lr:1.00e-02, fs:0.69951 (r=0.717,p=0.683),  time:31.597, tt:410.759\n",
      "Ep:13, loss:0.00010, loss_test:0.10308, lr:1.00e-02, fs:0.70051 (r=0.697,p=0.704),  time:31.826, tt:445.558\n",
      "Ep:14, loss:0.00010, loss_test:0.10205, lr:1.00e-02, fs:0.68657 (r=0.697,p=0.676),  time:31.810, tt:477.153\n",
      "Ep:15, loss:0.00009, loss_test:0.10102, lr:1.00e-02, fs:0.67327 (r=0.687,p=0.660),  time:31.809, tt:508.950\n",
      "Ep:16, loss:0.00009, loss_test:0.10007, lr:1.00e-02, fs:0.69000 (r=0.697,p=0.683),  time:31.902, tt:542.334\n",
      "Ep:17, loss:0.00009, loss_test:0.09943, lr:1.00e-02, fs:0.71717 (r=0.717,p=0.717),  time:31.939, tt:574.898\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00008, loss_test:0.09851, lr:1.00e-02, fs:0.72115 (r=0.758,p=0.688),  time:32.005, tt:608.103\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00008, loss_test:0.09748, lr:1.00e-02, fs:0.72906 (r=0.747,p=0.712),  time:31.981, tt:639.628\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00008, loss_test:0.09665, lr:1.00e-02, fs:0.72727 (r=0.727,p=0.727),  time:31.995, tt:671.900\n",
      "Ep:21, loss:0.00008, loss_test:0.09567, lr:1.00e-02, fs:0.73632 (r=0.747,p=0.725),  time:32.007, tt:704.148\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00008, loss_test:0.09490, lr:1.00e-02, fs:0.74510 (r=0.768,p=0.724),  time:32.123, tt:738.818\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00007, loss_test:0.09459, lr:1.00e-02, fs:0.73737 (r=0.737,p=0.737),  time:32.132, tt:771.167\n",
      "Ep:24, loss:0.00007, loss_test:0.09331, lr:1.00e-02, fs:0.74510 (r=0.768,p=0.724),  time:32.152, tt:803.807\n",
      "Ep:25, loss:0.00007, loss_test:0.09259, lr:1.00e-02, fs:0.73367 (r=0.737,p=0.730),  time:32.166, tt:836.316\n",
      "Ep:26, loss:0.00007, loss_test:0.09230, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:32.208, tt:869.615\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00007, loss_test:0.09171, lr:1.00e-02, fs:0.74627 (r=0.758,p=0.735),  time:32.203, tt:901.686\n",
      "Ep:28, loss:0.00006, loss_test:0.09169, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:32.222, tt:934.442\n",
      "Ep:29, loss:0.00006, loss_test:0.09044, lr:1.00e-02, fs:0.75758 (r=0.758,p=0.758),  time:32.207, tt:966.222\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00006, loss_test:0.08984, lr:1.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:32.187, tt:997.796\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00006, loss_test:0.08976, lr:1.00e-02, fs:0.76289 (r=0.747,p=0.779),  time:32.197, tt:1030.312\n",
      "Ep:32, loss:0.00006, loss_test:0.08901, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:32.233, tt:1063.683\n",
      "Ep:33, loss:0.00006, loss_test:0.08933, lr:1.00e-02, fs:0.75897 (r=0.747,p=0.771),  time:32.245, tt:1096.346\n",
      "Ep:34, loss:0.00006, loss_test:0.08874, lr:1.00e-02, fs:0.75897 (r=0.747,p=0.771),  time:32.269, tt:1129.401\n",
      "Ep:35, loss:0.00005, loss_test:0.08849, lr:1.00e-02, fs:0.75648 (r=0.737,p=0.777),  time:32.294, tt:1162.593\n",
      "Ep:36, loss:0.00005, loss_test:0.08809, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:32.328, tt:1196.132\n",
      "Ep:37, loss:0.00005, loss_test:0.08793, lr:1.00e-02, fs:0.74611 (r=0.727,p=0.766),  time:32.321, tt:1228.195\n",
      "Ep:38, loss:0.00005, loss_test:0.08793, lr:1.00e-02, fs:0.75393 (r=0.727,p=0.783),  time:32.318, tt:1260.397\n",
      "Ep:39, loss:0.00005, loss_test:0.08689, lr:1.00e-02, fs:0.74490 (r=0.737,p=0.753),  time:32.320, tt:1292.813\n",
      "Ep:40, loss:0.00005, loss_test:0.08703, lr:1.00e-02, fs:0.75000 (r=0.727,p=0.774),  time:32.226, tt:1321.256\n",
      "Ep:41, loss:0.00005, loss_test:0.08614, lr:1.00e-02, fs:0.74872 (r=0.737,p=0.760),  time:32.244, tt:1354.267\n",
      "Ep:42, loss:0.00005, loss_test:0.08648, lr:9.90e-03, fs:0.75132 (r=0.717,p=0.789),  time:32.284, tt:1388.218\n",
      "Ep:43, loss:0.00004, loss_test:0.08461, lr:9.80e-03, fs:0.75510 (r=0.747,p=0.763),  time:32.298, tt:1421.110\n",
      "Ep:44, loss:0.00004, loss_test:0.08521, lr:9.70e-03, fs:0.74737 (r=0.717,p=0.780),  time:32.294, tt:1453.229\n",
      "Ep:45, loss:0.00004, loss_test:0.08394, lr:9.61e-03, fs:0.75127 (r=0.747,p=0.755),  time:32.313, tt:1486.402\n",
      "Ep:46, loss:0.00004, loss_test:0.08420, lr:9.51e-03, fs:0.75132 (r=0.717,p=0.789),  time:32.333, tt:1519.649\n",
      "Ep:47, loss:0.00004, loss_test:0.08335, lr:9.41e-03, fs:0.75510 (r=0.747,p=0.763),  time:32.382, tt:1554.317\n",
      "Ep:48, loss:0.00004, loss_test:0.08388, lr:9.32e-03, fs:0.75532 (r=0.717,p=0.798),  time:32.408, tt:1587.968\n",
      "Ep:49, loss:0.00004, loss_test:0.08267, lr:9.23e-03, fs:0.76440 (r=0.737,p=0.793),  time:32.434, tt:1621.715\n",
      "Ep:50, loss:0.00004, loss_test:0.08301, lr:9.14e-03, fs:0.75789 (r=0.727,p=0.791),  time:32.434, tt:1654.154\n",
      "Ep:51, loss:0.00004, loss_test:0.08289, lr:9.04e-03, fs:0.76190 (r=0.727,p=0.800),  time:32.431, tt:1686.425\n",
      "Ep:52, loss:0.00004, loss_test:0.08116, lr:8.95e-03, fs:0.77083 (r=0.747,p=0.796),  time:32.436, tt:1719.083\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00004, loss_test:0.08255, lr:8.95e-03, fs:0.76344 (r=0.717,p=0.816),  time:32.482, tt:1754.020\n",
      "Ep:54, loss:0.00004, loss_test:0.08024, lr:8.95e-03, fs:0.77487 (r=0.747,p=0.804),  time:32.493, tt:1787.120\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00003, loss_test:0.08056, lr:8.95e-03, fs:0.76596 (r=0.727,p=0.809),  time:32.494, tt:1819.688\n",
      "Ep:56, loss:0.00003, loss_test:0.08002, lr:8.95e-03, fs:0.76596 (r=0.727,p=0.809),  time:32.532, tt:1854.320\n",
      "Ep:57, loss:0.00003, loss_test:0.08045, lr:8.95e-03, fs:0.76596 (r=0.727,p=0.809),  time:32.532, tt:1886.855\n",
      "Ep:58, loss:0.00003, loss_test:0.08036, lr:8.95e-03, fs:0.75000 (r=0.697,p=0.812),  time:32.532, tt:1919.382\n",
      "Ep:59, loss:0.00003, loss_test:0.07938, lr:8.95e-03, fs:0.76596 (r=0.727,p=0.809),  time:32.528, tt:1951.685\n",
      "Ep:60, loss:0.00003, loss_test:0.07902, lr:8.95e-03, fs:0.77005 (r=0.727,p=0.818),  time:32.549, tt:1985.508\n",
      "Ep:61, loss:0.00003, loss_test:0.08041, lr:8.95e-03, fs:0.76243 (r=0.697,p=0.841),  time:32.563, tt:2018.892\n",
      "Ep:62, loss:0.00003, loss_test:0.07859, lr:8.95e-03, fs:0.75676 (r=0.707,p=0.814),  time:32.574, tt:2052.132\n",
      "Ep:63, loss:0.00003, loss_test:0.07844, lr:8.95e-03, fs:0.75000 (r=0.697,p=0.812),  time:32.593, tt:2085.927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00003, loss_test:0.07930, lr:8.95e-03, fs:0.75978 (r=0.687,p=0.850),  time:32.589, tt:2118.314\n",
      "Ep:65, loss:0.00003, loss_test:0.07811, lr:8.95e-03, fs:0.76503 (r=0.707,p=0.833),  time:32.610, tt:2152.288\n",
      "Ep:66, loss:0.00003, loss_test:0.07848, lr:8.86e-03, fs:0.75978 (r=0.687,p=0.850),  time:32.602, tt:2184.328\n",
      "Ep:67, loss:0.00003, loss_test:0.07828, lr:8.78e-03, fs:0.75978 (r=0.687,p=0.850),  time:32.584, tt:2215.703\n",
      "Ep:68, loss:0.00003, loss_test:0.07793, lr:8.69e-03, fs:0.76667 (r=0.697,p=0.852),  time:32.570, tt:2247.318\n",
      "Ep:69, loss:0.00003, loss_test:0.07986, lr:8.60e-03, fs:0.77011 (r=0.677,p=0.893),  time:32.562, tt:2279.374\n",
      "Ep:70, loss:0.00003, loss_test:0.07730, lr:8.51e-03, fs:0.76667 (r=0.697,p=0.852),  time:32.556, tt:2311.481\n",
      "Ep:71, loss:0.00003, loss_test:0.07938, lr:8.43e-03, fs:0.76744 (r=0.667,p=0.904),  time:32.554, tt:2343.891\n",
      "Ep:72, loss:0.00002, loss_test:0.07827, lr:8.35e-03, fs:0.76571 (r=0.677,p=0.882),  time:32.548, tt:2375.986\n",
      "Ep:73, loss:0.00002, loss_test:0.07789, lr:8.26e-03, fs:0.77528 (r=0.697,p=0.873),  time:32.558, tt:2409.317\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00002, loss_test:0.07834, lr:8.26e-03, fs:0.77457 (r=0.677,p=0.905),  time:32.560, tt:2441.995\n",
      "Ep:75, loss:0.00002, loss_test:0.07791, lr:8.26e-03, fs:0.77457 (r=0.677,p=0.905),  time:32.573, tt:2475.562\n",
      "Ep:76, loss:0.00002, loss_test:0.07847, lr:8.26e-03, fs:0.77457 (r=0.677,p=0.905),  time:32.568, tt:2507.705\n",
      "Ep:77, loss:0.00002, loss_test:0.07864, lr:8.26e-03, fs:0.77457 (r=0.677,p=0.905),  time:32.559, tt:2539.609\n",
      "Ep:78, loss:0.00002, loss_test:0.07803, lr:8.26e-03, fs:0.77457 (r=0.677,p=0.905),  time:32.561, tt:2572.307\n",
      "Ep:79, loss:0.00002, loss_test:0.07996, lr:8.26e-03, fs:0.77381 (r=0.657,p=0.942),  time:32.561, tt:2604.847\n",
      "Ep:80, loss:0.00002, loss_test:0.07639, lr:8.26e-03, fs:0.77273 (r=0.687,p=0.883),  time:32.566, tt:2637.871\n",
      "Ep:81, loss:0.00002, loss_test:0.08041, lr:8.26e-03, fs:0.78313 (r=0.657,p=0.970),  time:32.576, tt:2671.250\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00002, loss_test:0.07809, lr:8.26e-03, fs:0.77907 (r=0.677,p=0.918),  time:32.588, tt:2704.832\n",
      "Ep:83, loss:0.00002, loss_test:0.07848, lr:8.26e-03, fs:0.77647 (r=0.667,p=0.930),  time:32.569, tt:2735.831\n",
      "Ep:84, loss:0.00002, loss_test:0.07944, lr:8.26e-03, fs:0.79290 (r=0.677,p=0.957),  time:32.555, tt:2767.154\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00002, loss_test:0.07769, lr:8.26e-03, fs:0.77193 (r=0.667,p=0.917),  time:32.562, tt:2800.366\n",
      "Ep:86, loss:0.00002, loss_test:0.07935, lr:8.26e-03, fs:0.77844 (r=0.657,p=0.956),  time:32.544, tt:2831.357\n",
      "Ep:87, loss:0.00002, loss_test:0.07793, lr:8.26e-03, fs:0.77647 (r=0.667,p=0.930),  time:32.536, tt:2863.177\n",
      "Ep:88, loss:0.00002, loss_test:0.07909, lr:8.26e-03, fs:0.78571 (r=0.667,p=0.957),  time:32.543, tt:2896.368\n",
      "Ep:89, loss:0.00002, loss_test:0.07745, lr:8.26e-03, fs:0.78571 (r=0.667,p=0.957),  time:32.541, tt:2928.676\n",
      "Ep:90, loss:0.00002, loss_test:0.07875, lr:8.26e-03, fs:0.78788 (r=0.657,p=0.985),  time:32.544, tt:2961.491\n",
      "Ep:91, loss:0.00002, loss_test:0.07767, lr:8.26e-03, fs:0.79042 (r=0.667,p=0.971),  time:32.537, tt:2993.434\n",
      "Ep:92, loss:0.00002, loss_test:0.07856, lr:8.26e-03, fs:0.78788 (r=0.657,p=0.985),  time:32.519, tt:3024.248\n",
      "Ep:93, loss:0.00002, loss_test:0.07974, lr:8.26e-03, fs:0.78788 (r=0.657,p=0.985),  time:32.519, tt:3056.820\n",
      "Ep:94, loss:0.00002, loss_test:0.07858, lr:8.26e-03, fs:0.78788 (r=0.657,p=0.985),  time:32.519, tt:3089.326\n",
      "Ep:95, loss:0.00002, loss_test:0.07886, lr:8.26e-03, fs:0.78788 (r=0.657,p=0.985),  time:32.511, tt:3121.101\n",
      "Ep:96, loss:0.00002, loss_test:0.07770, lr:8.18e-03, fs:0.79518 (r=0.667,p=0.985),  time:32.519, tt:3154.320\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00002, loss_test:0.08033, lr:8.18e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.526, tt:3187.530\n",
      "Ep:98, loss:0.00002, loss_test:0.07821, lr:8.18e-03, fs:0.79518 (r=0.667,p=0.985),  time:32.525, tt:3219.926\n",
      "Ep:99, loss:0.00001, loss_test:0.07862, lr:8.18e-03, fs:0.79518 (r=0.667,p=0.985),  time:32.534, tt:3253.402\n",
      "Ep:100, loss:0.00001, loss_test:0.08069, lr:8.18e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.517, tt:3284.229\n",
      "Ep:101, loss:0.00001, loss_test:0.07742, lr:8.18e-03, fs:0.79518 (r=0.667,p=0.985),  time:32.514, tt:3316.476\n",
      "Ep:102, loss:0.00001, loss_test:0.08116, lr:8.18e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.528, tt:3350.399\n",
      "Ep:103, loss:0.00001, loss_test:0.07812, lr:8.18e-03, fs:0.79518 (r=0.667,p=0.985),  time:32.540, tt:3384.110\n",
      "Ep:104, loss:0.00001, loss_test:0.08054, lr:8.18e-03, fs:0.78788 (r=0.657,p=0.985),  time:32.545, tt:3417.174\n",
      "Ep:105, loss:0.00001, loss_test:0.08076, lr:8.18e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.565, tt:3451.916\n",
      "Ep:106, loss:0.00001, loss_test:0.07746, lr:8.18e-03, fs:0.79518 (r=0.667,p=0.985),  time:32.576, tt:3485.646\n",
      "Ep:107, loss:0.00001, loss_test:0.08167, lr:8.18e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.566, tt:3517.085\n",
      "Ep:108, loss:0.00001, loss_test:0.07768, lr:8.10e-03, fs:0.79518 (r=0.667,p=0.985),  time:32.560, tt:3549.045\n",
      "Ep:109, loss:0.00001, loss_test:0.07996, lr:8.02e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.562, tt:3581.844\n",
      "Ep:110, loss:0.00001, loss_test:0.08021, lr:7.94e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.564, tt:3614.620\n",
      "Ep:111, loss:0.00001, loss_test:0.07803, lr:7.86e-03, fs:0.79518 (r=0.667,p=0.985),  time:32.560, tt:3646.691\n",
      "Ep:112, loss:0.00001, loss_test:0.08162, lr:7.78e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.555, tt:3678.710\n",
      "Ep:113, loss:0.00001, loss_test:0.07897, lr:7.70e-03, fs:0.80000 (r=0.667,p=1.000),  time:32.550, tt:3710.660\n",
      "##########Best model found so far##########\n",
      "Ep:114, loss:0.00001, loss_test:0.08071, lr:7.70e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.546, tt:3742.804\n",
      "Ep:115, loss:0.00001, loss_test:0.07996, lr:7.70e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.552, tt:3775.992\n",
      "Ep:116, loss:0.00001, loss_test:0.07972, lr:7.70e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.563, tt:3809.852\n",
      "Ep:117, loss:0.00001, loss_test:0.08074, lr:7.70e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.558, tt:3841.810\n",
      "Ep:118, loss:0.00001, loss_test:0.07913, lr:7.70e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.564, tt:3875.168\n",
      "Ep:119, loss:0.00001, loss_test:0.08220, lr:7.70e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.572, tt:3908.672\n",
      "Ep:120, loss:0.00001, loss_test:0.07947, lr:7.70e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.575, tt:3941.539\n",
      "Ep:121, loss:0.00001, loss_test:0.08089, lr:7.70e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.588, tt:3975.791\n",
      "Ep:122, loss:0.00001, loss_test:0.08100, lr:7.70e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.592, tt:4008.778\n",
      "Ep:123, loss:0.00001, loss_test:0.08088, lr:7.70e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.595, tt:4041.774\n",
      "Ep:124, loss:0.00001, loss_test:0.08136, lr:7.70e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.600, tt:4075.051\n",
      "Ep:125, loss:0.00001, loss_test:0.08059, lr:7.62e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.598, tt:4107.382\n",
      "Ep:126, loss:0.00001, loss_test:0.08240, lr:7.55e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.592, tt:4139.214\n",
      "Ep:127, loss:0.00001, loss_test:0.08067, lr:7.47e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.592, tt:4171.775\n",
      "Ep:128, loss:0.00001, loss_test:0.08200, lr:7.40e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.594, tt:4204.614\n",
      "Ep:129, loss:0.00001, loss_test:0.08062, lr:7.32e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.601, tt:4238.096\n",
      "Ep:130, loss:0.00001, loss_test:0.08214, lr:7.25e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.631, tt:4274.719\n",
      "Ep:131, loss:0.00001, loss_test:0.08002, lr:7.18e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.624, tt:4306.413\n",
      "Ep:132, loss:0.00001, loss_test:0.08306, lr:7.11e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.625, tt:4339.120\n",
      "Ep:133, loss:0.00001, loss_test:0.08064, lr:7.03e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.618, tt:4370.823\n",
      "Ep:134, loss:0.00001, loss_test:0.08101, lr:6.96e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.608, tt:4402.086\n",
      "Ep:135, loss:0.00001, loss_test:0.08210, lr:6.89e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.599, tt:4433.517\n",
      "Ep:136, loss:0.00001, loss_test:0.08079, lr:6.83e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.601, tt:4466.299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00001, loss_test:0.08248, lr:6.76e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.594, tt:4498.004\n",
      "Ep:138, loss:0.00001, loss_test:0.08152, lr:6.69e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.579, tt:4528.488\n",
      "Ep:139, loss:0.00001, loss_test:0.08105, lr:6.62e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.564, tt:4558.995\n",
      "Ep:140, loss:0.00001, loss_test:0.08114, lr:6.56e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.551, tt:4589.641\n",
      "Ep:141, loss:0.00001, loss_test:0.08217, lr:6.49e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.552, tt:4622.398\n",
      "Ep:142, loss:0.00001, loss_test:0.08173, lr:6.43e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.543, tt:4653.645\n",
      "Ep:143, loss:0.00001, loss_test:0.08225, lr:6.36e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.544, tt:4686.288\n",
      "Ep:144, loss:0.00001, loss_test:0.08352, lr:6.30e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.546, tt:4719.146\n",
      "Ep:145, loss:0.00001, loss_test:0.08103, lr:6.24e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.539, tt:4750.633\n",
      "Ep:146, loss:0.00001, loss_test:0.08339, lr:6.17e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.536, tt:4782.859\n",
      "Ep:147, loss:0.00001, loss_test:0.08159, lr:6.11e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.538, tt:4815.643\n",
      "Ep:148, loss:0.00001, loss_test:0.08284, lr:6.05e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.539, tt:4848.298\n",
      "Ep:149, loss:0.00001, loss_test:0.08272, lr:5.99e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.544, tt:4881.565\n",
      "Ep:150, loss:0.00001, loss_test:0.08233, lr:5.93e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.543, tt:4914.040\n",
      "Ep:151, loss:0.00001, loss_test:0.08241, lr:5.87e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.544, tt:4946.719\n",
      "Ep:152, loss:0.00001, loss_test:0.08175, lr:5.81e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.541, tt:4978.736\n",
      "Ep:153, loss:0.00001, loss_test:0.08282, lr:5.75e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.541, tt:5011.279\n",
      "Ep:154, loss:0.00001, loss_test:0.08188, lr:5.70e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.543, tt:5044.098\n",
      "Ep:155, loss:0.00001, loss_test:0.08276, lr:5.64e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.535, tt:5075.474\n",
      "Ep:156, loss:0.00001, loss_test:0.08255, lr:5.58e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.530, tt:5107.181\n",
      "Ep:157, loss:0.00001, loss_test:0.08256, lr:5.53e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.532, tt:5140.079\n",
      "Ep:158, loss:0.00001, loss_test:0.08245, lr:5.47e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.527, tt:5171.791\n",
      "Ep:159, loss:0.00001, loss_test:0.08255, lr:5.42e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.526, tt:5204.186\n",
      "Ep:160, loss:0.00001, loss_test:0.08401, lr:5.36e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.527, tt:5236.835\n",
      "Ep:161, loss:0.00001, loss_test:0.08141, lr:5.31e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.524, tt:5268.833\n",
      "Ep:162, loss:0.00001, loss_test:0.08417, lr:5.26e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.522, tt:5301.117\n",
      "Ep:163, loss:0.00001, loss_test:0.08303, lr:5.20e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.511, tt:5331.784\n",
      "Ep:164, loss:0.00001, loss_test:0.08233, lr:5.15e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.508, tt:5363.749\n",
      "Ep:165, loss:0.00001, loss_test:0.08367, lr:5.10e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.504, tt:5395.665\n",
      "Ep:166, loss:0.00001, loss_test:0.08281, lr:5.05e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.507, tt:5428.676\n",
      "Ep:167, loss:0.00001, loss_test:0.08349, lr:5.00e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.499, tt:5459.860\n",
      "Ep:168, loss:0.00001, loss_test:0.08345, lr:4.95e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.502, tt:5492.794\n",
      "Ep:169, loss:0.00001, loss_test:0.08286, lr:4.90e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.492, tt:5523.669\n",
      "Ep:170, loss:0.00001, loss_test:0.08325, lr:4.85e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.488, tt:5555.481\n",
      "Ep:171, loss:0.00001, loss_test:0.08317, lr:4.80e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.493, tt:5588.731\n",
      "Ep:172, loss:0.00001, loss_test:0.08332, lr:4.75e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.484, tt:5619.668\n",
      "Ep:173, loss:0.00001, loss_test:0.08287, lr:4.71e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.475, tt:5650.663\n",
      "Ep:174, loss:0.00001, loss_test:0.08317, lr:4.66e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.467, tt:5681.694\n",
      "Ep:175, loss:0.00001, loss_test:0.08338, lr:4.61e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.467, tt:5714.273\n",
      "Ep:176, loss:0.00001, loss_test:0.08284, lr:4.57e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.468, tt:5746.892\n",
      "Ep:177, loss:0.00001, loss_test:0.08360, lr:4.52e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.470, tt:5779.684\n",
      "Ep:178, loss:0.00001, loss_test:0.08262, lr:4.48e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.467, tt:5811.626\n",
      "Ep:179, loss:0.00001, loss_test:0.08421, lr:4.43e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.477, tt:5845.877\n",
      "Ep:180, loss:0.00001, loss_test:0.08449, lr:4.39e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.474, tt:5877.708\n",
      "Ep:181, loss:0.00001, loss_test:0.08217, lr:4.34e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.480, tt:5911.295\n",
      "Ep:182, loss:0.00001, loss_test:0.08461, lr:4.30e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.485, tt:5944.729\n",
      "Ep:183, loss:0.00001, loss_test:0.08354, lr:4.26e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.492, tt:5978.451\n",
      "Ep:184, loss:0.00001, loss_test:0.08433, lr:4.21e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.487, tt:6010.126\n",
      "Ep:185, loss:0.00001, loss_test:0.08572, lr:4.17e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.487, tt:6042.504\n",
      "Ep:186, loss:0.00001, loss_test:0.08282, lr:4.13e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.486, tt:6074.792\n",
      "Ep:187, loss:0.00000, loss_test:0.08415, lr:4.09e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.491, tt:6108.235\n",
      "Ep:188, loss:0.00000, loss_test:0.08537, lr:4.05e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.494, tt:6141.322\n",
      "Ep:189, loss:0.00000, loss_test:0.08361, lr:4.01e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.492, tt:6173.529\n",
      "Ep:190, loss:0.00000, loss_test:0.08373, lr:3.97e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.497, tt:6207.003\n",
      "Ep:191, loss:0.00000, loss_test:0.08468, lr:3.93e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.494, tt:6238.858\n",
      "Ep:192, loss:0.00000, loss_test:0.08371, lr:3.89e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.530, tt:6278.209\n",
      "Ep:193, loss:0.00000, loss_test:0.08403, lr:3.85e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.526, tt:6309.968\n",
      "Ep:194, loss:0.00000, loss_test:0.08434, lr:3.81e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.533, tt:6343.993\n",
      "Ep:195, loss:0.00000, loss_test:0.08333, lr:3.77e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.538, tt:6377.400\n",
      "Ep:196, loss:0.00000, loss_test:0.08411, lr:3.73e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.544, tt:6411.163\n",
      "Ep:197, loss:0.00000, loss_test:0.08415, lr:3.70e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.553, tt:6445.466\n",
      "Ep:198, loss:0.00000, loss_test:0.08355, lr:3.66e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.557, tt:6478.763\n",
      "Ep:199, loss:0.00000, loss_test:0.08448, lr:3.62e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.557, tt:6511.389\n",
      "Ep:200, loss:0.00000, loss_test:0.08388, lr:3.59e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.560, tt:6544.488\n",
      "Ep:201, loss:0.00000, loss_test:0.08392, lr:3.55e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.568, tt:6578.751\n",
      "Ep:202, loss:0.00000, loss_test:0.08408, lr:3.52e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.571, tt:6611.906\n",
      "Ep:203, loss:0.00000, loss_test:0.08386, lr:3.48e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.567, tt:6643.654\n",
      "Ep:204, loss:0.00000, loss_test:0.08407, lr:3.45e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.567, tt:6676.317\n",
      "Ep:205, loss:0.00000, loss_test:0.08395, lr:3.41e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.558, tt:6706.856\n",
      "Ep:206, loss:0.00000, loss_test:0.08397, lr:3.38e-03, fs:0.79268 (r=0.657,p=1.000),  time:32.501, tt:6727.759\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=2048 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14413, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:57.300, tt:57.300\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14190, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:62.303, tt:124.606\n",
      "Ep:2, loss:0.00054, loss_test:0.13667, lr:1.00e-02, fs:0.65763 (r=0.980,p=0.495),  time:63.730, tt:191.189\n",
      "Ep:3, loss:0.00051, loss_test:0.12451, lr:1.00e-02, fs:0.64615 (r=0.848,p=0.522),  time:64.319, tt:257.277\n",
      "Ep:4, loss:0.00046, loss_test:0.11063, lr:1.00e-02, fs:0.67647 (r=0.697,p=0.657),  time:64.429, tt:322.144\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00043, loss_test:0.10769, lr:1.00e-02, fs:0.68837 (r=0.747,p=0.638),  time:64.706, tt:388.234\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00041, loss_test:0.10178, lr:1.00e-02, fs:0.68718 (r=0.677,p=0.698),  time:65.050, tt:455.352\n",
      "Ep:7, loss:0.00039, loss_test:0.10086, lr:1.00e-02, fs:0.72381 (r=0.768,p=0.685),  time:65.066, tt:520.530\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00036, loss_test:0.09917, lr:1.00e-02, fs:0.70297 (r=0.717,p=0.689),  time:65.200, tt:586.799\n",
      "Ep:9, loss:0.00034, loss_test:0.09823, lr:1.00e-02, fs:0.69307 (r=0.707,p=0.680),  time:65.174, tt:651.738\n",
      "Ep:10, loss:0.00032, loss_test:0.09531, lr:1.00e-02, fs:0.71154 (r=0.747,p=0.679),  time:65.216, tt:717.378\n",
      "Ep:11, loss:0.00031, loss_test:0.09536, lr:1.00e-02, fs:0.69430 (r=0.677,p=0.713),  time:65.292, tt:783.505\n",
      "Ep:12, loss:0.00029, loss_test:0.09402, lr:1.00e-02, fs:0.70157 (r=0.677,p=0.728),  time:65.366, tt:849.752\n",
      "Ep:13, loss:0.00028, loss_test:0.09156, lr:1.00e-02, fs:0.72642 (r=0.778,p=0.681),  time:65.481, tt:916.731\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00027, loss_test:0.09175, lr:1.00e-02, fs:0.71503 (r=0.697,p=0.734),  time:65.600, tt:983.995\n",
      "Ep:15, loss:0.00025, loss_test:0.09268, lr:1.00e-02, fs:0.72251 (r=0.697,p=0.750),  time:65.723, tt:1051.567\n",
      "Ep:16, loss:0.00024, loss_test:0.09086, lr:1.00e-02, fs:0.72727 (r=0.727,p=0.727),  time:65.784, tt:1118.327\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00023, loss_test:0.08925, lr:1.00e-02, fs:0.73632 (r=0.747,p=0.725),  time:65.803, tt:1184.456\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00022, loss_test:0.08943, lr:1.00e-02, fs:0.76190 (r=0.727,p=0.800),  time:65.796, tt:1250.129\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00021, loss_test:0.08937, lr:1.00e-02, fs:0.76757 (r=0.717,p=0.826),  time:65.802, tt:1316.035\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00020, loss_test:0.08701, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:65.829, tt:1382.417\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00019, loss_test:0.08644, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:65.894, tt:1449.658\n",
      "Ep:22, loss:0.00018, loss_test:0.08588, lr:1.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:65.810, tt:1513.621\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00017, loss_test:0.08495, lr:1.00e-02, fs:0.77487 (r=0.747,p=0.804),  time:65.699, tt:1576.774\n",
      "Ep:24, loss:0.00016, loss_test:0.08499, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:65.715, tt:1642.882\n",
      "Ep:25, loss:0.00016, loss_test:0.08485, lr:1.00e-02, fs:0.77838 (r=0.727,p=0.837),  time:65.722, tt:1708.763\n",
      "Ep:26, loss:0.00015, loss_test:0.08592, lr:1.00e-02, fs:0.77778 (r=0.707,p=0.864),  time:65.669, tt:1773.065\n",
      "Ep:27, loss:0.00014, loss_test:0.08541, lr:1.00e-02, fs:0.77528 (r=0.697,p=0.873),  time:65.588, tt:1836.461\n",
      "Ep:28, loss:0.00014, loss_test:0.08337, lr:1.00e-02, fs:0.76923 (r=0.707,p=0.843),  time:65.643, tt:1903.656\n",
      "Ep:29, loss:0.00013, loss_test:0.08517, lr:1.00e-02, fs:0.76923 (r=0.707,p=0.843),  time:65.719, tt:1971.571\n",
      "Ep:30, loss:0.00013, loss_test:0.08463, lr:1.00e-02, fs:0.78409 (r=0.697,p=0.896),  time:65.743, tt:2038.038\n",
      "Ep:31, loss:0.00012, loss_test:0.08483, lr:1.00e-02, fs:0.79775 (r=0.717,p=0.899),  time:65.723, tt:2103.139\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00011, loss_test:0.08397, lr:1.00e-02, fs:0.79096 (r=0.707,p=0.897),  time:65.729, tt:2169.051\n",
      "Ep:33, loss:0.00011, loss_test:0.08670, lr:1.00e-02, fs:0.77907 (r=0.677,p=0.918),  time:65.697, tt:2233.701\n",
      "Ep:34, loss:0.00011, loss_test:0.08592, lr:1.00e-02, fs:0.80000 (r=0.687,p=0.958),  time:65.669, tt:2298.401\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00010, loss_test:0.08321, lr:1.00e-02, fs:0.80226 (r=0.717,p=0.910),  time:65.633, tt:2362.802\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00010, loss_test:0.08282, lr:1.00e-02, fs:0.78652 (r=0.707,p=0.886),  time:65.709, tt:2431.250\n",
      "Ep:37, loss:0.00009, loss_test:0.08454, lr:1.00e-02, fs:0.80233 (r=0.697,p=0.945),  time:65.701, tt:2496.651\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.08448, lr:1.00e-02, fs:0.79532 (r=0.687,p=0.944),  time:65.768, tt:2564.943\n",
      "Ep:39, loss:0.00009, loss_test:0.08567, lr:1.00e-02, fs:0.80000 (r=0.687,p=0.958),  time:65.745, tt:2629.782\n",
      "Ep:40, loss:0.00008, loss_test:0.08591, lr:1.00e-02, fs:0.80702 (r=0.697,p=0.958),  time:65.732, tt:2694.998\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00008, loss_test:0.08303, lr:1.00e-02, fs:0.80460 (r=0.707,p=0.933),  time:65.680, tt:2758.573\n",
      "Ep:42, loss:0.00008, loss_test:0.08334, lr:1.00e-02, fs:0.79070 (r=0.687,p=0.932),  time:65.693, tt:2824.807\n",
      "Ep:43, loss:0.00007, loss_test:0.08891, lr:1.00e-02, fs:0.76543 (r=0.626,p=0.984),  time:65.740, tt:2892.573\n",
      "Ep:44, loss:0.00007, loss_test:0.08716, lr:1.00e-02, fs:0.79290 (r=0.677,p=0.957),  time:65.692, tt:2956.155\n",
      "Ep:45, loss:0.00007, loss_test:0.08676, lr:1.00e-02, fs:0.80233 (r=0.697,p=0.945),  time:65.756, tt:3024.762\n",
      "Ep:46, loss:0.00006, loss_test:0.08819, lr:1.00e-02, fs:0.79290 (r=0.677,p=0.957),  time:65.749, tt:3090.194\n",
      "Ep:47, loss:0.00006, loss_test:0.08850, lr:1.00e-02, fs:0.79290 (r=0.677,p=0.957),  time:65.853, tt:3160.957\n",
      "Ep:48, loss:0.00006, loss_test:0.08825, lr:1.00e-02, fs:0.80000 (r=0.687,p=0.958),  time:65.864, tt:3227.356\n",
      "Ep:49, loss:0.00006, loss_test:0.08765, lr:1.00e-02, fs:0.77844 (r=0.657,p=0.956),  time:65.862, tt:3293.112\n",
      "Ep:50, loss:0.00005, loss_test:0.08571, lr:1.00e-02, fs:0.78107 (r=0.667,p=0.943),  time:65.838, tt:3357.750\n",
      "Ep:51, loss:0.00005, loss_test:0.08758, lr:1.00e-02, fs:0.78313 (r=0.657,p=0.970),  time:65.912, tt:3427.413\n",
      "Ep:52, loss:0.00005, loss_test:0.09087, lr:9.90e-03, fs:0.77019 (r=0.626,p=1.000),  time:65.909, tt:3493.200\n",
      "Ep:53, loss:0.00005, loss_test:0.08732, lr:9.80e-03, fs:0.78313 (r=0.657,p=0.970),  time:65.922, tt:3559.771\n",
      "Ep:54, loss:0.00005, loss_test:0.08732, lr:9.70e-03, fs:0.78313 (r=0.657,p=0.970),  time:65.907, tt:3624.894\n",
      "Ep:55, loss:0.00004, loss_test:0.08887, lr:9.61e-03, fs:0.78313 (r=0.657,p=0.970),  time:65.889, tt:3689.780\n",
      "Ep:56, loss:0.00004, loss_test:0.08923, lr:9.51e-03, fs:0.77576 (r=0.646,p=0.970),  time:65.908, tt:3756.752\n",
      "Ep:57, loss:0.00004, loss_test:0.09211, lr:9.41e-03, fs:0.76543 (r=0.626,p=0.984),  time:65.911, tt:3822.822\n",
      "Ep:58, loss:0.00004, loss_test:0.08924, lr:9.32e-03, fs:0.77844 (r=0.657,p=0.956),  time:65.935, tt:3890.161\n",
      "Ep:59, loss:0.00004, loss_test:0.09103, lr:9.23e-03, fs:0.76829 (r=0.636,p=0.969),  time:66.007, tt:3960.439\n",
      "Ep:60, loss:0.00004, loss_test:0.09012, lr:9.14e-03, fs:0.77301 (r=0.636,p=0.984),  time:66.028, tt:4027.711\n",
      "Ep:61, loss:0.00003, loss_test:0.08796, lr:9.04e-03, fs:0.78313 (r=0.657,p=0.970),  time:66.025, tt:4093.562\n",
      "Ep:62, loss:0.00003, loss_test:0.08939, lr:8.95e-03, fs:0.71429 (r=0.556,p=1.000),  time:66.046, tt:4160.929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00003, loss_test:0.08889, lr:8.86e-03, fs:0.76829 (r=0.636,p=0.969),  time:66.073, tt:4228.701\n",
      "Ep:64, loss:0.00003, loss_test:0.09140, lr:8.78e-03, fs:0.76074 (r=0.626,p=0.969),  time:66.046, tt:4292.996\n",
      "Ep:65, loss:0.00003, loss_test:0.09077, lr:8.69e-03, fs:0.77576 (r=0.646,p=0.970),  time:66.051, tt:4359.371\n",
      "Ep:66, loss:0.00003, loss_test:0.09055, lr:8.60e-03, fs:0.76829 (r=0.636,p=0.969),  time:66.045, tt:4425.015\n",
      "Ep:67, loss:0.00003, loss_test:0.09239, lr:8.51e-03, fs:0.76829 (r=0.636,p=0.969),  time:66.039, tt:4490.647\n",
      "Ep:68, loss:0.00003, loss_test:0.09279, lr:8.43e-03, fs:0.77019 (r=0.626,p=1.000),  time:66.046, tt:4557.161\n",
      "Ep:69, loss:0.00003, loss_test:0.09063, lr:8.35e-03, fs:0.76074 (r=0.626,p=0.969),  time:66.094, tt:4626.613\n",
      "Ep:70, loss:0.00003, loss_test:0.08969, lr:8.26e-03, fs:0.76074 (r=0.626,p=0.969),  time:66.088, tt:4692.279\n",
      "Ep:71, loss:0.00003, loss_test:0.09102, lr:8.18e-03, fs:0.76543 (r=0.626,p=0.984),  time:66.126, tt:4761.045\n",
      "Ep:72, loss:0.00002, loss_test:0.09262, lr:8.10e-03, fs:0.76074 (r=0.626,p=0.969),  time:66.172, tt:4830.539\n",
      "Ep:73, loss:0.00002, loss_test:0.09172, lr:8.02e-03, fs:0.76074 (r=0.626,p=0.969),  time:66.167, tt:4896.363\n",
      "Ep:74, loss:0.00002, loss_test:0.09262, lr:7.94e-03, fs:0.74534 (r=0.606,p=0.968),  time:66.223, tt:4966.726\n",
      "Ep:75, loss:0.00002, loss_test:0.09219, lr:7.86e-03, fs:0.76543 (r=0.626,p=0.984),  time:66.249, tt:5034.958\n",
      "Ep:76, loss:0.00002, loss_test:0.09421, lr:7.78e-03, fs:0.70968 (r=0.556,p=0.982),  time:66.258, tt:5101.846\n",
      "Ep:77, loss:0.00002, loss_test:0.09027, lr:7.70e-03, fs:0.74534 (r=0.606,p=0.968),  time:66.283, tt:5170.040\n",
      "Ep:78, loss:0.00002, loss_test:0.09495, lr:7.62e-03, fs:0.71429 (r=0.556,p=1.000),  time:66.281, tt:5236.196\n",
      "Ep:79, loss:0.00002, loss_test:0.09243, lr:7.55e-03, fs:0.70513 (r=0.556,p=0.965),  time:66.310, tt:5304.838\n",
      "Ep:80, loss:0.00002, loss_test:0.09259, lr:7.47e-03, fs:0.71795 (r=0.566,p=0.982),  time:66.343, tt:5373.765\n",
      "Ep:81, loss:0.00002, loss_test:0.09539, lr:7.40e-03, fs:0.75000 (r=0.606,p=0.984),  time:66.374, tt:5442.647\n",
      "Ep:82, loss:0.00002, loss_test:0.09398, lr:7.32e-03, fs:0.75000 (r=0.606,p=0.984),  time:66.360, tt:5507.917\n",
      "Ep:83, loss:0.00002, loss_test:0.09447, lr:7.25e-03, fs:0.72611 (r=0.576,p=0.983),  time:66.373, tt:5575.368\n",
      "Ep:84, loss:0.00002, loss_test:0.09236, lr:7.18e-03, fs:0.71795 (r=0.566,p=0.982),  time:66.388, tt:5643.020\n",
      "Ep:85, loss:0.00002, loss_test:0.09444, lr:7.11e-03, fs:0.74214 (r=0.596,p=0.983),  time:66.427, tt:5712.746\n",
      "Ep:86, loss:0.00002, loss_test:0.09468, lr:7.03e-03, fs:0.69281 (r=0.535,p=0.981),  time:66.445, tt:5780.753\n",
      "Ep:87, loss:0.00002, loss_test:0.09307, lr:6.96e-03, fs:0.74214 (r=0.596,p=0.983),  time:66.456, tt:5848.094\n",
      "Ep:88, loss:0.00002, loss_test:0.09419, lr:6.89e-03, fs:0.70130 (r=0.545,p=0.982),  time:66.463, tt:5915.229\n",
      "Ep:89, loss:0.00002, loss_test:0.09413, lr:6.83e-03, fs:0.70130 (r=0.545,p=0.982),  time:66.456, tt:5981.000\n",
      "Ep:90, loss:0.00002, loss_test:0.09564, lr:6.76e-03, fs:0.70130 (r=0.545,p=0.982),  time:66.468, tt:6048.543\n",
      "Ep:91, loss:0.00002, loss_test:0.09383, lr:6.69e-03, fs:0.70130 (r=0.545,p=0.982),  time:66.453, tt:6113.675\n",
      "Ep:92, loss:0.00002, loss_test:0.09543, lr:6.62e-03, fs:0.69281 (r=0.535,p=0.981),  time:66.432, tt:6178.161\n",
      "Ep:93, loss:0.00002, loss_test:0.09417, lr:6.56e-03, fs:0.69281 (r=0.535,p=0.981),  time:66.417, tt:6243.220\n",
      "Ep:94, loss:0.00001, loss_test:0.09599, lr:6.49e-03, fs:0.72611 (r=0.576,p=0.983),  time:66.395, tt:6307.484\n",
      "Ep:95, loss:0.00001, loss_test:0.09524, lr:6.43e-03, fs:0.70130 (r=0.545,p=0.982),  time:66.392, tt:6373.660\n",
      "Ep:96, loss:0.00001, loss_test:0.09539, lr:6.36e-03, fs:0.69281 (r=0.535,p=0.981),  time:66.392, tt:6440.064\n",
      "Ep:97, loss:0.00001, loss_test:0.09525, lr:6.30e-03, fs:0.69281 (r=0.535,p=0.981),  time:66.423, tt:6509.472\n",
      "Ep:98, loss:0.00001, loss_test:0.09440, lr:6.24e-03, fs:0.69281 (r=0.535,p=0.981),  time:66.415, tt:6575.098\n",
      "Ep:99, loss:0.00001, loss_test:0.09590, lr:6.17e-03, fs:0.70130 (r=0.545,p=0.982),  time:66.429, tt:6642.865\n",
      "Ep:100, loss:0.00001, loss_test:0.09485, lr:6.11e-03, fs:0.69281 (r=0.535,p=0.981),  time:66.404, tt:6706.760\n",
      "Ep:101, loss:0.00001, loss_test:0.09474, lr:6.05e-03, fs:0.69281 (r=0.535,p=0.981),  time:66.415, tt:6774.324\n",
      "Ep:102, loss:0.00001, loss_test:0.09605, lr:5.99e-03, fs:0.69281 (r=0.535,p=0.981),  time:66.430, tt:6842.303\n",
      "Ep:103, loss:0.00001, loss_test:0.09507, lr:5.93e-03, fs:0.70130 (r=0.545,p=0.982),  time:66.424, tt:6908.081\n",
      "Ep:104, loss:0.00001, loss_test:0.09661, lr:5.87e-03, fs:0.69281 (r=0.535,p=0.981),  time:66.421, tt:6974.172\n",
      "Ep:105, loss:0.00001, loss_test:0.09548, lr:5.81e-03, fs:0.69281 (r=0.535,p=0.981),  time:66.436, tt:7042.190\n",
      "Ep:106, loss:0.00001, loss_test:0.09566, lr:5.75e-03, fs:0.69281 (r=0.535,p=0.981),  time:66.338, tt:7098.143\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00014, loss_test:0.14588, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:10.625, tt:10.625\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00014, loss_test:0.14571, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.632, tt:25.264\n",
      "Ep:2, loss:0.00014, loss_test:0.14548, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.051, tt:39.152\n",
      "Ep:3, loss:0.00014, loss_test:0.14516, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.373, tt:53.491\n",
      "Ep:4, loss:0.00014, loss_test:0.14475, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.904, tt:69.518\n",
      "Ep:5, loss:0.00014, loss_test:0.14426, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.987, tt:83.921\n",
      "Ep:6, loss:0.00014, loss_test:0.14365, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.251, tt:99.759\n",
      "Ep:7, loss:0.00014, loss_test:0.14290, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:14.413, tt:115.305\n",
      "Ep:8, loss:0.00014, loss_test:0.14194, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:14.619, tt:131.573\n",
      "Ep:9, loss:0.00014, loss_test:0.14076, lr:1.00e-02, fs:0.65763 (r=0.980,p=0.495),  time:14.742, tt:147.421\n",
      "Ep:10, loss:0.00013, loss_test:0.13932, lr:1.00e-02, fs:0.65529 (r=0.970,p=0.495),  time:14.709, tt:161.796\n",
      "Ep:11, loss:0.00013, loss_test:0.13752, lr:1.00e-02, fs:0.65052 (r=0.949,p=0.495),  time:14.872, tt:178.459\n",
      "Ep:12, loss:0.00013, loss_test:0.13524, lr:9.90e-03, fs:0.65233 (r=0.919,p=0.506),  time:15.084, tt:196.093\n",
      "Ep:13, loss:0.00013, loss_test:0.13238, lr:9.80e-03, fs:0.65201 (r=0.899,p=0.511),  time:15.153, tt:212.144\n",
      "Ep:14, loss:0.00013, loss_test:0.12889, lr:9.70e-03, fs:0.64567 (r=0.828,p=0.529),  time:15.188, tt:227.827\n",
      "Ep:15, loss:0.00012, loss_test:0.12555, lr:9.61e-03, fs:0.62712 (r=0.747,p=0.540),  time:15.197, tt:243.145\n",
      "Ep:16, loss:0.00012, loss_test:0.12300, lr:9.51e-03, fs:0.63889 (r=0.697,p=0.590),  time:15.237, tt:259.025\n",
      "Ep:17, loss:0.00012, loss_test:0.12145, lr:9.41e-03, fs:0.62439 (r=0.646,p=0.604),  time:15.304, tt:275.476\n",
      "Ep:18, loss:0.00012, loss_test:0.12077, lr:9.32e-03, fs:0.61929 (r=0.616,p=0.622),  time:15.330, tt:291.266\n",
      "Ep:19, loss:0.00011, loss_test:0.12027, lr:9.23e-03, fs:0.60000 (r=0.576,p=0.626),  time:15.297, tt:305.936\n",
      "Ep:20, loss:0.00011, loss_test:0.11950, lr:9.14e-03, fs:0.62176 (r=0.606,p=0.638),  time:15.319, tt:321.695\n",
      "Ep:21, loss:0.00011, loss_test:0.11866, lr:9.04e-03, fs:0.63265 (r=0.626,p=0.639),  time:15.311, tt:336.842\n",
      "Ep:22, loss:0.00011, loss_test:0.11803, lr:8.95e-03, fs:0.63682 (r=0.646,p=0.627),  time:15.298, tt:351.854\n",
      "Ep:23, loss:0.00011, loss_test:0.11756, lr:8.86e-03, fs:0.63054 (r=0.646,p=0.615),  time:15.311, tt:367.470\n",
      "Ep:24, loss:0.00011, loss_test:0.11701, lr:8.78e-03, fs:0.63682 (r=0.646,p=0.627),  time:15.302, tt:382.552\n",
      "Ep:25, loss:0.00010, loss_test:0.11635, lr:8.69e-03, fs:0.63959 (r=0.636,p=0.643),  time:15.303, tt:397.884\n",
      "Ep:26, loss:0.00010, loss_test:0.11591, lr:8.60e-03, fs:0.64249 (r=0.626,p=0.660),  time:15.330, tt:413.906\n",
      "Ep:27, loss:0.00010, loss_test:0.11567, lr:8.51e-03, fs:0.65217 (r=0.606,p=0.706),  time:15.275, tt:427.706\n",
      "Ep:28, loss:0.00010, loss_test:0.11503, lr:8.43e-03, fs:0.65574 (r=0.606,p=0.714),  time:15.283, tt:443.197\n",
      "Ep:29, loss:0.00010, loss_test:0.11396, lr:8.35e-03, fs:0.65241 (r=0.616,p=0.693),  time:15.293, tt:458.776\n",
      "Ep:30, loss:0.00010, loss_test:0.11292, lr:8.26e-03, fs:0.64171 (r=0.606,p=0.682),  time:15.285, tt:473.840\n",
      "Ep:31, loss:0.00010, loss_test:0.11222, lr:8.18e-03, fs:0.63830 (r=0.606,p=0.674),  time:15.292, tt:489.355\n",
      "Ep:32, loss:0.00009, loss_test:0.11177, lr:8.10e-03, fs:0.63830 (r=0.606,p=0.674),  time:15.304, tt:505.034\n",
      "Ep:33, loss:0.00009, loss_test:0.11157, lr:8.02e-03, fs:0.64865 (r=0.606,p=0.698),  time:15.323, tt:520.992\n",
      "Ep:34, loss:0.00009, loss_test:0.11154, lr:7.94e-03, fs:0.65934 (r=0.606,p=0.723),  time:15.347, tt:537.158\n",
      "Ep:35, loss:0.00009, loss_test:0.11143, lr:7.86e-03, fs:0.67039 (r=0.606,p=0.750),  time:15.362, tt:553.022\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00009, loss_test:0.11097, lr:7.86e-03, fs:0.67403 (r=0.616,p=0.744),  time:15.397, tt:569.707\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00009, loss_test:0.11026, lr:7.86e-03, fs:0.67403 (r=0.616,p=0.744),  time:15.399, tt:585.180\n",
      "Ep:38, loss:0.00009, loss_test:0.10955, lr:7.86e-03, fs:0.67391 (r=0.626,p=0.729),  time:15.445, tt:602.336\n",
      "Ep:39, loss:0.00009, loss_test:0.10904, lr:7.86e-03, fs:0.67391 (r=0.626,p=0.729),  time:15.462, tt:618.483\n",
      "Ep:40, loss:0.00009, loss_test:0.10868, lr:7.86e-03, fs:0.68478 (r=0.636,p=0.741),  time:15.478, tt:634.604\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00008, loss_test:0.10847, lr:7.86e-03, fs:0.68852 (r=0.636,p=0.750),  time:15.504, tt:651.183\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00008, loss_test:0.10817, lr:7.86e-03, fs:0.69231 (r=0.636,p=0.759),  time:15.516, tt:667.181\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00008, loss_test:0.10784, lr:7.86e-03, fs:0.69231 (r=0.636,p=0.759),  time:15.517, tt:682.746\n",
      "Ep:44, loss:0.00008, loss_test:0.10747, lr:7.86e-03, fs:0.69231 (r=0.636,p=0.759),  time:15.506, tt:697.750\n",
      "Ep:45, loss:0.00008, loss_test:0.10716, lr:7.86e-03, fs:0.69231 (r=0.636,p=0.759),  time:15.533, tt:714.509\n",
      "Ep:46, loss:0.00008, loss_test:0.10681, lr:7.86e-03, fs:0.69231 (r=0.636,p=0.759),  time:15.546, tt:730.639\n",
      "Ep:47, loss:0.00008, loss_test:0.10645, lr:7.86e-03, fs:0.69231 (r=0.636,p=0.759),  time:15.540, tt:745.918\n",
      "Ep:48, loss:0.00008, loss_test:0.10609, lr:7.86e-03, fs:0.69231 (r=0.636,p=0.759),  time:15.519, tt:760.448\n",
      "Ep:49, loss:0.00008, loss_test:0.10566, lr:7.86e-03, fs:0.69231 (r=0.636,p=0.759),  time:15.519, tt:775.940\n",
      "Ep:50, loss:0.00008, loss_test:0.10521, lr:7.86e-03, fs:0.69231 (r=0.636,p=0.759),  time:15.505, tt:790.778\n",
      "Ep:51, loss:0.00008, loss_test:0.10476, lr:7.86e-03, fs:0.69231 (r=0.636,p=0.759),  time:15.484, tt:805.169\n",
      "Ep:52, loss:0.00007, loss_test:0.10442, lr:7.86e-03, fs:0.69231 (r=0.636,p=0.759),  time:15.477, tt:820.256\n",
      "Ep:53, loss:0.00007, loss_test:0.10427, lr:7.86e-03, fs:0.69231 (r=0.636,p=0.759),  time:15.460, tt:834.841\n",
      "Ep:54, loss:0.00007, loss_test:0.10425, lr:7.78e-03, fs:0.69231 (r=0.636,p=0.759),  time:15.459, tt:850.249\n",
      "Ep:55, loss:0.00007, loss_test:0.10419, lr:7.70e-03, fs:0.69231 (r=0.636,p=0.759),  time:15.465, tt:866.028\n",
      "Ep:56, loss:0.00007, loss_test:0.10391, lr:7.62e-03, fs:0.69231 (r=0.636,p=0.759),  time:15.476, tt:882.146\n",
      "Ep:57, loss:0.00007, loss_test:0.10353, lr:7.55e-03, fs:0.69945 (r=0.646,p=0.762),  time:15.473, tt:897.421\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00007, loss_test:0.10328, lr:7.55e-03, fs:0.69945 (r=0.646,p=0.762),  time:15.476, tt:913.097\n",
      "Ep:59, loss:0.00007, loss_test:0.10309, lr:7.55e-03, fs:0.69945 (r=0.646,p=0.762),  time:15.478, tt:928.690\n",
      "Ep:60, loss:0.00007, loss_test:0.10289, lr:7.55e-03, fs:0.69945 (r=0.646,p=0.762),  time:15.480, tt:944.306\n",
      "Ep:61, loss:0.00007, loss_test:0.10255, lr:7.55e-03, fs:0.70652 (r=0.657,p=0.765),  time:15.464, tt:958.765\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00007, loss_test:0.10218, lr:7.55e-03, fs:0.70652 (r=0.657,p=0.765),  time:15.455, tt:973.669\n",
      "Ep:63, loss:0.00007, loss_test:0.10188, lr:7.55e-03, fs:0.70652 (r=0.657,p=0.765),  time:15.463, tt:989.612\n",
      "Ep:64, loss:0.00007, loss_test:0.10160, lr:7.55e-03, fs:0.70270 (r=0.657,p=0.756),  time:15.458, tt:1004.788\n",
      "Ep:65, loss:0.00007, loss_test:0.10140, lr:7.55e-03, fs:0.70270 (r=0.657,p=0.756),  time:15.449, tt:1019.617\n",
      "Ep:66, loss:0.00006, loss_test:0.10127, lr:7.55e-03, fs:0.70652 (r=0.657,p=0.765),  time:15.446, tt:1034.861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:67, loss:0.00006, loss_test:0.10108, lr:7.55e-03, fs:0.70652 (r=0.657,p=0.765),  time:15.439, tt:1049.845\n",
      "Ep:68, loss:0.00006, loss_test:0.10091, lr:7.55e-03, fs:0.70652 (r=0.657,p=0.765),  time:15.424, tt:1064.243\n",
      "Ep:69, loss:0.00006, loss_test:0.10079, lr:7.55e-03, fs:0.71038 (r=0.657,p=0.774),  time:15.413, tt:1078.902\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00006, loss_test:0.10048, lr:7.55e-03, fs:0.71038 (r=0.657,p=0.774),  time:15.432, tt:1095.708\n",
      "Ep:71, loss:0.00006, loss_test:0.10005, lr:7.55e-03, fs:0.71038 (r=0.657,p=0.774),  time:15.429, tt:1110.907\n",
      "Ep:72, loss:0.00006, loss_test:0.09986, lr:7.55e-03, fs:0.71038 (r=0.657,p=0.774),  time:15.443, tt:1127.329\n",
      "Ep:73, loss:0.00006, loss_test:0.09967, lr:7.55e-03, fs:0.71038 (r=0.657,p=0.774),  time:15.453, tt:1143.496\n",
      "Ep:74, loss:0.00006, loss_test:0.09929, lr:7.55e-03, fs:0.71038 (r=0.657,p=0.774),  time:15.454, tt:1159.023\n",
      "Ep:75, loss:0.00006, loss_test:0.09883, lr:7.55e-03, fs:0.71038 (r=0.657,p=0.774),  time:15.454, tt:1174.502\n",
      "Ep:76, loss:0.00006, loss_test:0.09852, lr:7.55e-03, fs:0.71038 (r=0.657,p=0.774),  time:15.456, tt:1190.145\n",
      "Ep:77, loss:0.00006, loss_test:0.09830, lr:7.55e-03, fs:0.73118 (r=0.687,p=0.782),  time:15.462, tt:1206.052\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00006, loss_test:0.09801, lr:7.55e-03, fs:0.72727 (r=0.687,p=0.773),  time:15.463, tt:1221.553\n",
      "Ep:79, loss:0.00006, loss_test:0.09764, lr:7.55e-03, fs:0.72727 (r=0.687,p=0.773),  time:15.452, tt:1236.192\n",
      "Ep:80, loss:0.00006, loss_test:0.09739, lr:7.55e-03, fs:0.73797 (r=0.697,p=0.784),  time:15.438, tt:1250.451\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00006, loss_test:0.09726, lr:7.55e-03, fs:0.73797 (r=0.697,p=0.784),  time:15.429, tt:1265.192\n",
      "Ep:82, loss:0.00005, loss_test:0.09722, lr:7.55e-03, fs:0.73797 (r=0.697,p=0.784),  time:15.429, tt:1280.616\n",
      "Ep:83, loss:0.00005, loss_test:0.09699, lr:7.55e-03, fs:0.74866 (r=0.707,p=0.795),  time:15.422, tt:1295.452\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00005, loss_test:0.09668, lr:7.55e-03, fs:0.74866 (r=0.707,p=0.795),  time:15.411, tt:1309.947\n",
      "Ep:85, loss:0.00005, loss_test:0.09660, lr:7.55e-03, fs:0.74194 (r=0.697,p=0.793),  time:15.414, tt:1325.637\n",
      "Ep:86, loss:0.00005, loss_test:0.09637, lr:7.55e-03, fs:0.74194 (r=0.697,p=0.793),  time:15.413, tt:1340.947\n",
      "Ep:87, loss:0.00005, loss_test:0.09606, lr:7.55e-03, fs:0.73797 (r=0.697,p=0.784),  time:15.427, tt:1357.593\n",
      "Ep:88, loss:0.00005, loss_test:0.09586, lr:7.55e-03, fs:0.73797 (r=0.697,p=0.784),  time:15.433, tt:1373.496\n",
      "Ep:89, loss:0.00005, loss_test:0.09574, lr:7.55e-03, fs:0.73118 (r=0.687,p=0.782),  time:15.433, tt:1388.970\n",
      "Ep:90, loss:0.00005, loss_test:0.09561, lr:7.55e-03, fs:0.73118 (r=0.687,p=0.782),  time:15.436, tt:1404.641\n",
      "Ep:91, loss:0.00005, loss_test:0.09530, lr:7.55e-03, fs:0.73797 (r=0.697,p=0.784),  time:15.436, tt:1420.076\n",
      "Ep:92, loss:0.00005, loss_test:0.09505, lr:7.55e-03, fs:0.75132 (r=0.717,p=0.789),  time:15.432, tt:1435.202\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00005, loss_test:0.09507, lr:7.55e-03, fs:0.75132 (r=0.717,p=0.789),  time:15.429, tt:1450.344\n",
      "Ep:94, loss:0.00005, loss_test:0.09498, lr:7.55e-03, fs:0.75132 (r=0.717,p=0.789),  time:15.426, tt:1465.483\n",
      "Ep:95, loss:0.00005, loss_test:0.09446, lr:7.55e-03, fs:0.75789 (r=0.727,p=0.791),  time:15.412, tt:1479.538\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00005, loss_test:0.09427, lr:7.55e-03, fs:0.75789 (r=0.727,p=0.791),  time:15.408, tt:1494.562\n",
      "Ep:97, loss:0.00005, loss_test:0.09427, lr:7.55e-03, fs:0.75789 (r=0.727,p=0.791),  time:15.410, tt:1510.219\n",
      "Ep:98, loss:0.00005, loss_test:0.09425, lr:7.55e-03, fs:0.75789 (r=0.727,p=0.791),  time:15.407, tt:1525.262\n",
      "Ep:99, loss:0.00005, loss_test:0.09418, lr:7.55e-03, fs:0.75789 (r=0.727,p=0.791),  time:15.412, tt:1541.209\n",
      "Ep:100, loss:0.00005, loss_test:0.09400, lr:7.55e-03, fs:0.75789 (r=0.727,p=0.791),  time:15.401, tt:1555.504\n",
      "Ep:101, loss:0.00005, loss_test:0.09376, lr:7.55e-03, fs:0.75789 (r=0.727,p=0.791),  time:15.399, tt:1570.738\n",
      "Ep:102, loss:0.00005, loss_test:0.09348, lr:7.55e-03, fs:0.75789 (r=0.727,p=0.791),  time:15.401, tt:1586.314\n",
      "Ep:103, loss:0.00004, loss_test:0.09360, lr:7.55e-03, fs:0.75789 (r=0.727,p=0.791),  time:15.399, tt:1601.460\n",
      "Ep:104, loss:0.00004, loss_test:0.09373, lr:7.55e-03, fs:0.75132 (r=0.717,p=0.789),  time:15.393, tt:1616.284\n",
      "Ep:105, loss:0.00004, loss_test:0.09362, lr:7.55e-03, fs:0.74346 (r=0.717,p=0.772),  time:15.400, tt:1632.363\n",
      "Ep:106, loss:0.00004, loss_test:0.09336, lr:7.55e-03, fs:0.75132 (r=0.717,p=0.789),  time:15.406, tt:1648.417\n",
      "Ep:107, loss:0.00004, loss_test:0.09304, lr:7.47e-03, fs:0.75132 (r=0.717,p=0.789),  time:15.410, tt:1664.276\n",
      "Ep:108, loss:0.00004, loss_test:0.09271, lr:7.40e-03, fs:0.74346 (r=0.717,p=0.772),  time:15.407, tt:1679.367\n",
      "Ep:109, loss:0.00004, loss_test:0.09285, lr:7.32e-03, fs:0.74737 (r=0.717,p=0.780),  time:15.401, tt:1694.078\n",
      "Ep:110, loss:0.00004, loss_test:0.09300, lr:7.25e-03, fs:0.75532 (r=0.717,p=0.798),  time:15.395, tt:1708.805\n",
      "Ep:111, loss:0.00004, loss_test:0.09284, lr:7.18e-03, fs:0.75393 (r=0.727,p=0.783),  time:15.388, tt:1723.452\n",
      "Ep:112, loss:0.00004, loss_test:0.09284, lr:7.11e-03, fs:0.74737 (r=0.717,p=0.780),  time:15.383, tt:1738.308\n",
      "Ep:113, loss:0.00004, loss_test:0.09283, lr:7.03e-03, fs:0.75532 (r=0.717,p=0.798),  time:15.381, tt:1753.403\n",
      "Ep:114, loss:0.00004, loss_test:0.09268, lr:6.96e-03, fs:0.75393 (r=0.727,p=0.783),  time:15.376, tt:1768.286\n",
      "Ep:115, loss:0.00004, loss_test:0.09274, lr:6.89e-03, fs:0.75393 (r=0.727,p=0.783),  time:15.379, tt:1783.969\n",
      "Ep:116, loss:0.00004, loss_test:0.09267, lr:6.83e-03, fs:0.75393 (r=0.727,p=0.783),  time:15.389, tt:1800.536\n",
      "Ep:117, loss:0.00004, loss_test:0.09243, lr:6.76e-03, fs:0.75393 (r=0.727,p=0.783),  time:15.384, tt:1815.280\n",
      "Ep:118, loss:0.00004, loss_test:0.09230, lr:6.69e-03, fs:0.75789 (r=0.727,p=0.791),  time:15.381, tt:1830.352\n",
      "Ep:119, loss:0.00004, loss_test:0.09200, lr:6.62e-03, fs:0.75393 (r=0.727,p=0.783),  time:15.397, tt:1847.588\n",
      "Ep:120, loss:0.00004, loss_test:0.09221, lr:6.56e-03, fs:0.75789 (r=0.727,p=0.791),  time:15.397, tt:1863.024\n",
      "Ep:121, loss:0.00004, loss_test:0.09235, lr:6.49e-03, fs:0.76190 (r=0.727,p=0.800),  time:15.394, tt:1878.047\n",
      "##########Best model found so far##########\n",
      "Ep:122, loss:0.00004, loss_test:0.09217, lr:6.49e-03, fs:0.75789 (r=0.727,p=0.791),  time:15.396, tt:1893.722\n",
      "Ep:123, loss:0.00004, loss_test:0.09217, lr:6.49e-03, fs:0.75789 (r=0.727,p=0.791),  time:15.399, tt:1909.437\n",
      "Ep:124, loss:0.00004, loss_test:0.09196, lr:6.49e-03, fs:0.75132 (r=0.717,p=0.789),  time:15.404, tt:1925.504\n",
      "Ep:125, loss:0.00004, loss_test:0.09170, lr:6.49e-03, fs:0.75532 (r=0.717,p=0.798),  time:15.393, tt:1939.550\n",
      "Ep:126, loss:0.00004, loss_test:0.09197, lr:6.49e-03, fs:0.75269 (r=0.707,p=0.805),  time:15.389, tt:1954.398\n",
      "Ep:127, loss:0.00004, loss_test:0.09180, lr:6.49e-03, fs:0.75532 (r=0.717,p=0.798),  time:15.389, tt:1969.781\n",
      "Ep:128, loss:0.00004, loss_test:0.09155, lr:6.49e-03, fs:0.75532 (r=0.717,p=0.798),  time:15.384, tt:1984.592\n",
      "Ep:129, loss:0.00004, loss_test:0.09153, lr:6.49e-03, fs:0.75532 (r=0.717,p=0.798),  time:15.384, tt:1999.879\n",
      "Ep:130, loss:0.00003, loss_test:0.09121, lr:6.49e-03, fs:0.75532 (r=0.717,p=0.798),  time:15.377, tt:2014.410\n",
      "Ep:131, loss:0.00003, loss_test:0.09134, lr:6.49e-03, fs:0.75532 (r=0.717,p=0.798),  time:15.381, tt:2030.278\n",
      "Ep:132, loss:0.00003, loss_test:0.09092, lr:6.49e-03, fs:0.75532 (r=0.717,p=0.798),  time:15.378, tt:2045.236\n",
      "Ep:133, loss:0.00003, loss_test:0.09112, lr:6.43e-03, fs:0.75532 (r=0.717,p=0.798),  time:15.380, tt:2060.963\n",
      "Ep:134, loss:0.00003, loss_test:0.09115, lr:6.36e-03, fs:0.75532 (r=0.717,p=0.798),  time:15.380, tt:2076.239\n",
      "Ep:135, loss:0.00003, loss_test:0.09089, lr:6.30e-03, fs:0.75936 (r=0.717,p=0.807),  time:15.385, tt:2092.406\n",
      "Ep:136, loss:0.00003, loss_test:0.09133, lr:6.24e-03, fs:0.75936 (r=0.717,p=0.807),  time:15.380, tt:2107.057\n",
      "Ep:137, loss:0.00003, loss_test:0.09121, lr:6.17e-03, fs:0.75936 (r=0.717,p=0.807),  time:15.376, tt:2121.948\n",
      "Ep:138, loss:0.00003, loss_test:0.09059, lr:6.11e-03, fs:0.75936 (r=0.717,p=0.807),  time:15.373, tt:2136.887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:139, loss:0.00003, loss_test:0.09079, lr:6.05e-03, fs:0.75269 (r=0.707,p=0.805),  time:15.368, tt:2151.476\n",
      "Ep:140, loss:0.00003, loss_test:0.09095, lr:5.99e-03, fs:0.75269 (r=0.707,p=0.805),  time:15.357, tt:2165.383\n",
      "Ep:141, loss:0.00003, loss_test:0.09073, lr:5.93e-03, fs:0.75936 (r=0.717,p=0.807),  time:15.356, tt:2180.549\n",
      "Ep:142, loss:0.00003, loss_test:0.09070, lr:5.87e-03, fs:0.75936 (r=0.717,p=0.807),  time:15.357, tt:2196.000\n",
      "Ep:143, loss:0.00003, loss_test:0.09052, lr:5.81e-03, fs:0.75936 (r=0.717,p=0.807),  time:15.348, tt:2210.136\n",
      "Ep:144, loss:0.00003, loss_test:0.09029, lr:5.75e-03, fs:0.75936 (r=0.717,p=0.807),  time:15.389, tt:2231.423\n",
      "Ep:145, loss:0.00003, loss_test:0.09032, lr:5.70e-03, fs:0.75936 (r=0.717,p=0.807),  time:15.388, tt:2246.649\n",
      "Ep:146, loss:0.00003, loss_test:0.09114, lr:5.64e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.388, tt:2261.996\n",
      "##########Best model found so far##########\n",
      "Ep:147, loss:0.00003, loss_test:0.09118, lr:5.64e-03, fs:0.76757 (r=0.717,p=0.826),  time:15.388, tt:2277.436\n",
      "##########Best model found so far##########\n",
      "Ep:148, loss:0.00003, loss_test:0.09043, lr:5.64e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.383, tt:2292.108\n",
      "Ep:149, loss:0.00003, loss_test:0.08998, lr:5.64e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.367, tt:2304.975\n",
      "Ep:150, loss:0.00003, loss_test:0.09062, lr:5.64e-03, fs:0.77174 (r=0.717,p=0.835),  time:15.354, tt:2318.394\n",
      "##########Best model found so far##########\n",
      "Ep:151, loss:0.00003, loss_test:0.09075, lr:5.64e-03, fs:0.77596 (r=0.717,p=0.845),  time:15.343, tt:2332.159\n",
      "##########Best model found so far##########\n",
      "Ep:152, loss:0.00003, loss_test:0.09020, lr:5.64e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.319, tt:2343.745\n",
      "Ep:153, loss:0.00003, loss_test:0.08991, lr:5.64e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.297, tt:2355.774\n",
      "Ep:154, loss:0.00003, loss_test:0.09066, lr:5.64e-03, fs:0.76757 (r=0.717,p=0.826),  time:15.276, tt:2367.845\n",
      "Ep:155, loss:0.00003, loss_test:0.09058, lr:5.64e-03, fs:0.77174 (r=0.717,p=0.835),  time:15.263, tt:2381.044\n",
      "Ep:156, loss:0.00003, loss_test:0.08987, lr:5.64e-03, fs:0.76757 (r=0.717,p=0.826),  time:15.245, tt:2393.405\n",
      "Ep:157, loss:0.00003, loss_test:0.08998, lr:5.64e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.219, tt:2404.557\n",
      "Ep:158, loss:0.00003, loss_test:0.09078, lr:5.64e-03, fs:0.76757 (r=0.717,p=0.826),  time:15.206, tt:2417.832\n",
      "Ep:159, loss:0.00003, loss_test:0.09072, lr:5.64e-03, fs:0.76757 (r=0.717,p=0.826),  time:15.183, tt:2429.334\n",
      "Ep:160, loss:0.00003, loss_test:0.09006, lr:5.64e-03, fs:0.76757 (r=0.717,p=0.826),  time:15.164, tt:2441.405\n",
      "Ep:161, loss:0.00003, loss_test:0.08965, lr:5.64e-03, fs:0.77419 (r=0.727,p=0.828),  time:15.142, tt:2452.988\n",
      "Ep:162, loss:0.00003, loss_test:0.09047, lr:5.64e-03, fs:0.76757 (r=0.717,p=0.826),  time:15.124, tt:2465.280\n",
      "Ep:163, loss:0.00003, loss_test:0.09066, lr:5.58e-03, fs:0.76757 (r=0.717,p=0.826),  time:15.102, tt:2476.670\n",
      "Ep:164, loss:0.00003, loss_test:0.09014, lr:5.53e-03, fs:0.76757 (r=0.717,p=0.826),  time:15.087, tt:2489.277\n",
      "Ep:165, loss:0.00003, loss_test:0.08999, lr:5.47e-03, fs:0.77419 (r=0.727,p=0.828),  time:15.068, tt:2501.292\n",
      "Ep:166, loss:0.00003, loss_test:0.09004, lr:5.42e-03, fs:0.76757 (r=0.717,p=0.826),  time:15.059, tt:2514.919\n",
      "Ep:167, loss:0.00003, loss_test:0.08998, lr:5.36e-03, fs:0.77419 (r=0.727,p=0.828),  time:15.041, tt:2526.830\n",
      "Ep:168, loss:0.00003, loss_test:0.08980, lr:5.31e-03, fs:0.77419 (r=0.727,p=0.828),  time:15.030, tt:2540.138\n",
      "Ep:169, loss:0.00003, loss_test:0.09039, lr:5.26e-03, fs:0.77419 (r=0.727,p=0.828),  time:15.015, tt:2552.545\n",
      "Ep:170, loss:0.00003, loss_test:0.09033, lr:5.20e-03, fs:0.77419 (r=0.727,p=0.828),  time:15.005, tt:2565.880\n",
      "Ep:171, loss:0.00003, loss_test:0.08984, lr:5.15e-03, fs:0.77419 (r=0.727,p=0.828),  time:14.991, tt:2578.527\n",
      "Ep:172, loss:0.00003, loss_test:0.08973, lr:5.10e-03, fs:0.77419 (r=0.727,p=0.828),  time:14.985, tt:2592.482\n",
      "Ep:173, loss:0.00003, loss_test:0.08969, lr:5.05e-03, fs:0.77419 (r=0.727,p=0.828),  time:14.971, tt:2604.969\n",
      "Ep:174, loss:0.00003, loss_test:0.08966, lr:5.00e-03, fs:0.77419 (r=0.727,p=0.828),  time:14.965, tt:2618.911\n",
      "Ep:175, loss:0.00003, loss_test:0.08990, lr:4.95e-03, fs:0.76757 (r=0.717,p=0.826),  time:14.951, tt:2631.347\n",
      "Ep:176, loss:0.00003, loss_test:0.08970, lr:4.90e-03, fs:0.76757 (r=0.717,p=0.826),  time:14.931, tt:2642.802\n",
      "Ep:177, loss:0.00003, loss_test:0.08961, lr:4.85e-03, fs:0.77419 (r=0.727,p=0.828),  time:14.926, tt:2656.747\n",
      "Ep:178, loss:0.00003, loss_test:0.08994, lr:4.80e-03, fs:0.77174 (r=0.717,p=0.835),  time:14.914, tt:2669.630\n",
      "Ep:179, loss:0.00002, loss_test:0.08988, lr:4.75e-03, fs:0.77174 (r=0.717,p=0.835),  time:14.906, tt:2683.098\n",
      "Ep:180, loss:0.00002, loss_test:0.08954, lr:4.71e-03, fs:0.77174 (r=0.717,p=0.835),  time:14.895, tt:2696.037\n",
      "Ep:181, loss:0.00002, loss_test:0.08995, lr:4.66e-03, fs:0.76503 (r=0.707,p=0.833),  time:14.886, tt:2709.220\n",
      "Ep:182, loss:0.00002, loss_test:0.08996, lr:4.61e-03, fs:0.76503 (r=0.707,p=0.833),  time:14.871, tt:2721.463\n",
      "Ep:183, loss:0.00002, loss_test:0.08954, lr:4.57e-03, fs:0.77174 (r=0.717,p=0.835),  time:14.855, tt:2733.303\n",
      "Ep:184, loss:0.00002, loss_test:0.08964, lr:4.52e-03, fs:0.77174 (r=0.717,p=0.835),  time:14.852, tt:2747.594\n",
      "Ep:185, loss:0.00002, loss_test:0.08980, lr:4.48e-03, fs:0.76503 (r=0.707,p=0.833),  time:14.847, tt:2761.509\n",
      "Ep:186, loss:0.00002, loss_test:0.08955, lr:4.43e-03, fs:0.77174 (r=0.717,p=0.835),  time:14.830, tt:2773.265\n",
      "Ep:187, loss:0.00002, loss_test:0.08950, lr:4.39e-03, fs:0.77174 (r=0.717,p=0.835),  time:14.815, tt:2785.248\n",
      "Ep:188, loss:0.00002, loss_test:0.08963, lr:4.34e-03, fs:0.76503 (r=0.707,p=0.833),  time:14.799, tt:2796.975\n",
      "Ep:189, loss:0.00002, loss_test:0.08954, lr:4.30e-03, fs:0.77174 (r=0.717,p=0.835),  time:14.786, tt:2809.422\n",
      "Ep:190, loss:0.00002, loss_test:0.08964, lr:4.26e-03, fs:0.76503 (r=0.707,p=0.833),  time:14.784, tt:2823.673\n",
      "Ep:191, loss:0.00002, loss_test:0.08935, lr:4.21e-03, fs:0.77596 (r=0.717,p=0.845),  time:14.779, tt:2837.508\n",
      "Ep:192, loss:0.00002, loss_test:0.08941, lr:4.17e-03, fs:0.76923 (r=0.707,p=0.843),  time:14.769, tt:2850.329\n",
      "Ep:193, loss:0.00002, loss_test:0.08937, lr:4.13e-03, fs:0.76503 (r=0.707,p=0.833),  time:14.763, tt:2863.947\n",
      "Ep:194, loss:0.00002, loss_test:0.08922, lr:4.09e-03, fs:0.76503 (r=0.707,p=0.833),  time:14.762, tt:2878.650\n",
      "Ep:195, loss:0.00002, loss_test:0.08949, lr:4.05e-03, fs:0.76923 (r=0.707,p=0.843),  time:14.756, tt:2892.158\n",
      "Ep:196, loss:0.00002, loss_test:0.08938, lr:4.01e-03, fs:0.76923 (r=0.707,p=0.843),  time:14.755, tt:2906.637\n",
      "Ep:197, loss:0.00002, loss_test:0.08912, lr:3.97e-03, fs:0.77596 (r=0.717,p=0.845),  time:14.750, tt:2920.444\n",
      "Ep:198, loss:0.00002, loss_test:0.08958, lr:3.93e-03, fs:0.76923 (r=0.707,p=0.843),  time:14.744, tt:2933.959\n",
      "Ep:199, loss:0.00002, loss_test:0.08955, lr:3.89e-03, fs:0.76923 (r=0.707,p=0.843),  time:14.741, tt:2948.269\n",
      "Ep:200, loss:0.00002, loss_test:0.08919, lr:3.85e-03, fs:0.76923 (r=0.707,p=0.843),  time:14.738, tt:2962.362\n",
      "Ep:201, loss:0.00002, loss_test:0.08903, lr:3.81e-03, fs:0.76923 (r=0.707,p=0.843),  time:14.733, tt:2976.136\n",
      "Ep:202, loss:0.00002, loss_test:0.08946, lr:3.77e-03, fs:0.76923 (r=0.707,p=0.843),  time:14.729, tt:2990.011\n",
      "Ep:203, loss:0.00002, loss_test:0.08952, lr:3.73e-03, fs:0.77348 (r=0.707,p=0.854),  time:14.728, tt:3004.434\n",
      "Ep:204, loss:0.00002, loss_test:0.08934, lr:3.70e-03, fs:0.76923 (r=0.707,p=0.843),  time:14.711, tt:3015.765\n",
      "Ep:205, loss:0.00002, loss_test:0.08892, lr:3.66e-03, fs:0.76923 (r=0.707,p=0.843),  time:14.699, tt:3028.068\n",
      "Ep:206, loss:0.00002, loss_test:0.08895, lr:3.62e-03, fs:0.76923 (r=0.707,p=0.843),  time:14.680, tt:3038.844\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=1,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1954 Test samples: 108\n",
      "Train positive samples: 977 Test positive samples: 54\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14419, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.576, tt:23.576\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14317, lr:1.00e-02, fs:0.65839 (r=0.981,p=0.495),  time:26.241, tt:52.482\n",
      "Ep:2, loss:0.00028, loss_test:0.14146, lr:1.00e-02, fs:0.65000 (r=0.963,p=0.491),  time:28.102, tt:84.307\n",
      "Ep:3, loss:0.00027, loss_test:0.13890, lr:1.00e-02, fs:0.64968 (r=0.944,p=0.495),  time:29.089, tt:116.354\n",
      "Ep:4, loss:0.00026, loss_test:0.13482, lr:1.00e-02, fs:0.67105 (r=0.944,p=0.520),  time:29.823, tt:149.114\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.12940, lr:1.00e-02, fs:0.68613 (r=0.870,p=0.566),  time:30.144, tt:180.863\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.12413, lr:1.00e-02, fs:0.63793 (r=0.685,p=0.597),  time:30.457, tt:213.198\n",
      "Ep:7, loss:0.00024, loss_test:0.12121, lr:1.00e-02, fs:0.66667 (r=0.648,p=0.686),  time:30.681, tt:245.450\n",
      "Ep:8, loss:0.00023, loss_test:0.11788, lr:1.00e-02, fs:0.68519 (r=0.685,p=0.685),  time:30.848, tt:277.630\n",
      "Ep:9, loss:0.00022, loss_test:0.11572, lr:1.00e-02, fs:0.69421 (r=0.778,p=0.627),  time:30.939, tt:309.385\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.11317, lr:1.00e-02, fs:0.71186 (r=0.778,p=0.656),  time:30.945, tt:340.391\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.10944, lr:1.00e-02, fs:0.69643 (r=0.722,p=0.672),  time:31.027, tt:372.318\n",
      "Ep:12, loss:0.00021, loss_test:0.10736, lr:1.00e-02, fs:0.71154 (r=0.685,p=0.740),  time:30.997, tt:402.965\n",
      "Ep:13, loss:0.00020, loss_test:0.10423, lr:1.00e-02, fs:0.71028 (r=0.704,p=0.717),  time:31.044, tt:434.612\n",
      "Ep:14, loss:0.00019, loss_test:0.10151, lr:1.00e-02, fs:0.73214 (r=0.759,p=0.707),  time:31.151, tt:467.260\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.09872, lr:1.00e-02, fs:0.73874 (r=0.759,p=0.719),  time:31.248, tt:499.970\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.09640, lr:1.00e-02, fs:0.74766 (r=0.741,p=0.755),  time:31.210, tt:530.578\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.09374, lr:1.00e-02, fs:0.76364 (r=0.778,p=0.750),  time:31.250, tt:562.496\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.09127, lr:1.00e-02, fs:0.80702 (r=0.852,p=0.767),  time:31.302, tt:594.736\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.08895, lr:1.00e-02, fs:0.79279 (r=0.815,p=0.772),  time:31.308, tt:626.169\n",
      "Ep:20, loss:0.00017, loss_test:0.08665, lr:1.00e-02, fs:0.82143 (r=0.852,p=0.793),  time:31.298, tt:657.257\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.08453, lr:1.00e-02, fs:0.83186 (r=0.870,p=0.797),  time:31.329, tt:689.249\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00016, loss_test:0.08256, lr:1.00e-02, fs:0.84956 (r=0.889,p=0.814),  time:31.362, tt:721.317\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.08087, lr:1.00e-02, fs:0.85714 (r=0.889,p=0.828),  time:31.427, tt:754.242\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.07905, lr:1.00e-02, fs:0.84956 (r=0.889,p=0.814),  time:31.494, tt:787.360\n",
      "Ep:25, loss:0.00015, loss_test:0.07774, lr:1.00e-02, fs:0.84956 (r=0.889,p=0.814),  time:31.503, tt:819.085\n",
      "Ep:26, loss:0.00014, loss_test:0.07641, lr:1.00e-02, fs:0.84956 (r=0.889,p=0.814),  time:31.569, tt:852.365\n",
      "Ep:27, loss:0.00014, loss_test:0.07505, lr:1.00e-02, fs:0.84956 (r=0.889,p=0.814),  time:31.530, tt:882.842\n",
      "Ep:28, loss:0.00014, loss_test:0.07383, lr:1.00e-02, fs:0.85714 (r=0.889,p=0.828),  time:31.568, tt:915.473\n",
      "Ep:29, loss:0.00014, loss_test:0.07254, lr:1.00e-02, fs:0.84956 (r=0.889,p=0.814),  time:31.565, tt:946.956\n",
      "Ep:30, loss:0.00013, loss_test:0.07198, lr:1.00e-02, fs:0.85714 (r=0.889,p=0.828),  time:31.598, tt:979.551\n",
      "Ep:31, loss:0.00013, loss_test:0.07093, lr:1.00e-02, fs:0.85714 (r=0.889,p=0.828),  time:31.553, tt:1009.711\n",
      "Ep:32, loss:0.00013, loss_test:0.06928, lr:1.00e-02, fs:0.87719 (r=0.926,p=0.833),  time:31.575, tt:1041.991\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00012, loss_test:0.06829, lr:1.00e-02, fs:0.86726 (r=0.907,p=0.831),  time:31.567, tt:1073.288\n",
      "Ep:34, loss:0.00012, loss_test:0.06798, lr:1.00e-02, fs:0.87719 (r=0.926,p=0.833),  time:31.531, tt:1103.595\n",
      "Ep:35, loss:0.00012, loss_test:0.06689, lr:1.00e-02, fs:0.86957 (r=0.926,p=0.820),  time:31.530, tt:1135.083\n",
      "Ep:36, loss:0.00012, loss_test:0.06610, lr:1.00e-02, fs:0.87719 (r=0.926,p=0.833),  time:31.553, tt:1167.468\n",
      "Ep:37, loss:0.00011, loss_test:0.06498, lr:1.00e-02, fs:0.87719 (r=0.926,p=0.833),  time:31.549, tt:1198.872\n",
      "Ep:38, loss:0.00011, loss_test:0.06440, lr:1.00e-02, fs:0.87719 (r=0.926,p=0.833),  time:31.505, tt:1228.681\n",
      "Ep:39, loss:0.00011, loss_test:0.06305, lr:1.00e-02, fs:0.88696 (r=0.944,p=0.836),  time:31.488, tt:1259.540\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00011, loss_test:0.06223, lr:1.00e-02, fs:0.87719 (r=0.926,p=0.833),  time:31.509, tt:1291.882\n",
      "Ep:41, loss:0.00011, loss_test:0.06155, lr:1.00e-02, fs:0.87719 (r=0.926,p=0.833),  time:31.523, tt:1323.949\n",
      "Ep:42, loss:0.00010, loss_test:0.06030, lr:1.00e-02, fs:0.88696 (r=0.944,p=0.836),  time:31.581, tt:1357.979\n",
      "Ep:43, loss:0.00010, loss_test:0.05979, lr:1.00e-02, fs:0.89474 (r=0.944,p=0.850),  time:31.544, tt:1387.925\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00010, loss_test:0.05871, lr:1.00e-02, fs:0.89474 (r=0.944,p=0.850),  time:31.531, tt:1418.907\n",
      "Ep:45, loss:0.00010, loss_test:0.05764, lr:1.00e-02, fs:0.89474 (r=0.944,p=0.850),  time:31.514, tt:1449.666\n",
      "Ep:46, loss:0.00010, loss_test:0.05760, lr:1.00e-02, fs:0.91071 (r=0.944,p=0.879),  time:31.537, tt:1482.238\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00009, loss_test:0.05613, lr:1.00e-02, fs:0.88696 (r=0.944,p=0.836),  time:31.534, tt:1513.649\n",
      "Ep:48, loss:0.00009, loss_test:0.05503, lr:1.00e-02, fs:0.91071 (r=0.944,p=0.879),  time:31.549, tt:1545.924\n",
      "Ep:49, loss:0.00009, loss_test:0.05433, lr:1.00e-02, fs:0.91071 (r=0.944,p=0.879),  time:31.565, tt:1578.259\n",
      "Ep:50, loss:0.00009, loss_test:0.05293, lr:1.00e-02, fs:0.91228 (r=0.963,p=0.867),  time:31.575, tt:1610.337\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00009, loss_test:0.05228, lr:1.00e-02, fs:0.91071 (r=0.944,p=0.879),  time:31.537, tt:1639.944\n",
      "Ep:52, loss:0.00009, loss_test:0.05173, lr:1.00e-02, fs:0.92035 (r=0.963,p=0.881),  time:31.515, tt:1670.298\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00008, loss_test:0.05045, lr:1.00e-02, fs:0.92035 (r=0.963,p=0.881),  time:31.508, tt:1701.420\n",
      "Ep:54, loss:0.00008, loss_test:0.04943, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:31.516, tt:1733.359\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00008, loss_test:0.04961, lr:1.00e-02, fs:0.92035 (r=0.963,p=0.881),  time:31.530, tt:1765.653\n",
      "Ep:56, loss:0.00008, loss_test:0.04782, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:31.534, tt:1797.419\n",
      "Ep:57, loss:0.00008, loss_test:0.04730, lr:1.00e-02, fs:0.92035 (r=0.963,p=0.881),  time:31.520, tt:1828.171\n",
      "Ep:58, loss:0.00008, loss_test:0.04628, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:31.519, tt:1859.599\n",
      "Ep:59, loss:0.00007, loss_test:0.04512, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:31.524, tt:1891.414\n",
      "Ep:60, loss:0.00007, loss_test:0.04525, lr:1.00e-02, fs:0.92035 (r=0.963,p=0.881),  time:31.508, tt:1921.992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00007, loss_test:0.04355, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:31.492, tt:1952.484\n",
      "Ep:62, loss:0.00007, loss_test:0.04328, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:31.464, tt:1982.209\n",
      "Ep:63, loss:0.00007, loss_test:0.04302, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:31.479, tt:2014.664\n",
      "Ep:64, loss:0.00007, loss_test:0.04129, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:31.468, tt:2045.432\n",
      "Ep:65, loss:0.00007, loss_test:0.04209, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:31.463, tt:2076.557\n",
      "Ep:66, loss:0.00006, loss_test:0.04033, lr:9.90e-03, fs:0.92857 (r=0.963,p=0.897),  time:31.463, tt:2108.018\n",
      "Ep:67, loss:0.00006, loss_test:0.03967, lr:9.80e-03, fs:0.93805 (r=0.981,p=0.898),  time:31.447, tt:2138.369\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00006, loss_test:0.03898, lr:9.80e-03, fs:0.93805 (r=0.981,p=0.898),  time:31.421, tt:2168.075\n",
      "Ep:69, loss:0.00006, loss_test:0.03863, lr:9.80e-03, fs:0.93805 (r=0.981,p=0.898),  time:31.416, tt:2199.110\n",
      "Ep:70, loss:0.00006, loss_test:0.03811, lr:9.80e-03, fs:0.93805 (r=0.981,p=0.898),  time:31.404, tt:2229.705\n",
      "Ep:71, loss:0.00006, loss_test:0.03738, lr:9.80e-03, fs:0.93805 (r=0.981,p=0.898),  time:31.405, tt:2261.174\n",
      "Ep:72, loss:0.00006, loss_test:0.03707, lr:9.80e-03, fs:0.93805 (r=0.981,p=0.898),  time:31.412, tt:2293.064\n",
      "Ep:73, loss:0.00006, loss_test:0.03614, lr:9.80e-03, fs:0.93805 (r=0.981,p=0.898),  time:31.408, tt:2324.203\n",
      "Ep:74, loss:0.00006, loss_test:0.03668, lr:9.80e-03, fs:0.95495 (r=0.981,p=0.930),  time:31.406, tt:2355.450\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00005, loss_test:0.03525, lr:9.80e-03, fs:0.93805 (r=0.981,p=0.898),  time:31.406, tt:2386.856\n",
      "Ep:76, loss:0.00005, loss_test:0.03468, lr:9.80e-03, fs:0.94643 (r=0.981,p=0.914),  time:31.437, tt:2420.675\n",
      "Ep:77, loss:0.00005, loss_test:0.03417, lr:9.80e-03, fs:0.93805 (r=0.981,p=0.898),  time:31.428, tt:2451.397\n",
      "Ep:78, loss:0.00005, loss_test:0.03324, lr:9.80e-03, fs:0.94643 (r=0.981,p=0.914),  time:31.410, tt:2481.397\n",
      "Ep:79, loss:0.00005, loss_test:0.03275, lr:9.80e-03, fs:0.94643 (r=0.981,p=0.914),  time:31.414, tt:2513.132\n",
      "Ep:80, loss:0.00005, loss_test:0.03249, lr:9.80e-03, fs:0.94643 (r=0.981,p=0.914),  time:31.407, tt:2543.996\n",
      "Ep:81, loss:0.00005, loss_test:0.03186, lr:9.80e-03, fs:0.94643 (r=0.981,p=0.914),  time:31.399, tt:2574.687\n",
      "Ep:82, loss:0.00005, loss_test:0.03165, lr:9.80e-03, fs:0.96364 (r=0.981,p=0.946),  time:31.396, tt:2605.858\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00005, loss_test:0.03094, lr:9.80e-03, fs:0.94643 (r=0.981,p=0.914),  time:31.404, tt:2637.924\n",
      "Ep:84, loss:0.00005, loss_test:0.03060, lr:9.80e-03, fs:0.96364 (r=0.981,p=0.946),  time:31.416, tt:2670.343\n",
      "Ep:85, loss:0.00005, loss_test:0.02990, lr:9.80e-03, fs:0.94643 (r=0.981,p=0.914),  time:31.413, tt:2701.506\n",
      "Ep:86, loss:0.00005, loss_test:0.03053, lr:9.80e-03, fs:0.96364 (r=0.981,p=0.946),  time:31.411, tt:2732.745\n",
      "Ep:87, loss:0.00005, loss_test:0.02898, lr:9.80e-03, fs:0.94643 (r=0.981,p=0.914),  time:31.432, tt:2766.028\n",
      "Ep:88, loss:0.00005, loss_test:0.02911, lr:9.80e-03, fs:0.97248 (r=0.981,p=0.964),  time:31.442, tt:2798.363\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00005, loss_test:0.02847, lr:9.80e-03, fs:0.94643 (r=0.981,p=0.914),  time:31.456, tt:2831.028\n",
      "Ep:90, loss:0.00005, loss_test:0.02825, lr:9.80e-03, fs:0.95495 (r=0.981,p=0.930),  time:31.468, tt:2863.587\n",
      "Ep:91, loss:0.00004, loss_test:0.02697, lr:9.80e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.478, tt:2895.983\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00004, loss_test:0.02715, lr:9.80e-03, fs:0.94643 (r=0.981,p=0.914),  time:31.466, tt:2926.323\n",
      "Ep:93, loss:0.00004, loss_test:0.02658, lr:9.80e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.488, tt:2959.882\n",
      "Ep:94, loss:0.00004, loss_test:0.02510, lr:9.80e-03, fs:0.97248 (r=0.981,p=0.964),  time:31.502, tt:2992.720\n",
      "Ep:95, loss:0.00004, loss_test:0.02531, lr:9.80e-03, fs:0.97248 (r=0.981,p=0.964),  time:31.519, tt:3025.849\n",
      "Ep:96, loss:0.00004, loss_test:0.02485, lr:9.80e-03, fs:0.97248 (r=0.981,p=0.964),  time:31.575, tt:3062.740\n",
      "Ep:97, loss:0.00004, loss_test:0.02557, lr:9.80e-03, fs:0.97248 (r=0.981,p=0.964),  time:31.585, tt:3095.367\n",
      "Ep:98, loss:0.00004, loss_test:0.02378, lr:9.80e-03, fs:0.97248 (r=0.981,p=0.964),  time:31.597, tt:3128.113\n",
      "Ep:99, loss:0.00004, loss_test:0.02387, lr:9.80e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.591, tt:3159.099\n",
      "Ep:100, loss:0.00004, loss_test:0.02287, lr:9.80e-03, fs:0.97248 (r=0.981,p=0.964),  time:31.606, tt:3192.201\n",
      "Ep:101, loss:0.00003, loss_test:0.02284, lr:9.80e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.600, tt:3223.208\n",
      "Ep:102, loss:0.00003, loss_test:0.02198, lr:9.80e-03, fs:0.97248 (r=0.981,p=0.964),  time:31.612, tt:3256.081\n",
      "Ep:103, loss:0.00003, loss_test:0.02180, lr:9.70e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.617, tt:3288.219\n",
      "Ep:104, loss:0.00003, loss_test:0.02077, lr:9.61e-03, fs:0.97248 (r=0.981,p=0.964),  time:31.620, tt:3320.151\n",
      "Ep:105, loss:0.00003, loss_test:0.02043, lr:9.51e-03, fs:0.97248 (r=0.981,p=0.964),  time:31.618, tt:3351.490\n",
      "Ep:106, loss:0.00003, loss_test:0.02013, lr:9.41e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.616, tt:3382.961\n",
      "Ep:107, loss:0.00003, loss_test:0.01980, lr:9.32e-03, fs:0.97248 (r=0.981,p=0.964),  time:31.618, tt:3414.772\n",
      "Ep:108, loss:0.00003, loss_test:0.01962, lr:9.23e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.598, tt:3444.178\n",
      "Ep:109, loss:0.00003, loss_test:0.01921, lr:9.14e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.590, tt:3474.946\n",
      "Ep:110, loss:0.00003, loss_test:0.01833, lr:9.04e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.595, tt:3507.049\n",
      "Ep:111, loss:0.00003, loss_test:0.01821, lr:8.95e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.594, tt:3538.579\n",
      "Ep:112, loss:0.00003, loss_test:0.01793, lr:8.86e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.591, tt:3569.764\n",
      "Ep:113, loss:0.00003, loss_test:0.01824, lr:8.78e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.583, tt:3600.511\n",
      "Ep:114, loss:0.00002, loss_test:0.01724, lr:8.69e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.572, tt:3630.825\n",
      "Ep:115, loss:0.00002, loss_test:0.01761, lr:8.60e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.580, tt:3663.253\n",
      "Ep:116, loss:0.00002, loss_test:0.01678, lr:8.51e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.581, tt:3694.936\n",
      "Ep:117, loss:0.00002, loss_test:0.01696, lr:8.43e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.577, tt:3726.123\n",
      "Ep:118, loss:0.00002, loss_test:0.01619, lr:8.35e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.579, tt:3757.842\n",
      "Ep:119, loss:0.00002, loss_test:0.01667, lr:8.26e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.564, tt:3787.730\n",
      "Ep:120, loss:0.00002, loss_test:0.01571, lr:8.18e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.565, tt:3819.365\n",
      "Ep:121, loss:0.00002, loss_test:0.01581, lr:8.10e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.546, tt:3848.649\n",
      "Ep:122, loss:0.00002, loss_test:0.01521, lr:8.02e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.577, tt:3883.965\n",
      "Ep:123, loss:0.00002, loss_test:0.01579, lr:7.94e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.566, tt:3914.200\n",
      "Ep:124, loss:0.00002, loss_test:0.01491, lr:7.86e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.568, tt:3945.974\n",
      "Ep:125, loss:0.00002, loss_test:0.01467, lr:7.78e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.564, tt:3977.095\n",
      "Ep:126, loss:0.00002, loss_test:0.01568, lr:7.70e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.564, tt:4008.593\n",
      "Ep:127, loss:0.00002, loss_test:0.01433, lr:7.62e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.555, tt:4039.100\n",
      "Ep:128, loss:0.00002, loss_test:0.01553, lr:7.55e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.553, tt:4070.319\n",
      "Ep:129, loss:0.00002, loss_test:0.01403, lr:7.47e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.545, tt:4100.910\n",
      "Ep:130, loss:0.00002, loss_test:0.01477, lr:7.40e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.547, tt:4132.649\n",
      "Ep:131, loss:0.00002, loss_test:0.01381, lr:7.32e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.539, tt:4163.212\n",
      "Ep:132, loss:0.00002, loss_test:0.01462, lr:7.25e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.547, tt:4195.714\n",
      "Ep:133, loss:0.00002, loss_test:0.01310, lr:7.18e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.539, tt:4226.161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00002, loss_test:0.01344, lr:7.11e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.542, tt:4258.132\n",
      "Ep:135, loss:0.00002, loss_test:0.01296, lr:7.03e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.546, tt:4290.323\n",
      "Ep:136, loss:0.00002, loss_test:0.01335, lr:6.96e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.551, tt:4322.498\n",
      "Ep:137, loss:0.00002, loss_test:0.01260, lr:6.89e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.554, tt:4354.460\n",
      "Ep:138, loss:0.00002, loss_test:0.01309, lr:6.83e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.557, tt:4386.462\n",
      "Ep:139, loss:0.00002, loss_test:0.01223, lr:6.76e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.550, tt:4417.049\n",
      "Ep:140, loss:0.00002, loss_test:0.01250, lr:6.69e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.548, tt:4448.241\n",
      "Ep:141, loss:0.00002, loss_test:0.01207, lr:6.62e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.547, tt:4479.712\n",
      "Ep:142, loss:0.00002, loss_test:0.01244, lr:6.56e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.544, tt:4510.824\n",
      "Ep:143, loss:0.00002, loss_test:0.01197, lr:6.49e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.551, tt:4543.313\n",
      "Ep:144, loss:0.00002, loss_test:0.01241, lr:6.43e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.547, tt:4574.276\n",
      "Ep:145, loss:0.00002, loss_test:0.01176, lr:6.36e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.559, tt:4607.623\n",
      "Ep:146, loss:0.00002, loss_test:0.01227, lr:6.30e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.561, tt:4639.459\n",
      "Ep:147, loss:0.00002, loss_test:0.01133, lr:6.24e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.562, tt:4671.247\n",
      "Ep:148, loss:0.00001, loss_test:0.01171, lr:6.17e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.565, tt:4703.214\n",
      "Ep:149, loss:0.00001, loss_test:0.01136, lr:6.11e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.577, tt:4736.549\n",
      "Ep:150, loss:0.00001, loss_test:0.01145, lr:6.05e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.582, tt:4768.861\n",
      "Ep:151, loss:0.00001, loss_test:0.01121, lr:5.99e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.582, tt:4800.463\n",
      "Ep:152, loss:0.00001, loss_test:0.01119, lr:5.93e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.574, tt:4830.775\n",
      "Ep:153, loss:0.00001, loss_test:0.01140, lr:5.87e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.576, tt:4862.761\n",
      "Ep:154, loss:0.00001, loss_test:0.01112, lr:5.81e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.573, tt:4893.812\n",
      "Ep:155, loss:0.00001, loss_test:0.01081, lr:5.75e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.583, tt:4927.023\n",
      "Ep:156, loss:0.00001, loss_test:0.01073, lr:5.70e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.589, tt:4959.479\n",
      "Ep:157, loss:0.00001, loss_test:0.01060, lr:5.64e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.594, tt:4991.790\n",
      "Ep:158, loss:0.00001, loss_test:0.01071, lr:5.58e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.625, tt:5028.433\n",
      "Ep:159, loss:0.00001, loss_test:0.01066, lr:5.53e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.625, tt:5059.927\n",
      "##########Best model found so far##########\n",
      "Ep:160, loss:0.00001, loss_test:0.01052, lr:5.53e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.613, tt:5089.681\n",
      "Ep:161, loss:0.00001, loss_test:0.01038, lr:5.53e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.602, tt:5119.456\n",
      "Ep:162, loss:0.00001, loss_test:0.01019, lr:5.53e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.602, tt:5151.120\n",
      "Ep:163, loss:0.00001, loss_test:0.01023, lr:5.53e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.603, tt:5182.851\n",
      "Ep:164, loss:0.00001, loss_test:0.01026, lr:5.53e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.597, tt:5213.510\n",
      "Ep:165, loss:0.00001, loss_test:0.01012, lr:5.53e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.599, tt:5245.449\n",
      "Ep:166, loss:0.00001, loss_test:0.01018, lr:5.53e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.591, tt:5275.684\n",
      "Ep:167, loss:0.00001, loss_test:0.00993, lr:5.53e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.583, tt:5305.867\n",
      "Ep:168, loss:0.00001, loss_test:0.01063, lr:5.53e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.581, tt:5337.246\n",
      "Ep:169, loss:0.00001, loss_test:0.00974, lr:5.53e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.576, tt:5367.981\n",
      "Ep:170, loss:0.00001, loss_test:0.01017, lr:5.53e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.574, tt:5399.236\n",
      "Ep:171, loss:0.00001, loss_test:0.00971, lr:5.47e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.573, tt:5430.479\n",
      "Ep:172, loss:0.00001, loss_test:0.01013, lr:5.42e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.567, tt:5461.027\n",
      "Ep:173, loss:0.00001, loss_test:0.00959, lr:5.36e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.570, tt:5493.174\n",
      "Ep:174, loss:0.00001, loss_test:0.00986, lr:5.31e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.575, tt:5525.581\n",
      "Ep:175, loss:0.00001, loss_test:0.00958, lr:5.26e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.577, tt:5557.604\n",
      "Ep:176, loss:0.00001, loss_test:0.00980, lr:5.20e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.578, tt:5589.307\n",
      "Ep:177, loss:0.00001, loss_test:0.00950, lr:5.15e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.565, tt:5618.611\n",
      "Ep:178, loss:0.00001, loss_test:0.00978, lr:5.10e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.564, tt:5650.002\n",
      "Ep:179, loss:0.00001, loss_test:0.00930, lr:5.05e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.553, tt:5679.498\n",
      "Ep:180, loss:0.00001, loss_test:0.00949, lr:5.00e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.560, tt:5712.301\n",
      "Ep:181, loss:0.00001, loss_test:0.00915, lr:4.95e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.549, tt:5741.888\n",
      "Ep:182, loss:0.00001, loss_test:0.00935, lr:4.90e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.551, tt:5773.744\n",
      "Ep:183, loss:0.00001, loss_test:0.00896, lr:4.85e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.552, tt:5805.546\n",
      "Ep:184, loss:0.00001, loss_test:0.00908, lr:4.80e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.554, tt:5837.438\n",
      "Ep:185, loss:0.00001, loss_test:0.00906, lr:4.75e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.563, tt:5870.745\n",
      "Ep:186, loss:0.00001, loss_test:0.00899, lr:4.71e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.563, tt:5902.332\n",
      "Ep:187, loss:0.00001, loss_test:0.00941, lr:4.66e-03, fs:0.98148 (r=0.981,p=0.981),  time:31.569, tt:5934.898\n",
      "Ep:188, loss:0.00001, loss_test:0.00891, lr:4.61e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.577, tt:5968.010\n",
      "Ep:189, loss:0.00001, loss_test:0.00917, lr:4.57e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.588, tt:6001.653\n",
      "Ep:190, loss:0.00001, loss_test:0.00898, lr:4.52e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.585, tt:6032.741\n",
      "Ep:191, loss:0.00001, loss_test:0.00892, lr:4.48e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.592, tt:6065.686\n",
      "Ep:192, loss:0.00001, loss_test:0.00887, lr:4.43e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.598, tt:6098.460\n",
      "Ep:193, loss:0.00001, loss_test:0.00896, lr:4.39e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.603, tt:6131.021\n",
      "Ep:194, loss:0.00001, loss_test:0.00878, lr:4.34e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.602, tt:6162.435\n",
      "Ep:195, loss:0.00001, loss_test:0.00893, lr:4.30e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.610, tt:6195.644\n",
      "Ep:196, loss:0.00001, loss_test:0.00888, lr:4.26e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.618, tt:6228.782\n",
      "Ep:197, loss:0.00001, loss_test:0.00866, lr:4.21e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.620, tt:6260.741\n",
      "Ep:198, loss:0.00001, loss_test:0.00874, lr:4.17e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.628, tt:6294.068\n",
      "Ep:199, loss:0.00001, loss_test:0.00873, lr:4.13e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.634, tt:6326.703\n",
      "Ep:200, loss:0.00001, loss_test:0.00871, lr:4.09e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.631, tt:6357.863\n",
      "Ep:201, loss:0.00001, loss_test:0.00862, lr:4.05e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.640, tt:6391.191\n",
      "Ep:202, loss:0.00001, loss_test:0.00852, lr:4.01e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.646, tt:6424.038\n",
      "Ep:203, loss:0.00001, loss_test:0.00866, lr:3.97e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.654, tt:6457.365\n",
      "Ep:204, loss:0.00001, loss_test:0.00857, lr:3.93e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.659, tt:6490.049\n",
      "Ep:205, loss:0.00001, loss_test:0.00838, lr:3.89e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.666, tt:6523.121\n",
      "Ep:206, loss:0.00001, loss_test:0.00849, lr:3.85e-03, fs:0.99065 (r=0.981,p=1.000),  time:31.667, tt:6555.036\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1954 Test samples: 108\n",
      "Train positive samples: 977 Test positive samples: 54\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14457, lr:1.00e-02, fs:0.65806 (r=0.944,p=0.505),  time:27.652, tt:27.652\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14256, lr:1.00e-02, fs:0.65806 (r=0.944,p=0.505),  time:30.376, tt:60.752\n",
      "Ep:2, loss:0.00027, loss_test:0.13916, lr:1.00e-02, fs:0.66225 (r=0.926,p=0.515),  time:32.333, tt:96.999\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.13535, lr:1.00e-02, fs:0.64789 (r=0.852,p=0.523),  time:33.376, tt:133.504\n",
      "Ep:4, loss:0.00026, loss_test:0.13129, lr:1.00e-02, fs:0.63309 (r=0.815,p=0.518),  time:34.149, tt:170.744\n",
      "Ep:5, loss:0.00025, loss_test:0.12832, lr:1.00e-02, fs:0.63704 (r=0.796,p=0.531),  time:33.869, tt:203.212\n",
      "Ep:6, loss:0.00024, loss_test:0.12446, lr:1.00e-02, fs:0.66154 (r=0.796,p=0.566),  time:34.147, tt:239.031\n",
      "Ep:7, loss:0.00024, loss_test:0.12009, lr:1.00e-02, fs:0.66667 (r=0.796,p=0.573),  time:34.335, tt:274.678\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11525, lr:1.00e-02, fs:0.66667 (r=0.778,p=0.583),  time:34.553, tt:310.973\n",
      "Ep:9, loss:0.00023, loss_test:0.11064, lr:1.00e-02, fs:0.68852 (r=0.778,p=0.618),  time:34.703, tt:347.035\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.10635, lr:1.00e-02, fs:0.74576 (r=0.815,p=0.688),  time:34.757, tt:382.322\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.10253, lr:1.00e-02, fs:0.75214 (r=0.815,p=0.698),  time:34.819, tt:417.831\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.09872, lr:1.00e-02, fs:0.76522 (r=0.815,p=0.721),  time:34.964, tt:454.533\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.09489, lr:1.00e-02, fs:0.77477 (r=0.796,p=0.754),  time:34.980, tt:489.721\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.09234, lr:1.00e-02, fs:0.74545 (r=0.759,p=0.732),  time:35.128, tt:526.914\n",
      "Ep:15, loss:0.00019, loss_test:0.08948, lr:1.00e-02, fs:0.75229 (r=0.759,p=0.745),  time:35.146, tt:562.332\n",
      "Ep:16, loss:0.00018, loss_test:0.08620, lr:1.00e-02, fs:0.76364 (r=0.778,p=0.750),  time:35.175, tt:597.980\n",
      "Ep:17, loss:0.00018, loss_test:0.08318, lr:1.00e-02, fs:0.75229 (r=0.759,p=0.745),  time:35.298, tt:635.360\n",
      "Ep:18, loss:0.00017, loss_test:0.08083, lr:1.00e-02, fs:0.76364 (r=0.778,p=0.750),  time:35.227, tt:669.320\n",
      "Ep:19, loss:0.00017, loss_test:0.07862, lr:1.00e-02, fs:0.78899 (r=0.796,p=0.782),  time:35.263, tt:705.264\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.07612, lr:1.00e-02, fs:0.80357 (r=0.833,p=0.776),  time:35.310, tt:741.500\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.07418, lr:1.00e-02, fs:0.82143 (r=0.852,p=0.793),  time:35.317, tt:776.979\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.07161, lr:1.00e-02, fs:0.83186 (r=0.870,p=0.797),  time:35.402, tt:814.253\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.06965, lr:1.00e-02, fs:0.83929 (r=0.870,p=0.810),  time:35.422, tt:850.137\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.06745, lr:1.00e-02, fs:0.86726 (r=0.907,p=0.831),  time:35.451, tt:886.265\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.06575, lr:1.00e-02, fs:0.88288 (r=0.907,p=0.860),  time:35.471, tt:922.254\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.06409, lr:1.00e-02, fs:0.88288 (r=0.907,p=0.860),  time:35.461, tt:957.448\n",
      "Ep:27, loss:0.00013, loss_test:0.06251, lr:1.00e-02, fs:0.91071 (r=0.944,p=0.879),  time:35.649, tt:998.172\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.06039, lr:1.00e-02, fs:0.90265 (r=0.944,p=0.864),  time:35.674, tt:1034.543\n",
      "Ep:29, loss:0.00012, loss_test:0.05904, lr:1.00e-02, fs:0.91892 (r=0.944,p=0.895),  time:35.718, tt:1071.530\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00012, loss_test:0.05701, lr:1.00e-02, fs:0.92035 (r=0.963,p=0.881),  time:35.751, tt:1108.296\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00011, loss_test:0.05582, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:35.759, tt:1144.295\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00011, loss_test:0.05286, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:35.765, tt:1180.255\n",
      "Ep:33, loss:0.00011, loss_test:0.05140, lr:1.00e-02, fs:0.93694 (r=0.963,p=0.912),  time:35.747, tt:1215.388\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.04924, lr:1.00e-02, fs:0.93805 (r=0.981,p=0.898),  time:35.761, tt:1251.652\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00010, loss_test:0.04838, lr:1.00e-02, fs:0.93694 (r=0.963,p=0.912),  time:35.803, tt:1288.904\n",
      "Ep:36, loss:0.00010, loss_test:0.04675, lr:1.00e-02, fs:0.95495 (r=0.981,p=0.930),  time:35.805, tt:1324.795\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00010, loss_test:0.04612, lr:1.00e-02, fs:0.93694 (r=0.963,p=0.912),  time:35.864, tt:1362.836\n",
      "Ep:38, loss:0.00009, loss_test:0.04625, lr:1.00e-02, fs:0.96364 (r=0.981,p=0.946),  time:35.838, tt:1397.697\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00009, loss_test:0.04287, lr:1.00e-02, fs:0.95495 (r=0.981,p=0.930),  time:35.875, tt:1434.999\n",
      "Ep:40, loss:0.00009, loss_test:0.04135, lr:1.00e-02, fs:0.96364 (r=0.981,p=0.946),  time:35.935, tt:1473.318\n",
      "Ep:41, loss:0.00008, loss_test:0.03986, lr:1.00e-02, fs:0.96364 (r=0.981,p=0.946),  time:35.974, tt:1510.908\n",
      "Ep:42, loss:0.00008, loss_test:0.03897, lr:1.00e-02, fs:0.96364 (r=0.981,p=0.946),  time:35.956, tt:1546.099\n",
      "Ep:43, loss:0.00008, loss_test:0.03880, lr:1.00e-02, fs:0.96364 (r=0.981,p=0.946),  time:35.960, tt:1582.240\n",
      "Ep:44, loss:0.00007, loss_test:0.03706, lr:1.00e-02, fs:0.97248 (r=0.981,p=0.964),  time:35.992, tt:1619.623\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00008, loss_test:0.03551, lr:1.00e-02, fs:0.95413 (r=0.963,p=0.945),  time:36.026, tt:1657.198\n",
      "Ep:46, loss:0.00007, loss_test:0.03800, lr:1.00e-02, fs:0.97248 (r=0.981,p=0.964),  time:36.024, tt:1693.112\n",
      "Ep:47, loss:0.00007, loss_test:0.03614, lr:1.00e-02, fs:0.96296 (r=0.963,p=0.963),  time:36.016, tt:1728.786\n",
      "Ep:48, loss:0.00007, loss_test:0.03618, lr:1.00e-02, fs:0.97248 (r=0.981,p=0.964),  time:36.023, tt:1765.106\n",
      "Ep:49, loss:0.00007, loss_test:0.03286, lr:1.00e-02, fs:0.97248 (r=0.981,p=0.964),  time:36.037, tt:1801.854\n",
      "Ep:50, loss:0.00006, loss_test:0.03346, lr:1.00e-02, fs:0.97248 (r=0.981,p=0.964),  time:36.045, tt:1838.317\n",
      "Ep:51, loss:0.00006, loss_test:0.03122, lr:1.00e-02, fs:0.97248 (r=0.981,p=0.964),  time:36.036, tt:1873.888\n",
      "Ep:52, loss:0.00006, loss_test:0.03033, lr:1.00e-02, fs:0.97248 (r=0.981,p=0.964),  time:36.024, tt:1909.283\n",
      "Ep:53, loss:0.00006, loss_test:0.02873, lr:1.00e-02, fs:0.97248 (r=0.981,p=0.964),  time:36.035, tt:1945.867\n",
      "Ep:54, loss:0.00006, loss_test:0.02837, lr:1.00e-02, fs:0.96364 (r=0.981,p=0.946),  time:36.026, tt:1981.422\n",
      "Ep:55, loss:0.00006, loss_test:0.03285, lr:1.00e-02, fs:0.97248 (r=0.981,p=0.964),  time:36.024, tt:2017.330\n",
      "Ep:56, loss:0.00006, loss_test:0.02778, lr:9.90e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.033, tt:2053.902\n",
      "Ep:57, loss:0.00005, loss_test:0.02846, lr:9.80e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.016, tt:2088.941\n",
      "Ep:58, loss:0.00005, loss_test:0.02593, lr:9.70e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.025, tt:2125.471\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00005, loss_test:0.02381, lr:9.70e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.048, tt:2234.982\n",
      "Ep:62, loss:0.00004, loss_test:0.02431, lr:9.70e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.035, tt:2270.236\n",
      "Ep:63, loss:0.00004, loss_test:0.02340, lr:9.70e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.025, tt:2305.625\n",
      "Ep:64, loss:0.00004, loss_test:0.02477, lr:9.70e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.075, tt:2344.857\n",
      "Ep:65, loss:0.00004, loss_test:0.02349, lr:9.70e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.057, tt:2379.741\n",
      "Ep:66, loss:0.00004, loss_test:0.02499, lr:9.70e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.079, tt:2417.296\n",
      "Ep:67, loss:0.00004, loss_test:0.02151, lr:9.70e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.082, tt:2453.591\n",
      "Ep:68, loss:0.00004, loss_test:0.02138, lr:9.70e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.083, tt:2489.730\n",
      "Ep:69, loss:0.00004, loss_test:0.02127, lr:9.70e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.087, tt:2526.117\n",
      "Ep:70, loss:0.00004, loss_test:0.02044, lr:9.61e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.089, tt:2562.333\n",
      "Ep:71, loss:0.00003, loss_test:0.02088, lr:9.51e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.110, tt:2599.889\n",
      "Ep:72, loss:0.00003, loss_test:0.01960, lr:9.41e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.090, tt:2634.605\n",
      "Ep:73, loss:0.00003, loss_test:0.02028, lr:9.32e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.126, tt:2673.349\n",
      "Ep:74, loss:0.00003, loss_test:0.01950, lr:9.23e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.134, tt:2710.055\n",
      "Ep:75, loss:0.00003, loss_test:0.02058, lr:9.14e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.119, tt:2745.054\n",
      "Ep:76, loss:0.00003, loss_test:0.01925, lr:9.04e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.127, tt:2781.786\n",
      "Ep:77, loss:0.00003, loss_test:0.01863, lr:8.95e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.125, tt:2817.742\n",
      "Ep:78, loss:0.00003, loss_test:0.01895, lr:8.86e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.116, tt:2853.165\n",
      "Ep:79, loss:0.00003, loss_test:0.01782, lr:8.78e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.117, tt:2889.337\n",
      "Ep:80, loss:0.00003, loss_test:0.01877, lr:8.69e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.109, tt:2924.868\n",
      "Ep:81, loss:0.00003, loss_test:0.01786, lr:8.60e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.119, tt:2961.729\n",
      "Ep:82, loss:0.00003, loss_test:0.01748, lr:8.51e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.111, tt:2997.200\n",
      "Ep:83, loss:0.00003, loss_test:0.01776, lr:8.43e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.087, tt:3031.288\n",
      "Ep:84, loss:0.00002, loss_test:0.01708, lr:8.35e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.080, tt:3066.807\n",
      "Ep:85, loss:0.00002, loss_test:0.01759, lr:8.26e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.086, tt:3103.365\n",
      "Ep:86, loss:0.00002, loss_test:0.01681, lr:8.18e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.069, tt:3137.963\n",
      "Ep:87, loss:0.00002, loss_test:0.01685, lr:8.10e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.070, tt:3174.125\n",
      "Ep:88, loss:0.00002, loss_test:0.01694, lr:8.02e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.063, tt:3209.568\n",
      "Ep:89, loss:0.00002, loss_test:0.01652, lr:7.94e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.053, tt:3244.772\n",
      "Ep:90, loss:0.00002, loss_test:0.01683, lr:7.86e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.042, tt:3279.791\n",
      "Ep:91, loss:0.00002, loss_test:0.01637, lr:7.78e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.040, tt:3315.722\n",
      "Ep:92, loss:0.00002, loss_test:0.01629, lr:7.70e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.032, tt:3350.938\n",
      "Ep:93, loss:0.00002, loss_test:0.01601, lr:7.62e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.012, tt:3385.162\n",
      "Ep:94, loss:0.00002, loss_test:0.01577, lr:7.55e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.019, tt:3421.807\n",
      "Ep:95, loss:0.00002, loss_test:0.01580, lr:7.47e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.017, tt:3457.654\n",
      "Ep:96, loss:0.00002, loss_test:0.01573, lr:7.40e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.027, tt:3494.661\n",
      "Ep:97, loss:0.00002, loss_test:0.01554, lr:7.32e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.036, tt:3531.565\n",
      "Ep:98, loss:0.00002, loss_test:0.01539, lr:7.25e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.020, tt:3565.984\n",
      "Ep:99, loss:0.00002, loss_test:0.01503, lr:7.18e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.013, tt:3601.327\n",
      "Ep:100, loss:0.00002, loss_test:0.01517, lr:7.11e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.030, tt:3639.051\n",
      "Ep:101, loss:0.00002, loss_test:0.01469, lr:7.03e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.028, tt:3674.850\n",
      "Ep:102, loss:0.00002, loss_test:0.01478, lr:6.96e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.035, tt:3711.602\n",
      "Ep:103, loss:0.00002, loss_test:0.01473, lr:6.89e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.032, tt:3747.377\n",
      "Ep:104, loss:0.00002, loss_test:0.01455, lr:6.83e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.029, tt:3783.066\n",
      "Ep:105, loss:0.00002, loss_test:0.01468, lr:6.76e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.045, tt:3820.785\n",
      "Ep:106, loss:0.00002, loss_test:0.01432, lr:6.69e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.053, tt:3857.640\n",
      "Ep:107, loss:0.00002, loss_test:0.01459, lr:6.62e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.040, tt:3892.370\n",
      "Ep:108, loss:0.00002, loss_test:0.01419, lr:6.56e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.047, tt:3929.113\n",
      "Ep:109, loss:0.00002, loss_test:0.01419, lr:6.49e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.011, tt:3961.252\n",
      "Ep:110, loss:0.00002, loss_test:0.01411, lr:6.43e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.985, tt:3994.368\n",
      "Ep:111, loss:0.00002, loss_test:0.01402, lr:6.36e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.959, tt:4027.447\n",
      "Ep:112, loss:0.00002, loss_test:0.01419, lr:6.30e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.954, tt:4062.757\n",
      "Ep:113, loss:0.00001, loss_test:0.01402, lr:6.24e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.950, tt:4098.281\n",
      "Ep:114, loss:0.00001, loss_test:0.01386, lr:6.17e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.948, tt:4133.987\n",
      "Ep:115, loss:0.00001, loss_test:0.01368, lr:6.11e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.938, tt:4168.770\n",
      "Ep:116, loss:0.00001, loss_test:0.01378, lr:6.05e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.936, tt:4204.501\n",
      "Ep:117, loss:0.00001, loss_test:0.01360, lr:5.99e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.927, tt:4239.380\n",
      "Ep:118, loss:0.00001, loss_test:0.01368, lr:5.93e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.918, tt:4274.220\n",
      "Ep:119, loss:0.00001, loss_test:0.01355, lr:5.87e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.912, tt:4309.479\n",
      "Ep:120, loss:0.00001, loss_test:0.01355, lr:5.81e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.920, tt:4346.283\n",
      "Ep:121, loss:0.00001, loss_test:0.01356, lr:5.75e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.923, tt:4382.568\n",
      "Ep:122, loss:0.00001, loss_test:0.01337, lr:5.70e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.933, tt:4419.804\n",
      "Ep:123, loss:0.00001, loss_test:0.01365, lr:5.64e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.940, tt:4456.539\n",
      "Ep:124, loss:0.00001, loss_test:0.01316, lr:5.58e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.937, tt:4492.163\n",
      "Ep:125, loss:0.00001, loss_test:0.01333, lr:5.53e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.937, tt:4528.060\n",
      "Ep:126, loss:0.00001, loss_test:0.01315, lr:5.47e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.924, tt:4562.327\n",
      "Ep:127, loss:0.00001, loss_test:0.01313, lr:5.42e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.909, tt:4596.398\n",
      "Ep:128, loss:0.00001, loss_test:0.01330, lr:5.36e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.905, tt:4631.709\n",
      "Ep:129, loss:0.00001, loss_test:0.01316, lr:5.31e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.901, tt:4667.163\n",
      "Ep:130, loss:0.00001, loss_test:0.01305, lr:5.26e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.894, tt:4702.157\n",
      "Ep:131, loss:0.00001, loss_test:0.01295, lr:5.20e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.881, tt:4736.321\n",
      "Ep:132, loss:0.00001, loss_test:0.01301, lr:5.15e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.870, tt:4770.772\n",
      "Ep:133, loss:0.00001, loss_test:0.01287, lr:5.10e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.864, tt:4805.747\n",
      "Ep:134, loss:0.00001, loss_test:0.01316, lr:5.05e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.857, tt:4840.722\n",
      "Ep:135, loss:0.00001, loss_test:0.01275, lr:5.00e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.853, tt:4875.943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:136, loss:0.00001, loss_test:0.01317, lr:4.95e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.847, tt:4911.051\n",
      "Ep:137, loss:0.00001, loss_test:0.01267, lr:4.90e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.852, tt:4947.601\n",
      "Ep:138, loss:0.00001, loss_test:0.01287, lr:4.85e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.883, tt:4987.676\n",
      "Ep:139, loss:0.00001, loss_test:0.01263, lr:4.80e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.888, tt:5024.331\n",
      "Ep:140, loss:0.00001, loss_test:0.01273, lr:4.75e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.895, tt:5061.125\n",
      "Ep:141, loss:0.00001, loss_test:0.01253, lr:4.71e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.887, tt:5095.924\n",
      "Ep:142, loss:0.00001, loss_test:0.01264, lr:4.66e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.877, tt:5130.419\n",
      "Ep:143, loss:0.00001, loss_test:0.01256, lr:4.61e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.887, tt:5167.751\n",
      "Ep:144, loss:0.00001, loss_test:0.01254, lr:4.57e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.894, tt:5204.679\n",
      "Ep:145, loss:0.00001, loss_test:0.01237, lr:4.52e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.888, tt:5239.666\n",
      "Ep:146, loss:0.00001, loss_test:0.01245, lr:4.48e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.902, tt:5277.536\n",
      "Ep:147, loss:0.00001, loss_test:0.01253, lr:4.43e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.880, tt:5310.218\n",
      "Ep:148, loss:0.00001, loss_test:0.01225, lr:4.39e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.864, tt:5343.733\n",
      "Ep:149, loss:0.00001, loss_test:0.01235, lr:4.34e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.852, tt:5377.788\n",
      "Ep:150, loss:0.00001, loss_test:0.01239, lr:4.30e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.846, tt:5412.701\n",
      "Ep:151, loss:0.00001, loss_test:0.01237, lr:4.26e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.848, tt:5448.961\n",
      "Ep:152, loss:0.00001, loss_test:0.01239, lr:4.21e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.842, tt:5483.840\n",
      "Ep:153, loss:0.00001, loss_test:0.01222, lr:4.17e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.827, tt:5517.288\n",
      "Ep:154, loss:0.00001, loss_test:0.01236, lr:4.13e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.832, tt:5553.927\n",
      "Ep:155, loss:0.00001, loss_test:0.01228, lr:4.09e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.835, tt:5590.211\n",
      "Ep:156, loss:0.00001, loss_test:0.01243, lr:4.05e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.825, tt:5624.583\n",
      "Ep:157, loss:0.00001, loss_test:0.01225, lr:4.01e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.826, tt:5660.456\n",
      "Ep:158, loss:0.00001, loss_test:0.01229, lr:3.97e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.827, tt:5696.568\n",
      "Ep:159, loss:0.00001, loss_test:0.01203, lr:3.93e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.827, tt:5732.390\n",
      "Ep:160, loss:0.00001, loss_test:0.01228, lr:3.89e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.832, tt:5768.943\n",
      "Ep:161, loss:0.00001, loss_test:0.01209, lr:3.85e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.832, tt:5804.834\n",
      "Ep:162, loss:0.00001, loss_test:0.01213, lr:3.81e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.841, tt:5842.040\n",
      "Ep:163, loss:0.00001, loss_test:0.01220, lr:3.77e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.838, tt:5877.452\n",
      "Ep:164, loss:0.00001, loss_test:0.01218, lr:3.73e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.838, tt:5913.236\n",
      "Ep:165, loss:0.00001, loss_test:0.01220, lr:3.70e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.825, tt:5947.029\n",
      "Ep:166, loss:0.00001, loss_test:0.01220, lr:3.66e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.829, tt:5983.396\n",
      "Ep:167, loss:0.00001, loss_test:0.01195, lr:3.62e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.822, tt:6018.175\n",
      "Ep:168, loss:0.00001, loss_test:0.01225, lr:3.59e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.820, tt:6053.547\n",
      "Ep:169, loss:0.00001, loss_test:0.01197, lr:3.55e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.819, tt:6089.193\n",
      "Ep:170, loss:0.00001, loss_test:0.01210, lr:3.52e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.817, tt:6124.684\n",
      "Ep:171, loss:0.00001, loss_test:0.01212, lr:3.48e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.815, tt:6160.243\n",
      "Ep:172, loss:0.00001, loss_test:0.01202, lr:3.45e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.811, tt:6195.375\n",
      "Ep:173, loss:0.00001, loss_test:0.01204, lr:3.41e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.804, tt:6229.982\n",
      "Ep:174, loss:0.00001, loss_test:0.01201, lr:3.38e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.790, tt:6263.260\n",
      "Ep:175, loss:0.00001, loss_test:0.01199, lr:3.34e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.794, tt:6299.700\n",
      "Ep:176, loss:0.00001, loss_test:0.01196, lr:3.31e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.780, tt:6333.103\n",
      "Ep:177, loss:0.00001, loss_test:0.01204, lr:3.28e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.771, tt:6367.294\n",
      "Ep:178, loss:0.00001, loss_test:0.01195, lr:3.24e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.775, tt:6403.749\n",
      "Ep:179, loss:0.00001, loss_test:0.01201, lr:3.21e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.767, tt:6438.044\n",
      "Ep:180, loss:0.00001, loss_test:0.01183, lr:3.18e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.761, tt:6472.650\n",
      "Ep:181, loss:0.00001, loss_test:0.01216, lr:3.15e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.763, tt:6508.789\n",
      "Ep:182, loss:0.00001, loss_test:0.01170, lr:3.12e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.758, tt:6543.675\n",
      "Ep:183, loss:0.00001, loss_test:0.01190, lr:3.09e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.755, tt:6578.997\n",
      "Ep:184, loss:0.00001, loss_test:0.01195, lr:3.05e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.758, tt:6615.147\n",
      "Ep:185, loss:0.00001, loss_test:0.01180, lr:3.02e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.753, tt:6650.015\n",
      "Ep:186, loss:0.00001, loss_test:0.01186, lr:2.99e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.756, tt:6686.330\n",
      "Ep:187, loss:0.00001, loss_test:0.01179, lr:2.96e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.754, tt:6721.786\n",
      "Ep:188, loss:0.00001, loss_test:0.01175, lr:2.93e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.760, tt:6758.718\n",
      "Ep:189, loss:0.00001, loss_test:0.01183, lr:2.90e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.761, tt:6794.498\n",
      "Ep:190, loss:0.00001, loss_test:0.01180, lr:2.88e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.767, tt:6831.541\n",
      "Ep:191, loss:0.00001, loss_test:0.01174, lr:2.85e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.760, tt:6865.920\n",
      "Ep:192, loss:0.00001, loss_test:0.01173, lr:2.82e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.763, tt:6902.311\n",
      "Ep:193, loss:0.00001, loss_test:0.01195, lr:2.79e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.763, tt:6938.063\n",
      "Ep:194, loss:0.00001, loss_test:0.01154, lr:2.76e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.768, tt:6974.687\n",
      "Ep:195, loss:0.00001, loss_test:0.01173, lr:2.73e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.774, tt:7011.743\n",
      "Ep:196, loss:0.00001, loss_test:0.01160, lr:2.71e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.774, tt:7047.498\n",
      "Ep:197, loss:0.00001, loss_test:0.01141, lr:2.68e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.786, tt:7085.625\n",
      "Ep:198, loss:0.00001, loss_test:0.01207, lr:2.65e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.787, tt:7121.661\n",
      "Ep:199, loss:0.00001, loss_test:0.01162, lr:2.63e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.794, tt:7158.721\n",
      "Ep:200, loss:0.00001, loss_test:0.01164, lr:2.60e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.796, tt:7194.972\n",
      "Ep:201, loss:0.00001, loss_test:0.01178, lr:2.57e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.805, tt:7232.519\n",
      "Ep:202, loss:0.00001, loss_test:0.01160, lr:2.55e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.801, tt:7267.522\n",
      "Ep:203, loss:0.00001, loss_test:0.01180, lr:2.52e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.803, tt:7303.713\n",
      "Ep:204, loss:0.00001, loss_test:0.01151, lr:2.50e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.800, tt:7339.000\n",
      "Ep:205, loss:0.00001, loss_test:0.01149, lr:2.47e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.783, tt:7371.316\n",
      "Ep:206, loss:0.00001, loss_test:0.01176, lr:2.45e-03, fs:0.98148 (r=0.981,p=0.981),  time:35.694, tt:7388.579\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1954 Test samples: 108\n",
      "Train positive samples: 977 Test positive samples: 54\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00011, loss_test:0.03033, lr:6.00e-02, fs:0.60317 (r=0.704,p=0.528),  time:35.259, tt:35.259\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02557, lr:6.00e-02, fs:0.68000 (r=0.944,p=0.531),  time:34.742, tt:69.485\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02691, lr:6.00e-02, fs:0.65409 (r=0.963,p=0.495),  time:34.265, tt:102.796\n",
      "Ep:3, loss:0.00005, loss_test:0.02725, lr:6.00e-02, fs:0.65385 (r=0.944,p=0.500),  time:33.374, tt:133.495\n",
      "Ep:4, loss:0.00005, loss_test:0.02725, lr:6.00e-02, fs:0.65385 (r=0.944,p=0.500),  time:33.412, tt:167.060\n",
      "Ep:5, loss:0.00005, loss_test:0.02710, lr:6.00e-02, fs:0.66667 (r=0.926,p=0.521),  time:33.467, tt:200.803\n",
      "Ep:6, loss:0.00005, loss_test:0.02685, lr:6.00e-02, fs:0.66667 (r=0.907,p=0.527),  time:33.635, tt:235.446\n",
      "Ep:7, loss:0.00005, loss_test:0.02648, lr:6.00e-02, fs:0.66667 (r=0.889,p=0.533),  time:33.860, tt:270.878\n",
      "Ep:8, loss:0.00005, loss_test:0.02586, lr:6.00e-02, fs:0.66667 (r=0.889,p=0.533),  time:33.939, tt:305.450\n",
      "Ep:9, loss:0.00005, loss_test:0.02505, lr:6.00e-02, fs:0.66207 (r=0.889,p=0.527),  time:34.170, tt:341.700\n",
      "Ep:10, loss:0.00005, loss_test:0.02424, lr:6.00e-02, fs:0.65753 (r=0.889,p=0.522),  time:34.226, tt:376.485\n",
      "Ep:11, loss:0.00005, loss_test:0.02336, lr:6.00e-02, fs:0.67568 (r=0.926,p=0.532),  time:34.218, tt:410.618\n",
      "Ep:12, loss:0.00005, loss_test:0.02241, lr:6.00e-02, fs:0.68493 (r=0.926,p=0.543),  time:34.249, tt:445.241\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.02162, lr:6.00e-02, fs:0.67143 (r=0.870,p=0.547),  time:34.282, tt:479.946\n",
      "Ep:14, loss:0.00004, loss_test:0.02106, lr:6.00e-02, fs:0.67153 (r=0.852,p=0.554),  time:34.373, tt:515.600\n",
      "Ep:15, loss:0.00004, loss_test:0.02051, lr:6.00e-02, fs:0.70073 (r=0.889,p=0.578),  time:34.447, tt:551.157\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.02003, lr:6.00e-02, fs:0.70588 (r=0.889,p=0.585),  time:34.455, tt:585.729\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.01966, lr:6.00e-02, fs:0.69504 (r=0.907,p=0.563),  time:34.516, tt:621.293\n",
      "Ep:18, loss:0.00004, loss_test:0.01930, lr:6.00e-02, fs:0.70504 (r=0.907,p=0.576),  time:34.555, tt:656.553\n",
      "Ep:19, loss:0.00004, loss_test:0.01889, lr:6.00e-02, fs:0.72059 (r=0.907,p=0.598),  time:34.664, tt:693.285\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00004, loss_test:0.01851, lr:6.00e-02, fs:0.73684 (r=0.907,p=0.620),  time:34.694, tt:728.582\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00004, loss_test:0.01809, lr:6.00e-02, fs:0.73684 (r=0.907,p=0.620),  time:34.667, tt:762.685\n",
      "Ep:22, loss:0.00004, loss_test:0.01770, lr:6.00e-02, fs:0.74809 (r=0.907,p=0.636),  time:34.646, tt:796.848\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00004, loss_test:0.01729, lr:6.00e-02, fs:0.76923 (r=0.926,p=0.658),  time:34.716, tt:833.188\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00004, loss_test:0.01690, lr:6.00e-02, fs:0.76336 (r=0.926,p=0.649),  time:34.731, tt:868.268\n",
      "Ep:25, loss:0.00004, loss_test:0.01646, lr:6.00e-02, fs:0.75758 (r=0.926,p=0.641),  time:34.728, tt:902.928\n",
      "Ep:26, loss:0.00003, loss_test:0.01609, lr:6.00e-02, fs:0.77519 (r=0.926,p=0.667),  time:34.667, tt:936.000\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01578, lr:6.00e-02, fs:0.77863 (r=0.944,p=0.662),  time:34.660, tt:970.471\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01540, lr:6.00e-02, fs:0.79389 (r=0.963,p=0.675),  time:34.630, tt:1004.272\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01502, lr:6.00e-02, fs:0.80620 (r=0.963,p=0.693),  time:34.586, tt:1037.568\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01469, lr:6.00e-02, fs:0.81250 (r=0.963,p=0.703),  time:34.546, tt:1070.914\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01437, lr:6.00e-02, fs:0.80620 (r=0.963,p=0.693),  time:34.537, tt:1105.191\n",
      "Ep:32, loss:0.00003, loss_test:0.01400, lr:6.00e-02, fs:0.82813 (r=0.981,p=0.716),  time:34.570, tt:1140.823\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01367, lr:6.00e-02, fs:0.82171 (r=0.981,p=0.707),  time:34.574, tt:1175.526\n",
      "Ep:34, loss:0.00003, loss_test:0.01342, lr:6.00e-02, fs:0.80916 (r=0.981,p=0.688),  time:34.636, tt:1212.273\n",
      "Ep:35, loss:0.00003, loss_test:0.01306, lr:6.00e-02, fs:0.80620 (r=0.963,p=0.693),  time:34.623, tt:1246.412\n",
      "Ep:36, loss:0.00003, loss_test:0.01269, lr:6.00e-02, fs:0.80620 (r=0.963,p=0.693),  time:34.630, tt:1281.309\n",
      "Ep:37, loss:0.00003, loss_test:0.01230, lr:6.00e-02, fs:0.81250 (r=0.963,p=0.703),  time:34.623, tt:1315.658\n",
      "Ep:38, loss:0.00002, loss_test:0.01191, lr:6.00e-02, fs:0.81890 (r=0.963,p=0.712),  time:34.643, tt:1351.059\n",
      "Ep:39, loss:0.00002, loss_test:0.01162, lr:6.00e-02, fs:0.81890 (r=0.963,p=0.712),  time:34.646, tt:1385.851\n",
      "Ep:40, loss:0.00002, loss_test:0.01137, lr:6.00e-02, fs:0.82540 (r=0.963,p=0.722),  time:34.625, tt:1419.630\n",
      "Ep:41, loss:0.00002, loss_test:0.01104, lr:6.00e-02, fs:0.83871 (r=0.963,p=0.743),  time:34.664, tt:1455.878\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01073, lr:6.00e-02, fs:0.83871 (r=0.963,p=0.743),  time:34.676, tt:1491.059\n",
      "Ep:43, loss:0.00002, loss_test:0.01046, lr:6.00e-02, fs:0.82540 (r=0.963,p=0.722),  time:34.684, tt:1526.082\n",
      "Ep:44, loss:0.00002, loss_test:0.01005, lr:6.00e-02, fs:0.85246 (r=0.963,p=0.765),  time:34.699, tt:1561.442\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.00978, lr:6.00e-02, fs:0.86885 (r=0.981,p=0.779),  time:34.707, tt:1596.512\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.00937, lr:6.00e-02, fs:0.87603 (r=0.981,p=0.791),  time:34.681, tt:1630.008\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.00908, lr:6.00e-02, fs:0.87603 (r=0.981,p=0.791),  time:34.712, tt:1666.172\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6913c0e69143>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.3+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m207\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0;31m#loss.backward(retain_graph=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum_buffer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                         \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00009, loss_test:0.02359, lr:6.00e-02, fs:0.66122 (r=0.818,p=0.555),  time:19.815, tt:19.815\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02508, lr:6.00e-02, fs:0.67354 (r=0.990,p=0.510),  time:22.920, tt:45.841\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02713, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:25.379, tt:76.137\n",
      "Ep:3, loss:0.00005, loss_test:0.02698, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:26.514, tt:106.057\n",
      "Ep:4, loss:0.00005, loss_test:0.02638, lr:6.00e-02, fs:0.66897 (r=0.980,p=0.508),  time:27.549, tt:137.746\n",
      "Ep:5, loss:0.00005, loss_test:0.02546, lr:6.00e-02, fs:0.67368 (r=0.970,p=0.516),  time:28.046, tt:168.277\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00005, loss_test:0.02454, lr:6.00e-02, fs:0.65934 (r=0.909,p=0.517),  time:28.346, tt:198.424\n",
      "Ep:7, loss:0.00005, loss_test:0.02388, lr:6.00e-02, fs:0.65683 (r=0.899,p=0.517),  time:28.331, tt:226.644\n",
      "Ep:8, loss:0.00005, loss_test:0.02330, lr:6.00e-02, fs:0.65693 (r=0.909,p=0.514),  time:28.503, tt:256.523\n",
      "Ep:9, loss:0.00005, loss_test:0.02269, lr:6.00e-02, fs:0.68085 (r=0.970,p=0.525),  time:28.567, tt:285.671\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.02182, lr:6.00e-02, fs:0.67870 (r=0.949,p=0.528),  time:28.661, tt:315.276\n",
      "Ep:11, loss:0.00004, loss_test:0.02095, lr:6.00e-02, fs:0.69118 (r=0.949,p=0.543),  time:28.794, tt:345.524\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.02036, lr:6.00e-02, fs:0.69231 (r=0.909,p=0.559),  time:28.950, tt:376.344\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01991, lr:6.00e-02, fs:0.68966 (r=0.909,p=0.556),  time:28.988, tt:405.825\n",
      "Ep:14, loss:0.00004, loss_test:0.01956, lr:6.00e-02, fs:0.68939 (r=0.919,p=0.552),  time:28.987, tt:434.803\n",
      "Ep:15, loss:0.00004, loss_test:0.01919, lr:6.00e-02, fs:0.69403 (r=0.939,p=0.550),  time:29.051, tt:464.816\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.01865, lr:6.00e-02, fs:0.70722 (r=0.939,p=0.567),  time:29.074, tt:494.266\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.01821, lr:6.00e-02, fs:0.70312 (r=0.909,p=0.573),  time:29.200, tt:525.603\n",
      "Ep:18, loss:0.00004, loss_test:0.01783, lr:6.00e-02, fs:0.71146 (r=0.909,p=0.584),  time:29.271, tt:556.147\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01751, lr:6.00e-02, fs:0.71937 (r=0.919,p=0.591),  time:29.442, tt:588.849\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01724, lr:6.00e-02, fs:0.72510 (r=0.919,p=0.599),  time:29.506, tt:619.626\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01693, lr:6.00e-02, fs:0.73770 (r=0.909,p=0.621),  time:29.537, tt:649.807\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01665, lr:6.00e-02, fs:0.74590 (r=0.919,p=0.628),  time:29.542, tt:679.464\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01633, lr:6.00e-02, fs:0.76349 (r=0.929,p=0.648),  time:29.592, tt:710.211\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01590, lr:6.00e-02, fs:0.76349 (r=0.929,p=0.648),  time:29.606, tt:740.139\n",
      "Ep:25, loss:0.00003, loss_test:0.01548, lr:6.00e-02, fs:0.77637 (r=0.929,p=0.667),  time:29.558, tt:768.512\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01505, lr:6.00e-02, fs:0.78298 (r=0.929,p=0.676),  time:29.640, tt:800.284\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01470, lr:6.00e-02, fs:0.78298 (r=0.929,p=0.676),  time:29.658, tt:830.436\n",
      "Ep:28, loss:0.00003, loss_test:0.01429, lr:6.00e-02, fs:0.79149 (r=0.939,p=0.684),  time:29.681, tt:860.745\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01394, lr:6.00e-02, fs:0.80000 (r=0.949,p=0.691),  time:29.710, tt:891.298\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01367, lr:6.00e-02, fs:0.80508 (r=0.960,p=0.693),  time:29.787, tt:923.412\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01337, lr:6.00e-02, fs:0.80851 (r=0.960,p=0.699),  time:29.841, tt:954.908\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01325, lr:6.00e-02, fs:0.81385 (r=0.949,p=0.712),  time:29.845, tt:984.897\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01305, lr:6.00e-02, fs:0.82251 (r=0.960,p=0.720),  time:29.852, tt:1014.973\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01262, lr:6.00e-02, fs:0.83262 (r=0.980,p=0.724),  time:29.885, tt:1045.961\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01226, lr:6.00e-02, fs:0.83983 (r=0.980,p=0.735),  time:29.938, tt:1077.785\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01199, lr:6.00e-02, fs:0.84348 (r=0.980,p=0.740),  time:29.961, tt:1108.549\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01179, lr:6.00e-02, fs:0.84716 (r=0.980,p=0.746),  time:29.975, tt:1139.050\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01164, lr:6.00e-02, fs:0.84716 (r=0.980,p=0.746),  time:29.992, tt:1169.707\n",
      "Ep:39, loss:0.00002, loss_test:0.01134, lr:6.00e-02, fs:0.85965 (r=0.990,p=0.760),  time:30.000, tt:1199.981\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01112, lr:6.00e-02, fs:0.85463 (r=0.980,p=0.758),  time:30.041, tt:1231.684\n",
      "Ep:41, loss:0.00002, loss_test:0.01100, lr:6.00e-02, fs:0.85965 (r=0.990,p=0.760),  time:30.048, tt:1262.004\n",
      "Ep:42, loss:0.00001, loss_test:0.01071, lr:6.00e-02, fs:0.85965 (r=0.990,p=0.760),  time:30.082, tt:1293.538\n",
      "Ep:43, loss:0.00001, loss_test:0.01057, lr:6.00e-02, fs:0.86726 (r=0.990,p=0.772),  time:30.085, tt:1323.754\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00001, loss_test:0.01032, lr:6.00e-02, fs:0.86726 (r=0.990,p=0.772),  time:30.116, tt:1355.234\n",
      "Ep:45, loss:0.00001, loss_test:0.01021, lr:6.00e-02, fs:0.87111 (r=0.990,p=0.778),  time:30.138, tt:1386.349\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.00986, lr:6.00e-02, fs:0.88288 (r=0.990,p=0.797),  time:30.162, tt:1417.631\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.00981, lr:6.00e-02, fs:0.89091 (r=0.990,p=0.810),  time:30.185, tt:1448.885\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.00949, lr:6.00e-02, fs:0.89091 (r=0.990,p=0.810),  time:30.218, tt:1480.706\n",
      "Ep:49, loss:0.00001, loss_test:0.00931, lr:6.00e-02, fs:0.90323 (r=0.990,p=0.831),  time:30.222, tt:1511.096\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.00913, lr:6.00e-02, fs:0.89908 (r=0.990,p=0.824),  time:30.218, tt:1541.124\n",
      "Ep:51, loss:0.00001, loss_test:0.00910, lr:6.00e-02, fs:0.89908 (r=0.990,p=0.824),  time:30.210, tt:1570.942\n",
      "Ep:52, loss:0.00001, loss_test:0.00885, lr:6.00e-02, fs:0.89908 (r=0.990,p=0.824),  time:30.198, tt:1600.508\n",
      "Ep:53, loss:0.00001, loss_test:0.00880, lr:6.00e-02, fs:0.90741 (r=0.990,p=0.838),  time:30.212, tt:1631.464\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.00848, lr:6.00e-02, fs:0.91244 (r=1.000,p=0.839),  time:30.220, tt:1662.085\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.00850, lr:6.00e-02, fs:0.90323 (r=0.990,p=0.831),  time:30.225, tt:1692.603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:56, loss:0.00001, loss_test:0.00865, lr:6.00e-02, fs:0.89720 (r=0.970,p=0.835),  time:30.242, tt:1723.794\n",
      "Ep:57, loss:0.00001, loss_test:0.00829, lr:6.00e-02, fs:0.92453 (r=0.990,p=0.867),  time:30.261, tt:1755.117\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.00838, lr:6.00e-02, fs:0.90826 (r=1.000,p=0.832),  time:30.285, tt:1786.817\n",
      "Ep:59, loss:0.00001, loss_test:0.00906, lr:6.00e-02, fs:0.90233 (r=0.980,p=0.836),  time:30.295, tt:1817.699\n",
      "Ep:60, loss:0.00001, loss_test:0.00790, lr:6.00e-02, fs:0.92453 (r=0.990,p=0.867),  time:30.314, tt:1849.153\n",
      "Ep:61, loss:0.00001, loss_test:0.00798, lr:6.00e-02, fs:0.90741 (r=0.990,p=0.838),  time:30.320, tt:1879.825\n",
      "Ep:62, loss:0.00001, loss_test:0.00810, lr:6.00e-02, fs:0.90233 (r=0.980,p=0.836),  time:30.327, tt:1910.583\n",
      "Ep:63, loss:0.00001, loss_test:0.00794, lr:6.00e-02, fs:0.91080 (r=0.980,p=0.851),  time:30.330, tt:1941.123\n",
      "Ep:64, loss:0.00001, loss_test:0.00790, lr:6.00e-02, fs:0.93780 (r=0.990,p=0.891),  time:30.351, tt:1972.828\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.00794, lr:6.00e-02, fs:0.90047 (r=0.960,p=0.848),  time:30.370, tt:2004.406\n",
      "Ep:66, loss:0.00001, loss_test:0.00861, lr:6.00e-02, fs:0.88263 (r=0.949,p=0.825),  time:30.381, tt:2035.503\n",
      "Ep:67, loss:0.00001, loss_test:0.00857, lr:6.00e-02, fs:0.92537 (r=0.939,p=0.912),  time:30.375, tt:2065.478\n",
      "Ep:68, loss:0.00001, loss_test:0.00831, lr:6.00e-02, fs:0.86878 (r=0.970,p=0.787),  time:30.374, tt:2095.772\n",
      "Ep:69, loss:0.00001, loss_test:0.00764, lr:6.00e-02, fs:0.94737 (r=1.000,p=0.900),  time:30.368, tt:2125.728\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.00860, lr:6.00e-02, fs:0.89302 (r=0.970,p=0.828),  time:30.363, tt:2155.773\n",
      "Ep:71, loss:0.00001, loss_test:0.00746, lr:6.00e-02, fs:0.94686 (r=0.990,p=0.907),  time:30.364, tt:2186.183\n",
      "Ep:72, loss:0.00001, loss_test:0.00832, lr:6.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:30.371, tt:2217.087\n",
      "Ep:73, loss:0.00001, loss_test:0.00759, lr:6.00e-02, fs:0.94286 (r=1.000,p=0.892),  time:30.388, tt:2248.738\n",
      "Ep:74, loss:0.00001, loss_test:0.00787, lr:6.00e-02, fs:0.90909 (r=0.960,p=0.864),  time:30.384, tt:2278.793\n",
      "Ep:75, loss:0.00001, loss_test:0.00776, lr:6.00e-02, fs:0.96117 (r=1.000,p=0.925),  time:30.368, tt:2307.962\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.00831, lr:6.00e-02, fs:0.92611 (r=0.949,p=0.904),  time:30.366, tt:2338.148\n",
      "Ep:77, loss:0.00001, loss_test:0.00754, lr:6.00e-02, fs:0.94118 (r=0.970,p=0.914),  time:30.372, tt:2368.980\n",
      "Ep:78, loss:0.00000, loss_test:0.00846, lr:6.00e-02, fs:0.91542 (r=0.929,p=0.902),  time:30.385, tt:2400.430\n",
      "Ep:79, loss:0.00000, loss_test:0.00754, lr:6.00e-02, fs:0.94581 (r=0.970,p=0.923),  time:30.381, tt:2430.483\n",
      "Ep:80, loss:0.00000, loss_test:0.00817, lr:6.00e-02, fs:0.92000 (r=0.929,p=0.911),  time:30.389, tt:2461.545\n",
      "Ep:81, loss:0.00000, loss_test:0.00798, lr:6.00e-02, fs:0.93532 (r=0.949,p=0.922),  time:30.396, tt:2492.504\n",
      "Ep:82, loss:0.00000, loss_test:0.00756, lr:6.00e-02, fs:0.92611 (r=0.949,p=0.904),  time:30.404, tt:2523.534\n",
      "Ep:83, loss:0.00000, loss_test:0.00807, lr:6.00e-02, fs:0.94000 (r=0.949,p=0.931),  time:30.420, tt:2555.269\n",
      "Ep:84, loss:0.00000, loss_test:0.00754, lr:6.00e-02, fs:0.93532 (r=0.949,p=0.922),  time:30.441, tt:2587.492\n",
      "Ep:85, loss:0.00000, loss_test:0.00789, lr:6.00e-02, fs:0.93467 (r=0.939,p=0.930),  time:30.456, tt:2619.207\n",
      "Ep:86, loss:0.00000, loss_test:0.00792, lr:6.00e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.471, tt:2651.021\n",
      "Ep:87, loss:0.00000, loss_test:0.00803, lr:5.94e-02, fs:0.92000 (r=0.929,p=0.911),  time:30.451, tt:2679.670\n",
      "Ep:88, loss:0.00000, loss_test:0.00837, lr:5.88e-02, fs:0.94527 (r=0.960,p=0.931),  time:30.452, tt:2710.201\n",
      "Ep:89, loss:0.00000, loss_test:0.00810, lr:5.82e-02, fs:0.93401 (r=0.929,p=0.939),  time:30.471, tt:2742.397\n",
      "Ep:90, loss:0.00000, loss_test:0.00820, lr:5.76e-02, fs:0.93467 (r=0.939,p=0.930),  time:30.471, tt:2772.827\n",
      "Ep:91, loss:0.00000, loss_test:0.00838, lr:5.71e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.485, tt:2804.603\n",
      "Ep:92, loss:0.00000, loss_test:0.00820, lr:5.65e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.510, tt:2837.459\n",
      "Ep:93, loss:0.00000, loss_test:0.00844, lr:5.59e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.512, tt:2868.121\n",
      "Ep:94, loss:0.00000, loss_test:0.00850, lr:5.54e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.528, tt:2900.125\n",
      "Ep:95, loss:0.00000, loss_test:0.00857, lr:5.48e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.534, tt:2931.288\n",
      "Ep:96, loss:0.00000, loss_test:0.00863, lr:5.43e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.536, tt:2962.035\n",
      "Ep:97, loss:0.00000, loss_test:0.00843, lr:5.37e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.548, tt:2993.710\n",
      "Ep:98, loss:0.00000, loss_test:0.00891, lr:5.32e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.559, tt:3025.334\n",
      "Ep:99, loss:0.00000, loss_test:0.00853, lr:5.27e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.571, tt:3057.138\n",
      "Ep:100, loss:0.00000, loss_test:0.00893, lr:5.21e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.575, tt:3088.038\n",
      "Ep:101, loss:0.00000, loss_test:0.00876, lr:5.16e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.590, tt:3120.173\n",
      "Ep:102, loss:0.00000, loss_test:0.00878, lr:5.11e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.571, tt:3148.808\n",
      "Ep:103, loss:0.00000, loss_test:0.00895, lr:5.06e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.556, tt:3177.810\n",
      "Ep:104, loss:0.00000, loss_test:0.00882, lr:5.01e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.571, tt:3209.965\n",
      "Ep:105, loss:0.00000, loss_test:0.00886, lr:4.96e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.575, tt:3240.980\n",
      "Ep:106, loss:0.00000, loss_test:0.00893, lr:4.91e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.584, tt:3272.447\n",
      "Ep:107, loss:0.00000, loss_test:0.00893, lr:4.86e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.599, tt:3304.641\n",
      "Ep:108, loss:0.00000, loss_test:0.00909, lr:4.81e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.619, tt:3337.453\n",
      "Ep:109, loss:0.00000, loss_test:0.00907, lr:4.76e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.622, tt:3368.444\n",
      "Ep:110, loss:0.00000, loss_test:0.00918, lr:4.71e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.632, tt:3400.180\n",
      "Ep:111, loss:0.00000, loss_test:0.00892, lr:4.67e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.650, tt:3432.770\n",
      "Ep:112, loss:0.00000, loss_test:0.00932, lr:4.62e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.662, tt:3464.854\n",
      "Ep:113, loss:0.00000, loss_test:0.00913, lr:4.57e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.662, tt:3495.476\n",
      "Ep:114, loss:0.00000, loss_test:0.00911, lr:4.53e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.676, tt:3527.769\n",
      "Ep:115, loss:0.00000, loss_test:0.00932, lr:4.48e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.691, tt:3560.133\n",
      "Ep:116, loss:0.00000, loss_test:0.00931, lr:4.44e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.708, tt:3592.834\n",
      "Ep:117, loss:0.00000, loss_test:0.00929, lr:4.39e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.725, tt:3625.515\n",
      "Ep:118, loss:0.00000, loss_test:0.00945, lr:4.35e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.728, tt:3656.585\n",
      "Ep:119, loss:0.00000, loss_test:0.00921, lr:4.31e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.731, tt:3687.731\n",
      "Ep:120, loss:0.00000, loss_test:0.00944, lr:4.26e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.743, tt:3719.880\n",
      "Ep:121, loss:0.00000, loss_test:0.00945, lr:4.22e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.757, tt:3752.390\n",
      "Ep:122, loss:0.00000, loss_test:0.00926, lr:4.18e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.766, tt:3784.240\n",
      "Ep:123, loss:0.00000, loss_test:0.00954, lr:4.14e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.777, tt:3816.394\n",
      "Ep:124, loss:0.00000, loss_test:0.00953, lr:4.10e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.780, tt:3847.440\n",
      "Ep:125, loss:0.00000, loss_test:0.00946, lr:4.05e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.771, tt:3877.119\n",
      "Ep:126, loss:0.00000, loss_test:0.00965, lr:4.01e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.761, tt:3906.700\n",
      "Ep:127, loss:0.00000, loss_test:0.00953, lr:3.97e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.762, tt:3937.578\n",
      "Ep:128, loss:0.00000, loss_test:0.00954, lr:3.93e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.758, tt:3967.740\n",
      "Ep:129, loss:0.00000, loss_test:0.00959, lr:3.89e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.762, tt:3999.010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:130, loss:0.00000, loss_test:0.00958, lr:3.86e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.762, tt:4029.873\n",
      "Ep:131, loss:0.00000, loss_test:0.00959, lr:3.82e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.764, tt:4060.892\n",
      "Ep:132, loss:0.00000, loss_test:0.00966, lr:3.78e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.770, tt:4092.409\n",
      "Ep:133, loss:0.00000, loss_test:0.00955, lr:3.74e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.778, tt:4124.256\n",
      "Ep:134, loss:0.00000, loss_test:0.00963, lr:3.70e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.775, tt:4154.641\n",
      "Ep:135, loss:0.00000, loss_test:0.00971, lr:3.67e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.769, tt:4184.525\n",
      "Ep:136, loss:0.00000, loss_test:0.00960, lr:3.63e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.763, tt:4214.572\n",
      "Ep:137, loss:0.00000, loss_test:0.00976, lr:3.59e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.769, tt:4246.126\n",
      "Ep:138, loss:0.00000, loss_test:0.00964, lr:3.56e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.774, tt:4277.575\n",
      "Ep:139, loss:0.00000, loss_test:0.00968, lr:3.52e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.777, tt:4308.751\n",
      "Ep:140, loss:0.00000, loss_test:0.00986, lr:3.49e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.781, tt:4340.146\n",
      "Ep:141, loss:0.00000, loss_test:0.00965, lr:3.45e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.787, tt:4371.771\n",
      "Ep:142, loss:0.00000, loss_test:0.00980, lr:3.42e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.800, tt:4404.472\n",
      "Ep:143, loss:0.00000, loss_test:0.00985, lr:3.38e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.808, tt:4436.406\n",
      "Ep:144, loss:0.00000, loss_test:0.00978, lr:3.35e-02, fs:0.93401 (r=0.929,p=0.939),  time:30.818, tt:4468.559\n",
      "Ep:145, loss:0.00000, loss_test:0.00988, lr:3.32e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.825, tt:4500.389\n",
      "Ep:146, loss:0.00000, loss_test:0.00988, lr:3.28e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.838, tt:4533.229\n",
      "Ep:147, loss:0.00000, loss_test:0.00974, lr:3.25e-02, fs:0.93401 (r=0.929,p=0.939),  time:30.850, tt:4565.821\n",
      "Ep:148, loss:0.00000, loss_test:0.01002, lr:3.22e-02, fs:0.92386 (r=0.919,p=0.929),  time:30.865, tt:4598.875\n",
      "Ep:149, loss:0.00000, loss_test:0.00976, lr:3.19e-02, fs:0.93401 (r=0.929,p=0.939),  time:30.872, tt:4630.813\n",
      "Ep:150, loss:0.00000, loss_test:0.00987, lr:3.15e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.873, tt:4661.798\n",
      "Ep:151, loss:0.00000, loss_test:0.00991, lr:3.12e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.885, tt:4694.595\n",
      "Ep:152, loss:0.00000, loss_test:0.00985, lr:3.09e-02, fs:0.93401 (r=0.929,p=0.939),  time:30.888, tt:4725.919\n",
      "Ep:153, loss:0.00000, loss_test:0.00989, lr:3.06e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.883, tt:4755.919\n",
      "Ep:154, loss:0.00000, loss_test:0.00993, lr:3.03e-02, fs:0.93401 (r=0.929,p=0.939),  time:30.882, tt:4786.679\n",
      "Ep:155, loss:0.00000, loss_test:0.00992, lr:3.00e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.894, tt:4819.394\n",
      "Ep:156, loss:0.00000, loss_test:0.00993, lr:2.97e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.907, tt:4852.398\n",
      "Ep:157, loss:0.00000, loss_test:0.00998, lr:2.94e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.916, tt:4884.650\n",
      "Ep:158, loss:0.00000, loss_test:0.00999, lr:2.91e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.921, tt:4916.396\n",
      "Ep:159, loss:0.00000, loss_test:0.00996, lr:2.88e-02, fs:0.93401 (r=0.929,p=0.939),  time:30.924, tt:4947.899\n",
      "Ep:160, loss:0.00000, loss_test:0.01006, lr:2.85e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.924, tt:4978.819\n",
      "Ep:161, loss:0.00000, loss_test:0.00998, lr:2.82e-02, fs:0.93401 (r=0.929,p=0.939),  time:30.928, tt:5010.415\n",
      "Ep:162, loss:0.00000, loss_test:0.01005, lr:2.80e-02, fs:0.92929 (r=0.929,p=0.929),  time:30.927, tt:5041.084\n",
      "Ep:163, loss:0.00000, loss_test:0.01003, lr:2.77e-02, fs:0.93401 (r=0.929,p=0.939),  time:30.928, tt:5072.250\n",
      "Ep:164, loss:0.00000, loss_test:0.01006, lr:2.74e-02, fs:0.93401 (r=0.929,p=0.939),  time:30.930, tt:5103.388\n",
      "Ep:165, loss:0.00000, loss_test:0.01004, lr:2.71e-02, fs:0.93401 (r=0.929,p=0.939),  time:30.934, tt:5135.030\n",
      "Ep:166, loss:0.00000, loss_test:0.01008, lr:2.69e-02, fs:0.93401 (r=0.929,p=0.939),  time:30.951, tt:5168.734\n",
      "Ep:167, loss:0.00000, loss_test:0.01007, lr:2.66e-02, fs:0.93401 (r=0.929,p=0.939),  time:30.958, tt:5201.025\n",
      "Ep:168, loss:0.00000, loss_test:0.01006, lr:2.63e-02, fs:0.93401 (r=0.929,p=0.939),  time:30.956, tt:5231.643\n",
      "Ep:169, loss:0.00000, loss_test:0.01004, lr:2.61e-02, fs:0.93401 (r=0.929,p=0.939),  time:30.963, tt:5263.692\n",
      "Ep:170, loss:0.00000, loss_test:0.01010, lr:2.58e-02, fs:0.93401 (r=0.929,p=0.939),  time:30.979, tt:5297.398\n",
      "Ep:171, loss:0.00000, loss_test:0.01011, lr:2.55e-02, fs:0.93401 (r=0.929,p=0.939),  time:30.988, tt:5329.864\n",
      "Ep:172, loss:0.00000, loss_test:0.01005, lr:2.53e-02, fs:0.93401 (r=0.929,p=0.939),  time:31.009, tt:5364.560\n",
      "Ep:173, loss:0.00000, loss_test:0.01015, lr:2.50e-02, fs:0.92857 (r=0.919,p=0.938),  time:31.022, tt:5397.847\n",
      "Ep:174, loss:0.00000, loss_test:0.01011, lr:2.48e-02, fs:0.93401 (r=0.929,p=0.939),  time:31.034, tt:5431.005\n",
      "Ep:175, loss:0.00000, loss_test:0.01012, lr:2.45e-02, fs:0.92857 (r=0.919,p=0.938),  time:31.043, tt:5463.600\n",
      "Ep:176, loss:0.00000, loss_test:0.01013, lr:2.43e-02, fs:0.93401 (r=0.929,p=0.939),  time:31.051, tt:5496.000\n",
      "Ep:177, loss:0.00000, loss_test:0.01015, lr:2.40e-02, fs:0.93401 (r=0.929,p=0.939),  time:31.062, tt:5528.950\n",
      "Ep:178, loss:0.00000, loss_test:0.01012, lr:2.38e-02, fs:0.93401 (r=0.929,p=0.939),  time:31.063, tt:5560.342\n",
      "Ep:179, loss:0.00000, loss_test:0.01016, lr:2.36e-02, fs:0.93401 (r=0.929,p=0.939),  time:31.066, tt:5591.818\n",
      "Ep:180, loss:0.00000, loss_test:0.01023, lr:2.33e-02, fs:0.92857 (r=0.919,p=0.938),  time:31.069, tt:5623.548\n",
      "Ep:181, loss:0.00000, loss_test:0.01015, lr:2.31e-02, fs:0.93401 (r=0.929,p=0.939),  time:31.070, tt:5654.655\n",
      "Ep:182, loss:0.00000, loss_test:0.01018, lr:2.29e-02, fs:0.92857 (r=0.919,p=0.938),  time:31.065, tt:5684.982\n",
      "Ep:183, loss:0.00000, loss_test:0.01018, lr:2.26e-02, fs:0.93401 (r=0.929,p=0.939),  time:31.068, tt:5716.426\n",
      "Ep:184, loss:0.00000, loss_test:0.01022, lr:2.24e-02, fs:0.92857 (r=0.919,p=0.938),  time:31.065, tt:5747.051\n",
      "Ep:185, loss:0.00000, loss_test:0.01016, lr:2.22e-02, fs:0.93401 (r=0.929,p=0.939),  time:31.067, tt:5778.553\n",
      "Ep:186, loss:0.00000, loss_test:0.01022, lr:2.20e-02, fs:0.92857 (r=0.919,p=0.938),  time:31.071, tt:5810.284\n",
      "Ep:187, loss:0.00000, loss_test:0.01022, lr:2.17e-02, fs:0.92857 (r=0.919,p=0.938),  time:31.068, tt:5840.809\n",
      "Ep:188, loss:0.00000, loss_test:0.01021, lr:2.15e-02, fs:0.93401 (r=0.929,p=0.939),  time:31.067, tt:5871.702\n",
      "Ep:189, loss:0.00000, loss_test:0.01022, lr:2.13e-02, fs:0.92857 (r=0.919,p=0.938),  time:31.068, tt:5902.829\n",
      "Ep:190, loss:0.00000, loss_test:0.01024, lr:2.11e-02, fs:0.92857 (r=0.919,p=0.938),  time:31.071, tt:5934.607\n",
      "Ep:191, loss:0.00000, loss_test:0.01022, lr:2.09e-02, fs:0.93401 (r=0.929,p=0.939),  time:31.064, tt:5964.221\n",
      "Ep:192, loss:0.00000, loss_test:0.01023, lr:2.07e-02, fs:0.92857 (r=0.919,p=0.938),  time:31.064, tt:5995.347\n",
      "Ep:193, loss:0.00000, loss_test:0.01025, lr:2.05e-02, fs:0.92857 (r=0.919,p=0.938),  time:31.061, tt:6025.785\n",
      "Ep:194, loss:0.00000, loss_test:0.01028, lr:2.03e-02, fs:0.92857 (r=0.919,p=0.938),  time:31.071, tt:6058.798\n",
      "Ep:195, loss:0.00000, loss_test:0.01023, lr:2.01e-02, fs:0.92857 (r=0.919,p=0.938),  time:31.060, tt:6087.677\n",
      "Ep:196, loss:0.00000, loss_test:0.01027, lr:1.99e-02, fs:0.92857 (r=0.919,p=0.938),  time:31.058, tt:6118.458\n",
      "Ep:197, loss:0.00000, loss_test:0.01027, lr:1.97e-02, fs:0.92857 (r=0.919,p=0.938),  time:31.064, tt:6150.583\n",
      "Ep:198, loss:0.00000, loss_test:0.01028, lr:1.95e-02, fs:0.92857 (r=0.919,p=0.938),  time:31.069, tt:6182.762\n",
      "Ep:199, loss:0.00000, loss_test:0.01026, lr:1.93e-02, fs:0.92857 (r=0.919,p=0.938),  time:31.061, tt:6212.131\n",
      "Ep:200, loss:0.00000, loss_test:0.01029, lr:1.91e-02, fs:0.92857 (r=0.919,p=0.938),  time:31.052, tt:6241.431\n",
      "Ep:201, loss:0.00000, loss_test:0.01028, lr:1.89e-02, fs:0.92857 (r=0.919,p=0.938),  time:31.048, tt:6271.640\n",
      "Ep:202, loss:0.00000, loss_test:0.01031, lr:1.87e-02, fs:0.92857 (r=0.919,p=0.938),  time:31.052, tt:6303.496\n",
      "Ep:203, loss:0.00000, loss_test:0.01028, lr:1.85e-02, fs:0.92857 (r=0.919,p=0.938),  time:31.039, tt:6331.945\n",
      "Ep:204, loss:0.00000, loss_test:0.01028, lr:1.83e-02, fs:0.92857 (r=0.919,p=0.938),  time:31.011, tt:6357.252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:205, loss:0.00000, loss_test:0.01031, lr:1.81e-02, fs:0.92308 (r=0.909,p=0.938),  time:30.999, tt:6385.870\n",
      "Ep:206, loss:0.00000, loss_test:0.01032, lr:1.80e-02, fs:0.92308 (r=0.909,p=0.938),  time:31.002, tt:6417.331\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13089, lr:1.00e-02, fs:0.67704 (r=0.879,p=0.551),  time:30.640, tt:30.640\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13159, lr:1.00e-02, fs:0.67424 (r=0.899,p=0.539),  time:30.198, tt:60.397\n",
      "Ep:2, loss:0.00026, loss_test:0.13265, lr:1.00e-02, fs:0.66418 (r=0.899,p=0.527),  time:29.915, tt:89.745\n",
      "Ep:3, loss:0.00026, loss_test:0.13282, lr:1.00e-02, fs:0.66171 (r=0.899,p=0.524),  time:30.391, tt:121.565\n",
      "Ep:4, loss:0.00026, loss_test:0.13195, lr:1.00e-02, fs:0.66667 (r=0.899,p=0.530),  time:30.520, tt:152.598\n",
      "Ep:5, loss:0.00026, loss_test:0.13029, lr:1.00e-02, fs:0.67170 (r=0.899,p=0.536),  time:30.768, tt:184.606\n",
      "Ep:6, loss:0.00026, loss_test:0.12855, lr:1.00e-02, fs:0.67681 (r=0.899,p=0.543),  time:30.767, tt:215.368\n",
      "Ep:7, loss:0.00026, loss_test:0.12693, lr:1.00e-02, fs:0.68462 (r=0.899,p=0.553),  time:30.763, tt:246.101\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00025, loss_test:0.12567, lr:1.00e-02, fs:0.68482 (r=0.889,p=0.557),  time:30.886, tt:277.975\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00025, loss_test:0.12474, lr:1.00e-02, fs:0.68482 (r=0.889,p=0.557),  time:31.068, tt:310.683\n",
      "Ep:10, loss:0.00025, loss_test:0.12388, lr:1.00e-02, fs:0.68482 (r=0.889,p=0.557),  time:31.107, tt:342.175\n",
      "Ep:11, loss:0.00025, loss_test:0.12305, lr:1.00e-02, fs:0.68482 (r=0.889,p=0.557),  time:31.193, tt:374.319\n",
      "Ep:12, loss:0.00025, loss_test:0.12202, lr:1.00e-02, fs:0.67954 (r=0.889,p=0.550),  time:31.199, tt:405.583\n",
      "Ep:13, loss:0.00024, loss_test:0.12077, lr:1.00e-02, fs:0.69020 (r=0.889,p=0.564),  time:31.215, tt:437.015\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00024, loss_test:0.11945, lr:1.00e-02, fs:0.69020 (r=0.889,p=0.564),  time:31.384, tt:470.753\n",
      "Ep:15, loss:0.00024, loss_test:0.11786, lr:1.00e-02, fs:0.69323 (r=0.879,p=0.572),  time:31.382, tt:502.107\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00024, loss_test:0.11631, lr:1.00e-02, fs:0.69323 (r=0.879,p=0.572),  time:31.472, tt:535.026\n",
      "Ep:17, loss:0.00023, loss_test:0.11469, lr:1.00e-02, fs:0.69880 (r=0.879,p=0.580),  time:31.429, tt:565.729\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00023, loss_test:0.11296, lr:1.00e-02, fs:0.69880 (r=0.879,p=0.580),  time:31.465, tt:597.842\n",
      "Ep:19, loss:0.00023, loss_test:0.11132, lr:1.00e-02, fs:0.70683 (r=0.889,p=0.587),  time:31.508, tt:630.166\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00023, loss_test:0.10946, lr:1.00e-02, fs:0.71200 (r=0.899,p=0.589),  time:31.606, tt:663.734\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00022, loss_test:0.10742, lr:1.00e-02, fs:0.71200 (r=0.899,p=0.589),  time:31.661, tt:696.547\n",
      "Ep:22, loss:0.00022, loss_test:0.10526, lr:1.00e-02, fs:0.71311 (r=0.879,p=0.600),  time:31.676, tt:728.547\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00021, loss_test:0.10281, lr:1.00e-02, fs:0.71901 (r=0.879,p=0.608),  time:31.674, tt:760.187\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00021, loss_test:0.10052, lr:1.00e-02, fs:0.71967 (r=0.869,p=0.614),  time:31.703, tt:792.567\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00020, loss_test:0.09804, lr:1.00e-02, fs:0.74167 (r=0.899,p=0.631),  time:31.715, tt:824.594\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00020, loss_test:0.09565, lr:1.00e-02, fs:0.76667 (r=0.929,p=0.652),  time:31.726, tt:856.609\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00019, loss_test:0.09366, lr:1.00e-02, fs:0.76667 (r=0.929,p=0.652),  time:31.790, tt:890.108\n",
      "Ep:28, loss:0.00019, loss_test:0.09212, lr:1.00e-02, fs:0.76987 (r=0.929,p=0.657),  time:31.820, tt:922.791\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00018, loss_test:0.09056, lr:1.00e-02, fs:0.75862 (r=0.889,p=0.662),  time:31.874, tt:956.214\n",
      "Ep:30, loss:0.00017, loss_test:0.08959, lr:1.00e-02, fs:0.77056 (r=0.899,p=0.674),  time:31.870, tt:987.975\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00017, loss_test:0.08845, lr:1.00e-02, fs:0.78603 (r=0.909,p=0.692),  time:31.782, tt:1017.014\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00016, loss_test:0.08775, lr:1.00e-02, fs:0.77922 (r=0.909,p=0.682),  time:31.781, tt:1048.786\n",
      "Ep:33, loss:0.00016, loss_test:0.08790, lr:1.00e-02, fs:0.76522 (r=0.889,p=0.672),  time:31.798, tt:1081.138\n",
      "Ep:34, loss:0.00015, loss_test:0.08570, lr:1.00e-02, fs:0.78788 (r=0.919,p=0.689),  time:31.819, tt:1113.682\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00014, loss_test:0.08491, lr:1.00e-02, fs:0.77729 (r=0.899,p=0.685),  time:31.845, tt:1146.430\n",
      "Ep:36, loss:0.00014, loss_test:0.08458, lr:1.00e-02, fs:0.77193 (r=0.889,p=0.682),  time:31.837, tt:1177.975\n",
      "Ep:37, loss:0.00013, loss_test:0.08281, lr:1.00e-02, fs:0.81982 (r=0.919,p=0.740),  time:31.888, tt:1211.763\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00013, loss_test:0.08224, lr:1.00e-02, fs:0.78814 (r=0.939,p=0.679),  time:31.886, tt:1243.535\n",
      "Ep:39, loss:0.00012, loss_test:0.08164, lr:1.00e-02, fs:0.78341 (r=0.859,p=0.720),  time:31.895, tt:1275.794\n",
      "Ep:40, loss:0.00012, loss_test:0.07898, lr:1.00e-02, fs:0.79654 (r=0.929,p=0.697),  time:31.954, tt:1310.105\n",
      "Ep:41, loss:0.00011, loss_test:0.07886, lr:1.00e-02, fs:0.80717 (r=0.909,p=0.726),  time:31.954, tt:1342.051\n",
      "Ep:42, loss:0.00010, loss_test:0.07748, lr:1.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:31.972, tt:1374.785\n",
      "Ep:43, loss:0.00010, loss_test:0.07608, lr:1.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:32.001, tt:1408.023\n",
      "Ep:44, loss:0.00010, loss_test:0.07677, lr:1.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:31.952, tt:1437.826\n",
      "Ep:45, loss:0.00009, loss_test:0.07353, lr:1.00e-02, fs:0.80189 (r=0.859,p=0.752),  time:31.937, tt:1469.080\n",
      "Ep:46, loss:0.00009, loss_test:0.07886, lr:1.00e-02, fs:0.79412 (r=0.818,p=0.771),  time:31.892, tt:1498.944\n",
      "Ep:47, loss:0.00013, loss_test:0.07202, lr:1.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:31.923, tt:1532.304\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00010, loss_test:0.08007, lr:1.00e-02, fs:0.80000 (r=0.990,p=0.671),  time:31.897, tt:1562.955\n",
      "Ep:49, loss:0.00012, loss_test:0.07370, lr:1.00e-02, fs:0.85446 (r=0.919,p=0.798),  time:31.894, tt:1594.704\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00011, loss_test:0.06962, lr:1.00e-02, fs:0.83408 (r=0.939,p=0.750),  time:31.921, tt:1627.951\n",
      "Ep:51, loss:0.00010, loss_test:0.07472, lr:1.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:31.953, tt:1661.562\n",
      "Ep:52, loss:0.00009, loss_test:0.06570, lr:1.00e-02, fs:0.87204 (r=0.929,p=0.821),  time:31.934, tt:1692.484\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00009, loss_test:0.07082, lr:1.00e-02, fs:0.81481 (r=0.889,p=0.752),  time:31.957, tt:1725.667\n",
      "Ep:54, loss:0.00008, loss_test:0.06996, lr:1.00e-02, fs:0.81731 (r=0.859,p=0.780),  time:31.980, tt:1758.909\n",
      "Ep:55, loss:0.00008, loss_test:0.06734, lr:1.00e-02, fs:0.83962 (r=0.899,p=0.788),  time:31.978, tt:1790.775\n",
      "Ep:56, loss:0.00007, loss_test:0.07383, lr:1.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:31.995, tt:1823.691\n",
      "Ep:57, loss:0.00007, loss_test:0.06703, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:31.978, tt:1854.731\n",
      "Ep:58, loss:0.00007, loss_test:0.07983, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:31.977, tt:1886.619\n",
      "Ep:59, loss:0.00006, loss_test:0.06703, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:31.966, tt:1917.943\n",
      "Ep:60, loss:0.00006, loss_test:0.07356, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:31.966, tt:1949.912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00006, loss_test:0.06267, lr:1.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:31.974, tt:1982.371\n",
      "Ep:62, loss:0.00005, loss_test:0.06529, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:31.964, tt:2013.704\n",
      "Ep:63, loss:0.00005, loss_test:0.06632, lr:1.00e-02, fs:0.82234 (r=0.818,p=0.827),  time:31.968, tt:2045.980\n",
      "Ep:64, loss:0.00005, loss_test:0.06316, lr:9.90e-03, fs:0.84103 (r=0.828,p=0.854),  time:31.965, tt:2077.754\n",
      "Ep:65, loss:0.00005, loss_test:0.06525, lr:9.80e-03, fs:0.82828 (r=0.828,p=0.828),  time:31.971, tt:2110.101\n",
      "Ep:66, loss:0.00005, loss_test:0.06506, lr:9.70e-03, fs:0.83673 (r=0.828,p=0.845),  time:31.962, tt:2141.421\n",
      "Ep:67, loss:0.00004, loss_test:0.06937, lr:9.61e-03, fs:0.83249 (r=0.828,p=0.837),  time:32.004, tt:2176.245\n",
      "Ep:68, loss:0.00004, loss_test:0.05950, lr:9.51e-03, fs:0.83673 (r=0.828,p=0.845),  time:32.001, tt:2208.048\n",
      "Ep:69, loss:0.00004, loss_test:0.06581, lr:9.41e-03, fs:0.83673 (r=0.828,p=0.845),  time:32.042, tt:2242.943\n",
      "Ep:70, loss:0.00004, loss_test:0.06290, lr:9.32e-03, fs:0.86294 (r=0.859,p=0.867),  time:32.037, tt:2274.603\n",
      "Ep:71, loss:0.00004, loss_test:0.06447, lr:9.23e-03, fs:0.87000 (r=0.879,p=0.861),  time:32.042, tt:2307.051\n",
      "Ep:72, loss:0.00003, loss_test:0.06124, lr:9.14e-03, fs:0.87629 (r=0.859,p=0.895),  time:32.031, tt:2338.247\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00003, loss_test:0.06693, lr:9.14e-03, fs:0.87437 (r=0.879,p=0.870),  time:32.033, tt:2370.418\n",
      "Ep:74, loss:0.00003, loss_test:0.05980, lr:9.14e-03, fs:0.86294 (r=0.859,p=0.867),  time:32.041, tt:2403.042\n",
      "Ep:75, loss:0.00003, loss_test:0.06236, lr:9.14e-03, fs:0.87000 (r=0.879,p=0.861),  time:32.029, tt:2434.200\n",
      "Ep:76, loss:0.00003, loss_test:0.06219, lr:9.14e-03, fs:0.87179 (r=0.859,p=0.885),  time:32.027, tt:2466.108\n",
      "Ep:77, loss:0.00003, loss_test:0.06207, lr:9.14e-03, fs:0.89691 (r=0.879,p=0.916),  time:32.046, tt:2499.610\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00003, loss_test:0.06526, lr:9.14e-03, fs:0.86010 (r=0.838,p=0.883),  time:32.023, tt:2529.788\n",
      "Ep:79, loss:0.00003, loss_test:0.06294, lr:9.14e-03, fs:0.87958 (r=0.848,p=0.913),  time:32.009, tt:2560.728\n",
      "Ep:80, loss:0.00003, loss_test:0.05933, lr:9.14e-03, fs:0.87879 (r=0.879,p=0.879),  time:31.994, tt:2591.488\n",
      "Ep:81, loss:0.00003, loss_test:0.06690, lr:9.14e-03, fs:0.86772 (r=0.828,p=0.911),  time:31.992, tt:2623.367\n",
      "Ep:82, loss:0.00004, loss_test:0.05641, lr:9.14e-03, fs:0.90625 (r=0.879,p=0.935),  time:32.011, tt:2656.938\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00003, loss_test:0.06061, lr:9.14e-03, fs:0.85427 (r=0.859,p=0.850),  time:32.005, tt:2688.457\n",
      "Ep:84, loss:0.00003, loss_test:0.06129, lr:9.14e-03, fs:0.90625 (r=0.879,p=0.935),  time:31.997, tt:2719.770\n",
      "Ep:85, loss:0.00003, loss_test:0.06448, lr:9.14e-03, fs:0.88660 (r=0.869,p=0.905),  time:32.014, tt:2753.207\n",
      "Ep:86, loss:0.00003, loss_test:0.05698, lr:9.14e-03, fs:0.90155 (r=0.879,p=0.926),  time:32.036, tt:2787.162\n",
      "Ep:87, loss:0.00002, loss_test:0.06951, lr:9.14e-03, fs:0.85714 (r=0.818,p=0.900),  time:32.046, tt:2820.063\n",
      "Ep:88, loss:0.00002, loss_test:0.05510, lr:9.14e-03, fs:0.89231 (r=0.879,p=0.906),  time:32.092, tt:2856.231\n",
      "Ep:89, loss:0.00002, loss_test:0.06213, lr:9.14e-03, fs:0.87958 (r=0.848,p=0.913),  time:32.137, tt:2892.372\n",
      "Ep:90, loss:0.00002, loss_test:0.05492, lr:9.14e-03, fs:0.89005 (r=0.859,p=0.924),  time:32.178, tt:2928.229\n",
      "Ep:91, loss:0.00002, loss_test:0.06030, lr:9.14e-03, fs:0.86022 (r=0.808,p=0.920),  time:32.199, tt:2962.308\n",
      "Ep:92, loss:0.00002, loss_test:0.06066, lr:9.14e-03, fs:0.90625 (r=0.879,p=0.935),  time:32.231, tt:2997.494\n",
      "Ep:93, loss:0.00002, loss_test:0.05645, lr:9.14e-03, fs:0.90625 (r=0.879,p=0.935),  time:32.274, tt:3033.760\n",
      "Ep:94, loss:0.00002, loss_test:0.05852, lr:9.04e-03, fs:0.91099 (r=0.879,p=0.946),  time:32.319, tt:3070.298\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00002, loss_test:0.05739, lr:9.04e-03, fs:0.90625 (r=0.879,p=0.935),  time:32.344, tt:3105.055\n",
      "Ep:96, loss:0.00002, loss_test:0.05972, lr:9.04e-03, fs:0.91099 (r=0.879,p=0.946),  time:32.377, tt:3140.535\n",
      "Ep:97, loss:0.00002, loss_test:0.05687, lr:9.04e-03, fs:0.90155 (r=0.879,p=0.926),  time:32.412, tt:3176.423\n",
      "Ep:98, loss:0.00002, loss_test:0.06130, lr:9.04e-03, fs:0.90625 (r=0.879,p=0.935),  time:32.445, tt:3212.015\n",
      "Ep:99, loss:0.00002, loss_test:0.05651, lr:9.04e-03, fs:0.90625 (r=0.879,p=0.935),  time:32.458, tt:3245.756\n",
      "Ep:100, loss:0.00002, loss_test:0.05638, lr:9.04e-03, fs:0.90625 (r=0.879,p=0.935),  time:32.468, tt:3279.288\n",
      "Ep:101, loss:0.00002, loss_test:0.05921, lr:9.04e-03, fs:0.90625 (r=0.879,p=0.935),  time:32.503, tt:3315.267\n",
      "Ep:102, loss:0.00001, loss_test:0.06033, lr:9.04e-03, fs:0.89947 (r=0.859,p=0.944),  time:32.520, tt:3349.544\n",
      "Ep:103, loss:0.00001, loss_test:0.06140, lr:9.04e-03, fs:0.91099 (r=0.879,p=0.946),  time:32.549, tt:3385.095\n",
      "Ep:104, loss:0.00001, loss_test:0.06156, lr:9.04e-03, fs:0.87234 (r=0.828,p=0.921),  time:32.564, tt:3419.269\n",
      "Ep:105, loss:0.00001, loss_test:0.06099, lr:9.04e-03, fs:0.91099 (r=0.879,p=0.946),  time:32.582, tt:3453.725\n",
      "Ep:106, loss:0.00001, loss_test:0.06368, lr:8.95e-03, fs:0.90526 (r=0.869,p=0.945),  time:32.611, tt:3489.344\n",
      "Ep:107, loss:0.00001, loss_test:0.06164, lr:8.86e-03, fs:0.90526 (r=0.869,p=0.945),  time:32.645, tt:3525.632\n",
      "Ep:108, loss:0.00001, loss_test:0.05913, lr:8.78e-03, fs:0.91099 (r=0.879,p=0.946),  time:32.677, tt:3561.789\n",
      "Ep:109, loss:0.00001, loss_test:0.06677, lr:8.69e-03, fs:0.86486 (r=0.808,p=0.930),  time:32.715, tt:3598.645\n",
      "Ep:110, loss:0.00001, loss_test:0.06216, lr:8.60e-03, fs:0.86339 (r=0.798,p=0.940),  time:32.742, tt:3634.409\n",
      "Ep:111, loss:0.00001, loss_test:0.06323, lr:8.51e-03, fs:0.89005 (r=0.859,p=0.924),  time:32.764, tt:3669.565\n",
      "Ep:112, loss:0.00001, loss_test:0.06359, lr:8.43e-03, fs:0.86486 (r=0.808,p=0.930),  time:32.789, tt:3705.195\n",
      "Ep:113, loss:0.00001, loss_test:0.06456, lr:8.35e-03, fs:0.88421 (r=0.848,p=0.923),  time:32.813, tt:3740.675\n",
      "Ep:114, loss:0.00001, loss_test:0.06623, lr:8.26e-03, fs:0.85083 (r=0.778,p=0.939),  time:32.843, tt:3776.901\n",
      "Ep:115, loss:0.00001, loss_test:0.06137, lr:8.18e-03, fs:0.85714 (r=0.788,p=0.940),  time:32.856, tt:3811.272\n",
      "Ep:116, loss:0.00001, loss_test:0.06406, lr:8.10e-03, fs:0.89947 (r=0.859,p=0.944),  time:32.878, tt:3846.716\n",
      "Ep:117, loss:0.00001, loss_test:0.06368, lr:8.02e-03, fs:0.85083 (r=0.778,p=0.939),  time:32.895, tt:3881.629\n",
      "Ep:118, loss:0.00001, loss_test:0.06540, lr:7.94e-03, fs:0.88889 (r=0.848,p=0.933),  time:32.922, tt:3917.661\n",
      "Ep:119, loss:0.00001, loss_test:0.06306, lr:7.86e-03, fs:0.84615 (r=0.778,p=0.928),  time:32.955, tt:3954.601\n",
      "Ep:120, loss:0.00001, loss_test:0.06596, lr:7.78e-03, fs:0.86486 (r=0.808,p=0.930),  time:32.986, tt:3991.271\n",
      "Ep:121, loss:0.00001, loss_test:0.06576, lr:7.70e-03, fs:0.85083 (r=0.778,p=0.939),  time:33.008, tt:4027.007\n",
      "Ep:122, loss:0.00001, loss_test:0.06524, lr:7.62e-03, fs:0.85083 (r=0.778,p=0.939),  time:33.034, tt:4063.241\n",
      "Ep:123, loss:0.00001, loss_test:0.06841, lr:7.55e-03, fs:0.84444 (r=0.768,p=0.938),  time:33.048, tt:4097.979\n",
      "Ep:124, loss:0.00001, loss_test:0.06259, lr:7.47e-03, fs:0.85083 (r=0.778,p=0.939),  time:33.082, tt:4135.307\n",
      "Ep:125, loss:0.00001, loss_test:0.06638, lr:7.40e-03, fs:0.85714 (r=0.788,p=0.940),  time:33.103, tt:4170.954\n",
      "Ep:126, loss:0.00001, loss_test:0.06615, lr:7.32e-03, fs:0.83799 (r=0.758,p=0.938),  time:33.133, tt:4207.902\n",
      "Ep:127, loss:0.00001, loss_test:0.06600, lr:7.25e-03, fs:0.85083 (r=0.778,p=0.939),  time:33.146, tt:4242.654\n",
      "Ep:128, loss:0.00001, loss_test:0.06593, lr:7.18e-03, fs:0.83799 (r=0.758,p=0.938),  time:33.172, tt:4279.250\n",
      "Ep:129, loss:0.00001, loss_test:0.06563, lr:7.11e-03, fs:0.85083 (r=0.778,p=0.939),  time:33.187, tt:4314.320\n",
      "Ep:130, loss:0.00001, loss_test:0.06539, lr:7.03e-03, fs:0.83333 (r=0.758,p=0.926),  time:33.210, tt:4350.512\n",
      "Ep:131, loss:0.00001, loss_test:0.06520, lr:6.96e-03, fs:0.85083 (r=0.778,p=0.939),  time:33.235, tt:4386.978\n",
      "Ep:132, loss:0.00001, loss_test:0.06773, lr:6.89e-03, fs:0.83799 (r=0.758,p=0.938),  time:33.251, tt:4422.354\n",
      "Ep:133, loss:0.00001, loss_test:0.06561, lr:6.83e-03, fs:0.85083 (r=0.778,p=0.939),  time:33.282, tt:4459.844\n",
      "Ep:134, loss:0.00001, loss_test:0.06506, lr:6.76e-03, fs:0.85083 (r=0.778,p=0.939),  time:33.303, tt:4495.842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00001, loss_test:0.06780, lr:6.69e-03, fs:0.85083 (r=0.778,p=0.939),  time:33.331, tt:4532.962\n",
      "Ep:136, loss:0.00001, loss_test:0.06481, lr:6.62e-03, fs:0.83799 (r=0.758,p=0.938),  time:33.352, tt:4569.275\n",
      "Ep:137, loss:0.00001, loss_test:0.06676, lr:6.56e-03, fs:0.85083 (r=0.778,p=0.939),  time:33.373, tt:4605.440\n",
      "Ep:138, loss:0.00001, loss_test:0.06704, lr:6.49e-03, fs:0.84444 (r=0.768,p=0.938),  time:33.391, tt:4641.312\n",
      "Ep:139, loss:0.00001, loss_test:0.06631, lr:6.43e-03, fs:0.84615 (r=0.778,p=0.928),  time:33.404, tt:4676.616\n",
      "Ep:140, loss:0.00001, loss_test:0.06658, lr:6.36e-03, fs:0.84444 (r=0.768,p=0.938),  time:33.419, tt:4712.018\n",
      "Ep:141, loss:0.00001, loss_test:0.06713, lr:6.30e-03, fs:0.85083 (r=0.778,p=0.939),  time:33.436, tt:4747.842\n",
      "Ep:142, loss:0.00001, loss_test:0.06571, lr:6.24e-03, fs:0.83799 (r=0.758,p=0.938),  time:33.457, tt:4784.420\n",
      "Ep:143, loss:0.00001, loss_test:0.06923, lr:6.17e-03, fs:0.85083 (r=0.778,p=0.939),  time:33.472, tt:4820.027\n",
      "Ep:144, loss:0.00001, loss_test:0.06797, lr:6.11e-03, fs:0.83333 (r=0.758,p=0.926),  time:33.478, tt:4854.381\n",
      "Ep:145, loss:0.00001, loss_test:0.06601, lr:6.05e-03, fs:0.84615 (r=0.778,p=0.928),  time:33.494, tt:4890.074\n",
      "Ep:146, loss:0.00001, loss_test:0.06760, lr:5.99e-03, fs:0.84444 (r=0.768,p=0.938),  time:33.516, tt:4926.914\n",
      "Ep:147, loss:0.00001, loss_test:0.06710, lr:5.93e-03, fs:0.85556 (r=0.778,p=0.951),  time:33.539, tt:4963.846\n",
      "Ep:148, loss:0.00001, loss_test:0.06753, lr:5.87e-03, fs:0.82682 (r=0.747,p=0.925),  time:33.565, tt:5001.226\n",
      "Ep:149, loss:0.00001, loss_test:0.06763, lr:5.81e-03, fs:0.83799 (r=0.758,p=0.938),  time:33.585, tt:5037.693\n",
      "Ep:150, loss:0.00001, loss_test:0.06717, lr:5.75e-03, fs:0.85083 (r=0.778,p=0.939),  time:33.589, tt:5071.868\n",
      "Ep:151, loss:0.00001, loss_test:0.06758, lr:5.70e-03, fs:0.80000 (r=0.707,p=0.921),  time:33.599, tt:5107.056\n",
      "Ep:152, loss:0.00001, loss_test:0.06866, lr:5.64e-03, fs:0.85556 (r=0.778,p=0.951),  time:33.608, tt:5142.027\n",
      "Ep:153, loss:0.00001, loss_test:0.06840, lr:5.58e-03, fs:0.82022 (r=0.737,p=0.924),  time:33.622, tt:5177.727\n",
      "Ep:154, loss:0.00001, loss_test:0.06751, lr:5.53e-03, fs:0.84615 (r=0.778,p=0.928),  time:33.655, tt:5216.536\n",
      "Ep:155, loss:0.00001, loss_test:0.06825, lr:5.47e-03, fs:0.80000 (r=0.707,p=0.921),  time:33.673, tt:5253.059\n",
      "Ep:156, loss:0.00001, loss_test:0.06949, lr:5.42e-03, fs:0.85556 (r=0.778,p=0.951),  time:33.695, tt:5290.175\n",
      "Ep:157, loss:0.00001, loss_test:0.06682, lr:5.36e-03, fs:0.84615 (r=0.778,p=0.928),  time:33.710, tt:5326.126\n",
      "Ep:158, loss:0.00001, loss_test:0.06980, lr:5.31e-03, fs:0.80000 (r=0.707,p=0.921),  time:33.734, tt:5363.747\n",
      "Ep:159, loss:0.00001, loss_test:0.07019, lr:5.26e-03, fs:0.85556 (r=0.778,p=0.951),  time:33.754, tt:5400.647\n",
      "Ep:160, loss:0.00001, loss_test:0.06787, lr:5.20e-03, fs:0.80682 (r=0.717,p=0.922),  time:33.780, tt:5438.639\n",
      "Ep:161, loss:0.00001, loss_test:0.06905, lr:5.15e-03, fs:0.84615 (r=0.778,p=0.928),  time:33.803, tt:5476.148\n",
      "Ep:162, loss:0.00001, loss_test:0.06841, lr:5.10e-03, fs:0.85556 (r=0.778,p=0.951),  time:33.823, tt:5513.144\n",
      "Ep:163, loss:0.00001, loss_test:0.06932, lr:5.05e-03, fs:0.82022 (r=0.737,p=0.924),  time:33.840, tt:5549.730\n",
      "Ep:164, loss:0.00001, loss_test:0.06913, lr:5.00e-03, fs:0.83978 (r=0.768,p=0.927),  time:33.856, tt:5586.238\n",
      "Ep:165, loss:0.00001, loss_test:0.06773, lr:4.95e-03, fs:0.82486 (r=0.737,p=0.936),  time:33.869, tt:5622.322\n",
      "Ep:166, loss:0.00001, loss_test:0.07023, lr:4.90e-03, fs:0.83978 (r=0.768,p=0.927),  time:33.887, tt:5659.071\n",
      "Ep:167, loss:0.00001, loss_test:0.06834, lr:4.85e-03, fs:0.82022 (r=0.737,p=0.924),  time:33.899, tt:5695.007\n",
      "Ep:168, loss:0.00001, loss_test:0.06849, lr:4.80e-03, fs:0.84615 (r=0.778,p=0.928),  time:33.906, tt:5730.197\n",
      "Ep:169, loss:0.00001, loss_test:0.07263, lr:4.75e-03, fs:0.80000 (r=0.707,p=0.921),  time:33.924, tt:5767.026\n",
      "Ep:170, loss:0.00001, loss_test:0.06853, lr:4.71e-03, fs:0.83978 (r=0.768,p=0.927),  time:33.940, tt:5803.823\n",
      "Ep:171, loss:0.00001, loss_test:0.06929, lr:4.66e-03, fs:0.83333 (r=0.758,p=0.926),  time:33.967, tt:5842.321\n",
      "Ep:172, loss:0.00001, loss_test:0.07250, lr:4.61e-03, fs:0.83333 (r=0.758,p=0.926),  time:33.979, tt:5878.428\n",
      "Ep:173, loss:0.00001, loss_test:0.07011, lr:4.57e-03, fs:0.82486 (r=0.737,p=0.936),  time:33.983, tt:5913.054\n",
      "Ep:174, loss:0.00001, loss_test:0.06932, lr:4.52e-03, fs:0.83333 (r=0.758,p=0.926),  time:34.010, tt:5951.786\n",
      "Ep:175, loss:0.00001, loss_test:0.07101, lr:4.48e-03, fs:0.82222 (r=0.747,p=0.914),  time:34.024, tt:5988.146\n",
      "Ep:176, loss:0.00001, loss_test:0.06987, lr:4.43e-03, fs:0.84444 (r=0.768,p=0.938),  time:34.039, tt:6024.895\n",
      "Ep:177, loss:0.00001, loss_test:0.07045, lr:4.39e-03, fs:0.84615 (r=0.778,p=0.928),  time:34.047, tt:6060.288\n",
      "Ep:178, loss:0.00001, loss_test:0.07213, lr:4.34e-03, fs:0.80000 (r=0.707,p=0.921),  time:34.051, tt:6095.184\n",
      "Ep:179, loss:0.00001, loss_test:0.07030, lr:4.30e-03, fs:0.83978 (r=0.768,p=0.927),  time:34.071, tt:6132.835\n",
      "Ep:180, loss:0.00001, loss_test:0.07046, lr:4.26e-03, fs:0.83333 (r=0.758,p=0.926),  time:34.086, tt:6169.575\n",
      "Ep:181, loss:0.00001, loss_test:0.07159, lr:4.21e-03, fs:0.81356 (r=0.727,p=0.923),  time:34.099, tt:6206.018\n",
      "Ep:182, loss:0.00001, loss_test:0.06966, lr:4.17e-03, fs:0.84615 (r=0.778,p=0.928),  time:34.105, tt:6241.176\n",
      "Ep:183, loss:0.00001, loss_test:0.07206, lr:4.13e-03, fs:0.83978 (r=0.768,p=0.927),  time:34.112, tt:6276.600\n",
      "Ep:184, loss:0.00001, loss_test:0.07141, lr:4.09e-03, fs:0.83978 (r=0.768,p=0.927),  time:34.122, tt:6312.490\n",
      "Ep:185, loss:0.00001, loss_test:0.07013, lr:4.05e-03, fs:0.83333 (r=0.758,p=0.926),  time:34.133, tt:6348.741\n",
      "Ep:186, loss:0.00001, loss_test:0.07186, lr:4.01e-03, fs:0.80460 (r=0.707,p=0.933),  time:34.140, tt:6384.258\n",
      "Ep:187, loss:0.00001, loss_test:0.07135, lr:3.97e-03, fs:0.83333 (r=0.758,p=0.926),  time:34.148, tt:6419.906\n",
      "Ep:188, loss:0.00001, loss_test:0.07082, lr:3.93e-03, fs:0.83978 (r=0.768,p=0.927),  time:34.157, tt:6455.648\n",
      "Ep:189, loss:0.00001, loss_test:0.07189, lr:3.89e-03, fs:0.84444 (r=0.768,p=0.938),  time:34.171, tt:6492.524\n",
      "Ep:190, loss:0.00001, loss_test:0.07104, lr:3.85e-03, fs:0.80682 (r=0.717,p=0.922),  time:34.182, tt:6528.720\n",
      "Ep:191, loss:0.00001, loss_test:0.07109, lr:3.81e-03, fs:0.84615 (r=0.778,p=0.928),  time:34.195, tt:6565.382\n",
      "Ep:192, loss:0.00001, loss_test:0.07180, lr:3.77e-03, fs:0.83333 (r=0.758,p=0.926),  time:34.210, tt:6602.457\n",
      "Ep:193, loss:0.00001, loss_test:0.07151, lr:3.73e-03, fs:0.83978 (r=0.768,p=0.927),  time:34.217, tt:6638.151\n",
      "Ep:194, loss:0.00001, loss_test:0.07190, lr:3.70e-03, fs:0.84444 (r=0.768,p=0.938),  time:34.237, tt:6676.128\n",
      "Ep:195, loss:0.00001, loss_test:0.07148, lr:3.66e-03, fs:0.84444 (r=0.768,p=0.938),  time:34.254, tt:6713.744\n",
      "Ep:196, loss:0.00001, loss_test:0.07128, lr:3.62e-03, fs:0.83333 (r=0.758,p=0.926),  time:34.260, tt:6749.252\n",
      "Ep:197, loss:0.00001, loss_test:0.07268, lr:3.59e-03, fs:0.85083 (r=0.778,p=0.939),  time:34.265, tt:6784.478\n",
      "Ep:198, loss:0.00001, loss_test:0.07247, lr:3.55e-03, fs:0.80460 (r=0.707,p=0.933),  time:34.275, tt:6820.721\n",
      "Ep:199, loss:0.00001, loss_test:0.07239, lr:3.52e-03, fs:0.83799 (r=0.758,p=0.938),  time:34.286, tt:6857.121\n",
      "Ep:200, loss:0.00001, loss_test:0.07244, lr:3.48e-03, fs:0.83799 (r=0.758,p=0.938),  time:34.293, tt:6892.805\n",
      "Ep:201, loss:0.00001, loss_test:0.07280, lr:3.45e-03, fs:0.80460 (r=0.707,p=0.933),  time:34.300, tt:6928.527\n",
      "Ep:202, loss:0.00001, loss_test:0.07222, lr:3.41e-03, fs:0.84444 (r=0.768,p=0.938),  time:34.313, tt:6965.639\n",
      "Ep:203, loss:0.00001, loss_test:0.07219, lr:3.38e-03, fs:0.83146 (r=0.747,p=0.937),  time:34.303, tt:6997.860\n",
      "Ep:204, loss:0.00001, loss_test:0.07278, lr:3.34e-03, fs:0.83146 (r=0.747,p=0.937),  time:34.267, tt:7024.792\n",
      "Ep:205, loss:0.00001, loss_test:0.07331, lr:3.31e-03, fs:0.84444 (r=0.768,p=0.938),  time:34.234, tt:7052.155\n",
      "Ep:206, loss:0.00000, loss_test:0.07255, lr:3.28e-03, fs:0.84444 (r=0.768,p=0.938),  time:34.199, tt:7079.130\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00014, loss_test:0.02690, lr:6.00e-02, fs:0.64681 (r=0.768,p=0.559),  time:33.076, tt:33.076\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02728, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:34.820, tt:69.640\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.03012, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.834, tt:104.502\n",
      "Ep:3, loss:0.00006, loss_test:0.03034, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.843, tt:139.371\n",
      "Ep:4, loss:0.00006, loss_test:0.02970, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:35.224, tt:176.121\n",
      "Ep:5, loss:0.00006, loss_test:0.02883, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:35.509, tt:213.055\n",
      "Ep:6, loss:0.00005, loss_test:0.02798, lr:6.00e-02, fs:0.63604 (r=0.909,p=0.489),  time:35.672, tt:249.707\n",
      "Ep:7, loss:0.00005, loss_test:0.02738, lr:6.00e-02, fs:0.63043 (r=0.879,p=0.492),  time:35.638, tt:285.106\n",
      "Ep:8, loss:0.00005, loss_test:0.02698, lr:6.00e-02, fs:0.63704 (r=0.869,p=0.503),  time:35.600, tt:320.396\n",
      "Ep:9, loss:0.00005, loss_test:0.02667, lr:6.00e-02, fs:0.63910 (r=0.859,p=0.509),  time:35.644, tt:356.444\n",
      "Ep:10, loss:0.00005, loss_test:0.02634, lr:6.00e-02, fs:0.64179 (r=0.869,p=0.509),  time:35.635, tt:391.990\n",
      "Ep:11, loss:0.00005, loss_test:0.02631, lr:6.00e-02, fs:0.64234 (r=0.889,p=0.503),  time:35.587, tt:427.048\n",
      "Ep:12, loss:0.00005, loss_test:0.02623, lr:6.00e-02, fs:0.63768 (r=0.889,p=0.497),  time:35.551, tt:462.157\n",
      "Ep:13, loss:0.00005, loss_test:0.02589, lr:5.94e-02, fs:0.63538 (r=0.889,p=0.494),  time:35.538, tt:497.528\n",
      "Ep:14, loss:0.00005, loss_test:0.02532, lr:5.88e-02, fs:0.63768 (r=0.889,p=0.497),  time:35.470, tt:532.052\n",
      "Ep:15, loss:0.00005, loss_test:0.02468, lr:5.82e-02, fs:0.64945 (r=0.889,p=0.512),  time:35.590, tt:569.434\n",
      "Ep:16, loss:0.00005, loss_test:0.02406, lr:5.76e-02, fs:0.65185 (r=0.889,p=0.515),  time:35.566, tt:604.617\n",
      "Ep:17, loss:0.00005, loss_test:0.02345, lr:5.71e-02, fs:0.65926 (r=0.899,p=0.520),  time:35.581, tt:640.466\n",
      "Ep:18, loss:0.00005, loss_test:0.02285, lr:5.65e-02, fs:0.66171 (r=0.899,p=0.524),  time:35.482, tt:674.157\n",
      "Ep:19, loss:0.00004, loss_test:0.02225, lr:5.59e-02, fs:0.66165 (r=0.889,p=0.527),  time:35.491, tt:709.811\n",
      "Ep:20, loss:0.00004, loss_test:0.02175, lr:5.54e-02, fs:0.66914 (r=0.909,p=0.529),  time:35.465, tt:744.763\n",
      "Ep:21, loss:0.00004, loss_test:0.02117, lr:5.48e-02, fs:0.68914 (r=0.929,p=0.548),  time:35.444, tt:779.765\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00004, loss_test:0.02069, lr:5.48e-02, fs:0.69732 (r=0.919,p=0.562),  time:35.394, tt:814.070\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00004, loss_test:0.02033, lr:5.48e-02, fs:0.69732 (r=0.919,p=0.562),  time:35.381, tt:849.140\n",
      "Ep:24, loss:0.00004, loss_test:0.02015, lr:5.48e-02, fs:0.69962 (r=0.929,p=0.561),  time:35.366, tt:884.157\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00004, loss_test:0.01996, lr:5.48e-02, fs:0.69697 (r=0.929,p=0.558),  time:35.369, tt:919.607\n",
      "Ep:26, loss:0.00004, loss_test:0.01960, lr:5.48e-02, fs:0.70722 (r=0.939,p=0.567),  time:35.386, tt:955.418\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00004, loss_test:0.01922, lr:5.48e-02, fs:0.70229 (r=0.929,p=0.564),  time:35.392, tt:990.971\n",
      "Ep:28, loss:0.00004, loss_test:0.01893, lr:5.48e-02, fs:0.69732 (r=0.919,p=0.562),  time:35.385, tt:1026.151\n",
      "Ep:29, loss:0.00004, loss_test:0.01870, lr:5.48e-02, fs:0.72519 (r=0.960,p=0.583),  time:35.348, tt:1060.440\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00004, loss_test:0.01836, lr:5.48e-02, fs:0.73208 (r=0.980,p=0.584),  time:35.352, tt:1095.913\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01788, lr:5.48e-02, fs:0.73152 (r=0.949,p=0.595),  time:35.324, tt:1130.380\n",
      "Ep:32, loss:0.00003, loss_test:0.01752, lr:5.48e-02, fs:0.72868 (r=0.949,p=0.591),  time:35.338, tt:1166.140\n",
      "Ep:33, loss:0.00003, loss_test:0.01726, lr:5.48e-02, fs:0.73077 (r=0.960,p=0.590),  time:35.302, tt:1200.268\n",
      "Ep:34, loss:0.00003, loss_test:0.01690, lr:5.48e-02, fs:0.73643 (r=0.960,p=0.597),  time:35.308, tt:1235.795\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.01659, lr:5.48e-02, fs:0.75697 (r=0.960,p=0.625),  time:35.293, tt:1270.549\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01634, lr:5.48e-02, fs:0.75099 (r=0.960,p=0.617),  time:35.271, tt:1305.010\n",
      "Ep:37, loss:0.00003, loss_test:0.01604, lr:5.48e-02, fs:0.74494 (r=0.929,p=0.622),  time:35.258, tt:1339.797\n",
      "Ep:38, loss:0.00003, loss_test:0.01588, lr:5.48e-02, fs:0.76113 (r=0.949,p=0.635),  time:35.216, tt:1373.411\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.01579, lr:5.48e-02, fs:0.75610 (r=0.939,p=0.633),  time:35.200, tt:1407.994\n",
      "Ep:40, loss:0.00003, loss_test:0.01546, lr:5.48e-02, fs:0.77500 (r=0.939,p=0.660),  time:35.190, tt:1442.781\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00003, loss_test:0.01521, lr:5.48e-02, fs:0.77824 (r=0.939,p=0.664),  time:35.184, tt:1477.735\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.01514, lr:5.48e-02, fs:0.77500 (r=0.939,p=0.660),  time:35.156, tt:1511.705\n",
      "Ep:43, loss:0.00003, loss_test:0.01491, lr:5.48e-02, fs:0.78481 (r=0.939,p=0.674),  time:35.147, tt:1546.468\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01468, lr:5.48e-02, fs:0.78481 (r=0.939,p=0.674),  time:35.151, tt:1581.807\n",
      "Ep:45, loss:0.00002, loss_test:0.01446, lr:5.48e-02, fs:0.78481 (r=0.939,p=0.674),  time:35.146, tt:1616.707\n",
      "Ep:46, loss:0.00002, loss_test:0.01422, lr:5.48e-02, fs:0.78481 (r=0.939,p=0.674),  time:35.135, tt:1651.324\n",
      "Ep:47, loss:0.00002, loss_test:0.01396, lr:5.48e-02, fs:0.79149 (r=0.939,p=0.684),  time:35.114, tt:1685.485\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01384, lr:5.48e-02, fs:0.79149 (r=0.939,p=0.684),  time:35.100, tt:1719.894\n",
      "Ep:49, loss:0.00002, loss_test:0.01373, lr:5.48e-02, fs:0.79149 (r=0.939,p=0.684),  time:35.099, tt:1754.966\n",
      "Ep:50, loss:0.00002, loss_test:0.01351, lr:5.48e-02, fs:0.79828 (r=0.939,p=0.694),  time:35.078, tt:1788.960\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01352, lr:5.48e-02, fs:0.79654 (r=0.929,p=0.697),  time:35.045, tt:1822.359\n",
      "Ep:52, loss:0.00002, loss_test:0.01306, lr:5.48e-02, fs:0.80000 (r=0.949,p=0.691),  time:35.034, tt:1856.813\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01305, lr:5.48e-02, fs:0.81034 (r=0.949,p=0.707),  time:35.017, tt:1890.913\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.01278, lr:5.48e-02, fs:0.81197 (r=0.960,p=0.704),  time:35.014, tt:1925.782\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.01260, lr:5.48e-02, fs:0.80702 (r=0.929,p=0.713),  time:34.998, tt:1959.867\n",
      "Ep:56, loss:0.00002, loss_test:0.01249, lr:5.48e-02, fs:0.81938 (r=0.939,p=0.727),  time:34.976, tt:1993.654\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00002, loss_test:0.01229, lr:5.48e-02, fs:0.82456 (r=0.949,p=0.729),  time:34.962, tt:2027.787\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00002, loss_test:0.01270, lr:5.48e-02, fs:0.81250 (r=0.919,p=0.728),  time:34.953, tt:2062.203\n",
      "Ep:59, loss:0.00002, loss_test:0.01179, lr:5.48e-02, fs:0.82456 (r=0.949,p=0.729),  time:34.947, tt:2096.824\n",
      "Ep:60, loss:0.00002, loss_test:0.01184, lr:5.48e-02, fs:0.82667 (r=0.939,p=0.738),  time:34.941, tt:2131.380\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00002, loss_test:0.01260, lr:5.48e-02, fs:0.79638 (r=0.889,p=0.721),  time:34.937, tt:2166.104\n",
      "Ep:62, loss:0.00002, loss_test:0.01217, lr:5.48e-02, fs:0.82251 (r=0.960,p=0.720),  time:34.930, tt:2200.619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00002, loss_test:0.01230, lr:5.48e-02, fs:0.80734 (r=0.889,p=0.739),  time:34.913, tt:2234.429\n",
      "Ep:64, loss:0.00002, loss_test:0.01152, lr:5.48e-02, fs:0.83333 (r=0.960,p=0.736),  time:34.921, tt:2269.848\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.01164, lr:5.48e-02, fs:0.83036 (r=0.939,p=0.744),  time:34.912, tt:2304.186\n",
      "Ep:66, loss:0.00001, loss_test:0.01107, lr:5.48e-02, fs:0.83556 (r=0.949,p=0.746),  time:34.883, tt:2337.149\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01141, lr:5.48e-02, fs:0.79817 (r=0.879,p=0.731),  time:34.866, tt:2370.868\n",
      "Ep:68, loss:0.00001, loss_test:0.01141, lr:5.48e-02, fs:0.84793 (r=0.929,p=0.780),  time:34.841, tt:2404.043\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01188, lr:5.48e-02, fs:0.82407 (r=0.899,p=0.761),  time:34.834, tt:2438.378\n",
      "Ep:70, loss:0.00001, loss_test:0.01094, lr:5.48e-02, fs:0.82243 (r=0.889,p=0.765),  time:34.839, tt:2473.597\n",
      "Ep:71, loss:0.00001, loss_test:0.01196, lr:5.48e-02, fs:0.82407 (r=0.899,p=0.761),  time:34.828, tt:2507.633\n",
      "Ep:72, loss:0.00001, loss_test:0.01150, lr:5.48e-02, fs:0.82569 (r=0.909,p=0.756),  time:34.807, tt:2540.876\n",
      "Ep:73, loss:0.00001, loss_test:0.01146, lr:5.48e-02, fs:0.83178 (r=0.899,p=0.774),  time:34.795, tt:2574.858\n",
      "Ep:74, loss:0.00001, loss_test:0.01128, lr:5.48e-02, fs:0.82243 (r=0.889,p=0.765),  time:34.803, tt:2610.260\n",
      "Ep:75, loss:0.00001, loss_test:0.01098, lr:5.48e-02, fs:0.81690 (r=0.879,p=0.763),  time:34.794, tt:2644.329\n",
      "Ep:76, loss:0.00001, loss_test:0.01180, lr:5.48e-02, fs:0.80569 (r=0.859,p=0.759),  time:34.795, tt:2679.195\n",
      "Ep:77, loss:0.00001, loss_test:0.01104, lr:5.48e-02, fs:0.83412 (r=0.889,p=0.786),  time:34.778, tt:2712.667\n",
      "Ep:78, loss:0.00001, loss_test:0.01154, lr:5.48e-02, fs:0.81517 (r=0.869,p=0.768),  time:34.782, tt:2747.767\n",
      "Ep:79, loss:0.00001, loss_test:0.01134, lr:5.48e-02, fs:0.83654 (r=0.879,p=0.798),  time:34.752, tt:2780.150\n",
      "Ep:80, loss:0.00001, loss_test:0.01167, lr:5.43e-02, fs:0.81553 (r=0.848,p=0.785),  time:34.751, tt:2814.821\n",
      "Ep:81, loss:0.00001, loss_test:0.01163, lr:5.37e-02, fs:0.83092 (r=0.869,p=0.796),  time:34.754, tt:2849.793\n",
      "Ep:82, loss:0.00001, loss_test:0.01205, lr:5.32e-02, fs:0.82927 (r=0.859,p=0.802),  time:34.726, tt:2882.259\n",
      "Ep:83, loss:0.00001, loss_test:0.01180, lr:5.27e-02, fs:0.83582 (r=0.848,p=0.824),  time:34.712, tt:2915.829\n",
      "Ep:84, loss:0.00001, loss_test:0.01248, lr:5.21e-02, fs:0.83168 (r=0.848,p=0.816),  time:34.753, tt:2953.969\n",
      "Ep:85, loss:0.00001, loss_test:0.01199, lr:5.16e-02, fs:0.82759 (r=0.848,p=0.808),  time:34.751, tt:2988.605\n",
      "Ep:86, loss:0.00001, loss_test:0.01265, lr:5.11e-02, fs:0.83673 (r=0.828,p=0.845),  time:34.744, tt:3022.685\n",
      "Ep:87, loss:0.00001, loss_test:0.01268, lr:5.06e-02, fs:0.82412 (r=0.828,p=0.820),  time:34.729, tt:3056.127\n",
      "Ep:88, loss:0.00001, loss_test:0.01356, lr:5.01e-02, fs:0.78571 (r=0.778,p=0.794),  time:34.748, tt:3092.590\n",
      "Ep:89, loss:0.00001, loss_test:0.01289, lr:4.96e-02, fs:0.83417 (r=0.838,p=0.830),  time:34.749, tt:3127.411\n",
      "Ep:90, loss:0.00001, loss_test:0.01237, lr:4.91e-02, fs:0.83000 (r=0.838,p=0.822),  time:34.741, tt:3161.391\n",
      "Ep:91, loss:0.00001, loss_test:0.01454, lr:4.86e-02, fs:0.77949 (r=0.768,p=0.792),  time:34.737, tt:3195.846\n",
      "Ep:92, loss:0.00001, loss_test:0.01285, lr:4.81e-02, fs:0.84422 (r=0.848,p=0.840),  time:34.741, tt:3230.895\n",
      "Ep:93, loss:0.00001, loss_test:0.01312, lr:4.76e-02, fs:0.79000 (r=0.798,p=0.782),  time:34.728, tt:3264.388\n",
      "Ep:94, loss:0.00001, loss_test:0.01283, lr:4.71e-02, fs:0.85714 (r=0.879,p=0.837),  time:34.730, tt:3299.374\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00001, loss_test:0.01406, lr:4.71e-02, fs:0.77551 (r=0.768,p=0.784),  time:34.738, tt:3334.887\n",
      "Ep:96, loss:0.00001, loss_test:0.01271, lr:4.71e-02, fs:0.84577 (r=0.859,p=0.833),  time:34.751, tt:3370.867\n",
      "Ep:97, loss:0.00001, loss_test:0.01404, lr:4.71e-02, fs:0.80597 (r=0.818,p=0.794),  time:34.750, tt:3405.543\n",
      "Ep:98, loss:0.00001, loss_test:0.01273, lr:4.71e-02, fs:0.83582 (r=0.848,p=0.824),  time:34.754, tt:3440.643\n",
      "Ep:99, loss:0.00001, loss_test:0.01456, lr:4.71e-02, fs:0.79365 (r=0.758,p=0.833),  time:34.783, tt:3478.268\n",
      "Ep:100, loss:0.00001, loss_test:0.01369, lr:4.71e-02, fs:0.83838 (r=0.838,p=0.838),  time:34.784, tt:3513.196\n",
      "Ep:101, loss:0.00001, loss_test:0.01408, lr:4.71e-02, fs:0.77551 (r=0.768,p=0.784),  time:34.782, tt:3547.747\n",
      "Ep:102, loss:0.00001, loss_test:0.01388, lr:4.71e-02, fs:0.83938 (r=0.818,p=0.862),  time:34.783, tt:3582.690\n",
      "Ep:103, loss:0.00001, loss_test:0.01465, lr:4.71e-02, fs:0.78495 (r=0.737,p=0.839),  time:34.777, tt:3616.760\n",
      "Ep:104, loss:0.00001, loss_test:0.01433, lr:4.71e-02, fs:0.80214 (r=0.758,p=0.852),  time:34.767, tt:3650.515\n",
      "Ep:105, loss:0.00001, loss_test:0.01494, lr:4.71e-02, fs:0.78723 (r=0.747,p=0.831),  time:34.763, tt:3684.895\n",
      "Ep:106, loss:0.00001, loss_test:0.01456, lr:4.67e-02, fs:0.79348 (r=0.737,p=0.859),  time:34.755, tt:3718.763\n",
      "Ep:107, loss:0.00001, loss_test:0.01518, lr:4.62e-02, fs:0.79787 (r=0.758,p=0.843),  time:34.754, tt:3753.418\n",
      "Ep:108, loss:0.00001, loss_test:0.01534, lr:4.57e-02, fs:0.79781 (r=0.737,p=0.869),  time:34.750, tt:3787.800\n",
      "Ep:109, loss:0.00001, loss_test:0.01593, lr:4.53e-02, fs:0.78919 (r=0.737,p=0.849),  time:34.751, tt:3822.608\n",
      "Ep:110, loss:0.00000, loss_test:0.01490, lr:4.48e-02, fs:0.81081 (r=0.758,p=0.872),  time:34.736, tt:3855.685\n",
      "Ep:111, loss:0.00000, loss_test:0.01620, lr:4.44e-02, fs:0.79348 (r=0.737,p=0.859),  time:34.729, tt:3889.690\n",
      "Ep:112, loss:0.00000, loss_test:0.01538, lr:4.39e-02, fs:0.81522 (r=0.758,p=0.882),  time:34.731, tt:3924.599\n",
      "Ep:113, loss:0.00000, loss_test:0.01541, lr:4.35e-02, fs:0.81522 (r=0.758,p=0.882),  time:34.724, tt:3958.581\n",
      "Ep:114, loss:0.00000, loss_test:0.01694, lr:4.31e-02, fs:0.79121 (r=0.727,p=0.867),  time:34.701, tt:3990.596\n",
      "Ep:115, loss:0.00000, loss_test:0.01504, lr:4.26e-02, fs:0.81081 (r=0.758,p=0.872),  time:34.700, tt:4025.215\n",
      "Ep:116, loss:0.00000, loss_test:0.01672, lr:4.22e-02, fs:0.80220 (r=0.737,p=0.880),  time:34.698, tt:4059.701\n",
      "Ep:117, loss:0.00000, loss_test:0.01621, lr:4.18e-02, fs:0.79558 (r=0.727,p=0.878),  time:34.694, tt:4093.843\n",
      "Ep:118, loss:0.00000, loss_test:0.01577, lr:4.14e-02, fs:0.79781 (r=0.737,p=0.869),  time:34.690, tt:4128.148\n",
      "Ep:119, loss:0.00000, loss_test:0.01688, lr:4.10e-02, fs:0.78889 (r=0.717,p=0.877),  time:34.701, tt:4164.149\n",
      "Ep:120, loss:0.00000, loss_test:0.01615, lr:4.05e-02, fs:0.80220 (r=0.737,p=0.880),  time:34.713, tt:4200.239\n",
      "Ep:121, loss:0.00000, loss_test:0.01655, lr:4.01e-02, fs:0.81319 (r=0.747,p=0.892),  time:34.707, tt:4234.216\n",
      "Ep:122, loss:0.00000, loss_test:0.01736, lr:3.97e-02, fs:0.80000 (r=0.727,p=0.889),  time:34.705, tt:4268.672\n",
      "Ep:123, loss:0.00000, loss_test:0.01700, lr:3.93e-02, fs:0.80874 (r=0.747,p=0.881),  time:34.707, tt:4303.643\n",
      "Ep:124, loss:0.00000, loss_test:0.01663, lr:3.89e-02, fs:0.78889 (r=0.717,p=0.877),  time:34.705, tt:4338.132\n",
      "Ep:125, loss:0.00000, loss_test:0.01808, lr:3.86e-02, fs:0.78889 (r=0.717,p=0.877),  time:34.692, tt:4371.229\n",
      "Ep:126, loss:0.00000, loss_test:0.01663, lr:3.82e-02, fs:0.80220 (r=0.737,p=0.880),  time:34.684, tt:4404.903\n",
      "Ep:127, loss:0.00000, loss_test:0.01813, lr:3.78e-02, fs:0.79775 (r=0.717,p=0.899),  time:34.686, tt:4439.763\n",
      "Ep:128, loss:0.00000, loss_test:0.01706, lr:3.74e-02, fs:0.79330 (r=0.717,p=0.887),  time:34.688, tt:4474.806\n",
      "Ep:129, loss:0.00000, loss_test:0.01729, lr:3.70e-02, fs:0.79330 (r=0.717,p=0.887),  time:34.680, tt:4508.346\n",
      "Ep:130, loss:0.00000, loss_test:0.01843, lr:3.67e-02, fs:0.79775 (r=0.717,p=0.899),  time:34.676, tt:4542.529\n",
      "Ep:131, loss:0.00000, loss_test:0.01728, lr:3.63e-02, fs:0.80000 (r=0.727,p=0.889),  time:34.662, tt:4575.366\n",
      "Ep:132, loss:0.00000, loss_test:0.01776, lr:3.59e-02, fs:0.79330 (r=0.717,p=0.887),  time:34.659, tt:4609.698\n",
      "Ep:133, loss:0.00000, loss_test:0.01797, lr:3.56e-02, fs:0.79775 (r=0.717,p=0.899),  time:34.652, tt:4643.384\n",
      "Ep:134, loss:0.00000, loss_test:0.01801, lr:3.52e-02, fs:0.81111 (r=0.737,p=0.901),  time:34.647, tt:4677.320\n",
      "Ep:135, loss:0.00000, loss_test:0.01849, lr:3.49e-02, fs:0.79775 (r=0.717,p=0.899),  time:34.638, tt:4710.809\n",
      "Ep:136, loss:0.00000, loss_test:0.01810, lr:3.45e-02, fs:0.81111 (r=0.737,p=0.901),  time:34.629, tt:4744.167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.01821, lr:3.42e-02, fs:0.79775 (r=0.717,p=0.899),  time:34.626, tt:4778.410\n",
      "Ep:138, loss:0.00000, loss_test:0.01976, lr:3.38e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.613, tt:4811.142\n",
      "Ep:139, loss:0.00000, loss_test:0.01754, lr:3.35e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.602, tt:4844.255\n",
      "Ep:140, loss:0.00000, loss_test:0.01930, lr:3.32e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.604, tt:4879.225\n",
      "Ep:141, loss:0.00000, loss_test:0.01853, lr:3.28e-02, fs:0.79775 (r=0.717,p=0.899),  time:34.599, tt:4913.089\n",
      "Ep:142, loss:0.00000, loss_test:0.01821, lr:3.25e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.585, tt:4945.646\n",
      "Ep:143, loss:0.00000, loss_test:0.02023, lr:3.22e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.576, tt:4978.921\n",
      "Ep:144, loss:0.00000, loss_test:0.01772, lr:3.19e-02, fs:0.81564 (r=0.737,p=0.912),  time:34.568, tt:5012.396\n",
      "Ep:145, loss:0.00000, loss_test:0.02040, lr:3.15e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.571, tt:5047.339\n",
      "Ep:146, loss:0.00000, loss_test:0.01910, lr:3.12e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.565, tt:5081.017\n",
      "Ep:147, loss:0.00000, loss_test:0.01977, lr:3.09e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.560, tt:5114.953\n",
      "Ep:148, loss:0.00000, loss_test:0.02008, lr:3.06e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.549, tt:5147.737\n",
      "Ep:149, loss:0.00000, loss_test:0.01945, lr:3.03e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.539, tt:5180.829\n",
      "Ep:150, loss:0.00000, loss_test:0.02019, lr:3.00e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.530, tt:5214.043\n",
      "Ep:151, loss:0.00000, loss_test:0.01951, lr:2.97e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.527, tt:5248.105\n",
      "Ep:152, loss:0.00000, loss_test:0.02040, lr:2.94e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.518, tt:5281.236\n",
      "Ep:153, loss:0.00000, loss_test:0.02019, lr:2.91e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.525, tt:5316.865\n",
      "Ep:154, loss:0.00000, loss_test:0.02057, lr:2.88e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.517, tt:5350.186\n",
      "Ep:155, loss:0.00000, loss_test:0.01961, lr:2.85e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.512, tt:5383.941\n",
      "Ep:156, loss:0.00000, loss_test:0.02081, lr:2.82e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.511, tt:5418.283\n",
      "Ep:157, loss:0.00000, loss_test:0.01992, lr:2.80e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.501, tt:5451.154\n",
      "Ep:158, loss:0.00000, loss_test:0.02058, lr:2.77e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.490, tt:5483.942\n",
      "Ep:159, loss:0.00000, loss_test:0.02079, lr:2.74e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.473, tt:5515.606\n",
      "Ep:160, loss:0.00000, loss_test:0.02052, lr:2.71e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.460, tt:5548.128\n",
      "Ep:161, loss:0.00000, loss_test:0.02054, lr:2.69e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.450, tt:5580.976\n",
      "Ep:162, loss:0.00000, loss_test:0.02150, lr:2.66e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.438, tt:5613.376\n",
      "Ep:163, loss:0.00000, loss_test:0.02024, lr:2.63e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.430, tt:5646.490\n",
      "Ep:164, loss:0.00000, loss_test:0.02137, lr:2.61e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.418, tt:5678.926\n",
      "Ep:165, loss:0.00000, loss_test:0.02088, lr:2.58e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.409, tt:5711.946\n",
      "Ep:166, loss:0.00000, loss_test:0.02113, lr:2.55e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.395, tt:5743.893\n",
      "Ep:167, loss:0.00000, loss_test:0.02127, lr:2.53e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.387, tt:5777.085\n",
      "Ep:168, loss:0.00000, loss_test:0.02101, lr:2.50e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.389, tt:5811.658\n",
      "Ep:169, loss:0.00000, loss_test:0.02193, lr:2.48e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.381, tt:5844.775\n",
      "Ep:170, loss:0.00000, loss_test:0.02085, lr:2.45e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.373, tt:5877.789\n",
      "Ep:171, loss:0.00000, loss_test:0.02200, lr:2.43e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.361, tt:5910.092\n",
      "Ep:172, loss:0.00000, loss_test:0.02115, lr:2.40e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.362, tt:5944.668\n",
      "Ep:173, loss:0.00000, loss_test:0.02199, lr:2.38e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.353, tt:5977.367\n",
      "Ep:174, loss:0.00000, loss_test:0.02161, lr:2.36e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.359, tt:6012.830\n",
      "Ep:175, loss:0.00000, loss_test:0.02166, lr:2.33e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.363, tt:6047.903\n",
      "Ep:176, loss:0.00000, loss_test:0.02164, lr:2.31e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.362, tt:6081.987\n",
      "Ep:177, loss:0.00000, loss_test:0.02185, lr:2.29e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.367, tt:6117.299\n",
      "Ep:178, loss:0.00000, loss_test:0.02198, lr:2.26e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.366, tt:6151.501\n",
      "Ep:179, loss:0.00000, loss_test:0.02185, lr:2.24e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.361, tt:6184.957\n",
      "Ep:180, loss:0.00000, loss_test:0.02190, lr:2.22e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.358, tt:6218.785\n",
      "Ep:181, loss:0.00000, loss_test:0.02228, lr:2.20e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.355, tt:6252.649\n",
      "Ep:182, loss:0.00000, loss_test:0.02193, lr:2.17e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.353, tt:6286.533\n",
      "Ep:183, loss:0.00000, loss_test:0.02252, lr:2.15e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.348, tt:6320.103\n",
      "Ep:184, loss:0.00000, loss_test:0.02211, lr:2.13e-02, fs:0.80460 (r=0.707,p=0.933),  time:34.352, tt:6355.063\n",
      "Ep:185, loss:0.00000, loss_test:0.02261, lr:2.11e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.344, tt:6387.918\n",
      "Ep:186, loss:0.00000, loss_test:0.02246, lr:2.09e-02, fs:0.79070 (r=0.687,p=0.932),  time:34.339, tt:6421.441\n",
      "Ep:187, loss:0.00000, loss_test:0.02216, lr:2.07e-02, fs:0.81609 (r=0.717,p=0.947),  time:34.330, tt:6454.078\n",
      "Ep:188, loss:0.00000, loss_test:0.02281, lr:2.05e-02, fs:0.79070 (r=0.687,p=0.932),  time:34.324, tt:6487.325\n",
      "Ep:189, loss:0.00000, loss_test:0.02244, lr:2.03e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.324, tt:6521.581\n",
      "Ep:190, loss:0.00000, loss_test:0.02280, lr:2.01e-02, fs:0.79070 (r=0.687,p=0.932),  time:34.331, tt:6557.257\n",
      "Ep:191, loss:0.00000, loss_test:0.02262, lr:1.99e-02, fs:0.81609 (r=0.717,p=0.947),  time:34.329, tt:6591.240\n",
      "Ep:192, loss:0.00000, loss_test:0.02272, lr:1.97e-02, fs:0.79070 (r=0.687,p=0.932),  time:34.326, tt:6624.970\n",
      "Ep:193, loss:0.00000, loss_test:0.02281, lr:1.95e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.330, tt:6659.978\n",
      "Ep:194, loss:0.00000, loss_test:0.02292, lr:1.93e-02, fs:0.79070 (r=0.687,p=0.932),  time:34.331, tt:6694.495\n",
      "Ep:195, loss:0.00000, loss_test:0.02295, lr:1.91e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.334, tt:6729.553\n",
      "Ep:196, loss:0.00000, loss_test:0.02294, lr:1.89e-02, fs:0.79070 (r=0.687,p=0.932),  time:34.332, tt:6763.332\n",
      "Ep:197, loss:0.00000, loss_test:0.02330, lr:1.87e-02, fs:0.79070 (r=0.687,p=0.932),  time:34.328, tt:6796.906\n",
      "Ep:198, loss:0.00000, loss_test:0.02271, lr:1.85e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.333, tt:6832.360\n",
      "Ep:199, loss:0.00000, loss_test:0.02357, lr:1.83e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.330, tt:6866.020\n",
      "Ep:200, loss:0.00000, loss_test:0.02278, lr:1.81e-02, fs:0.79290 (r=0.677,p=0.957),  time:34.335, tt:6901.377\n",
      "Ep:201, loss:0.00000, loss_test:0.02347, lr:1.80e-02, fs:0.79070 (r=0.687,p=0.932),  time:34.333, tt:6935.266\n",
      "Ep:202, loss:0.00000, loss_test:0.02294, lr:1.78e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.324, tt:6967.790\n",
      "Ep:203, loss:0.00000, loss_test:0.02364, lr:1.76e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.318, tt:7000.934\n",
      "Ep:204, loss:0.00000, loss_test:0.02296, lr:1.74e-02, fs:0.79290 (r=0.677,p=0.957),  time:34.316, tt:7034.706\n",
      "Ep:205, loss:0.00000, loss_test:0.02359, lr:1.73e-02, fs:0.79070 (r=0.687,p=0.932),  time:34.313, tt:7068.410\n",
      "Ep:206, loss:0.00000, loss_test:0.02322, lr:1.71e-02, fs:0.79290 (r=0.677,p=0.957),  time:34.309, tt:7102.062\n",
      "Ep:207, loss:0.00000, loss_test:0.02363, lr:1.69e-02, fs:0.78107 (r=0.667,p=0.943),  time:34.298, tt:7134.029\n",
      "Ep:208, loss:0.00000, loss_test:0.02322, lr:1.67e-02, fs:0.79290 (r=0.677,p=0.957),  time:34.265, tt:7161.373\n",
      "Ep:209, loss:0.00000, loss_test:0.02376, lr:1.66e-02, fs:0.78107 (r=0.667,p=0.943),  time:34.221, tt:7186.398\n",
      "Ep:210, loss:0.00000, loss_test:0.02332, lr:1.64e-02, fs:0.78571 (r=0.667,p=0.957),  time:34.196, tt:7215.283\n",
      "Model and results saved\n",
      "Saving best model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13198, lr:1.00e-02, fs:0.67170 (r=0.899,p=0.536),  time:34.092, tt:34.092\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.13121, lr:1.00e-02, fs:0.67170 (r=0.899,p=0.536),  time:33.511, tt:67.022\n",
      "Ep:2, loss:0.00026, loss_test:0.13051, lr:1.00e-02, fs:0.67424 (r=0.899,p=0.539),  time:33.979, tt:101.937\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12956, lr:1.00e-02, fs:0.67681 (r=0.899,p=0.543),  time:34.130, tt:136.518\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12799, lr:1.00e-02, fs:0.68199 (r=0.899,p=0.549),  time:34.102, tt:170.507\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.12643, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:34.107, tt:204.643\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.12522, lr:1.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:34.530, tt:241.712\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00025, loss_test:0.12426, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:34.666, tt:277.329\n",
      "Ep:8, loss:0.00025, loss_test:0.12295, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:34.969, tt:314.724\n",
      "Ep:9, loss:0.00024, loss_test:0.12125, lr:1.00e-02, fs:0.69804 (r=0.899,p=0.571),  time:34.807, tt:348.069\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00024, loss_test:0.11941, lr:1.00e-02, fs:0.69804 (r=0.899,p=0.571),  time:34.875, tt:383.630\n",
      "Ep:11, loss:0.00024, loss_test:0.11747, lr:1.00e-02, fs:0.69600 (r=0.879,p=0.576),  time:34.966, tt:419.590\n",
      "Ep:12, loss:0.00023, loss_test:0.11533, lr:1.00e-02, fs:0.70161 (r=0.879,p=0.584),  time:34.950, tt:454.354\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00023, loss_test:0.11329, lr:1.00e-02, fs:0.70732 (r=0.879,p=0.592),  time:34.945, tt:489.229\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00023, loss_test:0.11129, lr:1.00e-02, fs:0.69710 (r=0.848,p=0.592),  time:34.999, tt:524.983\n",
      "Ep:15, loss:0.00022, loss_test:0.10964, lr:1.00e-02, fs:0.70539 (r=0.859,p=0.599),  time:34.991, tt:559.856\n",
      "Ep:16, loss:0.00022, loss_test:0.10817, lr:1.00e-02, fs:0.70833 (r=0.859,p=0.603),  time:34.964, tt:594.389\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00021, loss_test:0.10637, lr:1.00e-02, fs:0.71130 (r=0.859,p=0.607),  time:34.837, tt:627.068\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00021, loss_test:0.10501, lr:1.00e-02, fs:0.71130 (r=0.859,p=0.607),  time:34.914, tt:663.374\n",
      "Ep:19, loss:0.00020, loss_test:0.10333, lr:1.00e-02, fs:0.71429 (r=0.859,p=0.612),  time:34.854, tt:697.090\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00020, loss_test:0.10141, lr:1.00e-02, fs:0.71730 (r=0.859,p=0.616),  time:34.783, tt:730.446\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00019, loss_test:0.09989, lr:1.00e-02, fs:0.71489 (r=0.848,p=0.618),  time:34.729, tt:764.028\n",
      "Ep:22, loss:0.00019, loss_test:0.09724, lr:1.00e-02, fs:0.74359 (r=0.879,p=0.644),  time:34.713, tt:798.404\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00018, loss_test:0.09437, lr:1.00e-02, fs:0.76316 (r=0.879,p=0.674),  time:34.698, tt:832.745\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00017, loss_test:0.09245, lr:1.00e-02, fs:0.75745 (r=0.899,p=0.654),  time:34.683, tt:867.083\n",
      "Ep:25, loss:0.00017, loss_test:0.08904, lr:1.00e-02, fs:0.78222 (r=0.889,p=0.698),  time:34.719, tt:902.699\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00016, loss_test:0.08968, lr:1.00e-02, fs:0.77778 (r=0.919,p=0.674),  time:34.729, tt:937.679\n",
      "Ep:27, loss:0.00016, loss_test:0.08575, lr:1.00e-02, fs:0.79630 (r=0.869,p=0.735),  time:34.722, tt:972.213\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00015, loss_test:0.09067, lr:1.00e-02, fs:0.77391 (r=0.899,p=0.679),  time:34.707, tt:1006.504\n",
      "Ep:29, loss:0.00015, loss_test:0.08071, lr:1.00e-02, fs:0.81481 (r=0.889,p=0.752),  time:34.768, tt:1043.028\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00014, loss_test:0.08471, lr:1.00e-02, fs:0.77729 (r=0.899,p=0.685),  time:34.836, tt:1079.912\n",
      "Ep:31, loss:0.00013, loss_test:0.07822, lr:1.00e-02, fs:0.82243 (r=0.889,p=0.765),  time:34.828, tt:1114.492\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00013, loss_test:0.08704, lr:1.00e-02, fs:0.75349 (r=0.818,p=0.698),  time:34.818, tt:1148.992\n",
      "Ep:33, loss:0.00013, loss_test:0.07696, lr:1.00e-02, fs:0.81223 (r=0.939,p=0.715),  time:34.781, tt:1182.571\n",
      "Ep:34, loss:0.00012, loss_test:0.08116, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:34.801, tt:1218.026\n",
      "Ep:35, loss:0.00012, loss_test:0.08428, lr:1.00e-02, fs:0.74775 (r=0.838,p=0.675),  time:34.789, tt:1252.391\n",
      "Ep:36, loss:0.00012, loss_test:0.08800, lr:1.00e-02, fs:0.77729 (r=0.899,p=0.685),  time:34.800, tt:1287.599\n",
      "Ep:37, loss:0.00013, loss_test:0.09027, lr:1.00e-02, fs:0.74419 (r=0.808,p=0.690),  time:34.787, tt:1321.923\n",
      "Ep:38, loss:0.00012, loss_test:0.07773, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:34.762, tt:1355.715\n",
      "Ep:39, loss:0.00012, loss_test:0.07366, lr:1.00e-02, fs:0.80889 (r=0.919,p=0.722),  time:34.778, tt:1391.105\n",
      "Ep:40, loss:0.00011, loss_test:0.07554, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:34.793, tt:1426.530\n",
      "Ep:41, loss:0.00010, loss_test:0.06935, lr:1.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:34.777, tt:1460.654\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00009, loss_test:0.07144, lr:1.00e-02, fs:0.81448 (r=0.909,p=0.738),  time:34.798, tt:1496.309\n",
      "Ep:43, loss:0.00009, loss_test:0.06607, lr:1.00e-02, fs:0.84615 (r=0.889,p=0.807),  time:34.825, tt:1532.318\n",
      "Ep:44, loss:0.00008, loss_test:0.06272, lr:1.00e-02, fs:0.88479 (r=0.970,p=0.814),  time:34.813, tt:1566.602\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00008, loss_test:0.06625, lr:1.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:34.791, tt:1600.369\n",
      "Ep:46, loss:0.00008, loss_test:0.06696, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:34.780, tt:1634.677\n",
      "Ep:47, loss:0.00007, loss_test:0.06001, lr:1.00e-02, fs:0.86432 (r=0.869,p=0.860),  time:34.739, tt:1667.474\n",
      "Ep:48, loss:0.00007, loss_test:0.06999, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:34.759, tt:1703.185\n",
      "Ep:49, loss:0.00007, loss_test:0.06983, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:34.783, tt:1739.154\n",
      "Ep:50, loss:0.00007, loss_test:0.05968, lr:1.00e-02, fs:0.83000 (r=0.838,p=0.822),  time:34.814, tt:1775.529\n",
      "Ep:51, loss:0.00006, loss_test:0.06805, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:34.811, tt:1810.151\n",
      "Ep:52, loss:0.00007, loss_test:0.06506, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:34.775, tt:1843.086\n",
      "Ep:53, loss:0.00006, loss_test:0.06480, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:34.773, tt:1877.743\n",
      "Ep:54, loss:0.00006, loss_test:0.06973, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:34.754, tt:1911.473\n",
      "Ep:55, loss:0.00006, loss_test:0.06041, lr:1.00e-02, fs:0.85581 (r=0.929,p=0.793),  time:34.757, tt:1946.373\n",
      "Ep:56, loss:0.00006, loss_test:0.06647, lr:9.90e-03, fs:0.84492 (r=0.798,p=0.898),  time:34.755, tt:1981.058\n",
      "Ep:57, loss:0.00005, loss_test:0.06987, lr:9.80e-03, fs:0.78125 (r=0.758,p=0.806),  time:34.744, tt:2015.175\n",
      "Ep:58, loss:0.00005, loss_test:0.05679, lr:9.70e-03, fs:0.84848 (r=0.848,p=0.848),  time:34.743, tt:2049.860\n",
      "Ep:59, loss:0.00005, loss_test:0.06647, lr:9.61e-03, fs:0.81481 (r=0.778,p=0.856),  time:34.763, tt:2085.770\n",
      "Ep:60, loss:0.00005, loss_test:0.06531, lr:9.51e-03, fs:0.80000 (r=0.788,p=0.812),  time:34.764, tt:2120.622\n",
      "Ep:61, loss:0.00005, loss_test:0.05787, lr:9.41e-03, fs:0.89216 (r=0.919,p=0.867),  time:34.750, tt:2154.528\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00005, loss_test:0.06960, lr:9.41e-03, fs:0.83598 (r=0.798,p=0.878),  time:34.751, tt:2189.304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00006, loss_test:0.05990, lr:9.41e-03, fs:0.83673 (r=0.828,p=0.845),  time:34.737, tt:2223.140\n",
      "Ep:64, loss:0.00006, loss_test:0.05692, lr:9.41e-03, fs:0.89952 (r=0.949,p=0.855),  time:34.707, tt:2255.951\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00005, loss_test:0.07451, lr:9.41e-03, fs:0.82162 (r=0.768,p=0.884),  time:34.697, tt:2289.996\n",
      "Ep:66, loss:0.00005, loss_test:0.06291, lr:9.41e-03, fs:0.85714 (r=0.818,p=0.900),  time:34.660, tt:2322.242\n",
      "Ep:67, loss:0.00004, loss_test:0.06025, lr:9.41e-03, fs:0.89100 (r=0.949,p=0.839),  time:34.640, tt:2355.531\n",
      "Ep:68, loss:0.00004, loss_test:0.05676, lr:9.41e-03, fs:0.88660 (r=0.869,p=0.905),  time:34.630, tt:2389.443\n",
      "Ep:69, loss:0.00004, loss_test:0.06529, lr:9.41e-03, fs:0.81720 (r=0.768,p=0.874),  time:34.677, tt:2427.381\n",
      "Ep:70, loss:0.00004, loss_test:0.05461, lr:9.41e-03, fs:0.85714 (r=0.848,p=0.866),  time:34.669, tt:2461.500\n",
      "Ep:71, loss:0.00004, loss_test:0.06015, lr:9.41e-03, fs:0.81283 (r=0.768,p=0.864),  time:34.659, tt:2495.459\n",
      "Ep:72, loss:0.00003, loss_test:0.06033, lr:9.41e-03, fs:0.86170 (r=0.818,p=0.910),  time:34.669, tt:2530.859\n",
      "Ep:73, loss:0.00003, loss_test:0.06281, lr:9.41e-03, fs:0.80214 (r=0.758,p=0.852),  time:34.666, tt:2565.291\n",
      "Ep:74, loss:0.00003, loss_test:0.06961, lr:9.41e-03, fs:0.81967 (r=0.758,p=0.893),  time:34.671, tt:2600.355\n",
      "Ep:75, loss:0.00003, loss_test:0.06043, lr:9.41e-03, fs:0.86316 (r=0.828,p=0.901),  time:34.665, tt:2634.522\n",
      "Ep:76, loss:0.00003, loss_test:0.06487, lr:9.32e-03, fs:0.86631 (r=0.818,p=0.920),  time:34.664, tt:2669.109\n",
      "Ep:77, loss:0.00003, loss_test:0.05987, lr:9.23e-03, fs:0.83871 (r=0.788,p=0.897),  time:34.674, tt:2704.555\n",
      "Ep:78, loss:0.00003, loss_test:0.07091, lr:9.14e-03, fs:0.81081 (r=0.758,p=0.872),  time:34.681, tt:2739.824\n",
      "Ep:79, loss:0.00003, loss_test:0.06054, lr:9.04e-03, fs:0.85263 (r=0.818,p=0.890),  time:34.701, tt:2776.079\n",
      "Ep:80, loss:0.00003, loss_test:0.06829, lr:8.95e-03, fs:0.81522 (r=0.758,p=0.882),  time:34.708, tt:2811.310\n",
      "Ep:81, loss:0.00002, loss_test:0.06761, lr:8.86e-03, fs:0.85405 (r=0.798,p=0.919),  time:34.706, tt:2845.910\n",
      "Ep:82, loss:0.00002, loss_test:0.07191, lr:8.78e-03, fs:0.81967 (r=0.758,p=0.893),  time:34.699, tt:2880.022\n",
      "Ep:83, loss:0.00002, loss_test:0.05580, lr:8.69e-03, fs:0.85714 (r=0.818,p=0.900),  time:34.713, tt:2915.898\n",
      "Ep:84, loss:0.00002, loss_test:0.06307, lr:8.60e-03, fs:0.87234 (r=0.828,p=0.921),  time:34.718, tt:2951.068\n",
      "Ep:85, loss:0.00002, loss_test:0.06963, lr:8.51e-03, fs:0.82873 (r=0.758,p=0.915),  time:34.705, tt:2984.655\n",
      "Ep:86, loss:0.00002, loss_test:0.06725, lr:8.43e-03, fs:0.82222 (r=0.747,p=0.914),  time:34.657, tt:3015.144\n",
      "Ep:87, loss:0.00002, loss_test:0.06690, lr:8.35e-03, fs:0.82682 (r=0.747,p=0.925),  time:34.625, tt:3046.961\n",
      "Ep:88, loss:0.00002, loss_test:0.06398, lr:8.26e-03, fs:0.83978 (r=0.768,p=0.927),  time:34.618, tt:3080.996\n",
      "Ep:89, loss:0.00002, loss_test:0.07237, lr:8.18e-03, fs:0.82418 (r=0.758,p=0.904),  time:34.612, tt:3115.119\n",
      "Ep:90, loss:0.00002, loss_test:0.07093, lr:8.10e-03, fs:0.83799 (r=0.758,p=0.938),  time:34.616, tt:3150.057\n",
      "Ep:91, loss:0.00001, loss_test:0.06583, lr:8.02e-03, fs:0.83333 (r=0.758,p=0.926),  time:34.615, tt:3184.570\n",
      "Ep:92, loss:0.00001, loss_test:0.07067, lr:7.94e-03, fs:0.82022 (r=0.737,p=0.924),  time:34.612, tt:3218.932\n",
      "Ep:93, loss:0.00001, loss_test:0.07292, lr:7.86e-03, fs:0.83978 (r=0.768,p=0.927),  time:34.632, tt:3255.383\n",
      "Ep:94, loss:0.00001, loss_test:0.07760, lr:7.78e-03, fs:0.81768 (r=0.747,p=0.902),  time:34.635, tt:3290.291\n",
      "Ep:95, loss:0.00002, loss_test:0.06847, lr:7.70e-03, fs:0.83799 (r=0.758,p=0.938),  time:34.661, tt:3327.432\n",
      "Ep:96, loss:0.00001, loss_test:0.06838, lr:7.62e-03, fs:0.85870 (r=0.798,p=0.929),  time:34.652, tt:3361.256\n",
      "Ep:97, loss:0.00001, loss_test:0.08041, lr:7.55e-03, fs:0.81818 (r=0.727,p=0.935),  time:34.654, tt:3396.096\n",
      "Ep:98, loss:0.00001, loss_test:0.07171, lr:7.47e-03, fs:0.85405 (r=0.798,p=0.919),  time:34.660, tt:3431.332\n",
      "Ep:99, loss:0.00001, loss_test:0.08117, lr:7.40e-03, fs:0.83146 (r=0.747,p=0.937),  time:34.652, tt:3465.223\n",
      "Ep:100, loss:0.00001, loss_test:0.06790, lr:7.32e-03, fs:0.83333 (r=0.758,p=0.926),  time:34.650, tt:3499.655\n",
      "Ep:101, loss:0.00001, loss_test:0.07261, lr:7.25e-03, fs:0.85870 (r=0.798,p=0.929),  time:34.643, tt:3533.591\n",
      "Ep:102, loss:0.00001, loss_test:0.07555, lr:7.18e-03, fs:0.82022 (r=0.737,p=0.924),  time:34.652, tt:3569.127\n",
      "Ep:103, loss:0.00001, loss_test:0.07514, lr:7.11e-03, fs:0.83978 (r=0.768,p=0.927),  time:34.653, tt:3603.958\n",
      "Ep:104, loss:0.00001, loss_test:0.07371, lr:7.03e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.661, tt:3639.394\n",
      "Ep:105, loss:0.00001, loss_test:0.07323, lr:6.96e-03, fs:0.85561 (r=0.808,p=0.909),  time:34.650, tt:3672.856\n",
      "Ep:106, loss:0.00001, loss_test:0.07483, lr:6.89e-03, fs:0.83333 (r=0.758,p=0.926),  time:34.663, tt:3708.954\n",
      "Ep:107, loss:0.00001, loss_test:0.07640, lr:6.83e-03, fs:0.86486 (r=0.808,p=0.930),  time:34.666, tt:3743.926\n",
      "Ep:108, loss:0.00001, loss_test:0.06954, lr:6.76e-03, fs:0.82222 (r=0.747,p=0.914),  time:34.659, tt:3777.818\n",
      "Ep:109, loss:0.00001, loss_test:0.07641, lr:6.69e-03, fs:0.83333 (r=0.758,p=0.926),  time:34.641, tt:3810.554\n",
      "Ep:110, loss:0.00001, loss_test:0.07112, lr:6.62e-03, fs:0.80000 (r=0.707,p=0.921),  time:34.647, tt:3845.790\n",
      "Ep:111, loss:0.00001, loss_test:0.07480, lr:6.56e-03, fs:0.82873 (r=0.758,p=0.915),  time:34.647, tt:3880.461\n",
      "Ep:112, loss:0.00001, loss_test:0.07110, lr:6.49e-03, fs:0.81818 (r=0.727,p=0.935),  time:34.634, tt:3913.671\n",
      "Ep:113, loss:0.00001, loss_test:0.07981, lr:6.43e-03, fs:0.83333 (r=0.758,p=0.926),  time:34.630, tt:3947.852\n",
      "Ep:114, loss:0.00001, loss_test:0.06934, lr:6.36e-03, fs:0.84270 (r=0.758,p=0.949),  time:34.631, tt:3982.518\n",
      "Ep:115, loss:0.00001, loss_test:0.07377, lr:6.30e-03, fs:0.83333 (r=0.758,p=0.926),  time:34.627, tt:4016.710\n",
      "Ep:116, loss:0.00001, loss_test:0.06885, lr:6.24e-03, fs:0.83146 (r=0.747,p=0.937),  time:34.643, tt:4053.200\n",
      "Ep:117, loss:0.00001, loss_test:0.07204, lr:6.17e-03, fs:0.83799 (r=0.758,p=0.938),  time:34.671, tt:4091.136\n",
      "Ep:118, loss:0.00001, loss_test:0.07326, lr:6.11e-03, fs:0.87097 (r=0.818,p=0.931),  time:34.675, tt:4126.268\n",
      "Ep:119, loss:0.00001, loss_test:0.07301, lr:6.05e-03, fs:0.83146 (r=0.747,p=0.937),  time:34.674, tt:4160.860\n",
      "Ep:120, loss:0.00001, loss_test:0.07492, lr:5.99e-03, fs:0.80682 (r=0.717,p=0.922),  time:34.671, tt:4195.212\n",
      "Ep:121, loss:0.00001, loss_test:0.07085, lr:5.93e-03, fs:0.83799 (r=0.758,p=0.938),  time:34.660, tt:4228.570\n",
      "Ep:122, loss:0.00001, loss_test:0.07417, lr:5.87e-03, fs:0.83799 (r=0.758,p=0.938),  time:34.655, tt:4262.514\n",
      "Ep:123, loss:0.00001, loss_test:0.07049, lr:5.81e-03, fs:0.80682 (r=0.717,p=0.922),  time:34.649, tt:4296.522\n",
      "Ep:124, loss:0.00001, loss_test:0.07475, lr:5.75e-03, fs:0.83799 (r=0.758,p=0.938),  time:34.660, tt:4332.463\n",
      "Ep:125, loss:0.00001, loss_test:0.07361, lr:5.70e-03, fs:0.86339 (r=0.798,p=0.940),  time:34.651, tt:4366.071\n",
      "Ep:126, loss:0.00001, loss_test:0.07412, lr:5.64e-03, fs:0.83146 (r=0.747,p=0.937),  time:34.646, tt:4400.055\n",
      "Ep:127, loss:0.00001, loss_test:0.07517, lr:5.58e-03, fs:0.82486 (r=0.737,p=0.936),  time:34.642, tt:4434.210\n",
      "Ep:128, loss:0.00001, loss_test:0.07296, lr:5.53e-03, fs:0.85246 (r=0.788,p=0.929),  time:34.643, tt:4468.918\n",
      "Ep:129, loss:0.00001, loss_test:0.07745, lr:5.47e-03, fs:0.83333 (r=0.758,p=0.926),  time:34.658, tt:4505.567\n",
      "Ep:130, loss:0.00001, loss_test:0.07554, lr:5.42e-03, fs:0.85714 (r=0.788,p=0.940),  time:34.655, tt:4539.852\n",
      "Ep:131, loss:0.00001, loss_test:0.07624, lr:5.36e-03, fs:0.81143 (r=0.717,p=0.934),  time:34.654, tt:4574.354\n",
      "Ep:132, loss:0.00001, loss_test:0.07267, lr:5.31e-03, fs:0.81609 (r=0.717,p=0.947),  time:34.659, tt:4609.640\n",
      "Ep:133, loss:0.00001, loss_test:0.07782, lr:5.26e-03, fs:0.84270 (r=0.758,p=0.949),  time:34.661, tt:4644.608\n",
      "Ep:134, loss:0.00001, loss_test:0.07429, lr:5.20e-03, fs:0.85083 (r=0.778,p=0.939),  time:34.656, tt:4678.527\n",
      "Ep:135, loss:0.00001, loss_test:0.07636, lr:5.15e-03, fs:0.82955 (r=0.737,p=0.948),  time:34.680, tt:4716.537\n",
      "Ep:136, loss:0.00001, loss_test:0.07628, lr:5.10e-03, fs:0.84916 (r=0.768,p=0.950),  time:34.682, tt:4751.418\n",
      "Ep:137, loss:0.00001, loss_test:0.07973, lr:5.05e-03, fs:0.82286 (r=0.727,p=0.947),  time:34.680, tt:4785.777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:138, loss:0.00000, loss_test:0.07647, lr:5.00e-03, fs:0.86188 (r=0.788,p=0.951),  time:34.676, tt:4819.934\n",
      "Ep:139, loss:0.00000, loss_test:0.07599, lr:4.95e-03, fs:0.82486 (r=0.737,p=0.936),  time:34.669, tt:4853.659\n",
      "Ep:140, loss:0.00000, loss_test:0.07672, lr:4.90e-03, fs:0.84270 (r=0.758,p=0.949),  time:34.678, tt:4889.532\n",
      "Ep:141, loss:0.00000, loss_test:0.07775, lr:4.85e-03, fs:0.81143 (r=0.717,p=0.934),  time:34.674, tt:4923.693\n",
      "Ep:142, loss:0.00000, loss_test:0.07898, lr:4.80e-03, fs:0.82286 (r=0.727,p=0.947),  time:34.665, tt:4957.065\n",
      "Ep:143, loss:0.00000, loss_test:0.07706, lr:4.75e-03, fs:0.82286 (r=0.727,p=0.947),  time:34.663, tt:4991.509\n",
      "Ep:144, loss:0.00000, loss_test:0.07926, lr:4.71e-03, fs:0.84916 (r=0.768,p=0.950),  time:34.665, tt:5026.441\n",
      "Ep:145, loss:0.00000, loss_test:0.07756, lr:4.66e-03, fs:0.82486 (r=0.737,p=0.936),  time:34.671, tt:5061.929\n",
      "Ep:146, loss:0.00000, loss_test:0.07640, lr:4.61e-03, fs:0.84270 (r=0.758,p=0.949),  time:34.684, tt:5098.551\n",
      "Ep:147, loss:0.00000, loss_test:0.07944, lr:4.57e-03, fs:0.85083 (r=0.778,p=0.939),  time:34.688, tt:5133.845\n",
      "Ep:148, loss:0.00000, loss_test:0.07759, lr:4.52e-03, fs:0.83429 (r=0.737,p=0.961),  time:34.684, tt:5167.885\n",
      "Ep:149, loss:0.00000, loss_test:0.07910, lr:4.48e-03, fs:0.84916 (r=0.768,p=0.950),  time:34.691, tt:5203.692\n",
      "Ep:150, loss:0.00000, loss_test:0.07748, lr:4.43e-03, fs:0.80925 (r=0.707,p=0.946),  time:34.698, tt:5239.327\n",
      "Ep:151, loss:0.00000, loss_test:0.07877, lr:4.39e-03, fs:0.85083 (r=0.778,p=0.939),  time:34.700, tt:5274.436\n",
      "Ep:152, loss:0.00000, loss_test:0.08014, lr:4.34e-03, fs:0.82955 (r=0.737,p=0.948),  time:34.696, tt:5308.468\n",
      "Ep:153, loss:0.00000, loss_test:0.07871, lr:4.30e-03, fs:0.82682 (r=0.747,p=0.925),  time:34.696, tt:5343.238\n",
      "Ep:154, loss:0.00000, loss_test:0.08055, lr:4.26e-03, fs:0.78824 (r=0.677,p=0.944),  time:34.703, tt:5378.938\n",
      "Ep:155, loss:0.00000, loss_test:0.07823, lr:4.21e-03, fs:0.81143 (r=0.717,p=0.934),  time:34.704, tt:5413.766\n",
      "Ep:156, loss:0.00000, loss_test:0.08119, lr:4.17e-03, fs:0.85556 (r=0.778,p=0.951),  time:34.713, tt:5449.937\n",
      "Ep:157, loss:0.00000, loss_test:0.07256, lr:4.13e-03, fs:0.81356 (r=0.727,p=0.923),  time:34.718, tt:5485.502\n",
      "Ep:158, loss:0.00000, loss_test:0.08191, lr:4.09e-03, fs:0.81609 (r=0.717,p=0.947),  time:34.730, tt:5522.142\n",
      "Ep:159, loss:0.00000, loss_test:0.07786, lr:4.05e-03, fs:0.77381 (r=0.657,p=0.942),  time:34.750, tt:5560.065\n",
      "Ep:160, loss:0.00000, loss_test:0.07988, lr:4.01e-03, fs:0.81143 (r=0.717,p=0.934),  time:34.765, tt:5597.239\n",
      "Ep:161, loss:0.00000, loss_test:0.07833, lr:3.97e-03, fs:0.84270 (r=0.758,p=0.949),  time:34.782, tt:5634.743\n",
      "Ep:162, loss:0.00000, loss_test:0.07669, lr:3.93e-03, fs:0.81143 (r=0.717,p=0.934),  time:34.793, tt:5671.263\n",
      "Ep:163, loss:0.00000, loss_test:0.07779, lr:3.89e-03, fs:0.81609 (r=0.717,p=0.947),  time:34.805, tt:5708.063\n",
      "Ep:164, loss:0.00000, loss_test:0.07618, lr:3.85e-03, fs:0.81143 (r=0.717,p=0.934),  time:34.806, tt:5743.022\n",
      "Ep:165, loss:0.00000, loss_test:0.07594, lr:3.81e-03, fs:0.81609 (r=0.717,p=0.947),  time:34.818, tt:5779.727\n",
      "Ep:166, loss:0.00000, loss_test:0.07535, lr:3.77e-03, fs:0.81143 (r=0.717,p=0.934),  time:34.826, tt:5815.946\n",
      "Ep:167, loss:0.00000, loss_test:0.08006, lr:3.73e-03, fs:0.81143 (r=0.717,p=0.934),  time:34.833, tt:5851.931\n",
      "Ep:168, loss:0.00000, loss_test:0.07939, lr:3.70e-03, fs:0.77381 (r=0.657,p=0.942),  time:34.839, tt:5887.747\n",
      "Ep:169, loss:0.00000, loss_test:0.07949, lr:3.66e-03, fs:0.81143 (r=0.717,p=0.934),  time:34.846, tt:5923.887\n",
      "Ep:170, loss:0.00000, loss_test:0.07676, lr:3.62e-03, fs:0.77381 (r=0.657,p=0.942),  time:34.863, tt:5961.635\n",
      "Ep:171, loss:0.00000, loss_test:0.08062, lr:3.59e-03, fs:0.84444 (r=0.768,p=0.938),  time:34.875, tt:5998.511\n",
      "Ep:172, loss:0.00000, loss_test:0.07663, lr:3.55e-03, fs:0.77844 (r=0.657,p=0.956),  time:34.883, tt:6034.775\n",
      "Ep:173, loss:0.00000, loss_test:0.07786, lr:3.52e-03, fs:0.83146 (r=0.747,p=0.937),  time:34.900, tt:6072.669\n",
      "Ep:174, loss:0.00000, loss_test:0.07801, lr:3.48e-03, fs:0.81609 (r=0.717,p=0.947),  time:34.905, tt:6108.409\n",
      "Ep:175, loss:0.00000, loss_test:0.08165, lr:3.45e-03, fs:0.84270 (r=0.758,p=0.949),  time:34.920, tt:6145.841\n",
      "Ep:176, loss:0.00000, loss_test:0.07670, lr:3.41e-03, fs:0.81143 (r=0.717,p=0.934),  time:34.934, tt:6183.349\n",
      "Ep:177, loss:0.00000, loss_test:0.08022, lr:3.38e-03, fs:0.82955 (r=0.737,p=0.948),  time:34.944, tt:6220.036\n",
      "Ep:178, loss:0.00000, loss_test:0.07611, lr:3.34e-03, fs:0.81143 (r=0.717,p=0.934),  time:34.964, tt:6258.644\n",
      "Ep:179, loss:0.00000, loss_test:0.07826, lr:3.31e-03, fs:0.81143 (r=0.717,p=0.934),  time:34.972, tt:6295.025\n",
      "Ep:180, loss:0.00000, loss_test:0.08227, lr:3.28e-03, fs:0.81609 (r=0.717,p=0.947),  time:34.982, tt:6331.789\n",
      "Ep:181, loss:0.00000, loss_test:0.07687, lr:3.24e-03, fs:0.81143 (r=0.717,p=0.934),  time:34.987, tt:6367.574\n",
      "Ep:182, loss:0.00000, loss_test:0.07917, lr:3.21e-03, fs:0.81609 (r=0.717,p=0.947),  time:34.999, tt:6404.854\n",
      "Ep:183, loss:0.00000, loss_test:0.07825, lr:3.18e-03, fs:0.81609 (r=0.717,p=0.947),  time:35.002, tt:6440.338\n",
      "Ep:184, loss:0.00000, loss_test:0.07641, lr:3.15e-03, fs:0.81143 (r=0.717,p=0.934),  time:35.022, tt:6479.035\n",
      "Ep:185, loss:0.00000, loss_test:0.07697, lr:3.12e-03, fs:0.80460 (r=0.707,p=0.933),  time:35.028, tt:6515.233\n",
      "Ep:186, loss:0.00000, loss_test:0.07703, lr:3.09e-03, fs:0.81818 (r=0.727,p=0.935),  time:35.034, tt:6551.351\n",
      "Ep:187, loss:0.00000, loss_test:0.07677, lr:3.05e-03, fs:0.81143 (r=0.717,p=0.934),  time:35.045, tt:6588.375\n",
      "Ep:188, loss:0.00000, loss_test:0.07961, lr:3.02e-03, fs:0.81609 (r=0.717,p=0.947),  time:35.054, tt:6625.255\n",
      "Ep:189, loss:0.00000, loss_test:0.07696, lr:2.99e-03, fs:0.81143 (r=0.717,p=0.934),  time:35.067, tt:6662.805\n",
      "Ep:190, loss:0.00000, loss_test:0.07667, lr:2.96e-03, fs:0.81143 (r=0.717,p=0.934),  time:35.073, tt:6698.978\n",
      "Ep:191, loss:0.00000, loss_test:0.07547, lr:2.93e-03, fs:0.81143 (r=0.717,p=0.934),  time:35.081, tt:6735.566\n",
      "Ep:192, loss:0.00000, loss_test:0.07819, lr:2.90e-03, fs:0.81818 (r=0.727,p=0.935),  time:35.083, tt:6770.933\n",
      "Ep:193, loss:0.00000, loss_test:0.07724, lr:2.88e-03, fs:0.81143 (r=0.717,p=0.934),  time:35.083, tt:6806.088\n",
      "Ep:194, loss:0.00000, loss_test:0.07770, lr:2.85e-03, fs:0.81143 (r=0.717,p=0.934),  time:35.091, tt:6842.770\n",
      "Ep:195, loss:0.00000, loss_test:0.07790, lr:2.82e-03, fs:0.81143 (r=0.717,p=0.934),  time:35.098, tt:6879.258\n",
      "Ep:196, loss:0.00000, loss_test:0.07549, lr:2.79e-03, fs:0.81143 (r=0.717,p=0.934),  time:35.098, tt:6914.397\n",
      "Ep:197, loss:0.00000, loss_test:0.07763, lr:2.76e-03, fs:0.81143 (r=0.717,p=0.934),  time:35.101, tt:6950.036\n",
      "Ep:198, loss:0.00000, loss_test:0.07613, lr:2.73e-03, fs:0.81143 (r=0.717,p=0.934),  time:35.111, tt:6987.056\n",
      "Ep:199, loss:0.00000, loss_test:0.07636, lr:2.71e-03, fs:0.81143 (r=0.717,p=0.934),  time:35.121, tt:7024.224\n",
      "Ep:200, loss:0.00000, loss_test:0.07653, lr:2.68e-03, fs:0.81143 (r=0.717,p=0.934),  time:35.130, tt:7061.160\n",
      "Ep:201, loss:0.00000, loss_test:0.07736, lr:2.65e-03, fs:0.81143 (r=0.717,p=0.934),  time:35.133, tt:7096.924\n",
      "Ep:202, loss:0.00000, loss_test:0.07712, lr:2.63e-03, fs:0.81143 (r=0.717,p=0.934),  time:35.140, tt:7133.448\n",
      "Ep:203, loss:0.00000, loss_test:0.07678, lr:2.60e-03, fs:0.81143 (r=0.717,p=0.934),  time:35.148, tt:7170.144\n",
      "Ep:204, loss:0.00000, loss_test:0.07670, lr:2.57e-03, fs:0.81143 (r=0.717,p=0.934),  time:35.151, tt:7205.874\n",
      "Ep:205, loss:0.00000, loss_test:0.07618, lr:2.55e-03, fs:0.81143 (r=0.717,p=0.934),  time:35.150, tt:7240.933\n",
      "Ep:206, loss:0.00000, loss_test:0.07704, lr:2.52e-03, fs:0.81143 (r=0.717,p=0.934),  time:35.155, tt:7277.145\n",
      "Ep:207, loss:0.00000, loss_test:0.07822, lr:2.50e-03, fs:0.81143 (r=0.717,p=0.934),  time:35.132, tt:7307.401\n",
      "Ep:208, loss:0.00000, loss_test:0.07678, lr:2.47e-03, fs:0.81143 (r=0.717,p=0.934),  time:35.083, tt:7332.382\n",
      "Ep:209, loss:0.00000, loss_test:0.07708, lr:2.45e-03, fs:0.81143 (r=0.717,p=0.934),  time:35.034, tt:7357.157\n",
      "Ep:210, loss:0.00000, loss_test:0.07578, lr:2.42e-03, fs:0.81143 (r=0.717,p=0.934),  time:34.986, tt:7382.064\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00016, loss_test:0.02867, lr:6.00e-02, fs:0.63063 (r=0.707,p=0.569),  time:33.656, tt:33.656\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00006, loss_test:0.02586, lr:6.00e-02, fs:0.66667 (r=0.970,p=0.508),  time:34.820, tt:69.640\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02879, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.834, tt:104.502\n",
      "Ep:3, loss:0.00005, loss_test:0.02948, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.074, tt:140.294\n",
      "Ep:4, loss:0.00006, loss_test:0.02927, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.978, tt:174.892\n",
      "Ep:5, loss:0.00005, loss_test:0.02844, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:34.887, tt:209.324\n",
      "Ep:6, loss:0.00005, loss_test:0.02750, lr:6.00e-02, fs:0.65972 (r=0.960,p=0.503),  time:35.000, tt:245.000\n",
      "Ep:7, loss:0.00005, loss_test:0.02655, lr:6.00e-02, fs:0.64748 (r=0.909,p=0.503),  time:34.975, tt:279.798\n",
      "Ep:8, loss:0.00005, loss_test:0.02575, lr:6.00e-02, fs:0.64234 (r=0.889,p=0.503),  time:34.860, tt:313.738\n",
      "Ep:9, loss:0.00005, loss_test:0.02509, lr:6.00e-02, fs:0.64684 (r=0.879,p=0.512),  time:34.786, tt:347.863\n",
      "Ep:10, loss:0.00005, loss_test:0.02446, lr:6.00e-02, fs:0.65185 (r=0.889,p=0.515),  time:34.709, tt:381.796\n",
      "Ep:11, loss:0.00005, loss_test:0.02399, lr:6.00e-02, fs:0.65455 (r=0.909,p=0.511),  time:34.781, tt:417.369\n",
      "Ep:12, loss:0.00005, loss_test:0.02344, lr:6.00e-02, fs:0.66426 (r=0.929,p=0.517),  time:34.844, tt:452.967\n",
      "Ep:13, loss:0.00005, loss_test:0.02252, lr:5.94e-02, fs:0.65926 (r=0.899,p=0.520),  time:34.845, tt:487.827\n",
      "Ep:14, loss:0.00004, loss_test:0.02186, lr:5.88e-02, fs:0.66667 (r=0.889,p=0.533),  time:34.982, tt:524.731\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.02150, lr:5.88e-02, fs:0.66160 (r=0.879,p=0.530),  time:34.943, tt:559.095\n",
      "Ep:16, loss:0.00004, loss_test:0.02133, lr:5.88e-02, fs:0.69403 (r=0.939,p=0.550),  time:34.990, tt:594.828\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.02128, lr:5.88e-02, fs:0.69630 (r=0.949,p=0.550),  time:34.963, tt:629.341\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.02102, lr:5.88e-02, fs:0.69630 (r=0.949,p=0.550),  time:34.979, tt:664.600\n",
      "Ep:19, loss:0.00004, loss_test:0.02083, lr:5.88e-02, fs:0.69373 (r=0.949,p=0.547),  time:34.976, tt:699.522\n",
      "Ep:20, loss:0.00004, loss_test:0.02057, lr:5.88e-02, fs:0.69630 (r=0.949,p=0.550),  time:34.927, tt:733.476\n",
      "Ep:21, loss:0.00004, loss_test:0.02032, lr:5.88e-02, fs:0.69630 (r=0.949,p=0.550),  time:35.034, tt:770.756\n",
      "Ep:22, loss:0.00004, loss_test:0.02014, lr:5.88e-02, fs:0.69630 (r=0.949,p=0.550),  time:35.060, tt:806.391\n",
      "Ep:23, loss:0.00004, loss_test:0.02001, lr:5.88e-02, fs:0.70111 (r=0.960,p=0.552),  time:35.070, tt:841.678\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00004, loss_test:0.01989, lr:5.88e-02, fs:0.70370 (r=0.960,p=0.556),  time:35.051, tt:876.275\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00004, loss_test:0.01966, lr:5.88e-02, fs:0.71587 (r=0.980,p=0.564),  time:35.055, tt:911.439\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00004, loss_test:0.01938, lr:5.88e-02, fs:0.72593 (r=0.990,p=0.573),  time:35.059, tt:946.594\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00004, loss_test:0.01907, lr:5.88e-02, fs:0.72453 (r=0.970,p=0.578),  time:35.044, tt:981.238\n",
      "Ep:28, loss:0.00004, loss_test:0.01886, lr:5.88e-02, fs:0.73208 (r=0.980,p=0.584),  time:35.036, tt:1016.059\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00004, loss_test:0.01866, lr:5.88e-02, fs:0.73208 (r=0.980,p=0.584),  time:35.061, tt:1051.838\n",
      "Ep:30, loss:0.00004, loss_test:0.01838, lr:5.88e-02, fs:0.74242 (r=0.990,p=0.594),  time:35.075, tt:1087.327\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01810, lr:5.88e-02, fs:0.75385 (r=0.990,p=0.609),  time:35.043, tt:1121.372\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01786, lr:5.88e-02, fs:0.75194 (r=0.980,p=0.610),  time:35.002, tt:1155.082\n",
      "Ep:33, loss:0.00003, loss_test:0.01767, lr:5.88e-02, fs:0.74903 (r=0.980,p=0.606),  time:35.025, tt:1190.851\n",
      "Ep:34, loss:0.00003, loss_test:0.01749, lr:5.88e-02, fs:0.74330 (r=0.980,p=0.599),  time:35.057, tt:1226.996\n",
      "Ep:35, loss:0.00003, loss_test:0.01733, lr:5.88e-02, fs:0.75194 (r=0.980,p=0.610),  time:35.059, tt:1262.109\n",
      "Ep:36, loss:0.00003, loss_test:0.01713, lr:5.88e-02, fs:0.74510 (r=0.960,p=0.609),  time:35.122, tt:1299.532\n",
      "Ep:37, loss:0.00003, loss_test:0.01698, lr:5.88e-02, fs:0.74510 (r=0.960,p=0.609),  time:35.141, tt:1335.350\n",
      "Ep:38, loss:0.00003, loss_test:0.01697, lr:5.88e-02, fs:0.74803 (r=0.960,p=0.613),  time:35.154, tt:1371.010\n",
      "Ep:39, loss:0.00003, loss_test:0.01680, lr:5.88e-02, fs:0.74803 (r=0.960,p=0.613),  time:35.135, tt:1405.387\n",
      "Ep:40, loss:0.00003, loss_test:0.01668, lr:5.88e-02, fs:0.75697 (r=0.960,p=0.625),  time:35.177, tt:1442.244\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00003, loss_test:0.01672, lr:5.88e-02, fs:0.73171 (r=0.909,p=0.612),  time:35.166, tt:1476.990\n",
      "Ep:42, loss:0.00003, loss_test:0.01655, lr:5.88e-02, fs:0.75000 (r=0.939,p=0.624),  time:35.176, tt:1512.560\n",
      "Ep:43, loss:0.00003, loss_test:0.01656, lr:5.88e-02, fs:0.74494 (r=0.929,p=0.622),  time:35.149, tt:1546.537\n",
      "Ep:44, loss:0.00003, loss_test:0.01659, lr:5.88e-02, fs:0.73251 (r=0.899,p=0.618),  time:35.148, tt:1581.681\n",
      "Ep:45, loss:0.00003, loss_test:0.01645, lr:5.88e-02, fs:0.74590 (r=0.919,p=0.628),  time:35.162, tt:1617.457\n",
      "Ep:46, loss:0.00003, loss_test:0.01640, lr:5.88e-02, fs:0.72803 (r=0.879,p=0.621),  time:35.169, tt:1652.954\n",
      "Ep:47, loss:0.00003, loss_test:0.01638, lr:5.88e-02, fs:0.73418 (r=0.879,p=0.630),  time:35.173, tt:1688.304\n",
      "Ep:48, loss:0.00002, loss_test:0.01635, lr:5.88e-02, fs:0.72881 (r=0.869,p=0.628),  time:35.210, tt:1725.309\n",
      "Ep:49, loss:0.00002, loss_test:0.01633, lr:5.88e-02, fs:0.72574 (r=0.869,p=0.623),  time:35.201, tt:1760.074\n",
      "Ep:50, loss:0.00002, loss_test:0.01620, lr:5.88e-02, fs:0.72340 (r=0.859,p=0.625),  time:35.195, tt:1794.970\n",
      "Ep:51, loss:0.00002, loss_test:0.01612, lr:5.88e-02, fs:0.70690 (r=0.828,p=0.617),  time:35.217, tt:1831.261\n",
      "Ep:52, loss:0.00002, loss_test:0.01606, lr:5.82e-02, fs:0.69912 (r=0.798,p=0.622),  time:35.189, tt:1865.003\n",
      "Ep:53, loss:0.00002, loss_test:0.01595, lr:5.76e-02, fs:0.71616 (r=0.828,p=0.631),  time:35.204, tt:1900.991\n",
      "Ep:54, loss:0.00002, loss_test:0.01580, lr:5.71e-02, fs:0.70742 (r=0.818,p=0.623),  time:35.196, tt:1935.771\n",
      "Ep:55, loss:0.00002, loss_test:0.01564, lr:5.65e-02, fs:0.70852 (r=0.798,p=0.637),  time:35.200, tt:1971.179\n",
      "Ep:56, loss:0.00002, loss_test:0.01553, lr:5.59e-02, fs:0.72072 (r=0.808,p=0.650),  time:35.195, tt:2006.115\n",
      "Ep:57, loss:0.00002, loss_test:0.01598, lr:5.54e-02, fs:0.70742 (r=0.818,p=0.623),  time:35.202, tt:2041.707\n",
      "Ep:58, loss:0.00002, loss_test:0.01526, lr:5.48e-02, fs:0.74667 (r=0.848,p=0.667),  time:35.230, tt:2078.567\n",
      "Ep:59, loss:0.00002, loss_test:0.01575, lr:5.43e-02, fs:0.69955 (r=0.788,p=0.629),  time:35.213, tt:2112.809\n",
      "Ep:60, loss:0.00002, loss_test:0.01549, lr:5.37e-02, fs:0.70270 (r=0.788,p=0.634),  time:35.205, tt:2147.529\n",
      "Ep:61, loss:0.00002, loss_test:0.01489, lr:5.32e-02, fs:0.74208 (r=0.828,p=0.672),  time:35.193, tt:2181.939\n",
      "Ep:62, loss:0.00002, loss_test:0.01493, lr:5.27e-02, fs:0.72811 (r=0.798,p=0.669),  time:35.180, tt:2216.333\n",
      "Ep:63, loss:0.00002, loss_test:0.01545, lr:5.21e-02, fs:0.71296 (r=0.778,p=0.658),  time:35.154, tt:2249.824\n",
      "Ep:64, loss:0.00002, loss_test:0.01613, lr:5.16e-02, fs:0.72000 (r=0.818,p=0.643),  time:35.154, tt:2285.022\n",
      "Ep:65, loss:0.00002, loss_test:0.01456, lr:5.11e-02, fs:0.79295 (r=0.909,p=0.703),  time:35.140, tt:2319.254\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:66, loss:0.00002, loss_test:0.01508, lr:5.11e-02, fs:0.74783 (r=0.869,p=0.656),  time:35.139, tt:2354.301\n",
      "Ep:67, loss:0.00002, loss_test:0.01380, lr:5.11e-02, fs:0.76316 (r=0.879,p=0.674),  time:35.138, tt:2389.405\n",
      "Ep:68, loss:0.00002, loss_test:0.01458, lr:5.11e-02, fs:0.74336 (r=0.848,p=0.661),  time:35.121, tt:2423.349\n",
      "Ep:69, loss:0.00002, loss_test:0.01399, lr:5.11e-02, fs:0.77064 (r=0.848,p=0.706),  time:35.092, tt:2456.419\n",
      "Ep:70, loss:0.00002, loss_test:0.01432, lr:5.11e-02, fs:0.73543 (r=0.828,p=0.661),  time:35.073, tt:2490.158\n",
      "Ep:71, loss:0.00002, loss_test:0.01412, lr:5.11e-02, fs:0.75238 (r=0.798,p=0.712),  time:35.071, tt:2525.084\n",
      "Ep:72, loss:0.00001, loss_test:0.01406, lr:5.11e-02, fs:0.76555 (r=0.808,p=0.727),  time:35.068, tt:2559.948\n",
      "Ep:73, loss:0.00001, loss_test:0.01443, lr:5.11e-02, fs:0.75229 (r=0.828,p=0.689),  time:35.062, tt:2594.569\n",
      "Ep:74, loss:0.00001, loss_test:0.01393, lr:5.11e-02, fs:0.80189 (r=0.859,p=0.752),  time:35.055, tt:2629.154\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00001, loss_test:0.01432, lr:5.11e-02, fs:0.73684 (r=0.778,p=0.700),  time:35.047, tt:2663.540\n",
      "Ep:76, loss:0.00001, loss_test:0.01441, lr:5.11e-02, fs:0.73733 (r=0.808,p=0.678),  time:35.035, tt:2697.688\n",
      "Ep:77, loss:0.00001, loss_test:0.01370, lr:5.11e-02, fs:0.80751 (r=0.869,p=0.754),  time:35.037, tt:2732.857\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.01406, lr:5.11e-02, fs:0.75000 (r=0.788,p=0.716),  time:35.030, tt:2767.356\n",
      "Ep:79, loss:0.00001, loss_test:0.01394, lr:5.11e-02, fs:0.77670 (r=0.808,p=0.748),  time:35.025, tt:2802.002\n",
      "Ep:80, loss:0.00001, loss_test:0.01423, lr:5.11e-02, fs:0.76847 (r=0.788,p=0.750),  time:35.030, tt:2837.444\n",
      "Ep:81, loss:0.00001, loss_test:0.01491, lr:5.11e-02, fs:0.75238 (r=0.798,p=0.712),  time:35.004, tt:2870.364\n",
      "Ep:82, loss:0.00001, loss_test:0.01410, lr:5.11e-02, fs:0.79808 (r=0.838,p=0.761),  time:35.015, tt:2906.280\n",
      "Ep:83, loss:0.00002, loss_test:0.01410, lr:5.11e-02, fs:0.76777 (r=0.818,p=0.723),  time:35.018, tt:2941.478\n",
      "Ep:84, loss:0.00001, loss_test:0.01360, lr:5.11e-02, fs:0.76056 (r=0.818,p=0.711),  time:34.992, tt:2974.353\n",
      "Ep:85, loss:0.00001, loss_test:0.01325, lr:5.11e-02, fs:0.77670 (r=0.808,p=0.748),  time:34.987, tt:3008.847\n",
      "Ep:86, loss:0.00001, loss_test:0.01423, lr:5.11e-02, fs:0.76056 (r=0.818,p=0.711),  time:34.992, tt:3044.268\n",
      "Ep:87, loss:0.00001, loss_test:0.01383, lr:5.11e-02, fs:0.77295 (r=0.808,p=0.741),  time:34.981, tt:3078.340\n",
      "Ep:88, loss:0.00001, loss_test:0.01430, lr:5.11e-02, fs:0.78818 (r=0.808,p=0.769),  time:34.986, tt:3113.792\n",
      "Ep:89, loss:0.00001, loss_test:0.01440, lr:5.06e-02, fs:0.78431 (r=0.808,p=0.762),  time:34.991, tt:3149.153\n",
      "Ep:90, loss:0.00001, loss_test:0.01431, lr:5.01e-02, fs:0.78607 (r=0.798,p=0.775),  time:34.993, tt:3184.377\n",
      "Ep:91, loss:0.00001, loss_test:0.01465, lr:4.96e-02, fs:0.80000 (r=0.808,p=0.792),  time:34.995, tt:3219.545\n",
      "Ep:92, loss:0.00001, loss_test:0.01512, lr:4.91e-02, fs:0.77000 (r=0.778,p=0.762),  time:34.996, tt:3254.586\n",
      "Ep:93, loss:0.00001, loss_test:0.01469, lr:4.86e-02, fs:0.78607 (r=0.798,p=0.775),  time:34.989, tt:3288.993\n",
      "Ep:94, loss:0.00001, loss_test:0.01567, lr:4.81e-02, fs:0.75758 (r=0.758,p=0.758),  time:34.989, tt:3323.977\n",
      "Ep:95, loss:0.00001, loss_test:0.01495, lr:4.76e-02, fs:0.79188 (r=0.788,p=0.796),  time:34.989, tt:3358.943\n",
      "Ep:96, loss:0.00001, loss_test:0.01528, lr:4.71e-02, fs:0.78351 (r=0.768,p=0.800),  time:34.989, tt:3393.956\n",
      "Ep:97, loss:0.00001, loss_test:0.01627, lr:4.67e-02, fs:0.75127 (r=0.747,p=0.755),  time:34.993, tt:3429.335\n",
      "Ep:98, loss:0.00001, loss_test:0.01461, lr:4.62e-02, fs:0.79798 (r=0.798,p=0.798),  time:34.990, tt:3463.961\n",
      "Ep:99, loss:0.00001, loss_test:0.01585, lr:4.57e-02, fs:0.73632 (r=0.747,p=0.725),  time:34.996, tt:3499.570\n",
      "Ep:100, loss:0.00001, loss_test:0.01427, lr:4.53e-02, fs:0.80000 (r=0.808,p=0.792),  time:34.990, tt:3534.007\n",
      "Ep:101, loss:0.00001, loss_test:0.01575, lr:4.48e-02, fs:0.75897 (r=0.747,p=0.771),  time:34.986, tt:3568.538\n",
      "Ep:102, loss:0.00001, loss_test:0.01537, lr:4.44e-02, fs:0.77949 (r=0.768,p=0.792),  time:34.990, tt:3603.933\n",
      "Ep:103, loss:0.00001, loss_test:0.01646, lr:4.39e-02, fs:0.75897 (r=0.747,p=0.771),  time:35.000, tt:3639.956\n",
      "Ep:104, loss:0.00001, loss_test:0.01527, lr:4.35e-02, fs:0.77949 (r=0.768,p=0.792),  time:35.001, tt:3675.053\n",
      "Ep:105, loss:0.00001, loss_test:0.01658, lr:4.31e-02, fs:0.75789 (r=0.727,p=0.791),  time:35.002, tt:3710.189\n",
      "Ep:106, loss:0.00001, loss_test:0.01558, lr:4.26e-02, fs:0.77487 (r=0.747,p=0.804),  time:35.009, tt:3745.924\n",
      "Ep:107, loss:0.00001, loss_test:0.01664, lr:4.22e-02, fs:0.76344 (r=0.717,p=0.816),  time:35.001, tt:3780.119\n",
      "Ep:108, loss:0.00001, loss_test:0.01657, lr:4.18e-02, fs:0.75936 (r=0.717,p=0.807),  time:34.998, tt:3814.737\n",
      "Ep:109, loss:0.00001, loss_test:0.01624, lr:4.14e-02, fs:0.76344 (r=0.717,p=0.816),  time:34.988, tt:3848.628\n",
      "Ep:110, loss:0.00001, loss_test:0.01697, lr:4.10e-02, fs:0.75936 (r=0.717,p=0.807),  time:34.992, tt:3884.128\n",
      "Ep:111, loss:0.00001, loss_test:0.01644, lr:4.05e-02, fs:0.77419 (r=0.727,p=0.828),  time:35.004, tt:3920.487\n",
      "Ep:112, loss:0.00001, loss_test:0.01718, lr:4.01e-02, fs:0.76757 (r=0.717,p=0.826),  time:35.006, tt:3955.677\n",
      "Ep:113, loss:0.00001, loss_test:0.01665, lr:3.97e-02, fs:0.77005 (r=0.727,p=0.818),  time:35.022, tt:3992.532\n",
      "Ep:114, loss:0.00001, loss_test:0.01832, lr:3.93e-02, fs:0.75132 (r=0.717,p=0.789),  time:35.028, tt:4028.223\n",
      "Ep:115, loss:0.00001, loss_test:0.01600, lr:3.89e-02, fs:0.77005 (r=0.727,p=0.818),  time:35.030, tt:4063.505\n",
      "Ep:116, loss:0.00001, loss_test:0.01817, lr:3.86e-02, fs:0.77174 (r=0.717,p=0.835),  time:35.041, tt:4099.741\n",
      "Ep:117, loss:0.00001, loss_test:0.01718, lr:3.82e-02, fs:0.77174 (r=0.717,p=0.835),  time:35.035, tt:4134.093\n",
      "Ep:118, loss:0.00001, loss_test:0.01878, lr:3.78e-02, fs:0.76757 (r=0.717,p=0.826),  time:35.045, tt:4170.341\n",
      "Ep:119, loss:0.00001, loss_test:0.01759, lr:3.74e-02, fs:0.77174 (r=0.717,p=0.835),  time:35.049, tt:4205.900\n",
      "Ep:120, loss:0.00001, loss_test:0.01855, lr:3.70e-02, fs:0.76757 (r=0.717,p=0.826),  time:35.073, tt:4243.798\n",
      "Ep:121, loss:0.00001, loss_test:0.01859, lr:3.67e-02, fs:0.77174 (r=0.717,p=0.835),  time:35.086, tt:4280.536\n",
      "Ep:122, loss:0.00001, loss_test:0.01855, lr:3.63e-02, fs:0.77596 (r=0.717,p=0.845),  time:35.099, tt:4317.128\n",
      "Ep:123, loss:0.00001, loss_test:0.01959, lr:3.59e-02, fs:0.77174 (r=0.717,p=0.835),  time:35.099, tt:4352.338\n",
      "Ep:124, loss:0.00001, loss_test:0.01853, lr:3.56e-02, fs:0.77596 (r=0.717,p=0.845),  time:35.104, tt:4387.982\n",
      "Ep:125, loss:0.00001, loss_test:0.01978, lr:3.52e-02, fs:0.78022 (r=0.717,p=0.855),  time:35.107, tt:4423.452\n",
      "Ep:126, loss:0.00001, loss_test:0.01965, lr:3.49e-02, fs:0.77596 (r=0.717,p=0.845),  time:35.108, tt:4458.708\n",
      "Ep:127, loss:0.00001, loss_test:0.01998, lr:3.45e-02, fs:0.77596 (r=0.717,p=0.845),  time:35.118, tt:4495.088\n",
      "Ep:128, loss:0.00000, loss_test:0.02081, lr:3.42e-02, fs:0.77174 (r=0.717,p=0.835),  time:35.118, tt:4530.282\n",
      "Ep:129, loss:0.00000, loss_test:0.01995, lr:3.38e-02, fs:0.78022 (r=0.717,p=0.855),  time:35.123, tt:4565.927\n",
      "Ep:130, loss:0.00000, loss_test:0.02109, lr:3.35e-02, fs:0.77596 (r=0.717,p=0.845),  time:35.119, tt:4600.619\n",
      "Ep:131, loss:0.00000, loss_test:0.02116, lr:3.32e-02, fs:0.77596 (r=0.717,p=0.845),  time:35.124, tt:4636.311\n",
      "Ep:132, loss:0.00000, loss_test:0.02069, lr:3.28e-02, fs:0.78022 (r=0.717,p=0.855),  time:35.128, tt:4672.059\n",
      "Ep:133, loss:0.00000, loss_test:0.02216, lr:3.25e-02, fs:0.77174 (r=0.717,p=0.835),  time:35.152, tt:4710.331\n",
      "Ep:134, loss:0.00000, loss_test:0.02100, lr:3.22e-02, fs:0.78453 (r=0.717,p=0.866),  time:35.157, tt:4746.153\n",
      "Ep:135, loss:0.00000, loss_test:0.02267, lr:3.19e-02, fs:0.77596 (r=0.717,p=0.845),  time:35.169, tt:4783.037\n",
      "Ep:136, loss:0.00000, loss_test:0.02192, lr:3.15e-02, fs:0.77596 (r=0.717,p=0.845),  time:35.172, tt:4818.547\n",
      "Ep:137, loss:0.00000, loss_test:0.02182, lr:3.12e-02, fs:0.78453 (r=0.717,p=0.866),  time:35.179, tt:4854.758\n",
      "Ep:138, loss:0.00000, loss_test:0.02283, lr:3.09e-02, fs:0.77596 (r=0.717,p=0.845),  time:35.191, tt:4891.529\n",
      "Ep:139, loss:0.00000, loss_test:0.02137, lr:3.06e-02, fs:0.78022 (r=0.717,p=0.855),  time:35.197, tt:4927.617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:140, loss:0.00000, loss_test:0.02340, lr:3.03e-02, fs:0.77596 (r=0.717,p=0.845),  time:35.216, tt:4965.395\n",
      "Ep:141, loss:0.00000, loss_test:0.02295, lr:3.00e-02, fs:0.78453 (r=0.717,p=0.866),  time:35.219, tt:5001.101\n",
      "Ep:142, loss:0.00000, loss_test:0.02207, lr:2.97e-02, fs:0.78453 (r=0.717,p=0.866),  time:35.220, tt:5036.457\n",
      "Ep:143, loss:0.00000, loss_test:0.02440, lr:2.94e-02, fs:0.77596 (r=0.717,p=0.845),  time:35.217, tt:5071.252\n",
      "Ep:144, loss:0.00000, loss_test:0.02215, lr:2.91e-02, fs:0.78022 (r=0.717,p=0.855),  time:35.221, tt:5106.983\n",
      "Ep:145, loss:0.00000, loss_test:0.02390, lr:2.88e-02, fs:0.77596 (r=0.717,p=0.845),  time:35.225, tt:5142.864\n",
      "Ep:146, loss:0.00000, loss_test:0.02326, lr:2.85e-02, fs:0.78022 (r=0.717,p=0.855),  time:35.232, tt:5179.087\n",
      "Ep:147, loss:0.00000, loss_test:0.02244, lr:2.82e-02, fs:0.78022 (r=0.717,p=0.855),  time:35.232, tt:5214.339\n",
      "Ep:148, loss:0.00000, loss_test:0.02488, lr:2.80e-02, fs:0.77596 (r=0.717,p=0.845),  time:35.237, tt:5250.291\n",
      "Ep:149, loss:0.00000, loss_test:0.02216, lr:2.77e-02, fs:0.78022 (r=0.717,p=0.855),  time:35.237, tt:5285.491\n",
      "Ep:150, loss:0.00000, loss_test:0.02501, lr:2.74e-02, fs:0.77596 (r=0.717,p=0.845),  time:35.254, tt:5323.328\n",
      "Ep:151, loss:0.00000, loss_test:0.02327, lr:2.71e-02, fs:0.78453 (r=0.717,p=0.866),  time:35.259, tt:5359.320\n",
      "Ep:152, loss:0.00000, loss_test:0.02402, lr:2.69e-02, fs:0.78453 (r=0.717,p=0.866),  time:35.275, tt:5397.093\n",
      "Ep:153, loss:0.00000, loss_test:0.02354, lr:2.66e-02, fs:0.78453 (r=0.717,p=0.866),  time:35.284, tt:5433.811\n",
      "Ep:154, loss:0.00000, loss_test:0.02424, lr:2.63e-02, fs:0.78453 (r=0.717,p=0.866),  time:35.300, tt:5471.478\n",
      "Ep:155, loss:0.00000, loss_test:0.02508, lr:2.61e-02, fs:0.78453 (r=0.717,p=0.866),  time:35.306, tt:5507.739\n",
      "Ep:156, loss:0.00000, loss_test:0.02356, lr:2.58e-02, fs:0.78889 (r=0.717,p=0.877),  time:35.314, tt:5544.275\n",
      "Ep:157, loss:0.00000, loss_test:0.02560, lr:2.55e-02, fs:0.77596 (r=0.717,p=0.845),  time:35.310, tt:5578.922\n",
      "Ep:158, loss:0.00000, loss_test:0.02418, lr:2.53e-02, fs:0.78453 (r=0.717,p=0.866),  time:35.316, tt:5615.309\n",
      "Ep:159, loss:0.00000, loss_test:0.02513, lr:2.50e-02, fs:0.78889 (r=0.717,p=0.877),  time:35.313, tt:5650.071\n",
      "Ep:160, loss:0.00000, loss_test:0.02488, lr:2.48e-02, fs:0.78453 (r=0.717,p=0.866),  time:35.319, tt:5686.407\n",
      "Ep:161, loss:0.00000, loss_test:0.02487, lr:2.45e-02, fs:0.78889 (r=0.717,p=0.877),  time:35.331, tt:5723.703\n",
      "Ep:162, loss:0.00000, loss_test:0.02604, lr:2.43e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.342, tt:5760.696\n",
      "Ep:163, loss:0.00000, loss_test:0.02503, lr:2.40e-02, fs:0.78889 (r=0.717,p=0.877),  time:35.354, tt:5797.979\n",
      "Ep:164, loss:0.00000, loss_test:0.02589, lr:2.38e-02, fs:0.78453 (r=0.717,p=0.866),  time:35.364, tt:5835.031\n",
      "Ep:165, loss:0.00000, loss_test:0.02619, lr:2.36e-02, fs:0.78889 (r=0.717,p=0.877),  time:35.367, tt:5870.859\n",
      "Ep:166, loss:0.00000, loss_test:0.02618, lr:2.33e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.369, tt:5906.541\n",
      "Ep:167, loss:0.00000, loss_test:0.02678, lr:2.31e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.367, tt:5941.589\n",
      "Ep:168, loss:0.00000, loss_test:0.02638, lr:2.29e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.372, tt:5977.911\n",
      "Ep:169, loss:0.00000, loss_test:0.02670, lr:2.26e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.380, tt:6014.580\n",
      "Ep:170, loss:0.00000, loss_test:0.02671, lr:2.24e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.375, tt:6049.062\n",
      "Ep:171, loss:0.00000, loss_test:0.02658, lr:2.22e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.382, tt:6085.631\n",
      "Ep:172, loss:0.00000, loss_test:0.02737, lr:2.20e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.377, tt:6120.284\n",
      "Ep:173, loss:0.00000, loss_test:0.02654, lr:2.17e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.365, tt:6153.491\n",
      "Ep:174, loss:0.00000, loss_test:0.02764, lr:2.15e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.365, tt:6188.879\n",
      "Ep:175, loss:0.00000, loss_test:0.02723, lr:2.13e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.359, tt:6223.149\n",
      "Ep:176, loss:0.00000, loss_test:0.02744, lr:2.11e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.360, tt:6258.735\n",
      "Ep:177, loss:0.00000, loss_test:0.02778, lr:2.09e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.357, tt:6293.475\n",
      "Ep:178, loss:0.00000, loss_test:0.02681, lr:2.07e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.346, tt:6326.911\n",
      "Ep:179, loss:0.00000, loss_test:0.02888, lr:2.05e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.335, tt:6360.358\n",
      "Ep:180, loss:0.00000, loss_test:0.02685, lr:2.03e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.328, tt:6394.401\n",
      "Ep:181, loss:0.00000, loss_test:0.02856, lr:2.01e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.317, tt:6427.645\n",
      "Ep:182, loss:0.00000, loss_test:0.02697, lr:1.99e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.301, tt:6460.168\n",
      "Ep:183, loss:0.00000, loss_test:0.02875, lr:1.97e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.295, tt:6494.337\n",
      "Ep:184, loss:0.00000, loss_test:0.02812, lr:1.95e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.284, tt:6527.629\n",
      "Ep:185, loss:0.00000, loss_test:0.02877, lr:1.93e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.273, tt:6560.821\n",
      "Ep:186, loss:0.00000, loss_test:0.02854, lr:1.91e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.266, tt:6594.696\n",
      "Ep:187, loss:0.00000, loss_test:0.02820, lr:1.89e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.250, tt:6627.093\n",
      "Ep:188, loss:0.00000, loss_test:0.02865, lr:1.87e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.248, tt:6661.837\n",
      "Ep:189, loss:0.00000, loss_test:0.02823, lr:1.85e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.252, tt:6697.870\n",
      "Ep:190, loss:0.00000, loss_test:0.02925, lr:1.83e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.250, tt:6732.672\n",
      "Ep:191, loss:0.00000, loss_test:0.02843, lr:1.81e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.252, tt:6768.399\n",
      "Ep:192, loss:0.00000, loss_test:0.02916, lr:1.80e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.249, tt:6803.035\n",
      "Ep:193, loss:0.00000, loss_test:0.02899, lr:1.78e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.253, tt:6839.032\n",
      "Ep:194, loss:0.00000, loss_test:0.02884, lr:1.76e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.257, tt:6875.209\n",
      "Ep:195, loss:0.00000, loss_test:0.02928, lr:1.74e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.260, tt:6910.957\n",
      "Ep:196, loss:0.00000, loss_test:0.02937, lr:1.73e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.264, tt:6947.051\n",
      "Ep:197, loss:0.00000, loss_test:0.02911, lr:1.71e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.262, tt:6981.850\n",
      "Ep:198, loss:0.00000, loss_test:0.02931, lr:1.69e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.263, tt:7017.318\n",
      "Ep:199, loss:0.00000, loss_test:0.03017, lr:1.67e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.261, tt:7052.133\n",
      "Ep:200, loss:0.00000, loss_test:0.02898, lr:1.66e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.264, tt:7088.007\n",
      "Ep:201, loss:0.00000, loss_test:0.03060, lr:1.64e-02, fs:0.79775 (r=0.717,p=0.899),  time:35.261, tt:7122.767\n",
      "Ep:202, loss:0.00000, loss_test:0.02912, lr:1.62e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.259, tt:7157.592\n",
      "Ep:203, loss:0.00000, loss_test:0.03037, lr:1.61e-02, fs:0.79775 (r=0.717,p=0.899),  time:35.264, tt:7193.931\n",
      "Ep:204, loss:0.00000, loss_test:0.02904, lr:1.59e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.265, tt:7229.295\n",
      "Ep:205, loss:0.00000, loss_test:0.03018, lr:1.58e-02, fs:0.79775 (r=0.717,p=0.899),  time:35.261, tt:7263.777\n",
      "Ep:206, loss:0.00000, loss_test:0.03021, lr:1.56e-02, fs:0.79775 (r=0.717,p=0.899),  time:35.260, tt:7298.772\n",
      "Ep:207, loss:0.00000, loss_test:0.02935, lr:1.54e-02, fs:0.79775 (r=0.717,p=0.899),  time:35.264, tt:7334.936\n",
      "Ep:208, loss:0.00000, loss_test:0.03057, lr:1.53e-02, fs:0.79775 (r=0.717,p=0.899),  time:35.240, tt:7365.210\n",
      "Ep:209, loss:0.00000, loss_test:0.02992, lr:1.51e-02, fs:0.79775 (r=0.717,p=0.899),  time:35.220, tt:7396.122\n",
      "Ep:210, loss:0.00000, loss_test:0.03080, lr:1.50e-02, fs:0.79775 (r=0.717,p=0.899),  time:35.200, tt:7427.196\n",
      "Ep:211, loss:0.00000, loss_test:0.02979, lr:1.48e-02, fs:0.79775 (r=0.717,p=0.899),  time:35.182, tt:7458.587\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00026, loss_test:0.13003, lr:1.00e-02, fs:0.68462 (r=0.899,p=0.553),  time:33.487, tt:33.487\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.13002, lr:1.00e-02, fs:0.67939 (r=0.899,p=0.546),  time:33.624, tt:67.248\n",
      "Ep:2, loss:0.00026, loss_test:0.12975, lr:1.00e-02, fs:0.67681 (r=0.899,p=0.543),  time:34.018, tt:102.055\n",
      "Ep:3, loss:0.00026, loss_test:0.12867, lr:1.00e-02, fs:0.68199 (r=0.899,p=0.549),  time:34.603, tt:138.411\n",
      "Ep:4, loss:0.00026, loss_test:0.12736, lr:1.00e-02, fs:0.68199 (r=0.899,p=0.549),  time:35.071, tt:175.356\n",
      "Ep:5, loss:0.00025, loss_test:0.12645, lr:1.00e-02, fs:0.68462 (r=0.899,p=0.553),  time:35.086, tt:210.514\n",
      "Ep:6, loss:0.00025, loss_test:0.12562, lr:1.00e-02, fs:0.68726 (r=0.899,p=0.556),  time:35.340, tt:247.377\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00025, loss_test:0.12473, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:35.418, tt:283.341\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00025, loss_test:0.12372, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:35.322, tt:317.898\n",
      "Ep:9, loss:0.00025, loss_test:0.12258, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:35.369, tt:353.686\n",
      "Ep:10, loss:0.00024, loss_test:0.12158, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:35.446, tt:389.902\n",
      "Ep:11, loss:0.00024, loss_test:0.12032, lr:1.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:35.535, tt:426.425\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00024, loss_test:0.11886, lr:1.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:35.525, tt:461.819\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00023, loss_test:0.11715, lr:1.00e-02, fs:0.70079 (r=0.899,p=0.574),  time:35.552, tt:497.722\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00023, loss_test:0.11524, lr:1.00e-02, fs:0.69804 (r=0.899,p=0.571),  time:35.626, tt:534.394\n",
      "Ep:15, loss:0.00022, loss_test:0.11300, lr:1.00e-02, fs:0.71200 (r=0.899,p=0.589),  time:35.743, tt:571.882\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00022, loss_test:0.11005, lr:1.00e-02, fs:0.71486 (r=0.899,p=0.593),  time:35.827, tt:609.058\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00021, loss_test:0.10686, lr:1.00e-02, fs:0.71545 (r=0.889,p=0.599),  time:35.875, tt:645.741\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00021, loss_test:0.10364, lr:1.00e-02, fs:0.75304 (r=0.939,p=0.628),  time:35.987, tt:683.746\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00020, loss_test:0.10006, lr:1.00e-02, fs:0.75519 (r=0.919,p=0.641),  time:36.009, tt:720.185\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00019, loss_test:0.09676, lr:1.00e-02, fs:0.76987 (r=0.929,p=0.657),  time:36.071, tt:757.484\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00018, loss_test:0.09269, lr:1.00e-02, fs:0.77637 (r=0.929,p=0.667),  time:36.111, tt:794.435\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00017, loss_test:0.08954, lr:1.00e-02, fs:0.79654 (r=0.929,p=0.697),  time:36.089, tt:830.057\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00017, loss_test:0.08766, lr:1.00e-02, fs:0.80176 (r=0.919,p=0.711),  time:36.120, tt:866.868\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00016, loss_test:0.08650, lr:1.00e-02, fs:0.78222 (r=0.889,p=0.698),  time:36.148, tt:903.702\n",
      "Ep:25, loss:0.00015, loss_test:0.08583, lr:1.00e-02, fs:0.78027 (r=0.879,p=0.702),  time:36.320, tt:944.315\n",
      "Ep:26, loss:0.00015, loss_test:0.08490, lr:1.00e-02, fs:0.77130 (r=0.869,p=0.694),  time:36.314, tt:980.478\n",
      "Ep:27, loss:0.00014, loss_test:0.08265, lr:1.00e-02, fs:0.80000 (r=0.909,p=0.714),  time:36.337, tt:1017.446\n",
      "Ep:28, loss:0.00014, loss_test:0.08153, lr:1.00e-02, fs:0.81081 (r=0.909,p=0.732),  time:36.344, tt:1053.988\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.09357, lr:1.00e-02, fs:0.74667 (r=0.848,p=0.667),  time:36.334, tt:1090.033\n",
      "Ep:30, loss:0.00013, loss_test:0.08136, lr:1.00e-02, fs:0.77419 (r=0.848,p=0.712),  time:36.380, tt:1127.773\n",
      "Ep:31, loss:0.00012, loss_test:0.08047, lr:1.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:36.377, tt:1164.073\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00011, loss_test:0.09579, lr:1.00e-02, fs:0.75113 (r=0.838,p=0.680),  time:36.428, tt:1202.117\n",
      "Ep:33, loss:0.00012, loss_test:0.07913, lr:1.00e-02, fs:0.78539 (r=0.869,p=0.717),  time:36.442, tt:1239.029\n",
      "Ep:34, loss:0.00010, loss_test:0.08031, lr:1.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:36.465, tt:1276.290\n",
      "Ep:35, loss:0.00010, loss_test:0.08961, lr:1.00e-02, fs:0.75576 (r=0.828,p=0.695),  time:36.476, tt:1313.122\n",
      "Ep:36, loss:0.00010, loss_test:0.07529, lr:1.00e-02, fs:0.84259 (r=0.919,p=0.778),  time:36.450, tt:1348.662\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00010, loss_test:0.08163, lr:1.00e-02, fs:0.77570 (r=0.838,p=0.722),  time:36.460, tt:1385.493\n",
      "Ep:38, loss:0.00009, loss_test:0.08083, lr:1.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:36.455, tt:1421.743\n",
      "Ep:39, loss:0.00008, loss_test:0.07603, lr:1.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:36.454, tt:1458.151\n",
      "Ep:40, loss:0.00009, loss_test:0.08310, lr:1.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:36.497, tt:1496.395\n",
      "Ep:41, loss:0.00008, loss_test:0.08953, lr:1.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:36.538, tt:1534.601\n",
      "Ep:42, loss:0.00009, loss_test:0.08940, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:36.523, tt:1570.481\n",
      "Ep:43, loss:0.00007, loss_test:0.07629, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:36.520, tt:1606.879\n",
      "Ep:44, loss:0.00007, loss_test:0.08741, lr:1.00e-02, fs:0.78673 (r=0.838,p=0.741),  time:36.545, tt:1644.522\n",
      "Ep:45, loss:0.00008, loss_test:0.07786, lr:1.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:36.551, tt:1681.345\n",
      "Ep:46, loss:0.00007, loss_test:0.07568, lr:1.00e-02, fs:0.78095 (r=0.828,p=0.739),  time:36.557, tt:1718.176\n",
      "Ep:47, loss:0.00007, loss_test:0.08606, lr:1.00e-02, fs:0.77670 (r=0.808,p=0.748),  time:36.572, tt:1755.438\n",
      "Ep:48, loss:0.00007, loss_test:0.07810, lr:9.90e-03, fs:0.78571 (r=0.778,p=0.794),  time:36.598, tt:1793.294\n",
      "Ep:49, loss:0.00006, loss_test:0.08202, lr:9.80e-03, fs:0.77228 (r=0.788,p=0.757),  time:36.603, tt:1830.166\n",
      "Ep:50, loss:0.00006, loss_test:0.08240, lr:9.70e-03, fs:0.77157 (r=0.768,p=0.776),  time:36.623, tt:1867.757\n",
      "Ep:51, loss:0.00005, loss_test:0.07653, lr:9.61e-03, fs:0.80808 (r=0.808,p=0.808),  time:36.605, tt:1903.472\n",
      "Ep:52, loss:0.00005, loss_test:0.08065, lr:9.51e-03, fs:0.76098 (r=0.788,p=0.736),  time:36.601, tt:1939.843\n",
      "Ep:53, loss:0.00005, loss_test:0.07710, lr:9.41e-03, fs:0.78351 (r=0.768,p=0.800),  time:36.590, tt:1975.866\n",
      "Ep:54, loss:0.00005, loss_test:0.07169, lr:9.32e-03, fs:0.81218 (r=0.808,p=0.816),  time:36.577, tt:2011.759\n",
      "Ep:55, loss:0.00004, loss_test:0.08042, lr:9.23e-03, fs:0.79612 (r=0.828,p=0.766),  time:36.620, tt:2050.731\n",
      "Ep:56, loss:0.00004, loss_test:0.07441, lr:9.14e-03, fs:0.81633 (r=0.808,p=0.825),  time:36.625, tt:2087.615\n",
      "Ep:57, loss:0.00004, loss_test:0.08439, lr:9.04e-03, fs:0.76531 (r=0.758,p=0.773),  time:36.619, tt:2123.901\n",
      "Ep:58, loss:0.00004, loss_test:0.08019, lr:8.95e-03, fs:0.77083 (r=0.747,p=0.796),  time:36.638, tt:2161.628\n",
      "Ep:59, loss:0.00004, loss_test:0.07476, lr:8.86e-03, fs:0.78351 (r=0.768,p=0.800),  time:36.663, tt:2199.772\n",
      "Ep:60, loss:0.00003, loss_test:0.08620, lr:8.78e-03, fs:0.79167 (r=0.768,p=0.817),  time:36.670, tt:2236.845\n",
      "Ep:61, loss:0.00003, loss_test:0.08171, lr:8.69e-03, fs:0.76842 (r=0.737,p=0.802),  time:36.656, tt:2272.665\n",
      "Ep:62, loss:0.00003, loss_test:0.07978, lr:8.60e-03, fs:0.76440 (r=0.737,p=0.793),  time:36.634, tt:2307.944\n",
      "Ep:63, loss:0.00003, loss_test:0.08417, lr:8.51e-03, fs:0.77005 (r=0.727,p=0.818),  time:36.624, tt:2343.968\n",
      "Ep:64, loss:0.00003, loss_test:0.07854, lr:8.43e-03, fs:0.75936 (r=0.717,p=0.807),  time:36.596, tt:2378.749\n",
      "Ep:65, loss:0.00003, loss_test:0.08561, lr:8.35e-03, fs:0.75132 (r=0.717,p=0.789),  time:36.612, tt:2416.369\n",
      "Ep:66, loss:0.00003, loss_test:0.08027, lr:8.26e-03, fs:0.76757 (r=0.717,p=0.826),  time:36.619, tt:2453.452\n",
      "Ep:67, loss:0.00003, loss_test:0.07885, lr:8.18e-03, fs:0.77249 (r=0.737,p=0.811),  time:36.611, tt:2489.544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:68, loss:0.00003, loss_test:0.08567, lr:8.10e-03, fs:0.75393 (r=0.727,p=0.783),  time:36.615, tt:2526.404\n",
      "Ep:69, loss:0.00003, loss_test:0.08209, lr:8.02e-03, fs:0.76344 (r=0.717,p=0.816),  time:36.638, tt:2564.646\n",
      "Ep:70, loss:0.00003, loss_test:0.07687, lr:7.94e-03, fs:0.76344 (r=0.717,p=0.816),  time:36.640, tt:2601.471\n",
      "Ep:71, loss:0.00002, loss_test:0.08085, lr:7.86e-03, fs:0.75532 (r=0.717,p=0.798),  time:36.650, tt:2638.822\n",
      "Ep:72, loss:0.00002, loss_test:0.07829, lr:7.78e-03, fs:0.76344 (r=0.717,p=0.816),  time:36.641, tt:2674.760\n",
      "Ep:73, loss:0.00002, loss_test:0.08250, lr:7.70e-03, fs:0.76596 (r=0.727,p=0.809),  time:36.660, tt:2712.815\n",
      "Ep:74, loss:0.00002, loss_test:0.07746, lr:7.62e-03, fs:0.76344 (r=0.717,p=0.816),  time:36.652, tt:2748.919\n",
      "Ep:75, loss:0.00002, loss_test:0.07997, lr:7.55e-03, fs:0.76344 (r=0.717,p=0.816),  time:36.646, tt:2785.063\n",
      "Ep:76, loss:0.00002, loss_test:0.08275, lr:7.47e-03, fs:0.76344 (r=0.717,p=0.816),  time:36.657, tt:2822.599\n",
      "Ep:77, loss:0.00002, loss_test:0.07997, lr:7.40e-03, fs:0.76757 (r=0.717,p=0.826),  time:36.666, tt:2859.956\n",
      "Ep:78, loss:0.00002, loss_test:0.08259, lr:7.32e-03, fs:0.77419 (r=0.727,p=0.828),  time:36.673, tt:2897.163\n",
      "Ep:79, loss:0.00002, loss_test:0.07827, lr:7.25e-03, fs:0.76344 (r=0.717,p=0.816),  time:36.672, tt:2933.750\n",
      "Ep:80, loss:0.00002, loss_test:0.08014, lr:7.18e-03, fs:0.77174 (r=0.717,p=0.835),  time:36.683, tt:2971.325\n",
      "Ep:81, loss:0.00002, loss_test:0.08122, lr:7.11e-03, fs:0.77005 (r=0.727,p=0.818),  time:36.677, tt:3007.550\n",
      "Ep:82, loss:0.00002, loss_test:0.08461, lr:7.03e-03, fs:0.76596 (r=0.727,p=0.809),  time:36.665, tt:3043.195\n",
      "Ep:83, loss:0.00002, loss_test:0.08205, lr:6.96e-03, fs:0.77596 (r=0.717,p=0.845),  time:36.669, tt:3080.168\n",
      "Ep:84, loss:0.00002, loss_test:0.08298, lr:6.89e-03, fs:0.77174 (r=0.717,p=0.835),  time:36.662, tt:3116.301\n",
      "Ep:85, loss:0.00002, loss_test:0.08076, lr:6.83e-03, fs:0.78947 (r=0.758,p=0.824),  time:36.673, tt:3153.863\n",
      "Ep:86, loss:0.00002, loss_test:0.08159, lr:6.76e-03, fs:0.78022 (r=0.717,p=0.855),  time:36.676, tt:3190.801\n",
      "Ep:87, loss:0.00002, loss_test:0.07870, lr:6.69e-03, fs:0.77419 (r=0.727,p=0.828),  time:36.636, tt:3223.927\n",
      "Ep:88, loss:0.00002, loss_test:0.07594, lr:6.62e-03, fs:0.80663 (r=0.737,p=0.890),  time:36.615, tt:3258.734\n",
      "Ep:89, loss:0.00002, loss_test:0.07984, lr:6.56e-03, fs:0.78453 (r=0.717,p=0.866),  time:36.606, tt:3294.524\n",
      "Ep:90, loss:0.00002, loss_test:0.07804, lr:6.49e-03, fs:0.80663 (r=0.737,p=0.890),  time:36.607, tt:3331.221\n",
      "Ep:91, loss:0.00002, loss_test:0.07688, lr:6.43e-03, fs:0.79558 (r=0.727,p=0.878),  time:36.610, tt:3368.160\n",
      "Ep:92, loss:0.00002, loss_test:0.08216, lr:6.36e-03, fs:0.80000 (r=0.727,p=0.889),  time:36.618, tt:3405.438\n",
      "Ep:93, loss:0.00002, loss_test:0.07869, lr:6.30e-03, fs:0.79558 (r=0.727,p=0.878),  time:36.608, tt:3441.158\n",
      "Ep:94, loss:0.00001, loss_test:0.08090, lr:6.24e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.612, tt:3478.135\n",
      "Ep:95, loss:0.00001, loss_test:0.07856, lr:6.17e-03, fs:0.81319 (r=0.747,p=0.892),  time:36.616, tt:3515.139\n",
      "Ep:96, loss:0.00001, loss_test:0.07913, lr:6.11e-03, fs:0.79330 (r=0.717,p=0.887),  time:36.617, tt:3551.875\n",
      "Ep:97, loss:0.00001, loss_test:0.07904, lr:6.05e-03, fs:0.80000 (r=0.727,p=0.889),  time:36.616, tt:3588.357\n",
      "Ep:98, loss:0.00001, loss_test:0.07653, lr:5.99e-03, fs:0.80220 (r=0.737,p=0.880),  time:36.617, tt:3625.094\n",
      "Ep:99, loss:0.00001, loss_test:0.08110, lr:5.93e-03, fs:0.79558 (r=0.727,p=0.878),  time:36.617, tt:3661.744\n",
      "Ep:100, loss:0.00001, loss_test:0.08072, lr:5.87e-03, fs:0.81111 (r=0.737,p=0.901),  time:36.619, tt:3698.559\n",
      "Ep:101, loss:0.00001, loss_test:0.07984, lr:5.81e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.620, tt:3735.247\n",
      "Ep:102, loss:0.00001, loss_test:0.08200, lr:5.75e-03, fs:0.81111 (r=0.737,p=0.901),  time:36.616, tt:3771.405\n",
      "Ep:103, loss:0.00001, loss_test:0.07754, lr:5.70e-03, fs:0.79330 (r=0.717,p=0.887),  time:36.616, tt:3808.082\n",
      "Ep:104, loss:0.00001, loss_test:0.07926, lr:5.64e-03, fs:0.82222 (r=0.747,p=0.914),  time:36.617, tt:3844.760\n",
      "Ep:105, loss:0.00001, loss_test:0.08107, lr:5.58e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.615, tt:3881.210\n",
      "Ep:106, loss:0.00001, loss_test:0.07930, lr:5.53e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.612, tt:3917.438\n",
      "Ep:107, loss:0.00001, loss_test:0.07940, lr:5.47e-03, fs:0.81768 (r=0.747,p=0.902),  time:36.607, tt:3953.557\n",
      "Ep:108, loss:0.00001, loss_test:0.07943, lr:5.42e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.593, tt:3988.598\n",
      "Ep:109, loss:0.00001, loss_test:0.08251, lr:5.36e-03, fs:0.82418 (r=0.758,p=0.904),  time:36.593, tt:4025.266\n",
      "Ep:110, loss:0.00001, loss_test:0.08138, lr:5.31e-03, fs:0.81564 (r=0.737,p=0.912),  time:36.593, tt:4061.850\n",
      "Ep:111, loss:0.00001, loss_test:0.08440, lr:5.26e-03, fs:0.82682 (r=0.747,p=0.925),  time:36.596, tt:4098.779\n",
      "Ep:112, loss:0.00001, loss_test:0.07966, lr:5.20e-03, fs:0.81564 (r=0.737,p=0.912),  time:36.608, tt:4136.703\n",
      "Ep:113, loss:0.00001, loss_test:0.08130, lr:5.15e-03, fs:0.82682 (r=0.747,p=0.925),  time:36.601, tt:4172.459\n",
      "Ep:114, loss:0.00001, loss_test:0.08150, lr:5.10e-03, fs:0.82022 (r=0.737,p=0.924),  time:36.596, tt:4208.556\n",
      "Ep:115, loss:0.00001, loss_test:0.08062, lr:5.05e-03, fs:0.82873 (r=0.758,p=0.915),  time:36.598, tt:4245.377\n",
      "Ep:116, loss:0.00001, loss_test:0.08399, lr:5.00e-03, fs:0.82873 (r=0.758,p=0.915),  time:36.591, tt:4281.145\n",
      "Ep:117, loss:0.00001, loss_test:0.08173, lr:4.95e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.590, tt:4317.561\n",
      "Ep:118, loss:0.00001, loss_test:0.08456, lr:4.90e-03, fs:0.81818 (r=0.727,p=0.935),  time:36.580, tt:4352.968\n",
      "Ep:119, loss:0.00001, loss_test:0.07986, lr:4.85e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.565, tt:4387.781\n",
      "Ep:120, loss:0.00001, loss_test:0.08264, lr:4.80e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.547, tt:4422.130\n",
      "Ep:121, loss:0.00001, loss_test:0.08083, lr:4.75e-03, fs:0.82222 (r=0.747,p=0.914),  time:36.551, tt:4459.265\n",
      "Ep:122, loss:0.00001, loss_test:0.08288, lr:4.71e-03, fs:0.82486 (r=0.737,p=0.936),  time:36.555, tt:4496.268\n",
      "Ep:123, loss:0.00001, loss_test:0.08091, lr:4.66e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.551, tt:4532.304\n",
      "Ep:124, loss:0.00001, loss_test:0.08135, lr:4.61e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.551, tt:4568.849\n",
      "Ep:125, loss:0.00001, loss_test:0.08055, lr:4.57e-03, fs:0.83616 (r=0.747,p=0.949),  time:36.537, tt:4603.709\n",
      "Ep:126, loss:0.00001, loss_test:0.08036, lr:4.52e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.531, tt:4639.446\n",
      "Ep:127, loss:0.00001, loss_test:0.08113, lr:4.48e-03, fs:0.82682 (r=0.747,p=0.925),  time:36.527, tt:4675.492\n",
      "Ep:128, loss:0.00001, loss_test:0.08218, lr:4.43e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.535, tt:4712.993\n",
      "Ep:129, loss:0.00001, loss_test:0.07950, lr:4.39e-03, fs:0.82682 (r=0.747,p=0.925),  time:36.546, tt:4751.016\n",
      "Ep:130, loss:0.00001, loss_test:0.08172, lr:4.34e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.545, tt:4787.443\n",
      "Ep:131, loss:0.00001, loss_test:0.08008, lr:4.30e-03, fs:0.82022 (r=0.737,p=0.924),  time:36.556, tt:4825.433\n",
      "Ep:132, loss:0.00001, loss_test:0.08149, lr:4.26e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.551, tt:4861.308\n",
      "Ep:133, loss:0.00001, loss_test:0.08214, lr:4.21e-03, fs:0.82486 (r=0.737,p=0.936),  time:36.555, tt:4898.306\n",
      "Ep:134, loss:0.00001, loss_test:0.08328, lr:4.17e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.557, tt:4935.168\n",
      "Ep:135, loss:0.00001, loss_test:0.08282, lr:4.13e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.559, tt:4972.000\n",
      "Ep:136, loss:0.00001, loss_test:0.08198, lr:4.09e-03, fs:0.82682 (r=0.747,p=0.925),  time:36.563, tt:5009.144\n",
      "Ep:137, loss:0.00001, loss_test:0.08167, lr:4.05e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.560, tt:5045.342\n",
      "Ep:138, loss:0.00001, loss_test:0.08131, lr:4.01e-03, fs:0.83146 (r=0.747,p=0.937),  time:36.564, tt:5082.394\n",
      "Ep:139, loss:0.00001, loss_test:0.08165, lr:3.97e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.562, tt:5118.614\n",
      "Ep:140, loss:0.00001, loss_test:0.08205, lr:3.93e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.560, tt:5154.979\n",
      "Ep:141, loss:0.00001, loss_test:0.08206, lr:3.89e-03, fs:0.82682 (r=0.747,p=0.925),  time:36.546, tt:5189.512\n",
      "Ep:142, loss:0.00000, loss_test:0.08119, lr:3.85e-03, fs:0.83146 (r=0.747,p=0.937),  time:36.554, tt:5227.220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:143, loss:0.00000, loss_test:0.08035, lr:3.81e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.549, tt:5263.030\n",
      "Ep:144, loss:0.00000, loss_test:0.08002, lr:3.77e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.552, tt:5300.063\n",
      "Ep:145, loss:0.00000, loss_test:0.08326, lr:3.73e-03, fs:0.84746 (r=0.758,p=0.962),  time:36.552, tt:5336.524\n",
      "##########Best model found so far##########\n",
      "Ep:146, loss:0.00000, loss_test:0.08085, lr:3.73e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.549, tt:5372.718\n",
      "Ep:147, loss:0.00000, loss_test:0.08330, lr:3.73e-03, fs:0.82486 (r=0.737,p=0.936),  time:36.541, tt:5408.110\n",
      "Ep:148, loss:0.00000, loss_test:0.08232, lr:3.73e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.540, tt:5444.402\n",
      "Ep:149, loss:0.00000, loss_test:0.08138, lr:3.73e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.535, tt:5480.297\n",
      "Ep:150, loss:0.00000, loss_test:0.08305, lr:3.73e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.519, tt:5514.310\n",
      "Ep:151, loss:0.00000, loss_test:0.08140, lr:3.73e-03, fs:0.81818 (r=0.727,p=0.935),  time:36.534, tt:5553.110\n",
      "Ep:152, loss:0.00000, loss_test:0.08173, lr:3.73e-03, fs:0.84270 (r=0.758,p=0.949),  time:36.522, tt:5587.929\n",
      "Ep:153, loss:0.00000, loss_test:0.08270, lr:3.73e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.521, tt:5624.253\n",
      "Ep:154, loss:0.00000, loss_test:0.08194, lr:3.73e-03, fs:0.84270 (r=0.758,p=0.949),  time:36.512, tt:5659.384\n",
      "Ep:155, loss:0.00000, loss_test:0.08231, lr:3.73e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.508, tt:5695.273\n",
      "Ep:156, loss:0.00000, loss_test:0.08327, lr:3.73e-03, fs:0.82955 (r=0.737,p=0.948),  time:36.502, tt:5730.883\n",
      "Ep:157, loss:0.00000, loss_test:0.08221, lr:3.70e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.491, tt:5765.590\n",
      "Ep:158, loss:0.00000, loss_test:0.08320, lr:3.66e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.487, tt:5801.402\n",
      "Ep:159, loss:0.00000, loss_test:0.08276, lr:3.62e-03, fs:0.82486 (r=0.737,p=0.936),  time:36.487, tt:5837.994\n",
      "Ep:160, loss:0.00000, loss_test:0.08247, lr:3.59e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.492, tt:5875.284\n",
      "Ep:161, loss:0.00000, loss_test:0.08104, lr:3.55e-03, fs:0.84270 (r=0.758,p=0.949),  time:36.487, tt:5910.957\n",
      "Ep:162, loss:0.00000, loss_test:0.08208, lr:3.52e-03, fs:0.83146 (r=0.747,p=0.937),  time:36.494, tt:5948.514\n",
      "Ep:163, loss:0.00000, loss_test:0.08103, lr:3.48e-03, fs:0.82682 (r=0.747,p=0.925),  time:36.484, tt:5983.363\n",
      "Ep:164, loss:0.00000, loss_test:0.08109, lr:3.45e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.481, tt:6019.431\n",
      "Ep:165, loss:0.00000, loss_test:0.08154, lr:3.41e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.487, tt:6056.762\n",
      "Ep:166, loss:0.00000, loss_test:0.08199, lr:3.38e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.492, tt:6094.240\n",
      "Ep:167, loss:0.00000, loss_test:0.08267, lr:3.34e-03, fs:0.82682 (r=0.747,p=0.925),  time:36.495, tt:6131.142\n",
      "Ep:168, loss:0.00000, loss_test:0.08175, lr:3.31e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.492, tt:6167.193\n",
      "Ep:169, loss:0.00000, loss_test:0.08060, lr:3.28e-03, fs:0.81818 (r=0.727,p=0.935),  time:36.494, tt:6204.041\n",
      "Ep:170, loss:0.00000, loss_test:0.08181, lr:3.24e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.505, tt:6242.403\n",
      "Ep:171, loss:0.00000, loss_test:0.08097, lr:3.21e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.503, tt:6278.481\n",
      "Ep:172, loss:0.00000, loss_test:0.08133, lr:3.18e-03, fs:0.83146 (r=0.747,p=0.937),  time:36.512, tt:6316.615\n",
      "Ep:173, loss:0.00000, loss_test:0.08225, lr:3.15e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.514, tt:6353.429\n",
      "Ep:174, loss:0.00000, loss_test:0.08154, lr:3.12e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.525, tt:6391.788\n",
      "Ep:175, loss:0.00000, loss_test:0.08131, lr:3.09e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.521, tt:6427.756\n",
      "Ep:176, loss:0.00000, loss_test:0.08355, lr:3.05e-03, fs:0.83146 (r=0.747,p=0.937),  time:36.526, tt:6465.181\n",
      "Ep:177, loss:0.00000, loss_test:0.08203, lr:3.02e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.523, tt:6501.008\n",
      "Ep:178, loss:0.00000, loss_test:0.08352, lr:2.99e-03, fs:0.83146 (r=0.747,p=0.937),  time:36.517, tt:6536.625\n",
      "Ep:179, loss:0.00000, loss_test:0.08248, lr:2.96e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.518, tt:6573.204\n",
      "Ep:180, loss:0.00000, loss_test:0.08297, lr:2.93e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.514, tt:6609.110\n",
      "Ep:181, loss:0.00000, loss_test:0.08276, lr:2.90e-03, fs:0.82022 (r=0.737,p=0.924),  time:36.517, tt:6646.075\n",
      "Ep:182, loss:0.00000, loss_test:0.08182, lr:2.88e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.510, tt:6681.411\n",
      "Ep:183, loss:0.00000, loss_test:0.08225, lr:2.85e-03, fs:0.82682 (r=0.747,p=0.925),  time:36.511, tt:6717.956\n",
      "Ep:184, loss:0.00000, loss_test:0.08115, lr:2.82e-03, fs:0.83146 (r=0.747,p=0.937),  time:36.511, tt:6754.623\n",
      "Ep:185, loss:0.00000, loss_test:0.08080, lr:2.79e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.515, tt:6791.802\n",
      "Ep:186, loss:0.00000, loss_test:0.08159, lr:2.76e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.512, tt:6827.805\n",
      "Ep:187, loss:0.00000, loss_test:0.08124, lr:2.73e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.514, tt:6864.605\n",
      "Ep:188, loss:0.00000, loss_test:0.08366, lr:2.71e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.513, tt:6900.869\n",
      "Ep:189, loss:0.00000, loss_test:0.08252, lr:2.68e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.520, tt:6938.887\n",
      "Ep:190, loss:0.00000, loss_test:0.08244, lr:2.65e-03, fs:0.83146 (r=0.747,p=0.937),  time:36.524, tt:6976.090\n",
      "Ep:191, loss:0.00000, loss_test:0.08255, lr:2.63e-03, fs:0.82682 (r=0.747,p=0.925),  time:36.527, tt:7013.269\n",
      "Ep:192, loss:0.00000, loss_test:0.08268, lr:2.60e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.526, tt:7049.590\n",
      "Ep:193, loss:0.00000, loss_test:0.08175, lr:2.57e-03, fs:0.82022 (r=0.737,p=0.924),  time:36.527, tt:7086.293\n",
      "Ep:194, loss:0.00000, loss_test:0.08337, lr:2.55e-03, fs:0.82022 (r=0.737,p=0.924),  time:36.524, tt:7122.230\n",
      "Ep:195, loss:0.00000, loss_test:0.08255, lr:2.52e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.522, tt:7158.363\n",
      "Ep:196, loss:0.00000, loss_test:0.08260, lr:2.50e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.519, tt:7194.182\n",
      "Ep:197, loss:0.00000, loss_test:0.08280, lr:2.47e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.512, tt:7229.455\n",
      "Ep:198, loss:0.00000, loss_test:0.08151, lr:2.45e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.508, tt:7265.116\n",
      "Ep:199, loss:0.00000, loss_test:0.08270, lr:2.42e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.504, tt:7300.704\n",
      "Ep:200, loss:0.00000, loss_test:0.08265, lr:2.40e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.504, tt:7337.360\n",
      "Ep:201, loss:0.00000, loss_test:0.08262, lr:2.38e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.501, tt:7373.103\n",
      "Ep:202, loss:0.00000, loss_test:0.08280, lr:2.35e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.497, tt:7408.839\n",
      "Ep:203, loss:0.00000, loss_test:0.08324, lr:2.33e-03, fs:0.82486 (r=0.737,p=0.936),  time:36.494, tt:7444.865\n",
      "Ep:204, loss:0.00000, loss_test:0.08354, lr:2.31e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.491, tt:7480.742\n",
      "Ep:205, loss:0.00000, loss_test:0.08206, lr:2.28e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.492, tt:7517.330\n",
      "Ep:206, loss:0.00000, loss_test:0.08271, lr:2.26e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.484, tt:7552.087\n",
      "Ep:207, loss:0.00000, loss_test:0.08176, lr:2.24e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.485, tt:7588.876\n",
      "Ep:208, loss:0.00000, loss_test:0.08173, lr:2.21e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.471, tt:7622.414\n",
      "Ep:209, loss:0.00000, loss_test:0.08118, lr:2.19e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.437, tt:7651.810\n",
      "Ep:210, loss:0.00000, loss_test:0.08134, lr:2.17e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.397, tt:7679.842\n",
      "Ep:211, loss:0.00000, loss_test:0.08173, lr:2.15e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.368, tt:7710.015\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00012, loss_test:0.02936, lr:6.00e-02, fs:0.63519 (r=0.747,p=0.552),  time:33.175, tt:33.175\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00006, loss_test:0.02473, lr:6.00e-02, fs:0.65428 (r=0.889,p=0.518),  time:32.398, tt:64.796\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02628, lr:6.00e-02, fs:0.67586 (r=0.990,p=0.513),  time:33.683, tt:101.050\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02665, lr:6.00e-02, fs:0.67808 (r=1.000,p=0.513),  time:34.305, tt:137.220\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00005, loss_test:0.02610, lr:6.00e-02, fs:0.65248 (r=0.929,p=0.503),  time:34.339, tt:171.693\n",
      "Ep:5, loss:0.00005, loss_test:0.02548, lr:6.00e-02, fs:0.66176 (r=0.909,p=0.520),  time:34.880, tt:209.282\n",
      "Ep:6, loss:0.00005, loss_test:0.02511, lr:6.00e-02, fs:0.66171 (r=0.899,p=0.524),  time:35.013, tt:245.089\n",
      "Ep:7, loss:0.00005, loss_test:0.02482, lr:6.00e-02, fs:0.65672 (r=0.889,p=0.521),  time:35.090, tt:280.722\n",
      "Ep:8, loss:0.00005, loss_test:0.02449, lr:6.00e-02, fs:0.65428 (r=0.889,p=0.518),  time:35.067, tt:315.607\n",
      "Ep:9, loss:0.00005, loss_test:0.02417, lr:6.00e-02, fs:0.65683 (r=0.899,p=0.517),  time:35.045, tt:350.453\n",
      "Ep:10, loss:0.00005, loss_test:0.02378, lr:6.00e-02, fs:0.66176 (r=0.909,p=0.520),  time:34.990, tt:384.895\n",
      "Ep:11, loss:0.00005, loss_test:0.02321, lr:6.00e-02, fs:0.66176 (r=0.909,p=0.520),  time:35.009, tt:420.113\n",
      "Ep:12, loss:0.00005, loss_test:0.02256, lr:6.00e-02, fs:0.66421 (r=0.909,p=0.523),  time:35.021, tt:455.268\n",
      "Ep:13, loss:0.00004, loss_test:0.02186, lr:6.00e-02, fs:0.67170 (r=0.899,p=0.536),  time:35.045, tt:490.629\n",
      "Ep:14, loss:0.00004, loss_test:0.02121, lr:6.00e-02, fs:0.65900 (r=0.869,p=0.531),  time:35.049, tt:525.737\n",
      "Ep:15, loss:0.00004, loss_test:0.02060, lr:5.94e-02, fs:0.66920 (r=0.889,p=0.537),  time:35.020, tt:560.317\n",
      "Ep:16, loss:0.00004, loss_test:0.02008, lr:5.88e-02, fs:0.67681 (r=0.899,p=0.543),  time:34.989, tt:594.817\n",
      "Ep:17, loss:0.00004, loss_test:0.01960, lr:5.82e-02, fs:0.69732 (r=0.919,p=0.562),  time:35.046, tt:630.826\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.01913, lr:5.82e-02, fs:0.70992 (r=0.939,p=0.571),  time:34.978, tt:664.591\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00004, loss_test:0.01870, lr:5.82e-02, fs:0.72453 (r=0.970,p=0.578),  time:34.953, tt:699.050\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00004, loss_test:0.01825, lr:5.82e-02, fs:0.71429 (r=0.960,p=0.569),  time:34.958, tt:734.113\n",
      "Ep:21, loss:0.00004, loss_test:0.01783, lr:5.82e-02, fs:0.73004 (r=0.970,p=0.585),  time:34.974, tt:769.430\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01749, lr:5.82e-02, fs:0.74046 (r=0.980,p=0.595),  time:34.935, tt:803.504\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01714, lr:5.82e-02, fs:0.74525 (r=0.990,p=0.598),  time:34.932, tt:838.380\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01675, lr:5.82e-02, fs:0.75969 (r=0.990,p=0.616),  time:34.943, tt:873.574\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01635, lr:5.82e-02, fs:0.75099 (r=0.960,p=0.617),  time:34.897, tt:907.326\n",
      "Ep:26, loss:0.00003, loss_test:0.01601, lr:5.82e-02, fs:0.75200 (r=0.949,p=0.623),  time:34.924, tt:942.950\n",
      "Ep:27, loss:0.00003, loss_test:0.01569, lr:5.82e-02, fs:0.76735 (r=0.949,p=0.644),  time:34.933, tt:978.130\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01535, lr:5.82e-02, fs:0.77551 (r=0.960,p=0.651),  time:34.936, tt:1013.142\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01510, lr:5.82e-02, fs:0.78838 (r=0.960,p=0.669),  time:34.917, tt:1047.522\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01492, lr:5.82e-02, fs:0.78512 (r=0.960,p=0.664),  time:35.002, tt:1085.054\n",
      "Ep:31, loss:0.00002, loss_test:0.01477, lr:5.82e-02, fs:0.78838 (r=0.960,p=0.669),  time:34.994, tt:1119.802\n",
      "Ep:32, loss:0.00002, loss_test:0.01469, lr:5.82e-02, fs:0.79325 (r=0.949,p=0.681),  time:34.991, tt:1154.717\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01459, lr:5.82e-02, fs:0.80169 (r=0.960,p=0.688),  time:35.014, tt:1190.484\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01457, lr:5.82e-02, fs:0.80687 (r=0.949,p=0.701),  time:35.016, tt:1225.575\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01441, lr:5.82e-02, fs:0.80687 (r=0.949,p=0.701),  time:35.038, tt:1261.360\n",
      "Ep:36, loss:0.00002, loss_test:0.01419, lr:5.82e-02, fs:0.81197 (r=0.960,p=0.704),  time:35.048, tt:1296.776\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01407, lr:5.82e-02, fs:0.81545 (r=0.960,p=0.709),  time:35.069, tt:1332.619\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01403, lr:5.82e-02, fs:0.82251 (r=0.960,p=0.720),  time:35.062, tt:1367.410\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01398, lr:5.82e-02, fs:0.82456 (r=0.949,p=0.729),  time:35.040, tt:1401.585\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01401, lr:5.82e-02, fs:0.82819 (r=0.949,p=0.734),  time:35.051, tt:1437.089\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00001, loss_test:0.01393, lr:5.82e-02, fs:0.83556 (r=0.949,p=0.746),  time:35.061, tt:1472.550\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00001, loss_test:0.01405, lr:5.82e-02, fs:0.83556 (r=0.949,p=0.746),  time:35.041, tt:1506.755\n",
      "Ep:43, loss:0.00001, loss_test:0.01418, lr:5.82e-02, fs:0.84305 (r=0.949,p=0.758),  time:35.035, tt:1541.559\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00001, loss_test:0.01433, lr:5.82e-02, fs:0.83333 (r=0.909,p=0.769),  time:35.029, tt:1576.288\n",
      "Ep:45, loss:0.00001, loss_test:0.01429, lr:5.82e-02, fs:0.84163 (r=0.939,p=0.762),  time:35.052, tt:1612.402\n",
      "Ep:46, loss:0.00001, loss_test:0.01453, lr:5.82e-02, fs:0.82949 (r=0.909,p=0.763),  time:35.077, tt:1648.618\n",
      "Ep:47, loss:0.00001, loss_test:0.01487, lr:5.82e-02, fs:0.82243 (r=0.889,p=0.765),  time:35.093, tt:1684.466\n",
      "Ep:48, loss:0.00001, loss_test:0.01509, lr:5.82e-02, fs:0.81690 (r=0.879,p=0.763),  time:35.092, tt:1719.531\n",
      "Ep:49, loss:0.00001, loss_test:0.01529, lr:5.82e-02, fs:0.81517 (r=0.869,p=0.768),  time:35.100, tt:1754.991\n",
      "Ep:50, loss:0.00001, loss_test:0.01554, lr:5.82e-02, fs:0.80769 (r=0.848,p=0.771),  time:35.088, tt:1789.485\n",
      "Ep:51, loss:0.00001, loss_test:0.01574, lr:5.82e-02, fs:0.80769 (r=0.848,p=0.771),  time:35.107, tt:1825.566\n",
      "Ep:52, loss:0.00001, loss_test:0.01604, lr:5.82e-02, fs:0.79024 (r=0.818,p=0.764),  time:35.107, tt:1860.676\n",
      "Ep:53, loss:0.00001, loss_test:0.01640, lr:5.82e-02, fs:0.77833 (r=0.798,p=0.760),  time:35.135, tt:1897.305\n",
      "Ep:54, loss:0.00001, loss_test:0.01646, lr:5.82e-02, fs:0.77833 (r=0.798,p=0.760),  time:35.135, tt:1932.435\n",
      "Ep:55, loss:0.00001, loss_test:0.01691, lr:5.76e-02, fs:0.76000 (r=0.768,p=0.752),  time:35.122, tt:1966.847\n",
      "Ep:56, loss:0.00001, loss_test:0.01743, lr:5.71e-02, fs:0.72821 (r=0.717,p=0.740),  time:35.111, tt:2001.328\n",
      "Ep:57, loss:0.00001, loss_test:0.01744, lr:5.65e-02, fs:0.74227 (r=0.727,p=0.758),  time:35.121, tt:2037.000\n",
      "Ep:58, loss:0.00001, loss_test:0.01758, lr:5.59e-02, fs:0.71875 (r=0.697,p=0.742),  time:35.134, tt:2072.882\n",
      "Ep:59, loss:0.00001, loss_test:0.01830, lr:5.54e-02, fs:0.72632 (r=0.697,p=0.758),  time:35.131, tt:2107.866\n",
      "Ep:60, loss:0.00001, loss_test:0.01857, lr:5.48e-02, fs:0.71579 (r=0.687,p=0.747),  time:35.138, tt:2143.425\n",
      "Ep:61, loss:0.00001, loss_test:0.01857, lr:5.43e-02, fs:0.70968 (r=0.667,p=0.759),  time:35.145, tt:2178.990\n",
      "Ep:62, loss:0.00001, loss_test:0.01918, lr:5.37e-02, fs:0.70718 (r=0.646,p=0.780),  time:35.141, tt:2213.911\n",
      "Ep:63, loss:0.00001, loss_test:0.01928, lr:5.32e-02, fs:0.71351 (r=0.667,p=0.767),  time:35.146, tt:2249.355\n",
      "Ep:64, loss:0.00001, loss_test:0.01981, lr:5.27e-02, fs:0.71111 (r=0.646,p=0.790),  time:35.142, tt:2284.236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:65, loss:0.00001, loss_test:0.02028, lr:5.21e-02, fs:0.69663 (r=0.626,p=0.785),  time:35.142, tt:2319.340\n",
      "Ep:66, loss:0.00001, loss_test:0.02053, lr:5.16e-02, fs:0.70056 (r=0.626,p=0.795),  time:35.150, tt:2355.038\n",
      "Ep:67, loss:0.00001, loss_test:0.02061, lr:5.11e-02, fs:0.68927 (r=0.616,p=0.782),  time:35.149, tt:2390.107\n",
      "Ep:68, loss:0.00001, loss_test:0.02127, lr:5.06e-02, fs:0.70455 (r=0.626,p=0.805),  time:35.170, tt:2426.707\n",
      "Ep:69, loss:0.00000, loss_test:0.02147, lr:5.01e-02, fs:0.69714 (r=0.616,p=0.803),  time:35.162, tt:2461.316\n",
      "Ep:70, loss:0.00000, loss_test:0.02204, lr:4.96e-02, fs:0.69714 (r=0.616,p=0.803),  time:35.174, tt:2497.369\n",
      "Ep:71, loss:0.00000, loss_test:0.02241, lr:4.91e-02, fs:0.69714 (r=0.616,p=0.803),  time:35.158, tt:2531.347\n",
      "Ep:72, loss:0.00000, loss_test:0.02263, lr:4.86e-02, fs:0.69714 (r=0.616,p=0.803),  time:35.149, tt:2565.843\n",
      "Ep:73, loss:0.00000, loss_test:0.02318, lr:4.81e-02, fs:0.70115 (r=0.616,p=0.813),  time:35.152, tt:2601.250\n",
      "Ep:74, loss:0.00000, loss_test:0.02325, lr:4.76e-02, fs:0.69714 (r=0.616,p=0.803),  time:35.180, tt:2638.486\n",
      "Ep:75, loss:0.00000, loss_test:0.02379, lr:4.71e-02, fs:0.69714 (r=0.616,p=0.803),  time:35.182, tt:2673.826\n",
      "Ep:76, loss:0.00000, loss_test:0.02442, lr:4.67e-02, fs:0.70520 (r=0.616,p=0.824),  time:35.186, tt:2709.293\n",
      "Ep:77, loss:0.00000, loss_test:0.02434, lr:4.62e-02, fs:0.70520 (r=0.616,p=0.824),  time:35.187, tt:2744.557\n",
      "Ep:78, loss:0.00000, loss_test:0.02493, lr:4.57e-02, fs:0.69412 (r=0.596,p=0.831),  time:35.186, tt:2779.721\n",
      "Ep:79, loss:0.00000, loss_test:0.02502, lr:4.53e-02, fs:0.69767 (r=0.606,p=0.822),  time:35.170, tt:2813.568\n",
      "Ep:80, loss:0.00000, loss_test:0.02578, lr:4.48e-02, fs:0.69412 (r=0.596,p=0.831),  time:35.172, tt:2848.937\n",
      "Ep:81, loss:0.00000, loss_test:0.02591, lr:4.44e-02, fs:0.70175 (r=0.606,p=0.833),  time:35.188, tt:2885.429\n",
      "Ep:82, loss:0.00000, loss_test:0.02607, lr:4.39e-02, fs:0.69412 (r=0.596,p=0.831),  time:35.188, tt:2920.614\n",
      "Ep:83, loss:0.00000, loss_test:0.02694, lr:4.35e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.160, tt:2953.476\n",
      "Ep:84, loss:0.00000, loss_test:0.02694, lr:4.31e-02, fs:0.69412 (r=0.596,p=0.831),  time:35.173, tt:2989.666\n",
      "Ep:85, loss:0.00000, loss_test:0.02749, lr:4.26e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.190, tt:3026.375\n",
      "Ep:86, loss:0.00000, loss_test:0.02728, lr:4.22e-02, fs:0.69412 (r=0.596,p=0.831),  time:35.199, tt:3062.291\n",
      "Ep:87, loss:0.00000, loss_test:0.02828, lr:4.18e-02, fs:0.67066 (r=0.566,p=0.824),  time:35.214, tt:3098.871\n",
      "Ep:88, loss:0.00000, loss_test:0.02790, lr:4.14e-02, fs:0.68263 (r=0.576,p=0.838),  time:35.212, tt:3133.910\n",
      "Ep:89, loss:0.00000, loss_test:0.02837, lr:4.10e-02, fs:0.68639 (r=0.586,p=0.829),  time:35.246, tt:3172.149\n",
      "Ep:90, loss:0.00000, loss_test:0.02868, lr:4.05e-02, fs:0.68263 (r=0.576,p=0.838),  time:35.242, tt:3207.045\n",
      "Ep:91, loss:0.00000, loss_test:0.02943, lr:4.01e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.245, tt:3242.538\n",
      "Ep:92, loss:0.00000, loss_test:0.02977, lr:3.97e-02, fs:0.68639 (r=0.586,p=0.829),  time:35.225, tt:3275.883\n",
      "Ep:93, loss:0.00000, loss_test:0.02944, lr:3.93e-02, fs:0.69048 (r=0.586,p=0.841),  time:35.242, tt:3312.779\n",
      "Ep:94, loss:0.00000, loss_test:0.02996, lr:3.89e-02, fs:0.65031 (r=0.535,p=0.828),  time:35.238, tt:3347.583\n",
      "Ep:95, loss:0.00000, loss_test:0.03040, lr:3.86e-02, fs:0.69461 (r=0.586,p=0.853),  time:35.233, tt:3382.397\n",
      "Ep:96, loss:0.00000, loss_test:0.03095, lr:3.82e-02, fs:0.67879 (r=0.566,p=0.848),  time:35.240, tt:3418.236\n",
      "Ep:97, loss:0.00000, loss_test:0.03081, lr:3.78e-02, fs:0.69461 (r=0.586,p=0.853),  time:35.256, tt:3455.047\n",
      "Ep:98, loss:0.00000, loss_test:0.03123, lr:3.74e-02, fs:0.66667 (r=0.556,p=0.833),  time:35.266, tt:3491.359\n",
      "Ep:99, loss:0.00000, loss_test:0.03128, lr:3.70e-02, fs:0.69461 (r=0.586,p=0.853),  time:35.270, tt:3527.043\n",
      "Ep:100, loss:0.00000, loss_test:0.03189, lr:3.67e-02, fs:0.67485 (r=0.556,p=0.859),  time:35.281, tt:3563.340\n",
      "Ep:101, loss:0.00000, loss_test:0.03186, lr:3.63e-02, fs:0.69461 (r=0.586,p=0.853),  time:35.278, tt:3598.339\n",
      "Ep:102, loss:0.00000, loss_test:0.03217, lr:3.59e-02, fs:0.68293 (r=0.566,p=0.862),  time:35.281, tt:3633.900\n",
      "Ep:103, loss:0.00000, loss_test:0.03222, lr:3.56e-02, fs:0.68293 (r=0.566,p=0.862),  time:35.274, tt:3668.490\n",
      "Ep:104, loss:0.00000, loss_test:0.03242, lr:3.52e-02, fs:0.66667 (r=0.545,p=0.857),  time:35.286, tt:3704.999\n",
      "Ep:105, loss:0.00000, loss_test:0.03302, lr:3.49e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.288, tt:3740.519\n",
      "Ep:106, loss:0.00000, loss_test:0.03278, lr:3.45e-02, fs:0.67485 (r=0.556,p=0.859),  time:35.292, tt:3776.227\n",
      "Ep:107, loss:0.00000, loss_test:0.03328, lr:3.42e-02, fs:0.65409 (r=0.525,p=0.867),  time:35.288, tt:3811.145\n",
      "Ep:108, loss:0.00000, loss_test:0.03304, lr:3.38e-02, fs:0.66258 (r=0.545,p=0.844),  time:35.302, tt:3847.933\n",
      "Ep:109, loss:0.00000, loss_test:0.03362, lr:3.35e-02, fs:0.67081 (r=0.545,p=0.871),  time:35.333, tt:3886.644\n",
      "Ep:110, loss:0.00000, loss_test:0.03349, lr:3.32e-02, fs:0.67081 (r=0.545,p=0.871),  time:35.334, tt:3922.064\n",
      "Ep:111, loss:0.00000, loss_test:0.03401, lr:3.28e-02, fs:0.65409 (r=0.525,p=0.867),  time:35.330, tt:3956.990\n",
      "Ep:112, loss:0.00000, loss_test:0.03420, lr:3.25e-02, fs:0.66250 (r=0.535,p=0.869),  time:35.337, tt:3993.134\n",
      "Ep:113, loss:0.00000, loss_test:0.03404, lr:3.22e-02, fs:0.67081 (r=0.545,p=0.871),  time:35.338, tt:4028.541\n",
      "Ep:114, loss:0.00000, loss_test:0.03446, lr:3.19e-02, fs:0.64557 (r=0.515,p=0.864),  time:35.341, tt:4064.253\n",
      "Ep:115, loss:0.00000, loss_test:0.03433, lr:3.15e-02, fs:0.65409 (r=0.525,p=0.867),  time:35.345, tt:4099.990\n",
      "Ep:116, loss:0.00000, loss_test:0.03489, lr:3.12e-02, fs:0.66250 (r=0.535,p=0.869),  time:35.349, tt:4135.862\n",
      "Ep:117, loss:0.00000, loss_test:0.03453, lr:3.09e-02, fs:0.64557 (r=0.515,p=0.864),  time:35.344, tt:4170.578\n",
      "Ep:118, loss:0.00000, loss_test:0.03511, lr:3.06e-02, fs:0.64557 (r=0.515,p=0.864),  time:35.341, tt:4205.578\n",
      "Ep:119, loss:0.00000, loss_test:0.03495, lr:3.03e-02, fs:0.64557 (r=0.515,p=0.864),  time:35.347, tt:4241.690\n",
      "Ep:120, loss:0.00000, loss_test:0.03543, lr:3.00e-02, fs:0.63694 (r=0.505,p=0.862),  time:35.354, tt:4277.843\n",
      "Ep:121, loss:0.00000, loss_test:0.03498, lr:2.97e-02, fs:0.62821 (r=0.495,p=0.860),  time:35.356, tt:4313.487\n",
      "Ep:122, loss:0.00000, loss_test:0.03563, lr:2.94e-02, fs:0.63694 (r=0.505,p=0.862),  time:35.357, tt:4348.947\n",
      "Ep:123, loss:0.00000, loss_test:0.03547, lr:2.91e-02, fs:0.63694 (r=0.505,p=0.862),  time:35.353, tt:4383.807\n",
      "Ep:124, loss:0.00000, loss_test:0.03583, lr:2.88e-02, fs:0.62821 (r=0.495,p=0.860),  time:35.361, tt:4420.070\n",
      "Ep:125, loss:0.00000, loss_test:0.03545, lr:2.85e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.357, tt:4454.955\n",
      "Ep:126, loss:0.00000, loss_test:0.03594, lr:2.82e-02, fs:0.62821 (r=0.495,p=0.860),  time:35.356, tt:4490.239\n",
      "Ep:127, loss:0.00000, loss_test:0.03618, lr:2.80e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.351, tt:4524.903\n",
      "Ep:128, loss:0.00000, loss_test:0.03624, lr:2.77e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.353, tt:4560.481\n",
      "Ep:129, loss:0.00000, loss_test:0.03622, lr:2.74e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.353, tt:4595.936\n",
      "Ep:130, loss:0.00000, loss_test:0.03635, lr:2.71e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.349, tt:4630.684\n",
      "Ep:131, loss:0.00000, loss_test:0.03635, lr:2.69e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.352, tt:4666.419\n",
      "Ep:132, loss:0.00000, loss_test:0.03659, lr:2.66e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.347, tt:4701.201\n",
      "Ep:133, loss:0.00000, loss_test:0.03658, lr:2.63e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.352, tt:4737.148\n",
      "Ep:134, loss:0.00000, loss_test:0.03684, lr:2.61e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.345, tt:4771.599\n",
      "Ep:135, loss:0.00000, loss_test:0.03675, lr:2.58e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.345, tt:4806.890\n",
      "Ep:136, loss:0.00000, loss_test:0.03695, lr:2.55e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.345, tt:4842.214\n",
      "Ep:137, loss:0.00000, loss_test:0.03718, lr:2.53e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.343, tt:4877.375\n",
      "Ep:138, loss:0.00000, loss_test:0.03727, lr:2.50e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.333, tt:4911.292\n",
      "Ep:139, loss:0.00000, loss_test:0.03722, lr:2.48e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.327, tt:4945.741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:140, loss:0.00000, loss_test:0.03725, lr:2.45e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.330, tt:4981.560\n",
      "Ep:141, loss:0.00000, loss_test:0.03749, lr:2.43e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.335, tt:5017.540\n",
      "Ep:142, loss:0.00000, loss_test:0.03751, lr:2.40e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.341, tt:5053.789\n",
      "Ep:143, loss:0.00000, loss_test:0.03760, lr:2.38e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.351, tt:5090.558\n",
      "Ep:144, loss:0.00000, loss_test:0.03770, lr:2.36e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.348, tt:5125.506\n",
      "Ep:145, loss:0.00000, loss_test:0.03771, lr:2.33e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.345, tt:5160.424\n",
      "Ep:146, loss:0.00000, loss_test:0.03778, lr:2.31e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.348, tt:5196.095\n",
      "Ep:147, loss:0.00000, loss_test:0.03798, lr:2.29e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.353, tt:5232.230\n",
      "Ep:148, loss:0.00000, loss_test:0.03788, lr:2.26e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.356, tt:5267.998\n",
      "Ep:149, loss:0.00000, loss_test:0.03815, lr:2.24e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.356, tt:5303.370\n",
      "Ep:150, loss:0.00000, loss_test:0.03817, lr:2.22e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.348, tt:5337.551\n",
      "Ep:151, loss:0.00000, loss_test:0.03807, lr:2.20e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.358, tt:5374.367\n",
      "Ep:152, loss:0.00000, loss_test:0.03827, lr:2.17e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.353, tt:5409.064\n",
      "Ep:153, loss:0.00000, loss_test:0.03829, lr:2.15e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.347, tt:5443.394\n",
      "Ep:154, loss:0.00000, loss_test:0.03833, lr:2.13e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.351, tt:5479.333\n",
      "Ep:155, loss:0.00000, loss_test:0.03844, lr:2.11e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.346, tt:5514.001\n",
      "Ep:156, loss:0.00000, loss_test:0.03859, lr:2.09e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.346, tt:5549.316\n",
      "Ep:157, loss:0.00000, loss_test:0.03861, lr:2.07e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.334, tt:5582.712\n",
      "Ep:158, loss:0.00000, loss_test:0.03858, lr:2.05e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.333, tt:5618.023\n",
      "Ep:159, loss:0.00000, loss_test:0.03875, lr:2.03e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.320, tt:5651.263\n",
      "Ep:160, loss:0.00000, loss_test:0.03880, lr:2.01e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.314, tt:5685.564\n",
      "Ep:161, loss:0.00000, loss_test:0.03887, lr:1.99e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.314, tt:5720.927\n",
      "Ep:162, loss:0.00000, loss_test:0.03889, lr:1.97e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.303, tt:5754.448\n",
      "Ep:163, loss:0.00000, loss_test:0.03896, lr:1.95e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.296, tt:5788.559\n",
      "Ep:164, loss:0.00000, loss_test:0.03901, lr:1.93e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.285, tt:5822.080\n",
      "Ep:165, loss:0.00000, loss_test:0.03915, lr:1.91e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.277, tt:5855.945\n",
      "Ep:166, loss:0.00000, loss_test:0.03919, lr:1.89e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.265, tt:5889.318\n",
      "Ep:167, loss:0.00000, loss_test:0.03924, lr:1.87e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.256, tt:5922.943\n",
      "Ep:168, loss:0.00000, loss_test:0.03938, lr:1.85e-02, fs:0.62338 (r=0.485,p=0.873),  time:35.244, tt:5956.219\n",
      "Ep:169, loss:0.00000, loss_test:0.03939, lr:1.83e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.234, tt:5989.767\n",
      "Ep:170, loss:0.00000, loss_test:0.03953, lr:1.81e-02, fs:0.62338 (r=0.485,p=0.873),  time:35.227, tt:6023.743\n",
      "Ep:171, loss:0.00000, loss_test:0.03948, lr:1.80e-02, fs:0.62338 (r=0.485,p=0.873),  time:35.219, tt:6057.653\n",
      "Ep:172, loss:0.00000, loss_test:0.03953, lr:1.78e-02, fs:0.62338 (r=0.485,p=0.873),  time:35.220, tt:6093.016\n",
      "Ep:173, loss:0.00000, loss_test:0.03961, lr:1.76e-02, fs:0.62338 (r=0.485,p=0.873),  time:35.217, tt:6127.804\n",
      "Ep:174, loss:0.00000, loss_test:0.03962, lr:1.74e-02, fs:0.62338 (r=0.485,p=0.873),  time:35.202, tt:6160.363\n",
      "Ep:175, loss:0.00000, loss_test:0.03977, lr:1.73e-02, fs:0.62338 (r=0.485,p=0.873),  time:35.213, tt:6197.474\n",
      "Ep:176, loss:0.00000, loss_test:0.03974, lr:1.71e-02, fs:0.62338 (r=0.485,p=0.873),  time:35.204, tt:6231.086\n",
      "Ep:177, loss:0.00000, loss_test:0.03979, lr:1.69e-02, fs:0.62338 (r=0.485,p=0.873),  time:35.205, tt:6266.498\n",
      "Ep:178, loss:0.00000, loss_test:0.03985, lr:1.67e-02, fs:0.61438 (r=0.475,p=0.870),  time:35.204, tt:6301.526\n",
      "Ep:179, loss:0.00000, loss_test:0.03982, lr:1.66e-02, fs:0.61438 (r=0.475,p=0.870),  time:35.204, tt:6336.806\n",
      "Ep:180, loss:0.00000, loss_test:0.04000, lr:1.64e-02, fs:0.61438 (r=0.475,p=0.870),  time:35.198, tt:6370.803\n",
      "Ep:181, loss:0.00000, loss_test:0.04000, lr:1.62e-02, fs:0.61438 (r=0.475,p=0.870),  time:35.204, tt:6407.189\n",
      "Ep:182, loss:0.00000, loss_test:0.04007, lr:1.61e-02, fs:0.61438 (r=0.475,p=0.870),  time:35.204, tt:6442.375\n",
      "Ep:183, loss:0.00000, loss_test:0.03999, lr:1.59e-02, fs:0.61438 (r=0.475,p=0.870),  time:35.195, tt:6475.962\n",
      "Ep:184, loss:0.00000, loss_test:0.04005, lr:1.58e-02, fs:0.61438 (r=0.475,p=0.870),  time:35.196, tt:6511.276\n",
      "Ep:185, loss:0.00000, loss_test:0.04022, lr:1.56e-02, fs:0.60526 (r=0.465,p=0.868),  time:35.193, tt:6545.870\n",
      "Ep:186, loss:0.00000, loss_test:0.04033, lr:1.54e-02, fs:0.60526 (r=0.465,p=0.868),  time:35.198, tt:6581.964\n",
      "Ep:187, loss:0.00000, loss_test:0.04035, lr:1.53e-02, fs:0.60526 (r=0.465,p=0.868),  time:35.207, tt:6618.865\n",
      "Ep:188, loss:0.00000, loss_test:0.04025, lr:1.51e-02, fs:0.59603 (r=0.455,p=0.865),  time:35.214, tt:6655.534\n",
      "Ep:189, loss:0.00000, loss_test:0.04027, lr:1.50e-02, fs:0.60526 (r=0.465,p=0.868),  time:35.226, tt:6692.930\n",
      "Ep:190, loss:0.00000, loss_test:0.04041, lr:1.48e-02, fs:0.60526 (r=0.465,p=0.868),  time:35.235, tt:6729.799\n",
      "Ep:191, loss:0.00000, loss_test:0.04050, lr:1.47e-02, fs:0.60526 (r=0.465,p=0.868),  time:35.234, tt:6764.999\n",
      "Ep:192, loss:0.00000, loss_test:0.04049, lr:1.45e-02, fs:0.59603 (r=0.455,p=0.865),  time:35.233, tt:6799.916\n",
      "Ep:193, loss:0.00000, loss_test:0.04056, lr:1.44e-02, fs:0.60526 (r=0.465,p=0.868),  time:35.228, tt:6834.160\n",
      "Ep:194, loss:0.00000, loss_test:0.04058, lr:1.43e-02, fs:0.60526 (r=0.465,p=0.868),  time:35.226, tt:6869.119\n",
      "Ep:195, loss:0.00000, loss_test:0.04061, lr:1.41e-02, fs:0.60526 (r=0.465,p=0.868),  time:35.226, tt:6904.283\n",
      "Ep:196, loss:0.00000, loss_test:0.04067, lr:1.40e-02, fs:0.58667 (r=0.444,p=0.863),  time:35.219, tt:6938.140\n",
      "Ep:197, loss:0.00000, loss_test:0.04071, lr:1.38e-02, fs:0.59603 (r=0.455,p=0.865),  time:35.221, tt:6973.711\n",
      "Ep:198, loss:0.00000, loss_test:0.04072, lr:1.37e-02, fs:0.60526 (r=0.465,p=0.868),  time:35.212, tt:7007.234\n",
      "Ep:199, loss:0.00000, loss_test:0.04083, lr:1.36e-02, fs:0.60526 (r=0.465,p=0.868),  time:35.180, tt:7036.048\n",
      "Ep:200, loss:0.00000, loss_test:0.04082, lr:1.34e-02, fs:0.60526 (r=0.465,p=0.868),  time:35.148, tt:7064.777\n",
      "Ep:201, loss:0.00000, loss_test:0.04086, lr:1.33e-02, fs:0.57718 (r=0.434,p=0.860),  time:35.132, tt:7096.625\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13887, lr:1.00e-02, fs:0.67153 (r=0.929,p=0.526),  time:30.044, tt:30.044\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13723, lr:1.00e-02, fs:0.65201 (r=0.899,p=0.511),  time:30.946, tt:61.893\n",
      "Ep:2, loss:0.00027, loss_test:0.13617, lr:1.00e-02, fs:0.65693 (r=0.909,p=0.514),  time:32.496, tt:97.487\n",
      "Ep:3, loss:0.00027, loss_test:0.13554, lr:1.00e-02, fs:0.65942 (r=0.919,p=0.514),  time:33.265, tt:133.059\n",
      "Ep:4, loss:0.00027, loss_test:0.13523, lr:1.00e-02, fs:0.66182 (r=0.919,p=0.517),  time:34.007, tt:170.034\n",
      "Ep:5, loss:0.00026, loss_test:0.13478, lr:1.00e-02, fs:0.66182 (r=0.919,p=0.517),  time:34.211, tt:205.265\n",
      "Ep:6, loss:0.00026, loss_test:0.13405, lr:1.00e-02, fs:0.66176 (r=0.909,p=0.520),  time:34.436, tt:241.049\n",
      "Ep:7, loss:0.00026, loss_test:0.13299, lr:1.00e-02, fs:0.66418 (r=0.899,p=0.527),  time:34.485, tt:275.884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:8, loss:0.00026, loss_test:0.13175, lr:1.00e-02, fs:0.67170 (r=0.899,p=0.536),  time:34.487, tt:310.379\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00026, loss_test:0.13083, lr:1.00e-02, fs:0.67939 (r=0.899,p=0.546),  time:34.520, tt:345.204\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00025, loss_test:0.12998, lr:1.00e-02, fs:0.68199 (r=0.899,p=0.549),  time:34.656, tt:381.214\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00025, loss_test:0.12952, lr:1.00e-02, fs:0.68199 (r=0.899,p=0.549),  time:34.740, tt:416.885\n",
      "Ep:12, loss:0.00025, loss_test:0.12903, lr:1.00e-02, fs:0.68462 (r=0.899,p=0.553),  time:34.743, tt:451.655\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00025, loss_test:0.12858, lr:1.00e-02, fs:0.68726 (r=0.899,p=0.556),  time:35.038, tt:490.528\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00025, loss_test:0.12799, lr:1.00e-02, fs:0.68462 (r=0.899,p=0.553),  time:35.025, tt:525.380\n",
      "Ep:15, loss:0.00025, loss_test:0.12723, lr:1.00e-02, fs:0.68462 (r=0.899,p=0.553),  time:35.089, tt:561.431\n",
      "Ep:16, loss:0.00024, loss_test:0.12625, lr:1.00e-02, fs:0.68462 (r=0.899,p=0.553),  time:35.037, tt:595.634\n",
      "Ep:17, loss:0.00024, loss_test:0.12508, lr:1.00e-02, fs:0.68462 (r=0.899,p=0.553),  time:35.062, tt:631.109\n",
      "Ep:18, loss:0.00024, loss_test:0.12412, lr:1.00e-02, fs:0.68726 (r=0.899,p=0.556),  time:35.049, tt:665.934\n",
      "Ep:19, loss:0.00024, loss_test:0.12325, lr:1.00e-02, fs:0.68217 (r=0.889,p=0.553),  time:35.122, tt:702.437\n",
      "Ep:20, loss:0.00023, loss_test:0.12238, lr:1.00e-02, fs:0.68482 (r=0.889,p=0.557),  time:35.101, tt:737.131\n",
      "Ep:21, loss:0.00023, loss_test:0.12114, lr:1.00e-02, fs:0.68750 (r=0.889,p=0.561),  time:35.099, tt:772.187\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00023, loss_test:0.11966, lr:1.00e-02, fs:0.69020 (r=0.889,p=0.564),  time:35.122, tt:807.799\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00022, loss_test:0.11789, lr:1.00e-02, fs:0.69565 (r=0.889,p=0.571),  time:35.165, tt:843.971\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00022, loss_test:0.11654, lr:1.00e-02, fs:0.69841 (r=0.889,p=0.575),  time:35.139, tt:878.476\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00021, loss_test:0.11529, lr:1.00e-02, fs:0.69323 (r=0.879,p=0.572),  time:35.155, tt:914.040\n",
      "Ep:26, loss:0.00021, loss_test:0.11335, lr:1.00e-02, fs:0.70161 (r=0.879,p=0.584),  time:35.246, tt:951.638\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00020, loss_test:0.11178, lr:1.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:35.218, tt:986.102\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00020, loss_test:0.11092, lr:1.00e-02, fs:0.69421 (r=0.848,p=0.587),  time:35.196, tt:1020.674\n",
      "Ep:29, loss:0.00019, loss_test:0.11069, lr:1.00e-02, fs:0.68880 (r=0.838,p=0.585),  time:35.216, tt:1056.494\n",
      "Ep:30, loss:0.00018, loss_test:0.10918, lr:1.00e-02, fs:0.68103 (r=0.798,p=0.594),  time:35.209, tt:1091.479\n",
      "Ep:31, loss:0.00018, loss_test:0.10946, lr:1.00e-02, fs:0.68670 (r=0.808,p=0.597),  time:35.221, tt:1127.072\n",
      "Ep:32, loss:0.00017, loss_test:0.11012, lr:1.00e-02, fs:0.68966 (r=0.808,p=0.602),  time:35.228, tt:1162.515\n",
      "Ep:33, loss:0.00017, loss_test:0.10860, lr:1.00e-02, fs:0.68421 (r=0.788,p=0.605),  time:35.193, tt:1196.562\n",
      "Ep:34, loss:0.00016, loss_test:0.11120, lr:1.00e-02, fs:0.68936 (r=0.818,p=0.596),  time:35.243, tt:1233.499\n",
      "Ep:35, loss:0.00015, loss_test:0.11059, lr:1.00e-02, fs:0.68444 (r=0.778,p=0.611),  time:35.263, tt:1269.464\n",
      "Ep:36, loss:0.00014, loss_test:0.11272, lr:1.00e-02, fs:0.67857 (r=0.768,p=0.608),  time:35.290, tt:1305.744\n",
      "Ep:37, loss:0.00014, loss_test:0.11227, lr:1.00e-02, fs:0.67580 (r=0.747,p=0.617),  time:35.310, tt:1341.777\n",
      "Ep:38, loss:0.00013, loss_test:0.11179, lr:1.00e-02, fs:0.69725 (r=0.768,p=0.639),  time:35.302, tt:1376.786\n",
      "Ep:39, loss:0.00012, loss_test:0.10959, lr:9.90e-03, fs:0.69767 (r=0.758,p=0.647),  time:35.300, tt:1412.008\n",
      "Ep:40, loss:0.00012, loss_test:0.10746, lr:9.80e-03, fs:0.70476 (r=0.747,p=0.667),  time:35.307, tt:1447.567\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00011, loss_test:0.10910, lr:9.80e-03, fs:0.70874 (r=0.737,p=0.682),  time:35.345, tt:1484.474\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00010, loss_test:0.11221, lr:9.80e-03, fs:0.67021 (r=0.636,p=0.708),  time:35.364, tt:1520.642\n",
      "Ep:43, loss:0.00009, loss_test:0.11147, lr:9.80e-03, fs:0.68478 (r=0.636,p=0.741),  time:35.346, tt:1555.221\n",
      "Ep:44, loss:0.00009, loss_test:0.10728, lr:9.80e-03, fs:0.72165 (r=0.707,p=0.737),  time:35.321, tt:1589.462\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00008, loss_test:0.10696, lr:9.80e-03, fs:0.75532 (r=0.717,p=0.798),  time:35.312, tt:1624.330\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00008, loss_test:0.11365, lr:9.80e-03, fs:0.71038 (r=0.657,p=0.774),  time:35.308, tt:1659.472\n",
      "Ep:47, loss:0.00007, loss_test:0.10358, lr:9.80e-03, fs:0.74112 (r=0.737,p=0.745),  time:35.347, tt:1696.655\n",
      "Ep:48, loss:0.00007, loss_test:0.09933, lr:9.80e-03, fs:0.78307 (r=0.747,p=0.822),  time:35.371, tt:1733.202\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00007, loss_test:0.10894, lr:9.80e-03, fs:0.73118 (r=0.687,p=0.782),  time:35.380, tt:1768.999\n",
      "Ep:50, loss:0.00006, loss_test:0.10224, lr:9.80e-03, fs:0.75676 (r=0.707,p=0.814),  time:35.362, tt:1803.469\n",
      "Ep:51, loss:0.00006, loss_test:0.09808, lr:9.80e-03, fs:0.78756 (r=0.768,p=0.809),  time:35.339, tt:1837.614\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00005, loss_test:0.10432, lr:9.80e-03, fs:0.74033 (r=0.677,p=0.817),  time:35.336, tt:1872.810\n",
      "Ep:53, loss:0.00005, loss_test:0.10004, lr:9.80e-03, fs:0.81675 (r=0.788,p=0.848),  time:35.331, tt:1907.899\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00005, loss_test:0.09567, lr:9.80e-03, fs:0.80435 (r=0.747,p=0.871),  time:35.337, tt:1943.546\n",
      "Ep:55, loss:0.00005, loss_test:0.09458, lr:9.80e-03, fs:0.82796 (r=0.778,p=0.885),  time:35.303, tt:1976.953\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00004, loss_test:0.10386, lr:9.80e-03, fs:0.71429 (r=0.606,p=0.870),  time:35.312, tt:2012.810\n",
      "Ep:57, loss:0.00004, loss_test:0.09558, lr:9.80e-03, fs:0.82796 (r=0.778,p=0.885),  time:35.295, tt:2047.112\n",
      "Ep:58, loss:0.00004, loss_test:0.10109, lr:9.80e-03, fs:0.73684 (r=0.636,p=0.875),  time:35.293, tt:2082.311\n",
      "Ep:59, loss:0.00004, loss_test:0.10212, lr:9.80e-03, fs:0.73988 (r=0.646,p=0.865),  time:35.262, tt:2115.704\n",
      "Ep:60, loss:0.00003, loss_test:0.09829, lr:9.80e-03, fs:0.70659 (r=0.596,p=0.868),  time:35.256, tt:2150.612\n",
      "Ep:61, loss:0.00003, loss_test:0.09480, lr:9.80e-03, fs:0.77966 (r=0.697,p=0.885),  time:35.227, tt:2184.053\n",
      "Ep:62, loss:0.00003, loss_test:0.11205, lr:9.80e-03, fs:0.66258 (r=0.545,p=0.844),  time:35.210, tt:2218.219\n",
      "Ep:63, loss:0.00003, loss_test:0.10035, lr:9.80e-03, fs:0.74419 (r=0.646,p=0.877),  time:35.227, tt:2254.525\n",
      "Ep:64, loss:0.00003, loss_test:0.10265, lr:9.80e-03, fs:0.72189 (r=0.616,p=0.871),  time:35.219, tt:2289.257\n",
      "Ep:65, loss:0.00003, loss_test:0.10393, lr:9.80e-03, fs:0.73988 (r=0.646,p=0.865),  time:35.221, tt:2324.588\n",
      "Ep:66, loss:0.00002, loss_test:0.10358, lr:9.80e-03, fs:0.70659 (r=0.596,p=0.868),  time:35.220, tt:2359.736\n",
      "Ep:67, loss:0.00002, loss_test:0.10253, lr:9.70e-03, fs:0.71429 (r=0.606,p=0.870),  time:35.234, tt:2395.937\n",
      "Ep:68, loss:0.00002, loss_test:0.11443, lr:9.61e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.253, tt:2432.442\n",
      "Ep:69, loss:0.00002, loss_test:0.10278, lr:9.51e-03, fs:0.73988 (r=0.646,p=0.865),  time:35.247, tt:2467.321\n",
      "Ep:70, loss:0.00002, loss_test:0.10634, lr:9.41e-03, fs:0.72189 (r=0.616,p=0.871),  time:35.255, tt:2503.121\n",
      "Ep:71, loss:0.00002, loss_test:0.10854, lr:9.32e-03, fs:0.69091 (r=0.576,p=0.864),  time:35.281, tt:2540.259\n",
      "Ep:72, loss:0.00002, loss_test:0.10581, lr:9.23e-03, fs:0.72189 (r=0.616,p=0.871),  time:35.271, tt:2574.758\n",
      "Ep:73, loss:0.00002, loss_test:0.10660, lr:9.14e-03, fs:0.71765 (r=0.616,p=0.859),  time:35.266, tt:2609.654\n",
      "Ep:74, loss:0.00002, loss_test:0.10590, lr:9.04e-03, fs:0.71765 (r=0.616,p=0.859),  time:35.280, tt:2645.967\n",
      "Ep:75, loss:0.00002, loss_test:0.11070, lr:8.95e-03, fs:0.70238 (r=0.596,p=0.855),  time:35.285, tt:2681.670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:76, loss:0.00001, loss_test:0.10521, lr:8.86e-03, fs:0.71765 (r=0.616,p=0.859),  time:35.275, tt:2716.177\n",
      "Ep:77, loss:0.00001, loss_test:0.11026, lr:8.78e-03, fs:0.71765 (r=0.616,p=0.859),  time:35.260, tt:2750.280\n",
      "Ep:78, loss:0.00001, loss_test:0.10984, lr:8.69e-03, fs:0.71765 (r=0.616,p=0.859),  time:35.251, tt:2784.793\n",
      "Ep:79, loss:0.00001, loss_test:0.11279, lr:8.60e-03, fs:0.71006 (r=0.606,p=0.857),  time:35.252, tt:2820.137\n",
      "Ep:80, loss:0.00001, loss_test:0.10998, lr:8.51e-03, fs:0.71765 (r=0.616,p=0.859),  time:35.257, tt:2855.777\n",
      "Ep:81, loss:0.00001, loss_test:0.11305, lr:8.43e-03, fs:0.71765 (r=0.616,p=0.859),  time:35.254, tt:2890.839\n",
      "Ep:82, loss:0.00001, loss_test:0.11449, lr:8.35e-03, fs:0.71006 (r=0.606,p=0.857),  time:35.249, tt:2925.636\n",
      "Ep:83, loss:0.00001, loss_test:0.11140, lr:8.26e-03, fs:0.71765 (r=0.616,p=0.859),  time:35.240, tt:2960.128\n",
      "Ep:84, loss:0.00001, loss_test:0.11754, lr:8.18e-03, fs:0.71429 (r=0.606,p=0.870),  time:35.231, tt:2994.631\n",
      "Ep:85, loss:0.00001, loss_test:0.11327, lr:8.10e-03, fs:0.71765 (r=0.616,p=0.859),  time:35.245, tt:3031.052\n",
      "Ep:86, loss:0.00001, loss_test:0.11180, lr:8.02e-03, fs:0.71765 (r=0.616,p=0.859),  time:35.270, tt:3068.486\n",
      "Ep:87, loss:0.00001, loss_test:0.11832, lr:7.94e-03, fs:0.66667 (r=0.545,p=0.857),  time:35.261, tt:3102.956\n",
      "Ep:88, loss:0.00001, loss_test:0.11338, lr:7.86e-03, fs:0.72189 (r=0.616,p=0.871),  time:35.270, tt:3138.988\n",
      "Ep:89, loss:0.00001, loss_test:0.11709, lr:7.78e-03, fs:0.68675 (r=0.576,p=0.851),  time:35.285, tt:3175.685\n",
      "Ep:90, loss:0.00001, loss_test:0.11234, lr:7.70e-03, fs:0.72189 (r=0.616,p=0.871),  time:35.315, tt:3213.620\n",
      "Ep:91, loss:0.00001, loss_test:0.11403, lr:7.62e-03, fs:0.72189 (r=0.616,p=0.871),  time:35.335, tt:3250.803\n",
      "Ep:92, loss:0.00001, loss_test:0.11740, lr:7.55e-03, fs:0.72189 (r=0.616,p=0.871),  time:35.381, tt:3290.462\n",
      "Ep:93, loss:0.00001, loss_test:0.11208, lr:7.47e-03, fs:0.71765 (r=0.616,p=0.859),  time:35.408, tt:3328.389\n",
      "Ep:94, loss:0.00001, loss_test:0.11747, lr:7.40e-03, fs:0.68293 (r=0.566,p=0.862),  time:35.415, tt:3364.462\n",
      "Ep:95, loss:0.00001, loss_test:0.11216, lr:7.32e-03, fs:0.71765 (r=0.616,p=0.859),  time:35.424, tt:3400.697\n",
      "Ep:96, loss:0.00001, loss_test:0.11748, lr:7.25e-03, fs:0.67879 (r=0.566,p=0.848),  time:35.423, tt:3436.080\n",
      "Ep:97, loss:0.00001, loss_test:0.11775, lr:7.18e-03, fs:0.71006 (r=0.606,p=0.857),  time:35.427, tt:3471.835\n",
      "Ep:98, loss:0.00001, loss_test:0.11502, lr:7.11e-03, fs:0.71345 (r=0.616,p=0.847),  time:35.453, tt:3509.869\n",
      "Ep:99, loss:0.00001, loss_test:0.11779, lr:7.03e-03, fs:0.71006 (r=0.606,p=0.857),  time:35.495, tt:3549.516\n",
      "Ep:100, loss:0.00001, loss_test:0.11614, lr:6.96e-03, fs:0.71345 (r=0.616,p=0.847),  time:35.530, tt:3588.511\n",
      "Ep:101, loss:0.00001, loss_test:0.11616, lr:6.89e-03, fs:0.71765 (r=0.616,p=0.859),  time:35.541, tt:3625.138\n",
      "Ep:102, loss:0.00001, loss_test:0.11973, lr:6.83e-03, fs:0.67081 (r=0.545,p=0.871),  time:35.552, tt:3661.882\n",
      "Ep:103, loss:0.00001, loss_test:0.11513, lr:6.76e-03, fs:0.71765 (r=0.616,p=0.859),  time:35.586, tt:3700.995\n",
      "Ep:104, loss:0.00001, loss_test:0.11802, lr:6.69e-03, fs:0.69091 (r=0.576,p=0.864),  time:35.606, tt:3738.656\n",
      "Ep:105, loss:0.00001, loss_test:0.11771, lr:6.62e-03, fs:0.71429 (r=0.606,p=0.870),  time:35.624, tt:3776.113\n",
      "Ep:106, loss:0.00001, loss_test:0.12125, lr:6.56e-03, fs:0.67879 (r=0.566,p=0.848),  time:35.623, tt:3811.691\n",
      "Ep:107, loss:0.00001, loss_test:0.11725, lr:6.49e-03, fs:0.72189 (r=0.616,p=0.871),  time:35.624, tt:3847.429\n",
      "Ep:108, loss:0.00001, loss_test:0.11875, lr:6.43e-03, fs:0.66258 (r=0.545,p=0.844),  time:35.622, tt:3882.815\n",
      "Ep:109, loss:0.00001, loss_test:0.11415, lr:6.36e-03, fs:0.71345 (r=0.616,p=0.847),  time:35.624, tt:3918.591\n",
      "Ep:110, loss:0.00001, loss_test:0.12068, lr:6.30e-03, fs:0.66667 (r=0.545,p=0.857),  time:35.621, tt:3953.933\n",
      "Ep:111, loss:0.00001, loss_test:0.11773, lr:6.24e-03, fs:0.69091 (r=0.576,p=0.864),  time:35.624, tt:3989.924\n",
      "Ep:112, loss:0.00001, loss_test:0.11964, lr:6.17e-03, fs:0.67485 (r=0.556,p=0.859),  time:35.621, tt:4025.191\n",
      "Ep:113, loss:0.00001, loss_test:0.11843, lr:6.11e-03, fs:0.66258 (r=0.545,p=0.844),  time:35.614, tt:4059.968\n",
      "Ep:114, loss:0.00001, loss_test:0.11784, lr:6.05e-03, fs:0.66667 (r=0.545,p=0.857),  time:35.620, tt:4096.258\n",
      "Ep:115, loss:0.00001, loss_test:0.11807, lr:5.99e-03, fs:0.66258 (r=0.545,p=0.844),  time:35.626, tt:4132.671\n",
      "Ep:116, loss:0.00001, loss_test:0.11917, lr:5.93e-03, fs:0.66258 (r=0.545,p=0.844),  time:35.615, tt:4166.934\n",
      "Ep:117, loss:0.00001, loss_test:0.11995, lr:5.87e-03, fs:0.66667 (r=0.545,p=0.857),  time:35.614, tt:4202.505\n",
      "Ep:118, loss:0.00001, loss_test:0.11878, lr:5.81e-03, fs:0.67073 (r=0.556,p=0.846),  time:35.617, tt:4238.403\n",
      "Ep:119, loss:0.00001, loss_test:0.12025, lr:5.75e-03, fs:0.66258 (r=0.545,p=0.844),  time:35.616, tt:4273.895\n",
      "Ep:120, loss:0.00001, loss_test:0.11813, lr:5.70e-03, fs:0.66258 (r=0.545,p=0.844),  time:35.609, tt:4308.664\n",
      "Ep:121, loss:0.00001, loss_test:0.11912, lr:5.64e-03, fs:0.66258 (r=0.545,p=0.844),  time:35.617, tt:4345.234\n",
      "Ep:122, loss:0.00000, loss_test:0.12017, lr:5.58e-03, fs:0.66667 (r=0.545,p=0.857),  time:35.627, tt:4382.118\n",
      "Ep:123, loss:0.00000, loss_test:0.12003, lr:5.53e-03, fs:0.66258 (r=0.545,p=0.844),  time:35.624, tt:4417.349\n",
      "Ep:124, loss:0.00000, loss_test:0.11893, lr:5.47e-03, fs:0.66258 (r=0.545,p=0.844),  time:35.628, tt:4453.543\n",
      "Ep:125, loss:0.00000, loss_test:0.12013, lr:5.42e-03, fs:0.66258 (r=0.545,p=0.844),  time:35.633, tt:4489.766\n",
      "Ep:126, loss:0.00000, loss_test:0.11988, lr:5.36e-03, fs:0.66667 (r=0.545,p=0.857),  time:35.637, tt:4525.888\n",
      "Ep:127, loss:0.00000, loss_test:0.12103, lr:5.31e-03, fs:0.66667 (r=0.545,p=0.857),  time:35.634, tt:4561.096\n",
      "Ep:128, loss:0.00000, loss_test:0.12156, lr:5.26e-03, fs:0.66258 (r=0.545,p=0.844),  time:35.639, tt:4597.407\n",
      "Ep:129, loss:0.00000, loss_test:0.12065, lr:5.20e-03, fs:0.66667 (r=0.545,p=0.857),  time:35.636, tt:4632.639\n",
      "Ep:130, loss:0.00000, loss_test:0.12021, lr:5.15e-03, fs:0.66258 (r=0.545,p=0.844),  time:35.646, tt:4669.629\n",
      "Ep:131, loss:0.00000, loss_test:0.12159, lr:5.10e-03, fs:0.65839 (r=0.535,p=0.855),  time:35.647, tt:4705.391\n",
      "Ep:132, loss:0.00000, loss_test:0.11954, lr:5.05e-03, fs:0.66667 (r=0.545,p=0.857),  time:35.675, tt:4744.820\n",
      "Ep:133, loss:0.00000, loss_test:0.12275, lr:5.00e-03, fs:0.66667 (r=0.545,p=0.857),  time:35.687, tt:4782.123\n",
      "Ep:134, loss:0.00000, loss_test:0.12208, lr:4.95e-03, fs:0.66667 (r=0.545,p=0.857),  time:35.696, tt:4818.895\n",
      "Ep:135, loss:0.00000, loss_test:0.12293, lr:4.90e-03, fs:0.65839 (r=0.535,p=0.855),  time:35.704, tt:4855.808\n",
      "Ep:136, loss:0.00000, loss_test:0.12092, lr:4.85e-03, fs:0.65839 (r=0.535,p=0.855),  time:35.711, tt:4892.437\n",
      "Ep:137, loss:0.00000, loss_test:0.12176, lr:4.80e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.728, tt:4930.433\n",
      "Ep:138, loss:0.00000, loss_test:0.12368, lr:4.75e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.743, tt:4968.316\n",
      "Ep:139, loss:0.00000, loss_test:0.12011, lr:4.71e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.737, tt:5003.152\n",
      "Ep:140, loss:0.00000, loss_test:0.12262, lr:4.66e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.738, tt:5039.006\n",
      "Ep:141, loss:0.00000, loss_test:0.12135, lr:4.61e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.727, tt:5073.272\n",
      "Ep:142, loss:0.00000, loss_test:0.12221, lr:4.57e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.726, tt:5108.800\n",
      "Ep:143, loss:0.00000, loss_test:0.12377, lr:4.52e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.728, tt:5144.814\n",
      "Ep:144, loss:0.00000, loss_test:0.12100, lr:4.48e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.728, tt:5180.569\n",
      "Ep:145, loss:0.00000, loss_test:0.12180, lr:4.43e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.723, tt:5215.496\n",
      "Ep:146, loss:0.00000, loss_test:0.12510, lr:4.39e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.717, tt:5250.397\n",
      "Ep:147, loss:0.00000, loss_test:0.12187, lr:4.34e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.716, tt:5285.901\n",
      "Ep:148, loss:0.00000, loss_test:0.12354, lr:4.30e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.703, tt:5319.680\n",
      "Ep:149, loss:0.00000, loss_test:0.12124, lr:4.26e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.699, tt:5354.900\n",
      "Ep:152, loss:0.00000, loss_test:0.12300, lr:4.13e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.691, tt:5460.699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:153, loss:0.00000, loss_test:0.12366, lr:4.09e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.689, tt:5496.121\n",
      "Ep:154, loss:0.00000, loss_test:0.12239, lr:4.05e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.683, tt:5530.869\n",
      "Ep:155, loss:0.00000, loss_test:0.12230, lr:4.01e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.680, tt:5566.108\n",
      "Ep:156, loss:0.00000, loss_test:0.12479, lr:3.97e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.682, tt:5602.144\n",
      "Ep:157, loss:0.00000, loss_test:0.12205, lr:3.93e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.678, tt:5637.095\n",
      "Ep:158, loss:0.00000, loss_test:0.12383, lr:3.89e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.673, tt:5671.979\n",
      "Ep:159, loss:0.00000, loss_test:0.12360, lr:3.85e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.670, tt:5707.147\n",
      "Ep:160, loss:0.00000, loss_test:0.12247, lr:3.81e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.674, tt:5743.478\n",
      "Ep:161, loss:0.00000, loss_test:0.12397, lr:3.77e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.672, tt:5778.870\n",
      "Ep:162, loss:0.00000, loss_test:0.12190, lr:3.73e-03, fs:0.66667 (r=0.545,p=0.857),  time:35.664, tt:5813.210\n",
      "Ep:163, loss:0.00000, loss_test:0.12353, lr:3.70e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.648, tt:5846.237\n",
      "Ep:164, loss:0.00000, loss_test:0.12280, lr:3.66e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.649, tt:5882.136\n",
      "Ep:165, loss:0.00000, loss_test:0.12547, lr:3.62e-03, fs:0.63291 (r=0.505,p=0.847),  time:35.650, tt:5917.950\n",
      "Ep:166, loss:0.00000, loss_test:0.12588, lr:3.59e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.646, tt:5952.927\n",
      "Ep:167, loss:0.00000, loss_test:0.12230, lr:3.55e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.637, tt:5987.065\n",
      "Ep:168, loss:0.00000, loss_test:0.12327, lr:3.52e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.632, tt:6021.871\n",
      "Ep:169, loss:0.00000, loss_test:0.12346, lr:3.48e-03, fs:0.65839 (r=0.535,p=0.855),  time:35.628, tt:6056.761\n",
      "Ep:170, loss:0.00000, loss_test:0.12168, lr:3.45e-03, fs:0.63291 (r=0.505,p=0.847),  time:35.623, tt:6091.576\n",
      "Ep:171, loss:0.00000, loss_test:0.12318, lr:3.41e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.623, tt:6127.078\n",
      "Ep:172, loss:0.00000, loss_test:0.12335, lr:3.38e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.624, tt:6163.015\n",
      "Ep:173, loss:0.00000, loss_test:0.12210, lr:3.34e-03, fs:0.64151 (r=0.515,p=0.850),  time:35.633, tt:6200.116\n",
      "Ep:174, loss:0.00000, loss_test:0.12269, lr:3.31e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.642, tt:6237.416\n",
      "Ep:175, loss:0.00000, loss_test:0.12363, lr:3.28e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.640, tt:6272.568\n",
      "Ep:176, loss:0.00000, loss_test:0.12162, lr:3.24e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.651, tt:6310.272\n",
      "Ep:177, loss:0.00000, loss_test:0.12325, lr:3.21e-03, fs:0.65839 (r=0.535,p=0.855),  time:35.649, tt:6345.508\n",
      "Ep:178, loss:0.00000, loss_test:0.12465, lr:3.18e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.649, tt:6381.174\n",
      "Ep:179, loss:0.00000, loss_test:0.12290, lr:3.15e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.649, tt:6416.774\n",
      "Ep:180, loss:0.00000, loss_test:0.12420, lr:3.12e-03, fs:0.63291 (r=0.505,p=0.847),  time:35.671, tt:6456.412\n",
      "Ep:181, loss:0.00000, loss_test:0.12368, lr:3.09e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.665, tt:6490.965\n",
      "Ep:182, loss:0.00000, loss_test:0.12158, lr:3.05e-03, fs:0.65839 (r=0.535,p=0.855),  time:35.674, tt:6528.289\n",
      "Ep:183, loss:0.00000, loss_test:0.12416, lr:3.02e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.677, tt:6564.591\n",
      "Ep:184, loss:0.00000, loss_test:0.12303, lr:2.99e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.671, tt:6599.135\n",
      "Ep:185, loss:0.00000, loss_test:0.12307, lr:2.96e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.669, tt:6634.472\n",
      "Ep:186, loss:0.00000, loss_test:0.12453, lr:2.93e-03, fs:0.64151 (r=0.515,p=0.850),  time:35.666, tt:6669.546\n",
      "Ep:187, loss:0.00000, loss_test:0.12266, lr:2.90e-03, fs:0.65839 (r=0.535,p=0.855),  time:35.671, tt:6706.203\n",
      "Ep:188, loss:0.00000, loss_test:0.12290, lr:2.88e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.670, tt:6741.718\n",
      "Ep:189, loss:0.00000, loss_test:0.12332, lr:2.85e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.673, tt:6777.827\n",
      "Ep:190, loss:0.00000, loss_test:0.12332, lr:2.82e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.668, tt:6812.631\n",
      "Ep:191, loss:0.00000, loss_test:0.12430, lr:2.79e-03, fs:0.64151 (r=0.515,p=0.850),  time:35.669, tt:6848.479\n",
      "Ep:192, loss:0.00000, loss_test:0.12522, lr:2.76e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.668, tt:6883.844\n",
      "Ep:193, loss:0.00000, loss_test:0.12431, lr:2.73e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.671, tt:6920.240\n",
      "Ep:194, loss:0.00000, loss_test:0.12262, lr:2.71e-03, fs:0.65839 (r=0.535,p=0.855),  time:35.665, tt:6954.636\n",
      "Ep:195, loss:0.00000, loss_test:0.12340, lr:2.68e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.667, tt:6990.681\n",
      "Ep:196, loss:0.00000, loss_test:0.12387, lr:2.65e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.659, tt:7024.893\n",
      "Ep:197, loss:0.00000, loss_test:0.12340, lr:2.63e-03, fs:0.64151 (r=0.515,p=0.850),  time:35.660, tt:7060.653\n",
      "Ep:198, loss:0.00000, loss_test:0.12344, lr:2.60e-03, fs:0.64151 (r=0.515,p=0.850),  time:35.642, tt:7092.665\n",
      "Ep:199, loss:0.00000, loss_test:0.12382, lr:2.57e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.614, tt:7122.771\n",
      "Ep:200, loss:0.00000, loss_test:0.12286, lr:2.55e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.571, tt:7149.782\n",
      "Ep:201, loss:0.00000, loss_test:0.12355, lr:2.52e-03, fs:0.65000 (r=0.525,p=0.852),  time:35.542, tt:7179.543\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00012, loss_test:0.02568, lr:6.00e-02, fs:0.64103 (r=0.758,p=0.556),  time:26.175, tt:26.175\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02513, lr:6.00e-02, fs:0.66667 (r=0.960,p=0.511),  time:25.388, tt:50.775\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02759, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.329, tt:81.987\n",
      "Ep:3, loss:0.00005, loss_test:0.02767, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.096, tt:112.385\n",
      "Ep:4, loss:0.00005, loss_test:0.02666, lr:6.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:28.568, tt:142.841\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00005, loss_test:0.02564, lr:6.00e-02, fs:0.68070 (r=0.980,p=0.522),  time:28.696, tt:172.176\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00005, loss_test:0.02507, lr:6.00e-02, fs:0.66165 (r=0.889,p=0.527),  time:29.087, tt:203.606\n",
      "Ep:7, loss:0.00005, loss_test:0.02478, lr:6.00e-02, fs:0.66667 (r=0.889,p=0.533),  time:29.245, tt:233.956\n",
      "Ep:8, loss:0.00005, loss_test:0.02436, lr:6.00e-02, fs:0.66415 (r=0.889,p=0.530),  time:29.331, tt:263.975\n",
      "Ep:9, loss:0.00005, loss_test:0.02396, lr:6.00e-02, fs:0.66914 (r=0.909,p=0.529),  time:29.465, tt:294.646\n",
      "Ep:10, loss:0.00005, loss_test:0.02354, lr:6.00e-02, fs:0.68817 (r=0.970,p=0.533),  time:29.611, tt:325.723\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00005, loss_test:0.02297, lr:6.00e-02, fs:0.69286 (r=0.980,p=0.536),  time:29.612, tt:355.346\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.02220, lr:6.00e-02, fs:0.68864 (r=0.949,p=0.540),  time:29.649, tt:385.435\n",
      "Ep:13, loss:0.00004, loss_test:0.02154, lr:6.00e-02, fs:0.69434 (r=0.929,p=0.554),  time:29.804, tt:417.250\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.02108, lr:6.00e-02, fs:0.68702 (r=0.909,p=0.552),  time:29.768, tt:446.518\n",
      "Ep:15, loss:0.00004, loss_test:0.02083, lr:6.00e-02, fs:0.69767 (r=0.909,p=0.566),  time:29.735, tt:475.757\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:16, loss:0.00004, loss_test:0.02070, lr:6.00e-02, fs:0.67954 (r=0.889,p=0.550),  time:29.735, tt:505.502\n",
      "Ep:17, loss:0.00004, loss_test:0.02065, lr:6.00e-02, fs:0.67176 (r=0.889,p=0.540),  time:29.771, tt:535.878\n",
      "Ep:18, loss:0.00004, loss_test:0.02052, lr:6.00e-02, fs:0.67939 (r=0.899,p=0.546),  time:29.772, tt:565.665\n",
      "Ep:19, loss:0.00004, loss_test:0.02039, lr:6.00e-02, fs:0.67939 (r=0.899,p=0.546),  time:29.811, tt:596.219\n",
      "Ep:20, loss:0.00004, loss_test:0.02028, lr:6.00e-02, fs:0.68199 (r=0.899,p=0.549),  time:29.808, tt:625.963\n",
      "Ep:21, loss:0.00004, loss_test:0.02013, lr:6.00e-02, fs:0.67433 (r=0.889,p=0.543),  time:29.803, tt:655.666\n",
      "Ep:22, loss:0.00004, loss_test:0.02001, lr:6.00e-02, fs:0.68702 (r=0.909,p=0.552),  time:29.790, tt:685.170\n",
      "Ep:23, loss:0.00004, loss_test:0.01987, lr:6.00e-02, fs:0.69466 (r=0.919,p=0.558),  time:29.800, tt:715.207\n",
      "Ep:24, loss:0.00004, loss_test:0.01970, lr:6.00e-02, fs:0.69732 (r=0.919,p=0.562),  time:29.793, tt:744.814\n",
      "Ep:25, loss:0.00004, loss_test:0.01955, lr:6.00e-02, fs:0.70270 (r=0.919,p=0.569),  time:29.779, tt:774.266\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00004, loss_test:0.01943, lr:6.00e-02, fs:0.70039 (r=0.909,p=0.570),  time:29.829, tt:805.385\n",
      "Ep:27, loss:0.00004, loss_test:0.01926, lr:6.00e-02, fs:0.70817 (r=0.919,p=0.576),  time:29.786, tt:834.012\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00004, loss_test:0.01912, lr:6.00e-02, fs:0.71094 (r=0.919,p=0.580),  time:29.787, tt:863.827\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00004, loss_test:0.01897, lr:6.00e-02, fs:0.71318 (r=0.929,p=0.579),  time:29.802, tt:894.059\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01879, lr:6.00e-02, fs:0.71042 (r=0.929,p=0.575),  time:29.821, tt:924.440\n",
      "Ep:31, loss:0.00003, loss_test:0.01862, lr:6.00e-02, fs:0.72656 (r=0.939,p=0.592),  time:29.828, tt:954.492\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01850, lr:6.00e-02, fs:0.72441 (r=0.929,p=0.594),  time:29.809, tt:983.688\n",
      "Ep:33, loss:0.00003, loss_test:0.01835, lr:6.00e-02, fs:0.72727 (r=0.929,p=0.597),  time:29.801, tt:1013.218\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01819, lr:6.00e-02, fs:0.73016 (r=0.929,p=0.601),  time:29.808, tt:1043.273\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.01798, lr:6.00e-02, fs:0.74494 (r=0.929,p=0.622),  time:29.810, tt:1073.174\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01778, lr:6.00e-02, fs:0.74797 (r=0.929,p=0.626),  time:29.805, tt:1102.781\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00003, loss_test:0.01774, lr:6.00e-02, fs:0.73984 (r=0.919,p=0.619),  time:29.790, tt:1132.037\n",
      "Ep:38, loss:0.00003, loss_test:0.01768, lr:6.00e-02, fs:0.74286 (r=0.919,p=0.623),  time:29.773, tt:1161.153\n",
      "Ep:39, loss:0.00003, loss_test:0.01742, lr:6.00e-02, fs:0.75102 (r=0.929,p=0.630),  time:29.810, tt:1192.419\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.01713, lr:6.00e-02, fs:0.75099 (r=0.960,p=0.617),  time:29.811, tt:1222.263\n",
      "Ep:41, loss:0.00002, loss_test:0.01698, lr:6.00e-02, fs:0.75000 (r=0.939,p=0.624),  time:29.806, tt:1251.833\n",
      "Ep:42, loss:0.00002, loss_test:0.01674, lr:6.00e-02, fs:0.75806 (r=0.949,p=0.631),  time:29.814, tt:1281.999\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01627, lr:6.00e-02, fs:0.76860 (r=0.939,p=0.650),  time:29.818, tt:1311.976\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01597, lr:6.00e-02, fs:0.76735 (r=0.949,p=0.644),  time:29.834, tt:1342.513\n",
      "Ep:45, loss:0.00002, loss_test:0.01565, lr:6.00e-02, fs:0.78333 (r=0.949,p=0.667),  time:29.857, tt:1373.439\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01529, lr:6.00e-02, fs:0.78661 (r=0.949,p=0.671),  time:29.842, tt:1402.552\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01481, lr:6.00e-02, fs:0.79149 (r=0.939,p=0.684),  time:29.876, tt:1434.050\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01449, lr:6.00e-02, fs:0.80000 (r=0.949,p=0.691),  time:29.901, tt:1465.166\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01425, lr:6.00e-02, fs:0.80000 (r=0.949,p=0.691),  time:29.911, tt:1495.528\n",
      "Ep:50, loss:0.00002, loss_test:0.01384, lr:6.00e-02, fs:0.81545 (r=0.960,p=0.709),  time:29.935, tt:1526.661\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01369, lr:6.00e-02, fs:0.81223 (r=0.939,p=0.715),  time:29.946, tt:1557.170\n",
      "Ep:52, loss:0.00002, loss_test:0.01358, lr:6.00e-02, fs:0.81778 (r=0.929,p=0.730),  time:29.929, tt:1586.241\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01333, lr:6.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:29.924, tt:1615.896\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.01324, lr:6.00e-02, fs:0.83784 (r=0.939,p=0.756),  time:29.902, tt:1644.625\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01334, lr:6.00e-02, fs:0.81250 (r=0.919,p=0.728),  time:29.919, tt:1675.482\n",
      "Ep:56, loss:0.00001, loss_test:0.01295, lr:6.00e-02, fs:0.84112 (r=0.909,p=0.783),  time:29.915, tt:1705.163\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.01327, lr:6.00e-02, fs:0.82096 (r=0.949,p=0.723),  time:29.912, tt:1734.867\n",
      "Ep:58, loss:0.00001, loss_test:0.01278, lr:6.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:29.899, tt:1764.051\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01323, lr:6.00e-02, fs:0.81778 (r=0.929,p=0.730),  time:29.896, tt:1793.759\n",
      "Ep:60, loss:0.00001, loss_test:0.01280, lr:6.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:29.883, tt:1822.851\n",
      "Ep:61, loss:0.00001, loss_test:0.01312, lr:6.00e-02, fs:0.81651 (r=0.899,p=0.748),  time:29.873, tt:1852.116\n",
      "Ep:62, loss:0.00001, loss_test:0.01257, lr:6.00e-02, fs:0.82126 (r=0.859,p=0.787),  time:29.889, tt:1882.976\n",
      "Ep:63, loss:0.00001, loss_test:0.01321, lr:6.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:29.890, tt:1912.944\n",
      "Ep:64, loss:0.00001, loss_test:0.01272, lr:6.00e-02, fs:0.80392 (r=0.828,p=0.781),  time:29.876, tt:1941.914\n",
      "Ep:65, loss:0.00001, loss_test:0.01315, lr:6.00e-02, fs:0.81132 (r=0.869,p=0.761),  time:29.891, tt:1972.784\n",
      "Ep:66, loss:0.00001, loss_test:0.01308, lr:6.00e-02, fs:0.79412 (r=0.818,p=0.771),  time:29.890, tt:2002.600\n",
      "Ep:67, loss:0.00001, loss_test:0.01311, lr:6.00e-02, fs:0.81731 (r=0.859,p=0.780),  time:29.908, tt:2033.740\n",
      "Ep:68, loss:0.00001, loss_test:0.01312, lr:6.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:29.906, tt:2063.484\n",
      "Ep:69, loss:0.00001, loss_test:0.01305, lr:6.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:29.897, tt:2092.789\n",
      "Ep:70, loss:0.00001, loss_test:0.01315, lr:5.94e-02, fs:0.80000 (r=0.828,p=0.774),  time:29.894, tt:2122.475\n",
      "Ep:71, loss:0.00001, loss_test:0.01340, lr:5.88e-02, fs:0.79208 (r=0.808,p=0.777),  time:29.902, tt:2152.948\n",
      "Ep:72, loss:0.00001, loss_test:0.01332, lr:5.82e-02, fs:0.82126 (r=0.859,p=0.787),  time:29.905, tt:2183.063\n",
      "Ep:73, loss:0.00001, loss_test:0.01365, lr:5.76e-02, fs:0.77551 (r=0.768,p=0.784),  time:29.895, tt:2212.205\n",
      "Ep:74, loss:0.00001, loss_test:0.01341, lr:5.71e-02, fs:0.81373 (r=0.838,p=0.790),  time:29.903, tt:2242.717\n",
      "Ep:75, loss:0.00001, loss_test:0.01408, lr:5.65e-02, fs:0.75648 (r=0.737,p=0.777),  time:29.903, tt:2272.605\n",
      "Ep:76, loss:0.00001, loss_test:0.01343, lr:5.59e-02, fs:0.81407 (r=0.818,p=0.810),  time:29.903, tt:2302.514\n",
      "Ep:77, loss:0.00001, loss_test:0.01401, lr:5.54e-02, fs:0.77551 (r=0.768,p=0.784),  time:29.899, tt:2332.147\n",
      "Ep:78, loss:0.00001, loss_test:0.01388, lr:5.48e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.896, tt:2361.790\n",
      "Ep:79, loss:0.00001, loss_test:0.01420, lr:5.43e-02, fs:0.76842 (r=0.737,p=0.802),  time:29.903, tt:2392.270\n",
      "Ep:80, loss:0.00001, loss_test:0.01444, lr:5.37e-02, fs:0.78756 (r=0.768,p=0.809),  time:29.917, tt:2423.301\n",
      "Ep:81, loss:0.00001, loss_test:0.01391, lr:5.32e-02, fs:0.77895 (r=0.747,p=0.813),  time:29.915, tt:2453.059\n",
      "Ep:82, loss:0.00001, loss_test:0.01416, lr:5.27e-02, fs:0.77660 (r=0.737,p=0.820),  time:29.947, tt:2485.564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:83, loss:0.00001, loss_test:0.01430, lr:5.21e-02, fs:0.80612 (r=0.798,p=0.814),  time:29.959, tt:2516.525\n",
      "Ep:84, loss:0.00001, loss_test:0.01414, lr:5.16e-02, fs:0.77174 (r=0.717,p=0.835),  time:29.957, tt:2546.361\n",
      "Ep:85, loss:0.00001, loss_test:0.01406, lr:5.11e-02, fs:0.80208 (r=0.778,p=0.828),  time:29.963, tt:2576.834\n",
      "Ep:86, loss:0.00001, loss_test:0.01421, lr:5.06e-02, fs:0.81675 (r=0.788,p=0.848),  time:29.962, tt:2606.675\n",
      "Ep:87, loss:0.00001, loss_test:0.01419, lr:5.01e-02, fs:0.79121 (r=0.727,p=0.867),  time:29.968, tt:2637.192\n",
      "Ep:88, loss:0.00001, loss_test:0.01464, lr:4.96e-02, fs:0.81865 (r=0.798,p=0.840),  time:29.971, tt:2667.385\n",
      "Ep:89, loss:0.00001, loss_test:0.01435, lr:4.91e-02, fs:0.79121 (r=0.727,p=0.867),  time:29.970, tt:2697.318\n",
      "Ep:90, loss:0.00000, loss_test:0.01492, lr:4.86e-02, fs:0.76923 (r=0.707,p=0.843),  time:29.967, tt:2726.966\n",
      "Ep:91, loss:0.00001, loss_test:0.01480, lr:4.81e-02, fs:0.81481 (r=0.778,p=0.856),  time:29.985, tt:2758.578\n",
      "Ep:92, loss:0.00000, loss_test:0.01457, lr:4.76e-02, fs:0.77778 (r=0.707,p=0.864),  time:30.004, tt:2790.347\n",
      "Ep:93, loss:0.00000, loss_test:0.01485, lr:4.71e-02, fs:0.81675 (r=0.788,p=0.848),  time:30.024, tt:2822.295\n",
      "Ep:94, loss:0.00000, loss_test:0.01488, lr:4.67e-02, fs:0.80435 (r=0.747,p=0.871),  time:30.034, tt:2853.269\n",
      "Ep:95, loss:0.00000, loss_test:0.01518, lr:4.62e-02, fs:0.77778 (r=0.707,p=0.864),  time:30.044, tt:2884.180\n",
      "Ep:96, loss:0.00000, loss_test:0.01523, lr:4.57e-02, fs:0.82353 (r=0.778,p=0.875),  time:30.059, tt:2915.734\n",
      "Ep:97, loss:0.00000, loss_test:0.01539, lr:4.53e-02, fs:0.81720 (r=0.768,p=0.874),  time:30.060, tt:2945.899\n",
      "Ep:98, loss:0.00000, loss_test:0.01555, lr:4.48e-02, fs:0.78212 (r=0.707,p=0.875),  time:30.066, tt:2976.493\n",
      "Ep:99, loss:0.00000, loss_test:0.01559, lr:4.44e-02, fs:0.82796 (r=0.778,p=0.885),  time:30.080, tt:3008.006\n",
      "Ep:100, loss:0.00000, loss_test:0.01592, lr:4.39e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.109, tt:3040.985\n",
      "Ep:101, loss:0.00000, loss_test:0.01584, lr:4.35e-02, fs:0.79558 (r=0.727,p=0.878),  time:30.117, tt:3071.969\n",
      "Ep:102, loss:0.00000, loss_test:0.01582, lr:4.31e-02, fs:0.80000 (r=0.727,p=0.889),  time:30.122, tt:3102.551\n",
      "Ep:103, loss:0.00000, loss_test:0.01609, lr:4.26e-02, fs:0.82162 (r=0.768,p=0.884),  time:30.122, tt:3132.683\n",
      "Ep:104, loss:0.00000, loss_test:0.01627, lr:4.22e-02, fs:0.79558 (r=0.727,p=0.878),  time:30.124, tt:3163.068\n",
      "Ep:105, loss:0.00000, loss_test:0.01629, lr:4.18e-02, fs:0.80000 (r=0.727,p=0.889),  time:30.132, tt:3193.950\n",
      "Ep:106, loss:0.00000, loss_test:0.01624, lr:4.14e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.141, tt:3225.086\n",
      "Ep:107, loss:0.00000, loss_test:0.01657, lr:4.10e-02, fs:0.81319 (r=0.747,p=0.892),  time:30.149, tt:3256.143\n",
      "Ep:108, loss:0.00000, loss_test:0.01678, lr:4.05e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.156, tt:3287.028\n",
      "Ep:109, loss:0.00000, loss_test:0.01654, lr:4.01e-02, fs:0.82682 (r=0.747,p=0.925),  time:30.159, tt:3317.444\n",
      "Ep:110, loss:0.00000, loss_test:0.01660, lr:3.97e-02, fs:0.81356 (r=0.727,p=0.923),  time:30.160, tt:3347.759\n",
      "Ep:111, loss:0.00000, loss_test:0.01718, lr:3.93e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.150, tt:3376.759\n",
      "##########Best model found so far##########\n",
      "Ep:112, loss:0.00000, loss_test:0.01699, lr:3.93e-02, fs:0.83333 (r=0.758,p=0.926),  time:30.147, tt:3406.651\n",
      "Ep:113, loss:0.00000, loss_test:0.01669, lr:3.93e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.159, tt:3438.083\n",
      "Ep:114, loss:0.00000, loss_test:0.01707, lr:3.93e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.157, tt:3468.029\n",
      "Ep:115, loss:0.00000, loss_test:0.01760, lr:3.93e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.154, tt:3497.896\n",
      "Ep:116, loss:0.00000, loss_test:0.01732, lr:3.93e-02, fs:0.86772 (r=0.828,p=0.911),  time:30.166, tt:3529.392\n",
      "Ep:117, loss:0.00000, loss_test:0.01721, lr:3.93e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.172, tt:3560.280\n",
      "Ep:118, loss:0.00000, loss_test:0.01780, lr:3.93e-02, fs:0.87368 (r=0.838,p=0.912),  time:30.171, tt:3590.299\n",
      "##########Best model found so far##########\n",
      "Ep:119, loss:0.00000, loss_test:0.01785, lr:3.93e-02, fs:0.86486 (r=0.808,p=0.930),  time:30.164, tt:3619.638\n",
      "Ep:120, loss:0.00000, loss_test:0.01716, lr:3.93e-02, fs:0.84746 (r=0.758,p=0.962),  time:30.162, tt:3649.562\n",
      "Ep:121, loss:0.00000, loss_test:0.01787, lr:3.93e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.171, tt:3680.861\n",
      "Ep:122, loss:0.00000, loss_test:0.01828, lr:3.93e-02, fs:0.87831 (r=0.838,p=0.922),  time:30.166, tt:3710.358\n",
      "##########Best model found so far##########\n",
      "Ep:123, loss:0.00000, loss_test:0.01766, lr:3.93e-02, fs:0.86813 (r=0.798,p=0.952),  time:30.186, tt:3743.016\n",
      "Ep:124, loss:0.00000, loss_test:0.01752, lr:3.93e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.181, tt:3772.658\n",
      "Ep:125, loss:0.00000, loss_test:0.01811, lr:3.93e-02, fs:0.86022 (r=0.808,p=0.920),  time:30.178, tt:3802.426\n",
      "Ep:126, loss:0.00000, loss_test:0.01855, lr:3.93e-02, fs:0.86339 (r=0.798,p=0.940),  time:30.180, tt:3832.797\n",
      "Ep:127, loss:0.00000, loss_test:0.01813, lr:3.93e-02, fs:0.86813 (r=0.798,p=0.952),  time:30.175, tt:3862.375\n",
      "Ep:128, loss:0.00000, loss_test:0.01820, lr:3.93e-02, fs:0.85556 (r=0.778,p=0.951),  time:30.178, tt:3892.991\n",
      "Ep:129, loss:0.00000, loss_test:0.01874, lr:3.93e-02, fs:0.86957 (r=0.808,p=0.941),  time:30.174, tt:3922.584\n",
      "Ep:130, loss:0.00000, loss_test:0.01873, lr:3.93e-02, fs:0.86813 (r=0.798,p=0.952),  time:30.177, tt:3953.200\n",
      "Ep:131, loss:0.00000, loss_test:0.01842, lr:3.93e-02, fs:0.85556 (r=0.778,p=0.951),  time:30.180, tt:3983.824\n",
      "Ep:132, loss:0.00000, loss_test:0.01856, lr:3.93e-02, fs:0.85556 (r=0.778,p=0.951),  time:30.184, tt:4014.522\n",
      "Ep:133, loss:0.00000, loss_test:0.01914, lr:3.93e-02, fs:0.88649 (r=0.828,p=0.953),  time:30.191, tt:4045.584\n",
      "##########Best model found so far##########\n",
      "Ep:134, loss:0.00000, loss_test:0.01936, lr:3.93e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.197, tt:4076.537\n",
      "Ep:135, loss:0.00000, loss_test:0.01879, lr:3.93e-02, fs:0.85556 (r=0.778,p=0.951),  time:30.190, tt:4105.852\n",
      "Ep:136, loss:0.00000, loss_test:0.01864, lr:3.93e-02, fs:0.86034 (r=0.778,p=0.963),  time:30.191, tt:4136.143\n",
      "Ep:137, loss:0.00000, loss_test:0.01953, lr:3.93e-02, fs:0.88043 (r=0.818,p=0.953),  time:30.188, tt:4165.947\n",
      "Ep:138, loss:0.00000, loss_test:0.01946, lr:3.93e-02, fs:0.88298 (r=0.838,p=0.933),  time:30.182, tt:4195.234\n",
      "Ep:139, loss:0.00000, loss_test:0.01858, lr:3.93e-02, fs:0.86034 (r=0.778,p=0.963),  time:30.181, tt:4225.316\n",
      "Ep:140, loss:0.00000, loss_test:0.01871, lr:3.93e-02, fs:0.86034 (r=0.778,p=0.963),  time:30.179, tt:4255.262\n",
      "Ep:141, loss:0.00000, loss_test:0.01962, lr:3.93e-02, fs:0.89247 (r=0.838,p=0.954),  time:30.174, tt:4284.771\n",
      "##########Best model found so far##########\n",
      "Ep:142, loss:0.00000, loss_test:0.01980, lr:3.93e-02, fs:0.86813 (r=0.798,p=0.952),  time:30.177, tt:4315.363\n",
      "Ep:143, loss:0.00000, loss_test:0.01905, lr:3.93e-02, fs:0.87293 (r=0.798,p=0.963),  time:30.178, tt:4345.618\n",
      "Ep:144, loss:0.00000, loss_test:0.01903, lr:3.93e-02, fs:0.86034 (r=0.778,p=0.963),  time:30.171, tt:4374.792\n",
      "Ep:145, loss:0.00000, loss_test:0.01986, lr:3.93e-02, fs:0.86813 (r=0.798,p=0.952),  time:30.168, tt:4404.568\n",
      "Ep:146, loss:0.00000, loss_test:0.02003, lr:3.93e-02, fs:0.89247 (r=0.838,p=0.954),  time:30.169, tt:4434.863\n",
      "Ep:147, loss:0.00000, loss_test:0.01955, lr:3.93e-02, fs:0.86813 (r=0.798,p=0.952),  time:30.164, tt:4464.215\n",
      "Ep:148, loss:0.00000, loss_test:0.01965, lr:3.93e-02, fs:0.87293 (r=0.798,p=0.963),  time:30.159, tt:4493.712\n",
      "Ep:149, loss:0.00000, loss_test:0.02047, lr:3.93e-02, fs:0.87432 (r=0.808,p=0.952),  time:30.175, tt:4526.298\n",
      "Ep:150, loss:0.00000, loss_test:0.02026, lr:3.93e-02, fs:0.89947 (r=0.859,p=0.944),  time:30.175, tt:4556.432\n",
      "##########Best model found so far##########\n",
      "Ep:151, loss:0.00000, loss_test:0.01952, lr:3.93e-02, fs:0.86034 (r=0.778,p=0.963),  time:30.171, tt:4585.952\n",
      "Ep:152, loss:0.00000, loss_test:0.01958, lr:3.93e-02, fs:0.87293 (r=0.798,p=0.963),  time:30.166, tt:4615.376\n",
      "Ep:153, loss:0.00000, loss_test:0.02069, lr:3.93e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.152, tt:4643.406\n",
      "Ep:154, loss:0.00000, loss_test:0.01950, lr:3.93e-02, fs:0.87912 (r=0.808,p=0.964),  time:30.149, tt:4673.106\n",
      "Ep:155, loss:0.00000, loss_test:0.01886, lr:3.93e-02, fs:0.86034 (r=0.778,p=0.963),  time:30.153, tt:4703.815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:156, loss:0.00000, loss_test:0.01958, lr:3.93e-02, fs:0.87432 (r=0.808,p=0.952),  time:30.151, tt:4733.756\n",
      "Ep:157, loss:0.00000, loss_test:0.02106, lr:3.93e-02, fs:0.89005 (r=0.859,p=0.924),  time:30.145, tt:4762.966\n",
      "Ep:158, loss:0.00000, loss_test:0.01817, lr:3.93e-02, fs:0.86667 (r=0.788,p=0.963),  time:30.143, tt:4792.679\n",
      "Ep:159, loss:0.00000, loss_test:0.01875, lr:3.93e-02, fs:0.87912 (r=0.808,p=0.964),  time:30.133, tt:4821.272\n",
      "Ep:160, loss:0.00000, loss_test:0.01975, lr:3.93e-02, fs:0.89474 (r=0.859,p=0.934),  time:30.129, tt:4850.710\n",
      "Ep:161, loss:0.00000, loss_test:0.01791, lr:3.93e-02, fs:0.86667 (r=0.788,p=0.963),  time:30.124, tt:4880.066\n",
      "Ep:162, loss:0.00000, loss_test:0.01957, lr:3.89e-02, fs:0.86957 (r=0.808,p=0.941),  time:30.126, tt:4910.567\n",
      "Ep:163, loss:0.00000, loss_test:0.01861, lr:3.86e-02, fs:0.89474 (r=0.859,p=0.934),  time:30.121, tt:4939.777\n",
      "Ep:164, loss:0.00000, loss_test:0.01761, lr:3.82e-02, fs:0.84746 (r=0.758,p=0.962),  time:30.117, tt:4969.324\n",
      "Ep:165, loss:0.00000, loss_test:0.01938, lr:3.78e-02, fs:0.87368 (r=0.838,p=0.912),  time:30.115, tt:4999.101\n",
      "Ep:166, loss:0.00000, loss_test:0.01768, lr:3.74e-02, fs:0.86034 (r=0.778,p=0.963),  time:30.114, tt:5029.112\n",
      "Ep:167, loss:0.00000, loss_test:0.02000, lr:3.70e-02, fs:0.86339 (r=0.798,p=0.940),  time:30.113, tt:5059.004\n",
      "Ep:168, loss:0.00000, loss_test:0.01802, lr:3.67e-02, fs:0.86667 (r=0.788,p=0.963),  time:30.117, tt:5089.700\n",
      "Ep:169, loss:0.00000, loss_test:0.01960, lr:3.63e-02, fs:0.87432 (r=0.808,p=0.952),  time:30.118, tt:5119.991\n",
      "Ep:170, loss:0.00000, loss_test:0.01828, lr:3.59e-02, fs:0.87912 (r=0.808,p=0.964),  time:30.112, tt:5149.194\n",
      "Ep:171, loss:0.00000, loss_test:0.01940, lr:3.56e-02, fs:0.86813 (r=0.798,p=0.952),  time:30.111, tt:5179.062\n",
      "Ep:172, loss:0.00000, loss_test:0.01950, lr:3.52e-02, fs:0.87293 (r=0.798,p=0.963),  time:30.109, tt:5208.828\n",
      "Ep:173, loss:0.00000, loss_test:0.01905, lr:3.49e-02, fs:0.87912 (r=0.808,p=0.964),  time:30.113, tt:5239.697\n",
      "Ep:174, loss:0.00000, loss_test:0.01967, lr:3.45e-02, fs:0.87912 (r=0.808,p=0.964),  time:30.131, tt:5272.945\n",
      "Ep:175, loss:0.00000, loss_test:0.01934, lr:3.42e-02, fs:0.88525 (r=0.818,p=0.964),  time:30.128, tt:5302.491\n",
      "Ep:176, loss:0.00000, loss_test:0.02002, lr:3.38e-02, fs:0.87293 (r=0.798,p=0.963),  time:30.123, tt:5331.747\n",
      "Ep:177, loss:0.00000, loss_test:0.01992, lr:3.35e-02, fs:0.87912 (r=0.808,p=0.964),  time:30.113, tt:5360.154\n",
      "Ep:178, loss:0.00000, loss_test:0.02034, lr:3.32e-02, fs:0.87912 (r=0.808,p=0.964),  time:30.109, tt:5389.468\n",
      "Ep:179, loss:0.00000, loss_test:0.02033, lr:3.28e-02, fs:0.87912 (r=0.808,p=0.964),  time:30.102, tt:5418.438\n",
      "Ep:180, loss:0.00000, loss_test:0.02041, lr:3.25e-02, fs:0.87912 (r=0.808,p=0.964),  time:30.109, tt:5449.721\n",
      "Ep:181, loss:0.00000, loss_test:0.02064, lr:3.22e-02, fs:0.87912 (r=0.808,p=0.964),  time:30.108, tt:5479.731\n",
      "Ep:182, loss:0.00000, loss_test:0.02056, lr:3.19e-02, fs:0.87912 (r=0.808,p=0.964),  time:30.104, tt:5509.027\n",
      "Ep:183, loss:0.00000, loss_test:0.02096, lr:3.15e-02, fs:0.87912 (r=0.808,p=0.964),  time:30.101, tt:5538.523\n",
      "Ep:184, loss:0.00000, loss_test:0.02070, lr:3.12e-02, fs:0.87912 (r=0.808,p=0.964),  time:30.102, tt:5568.943\n",
      "Ep:185, loss:0.00000, loss_test:0.02093, lr:3.09e-02, fs:0.87912 (r=0.808,p=0.964),  time:30.104, tt:5599.424\n",
      "Ep:186, loss:0.00000, loss_test:0.02075, lr:3.06e-02, fs:0.87912 (r=0.808,p=0.964),  time:30.101, tt:5628.861\n",
      "Ep:187, loss:0.00000, loss_test:0.02087, lr:3.03e-02, fs:0.87912 (r=0.808,p=0.964),  time:30.103, tt:5659.282\n",
      "Ep:188, loss:0.00000, loss_test:0.02109, lr:3.00e-02, fs:0.87912 (r=0.808,p=0.964),  time:30.099, tt:5688.722\n",
      "Ep:189, loss:0.00000, loss_test:0.02108, lr:2.97e-02, fs:0.87912 (r=0.808,p=0.964),  time:30.099, tt:5718.844\n",
      "Ep:190, loss:0.00000, loss_test:0.02125, lr:2.94e-02, fs:0.87912 (r=0.808,p=0.964),  time:30.093, tt:5747.813\n",
      "Ep:191, loss:0.00000, loss_test:0.02124, lr:2.91e-02, fs:0.87912 (r=0.808,p=0.964),  time:30.088, tt:5776.970\n",
      "Ep:192, loss:0.00000, loss_test:0.02133, lr:2.88e-02, fs:0.87912 (r=0.808,p=0.964),  time:30.083, tt:5806.053\n",
      "Ep:193, loss:0.00000, loss_test:0.02144, lr:2.85e-02, fs:0.87912 (r=0.808,p=0.964),  time:30.081, tt:5835.681\n",
      "Ep:194, loss:0.00000, loss_test:0.02136, lr:2.82e-02, fs:0.87912 (r=0.808,p=0.964),  time:30.079, tt:5865.498\n",
      "Ep:195, loss:0.00000, loss_test:0.02143, lr:2.80e-02, fs:0.87912 (r=0.808,p=0.964),  time:30.082, tt:5896.113\n",
      "Ep:196, loss:0.00000, loss_test:0.02155, lr:2.77e-02, fs:0.87912 (r=0.808,p=0.964),  time:30.081, tt:5925.932\n",
      "Ep:197, loss:0.00000, loss_test:0.02152, lr:2.74e-02, fs:0.87912 (r=0.808,p=0.964),  time:30.063, tt:5952.502\n",
      "Ep:198, loss:0.00000, loss_test:0.02177, lr:2.71e-02, fs:0.87912 (r=0.808,p=0.964),  time:30.042, tt:5978.292\n",
      "Ep:199, loss:0.00000, loss_test:0.02168, lr:2.69e-02, fs:0.87912 (r=0.808,p=0.964),  time:30.024, tt:6004.865\n",
      "Ep:200, loss:0.00000, loss_test:0.02155, lr:2.66e-02, fs:0.87912 (r=0.808,p=0.964),  time:30.012, tt:6032.474\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13083, lr:1.00e-02, fs:0.68217 (r=0.889,p=0.553),  time:26.384, tt:26.384\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13008, lr:1.00e-02, fs:0.68966 (r=0.909,p=0.556),  time:25.592, tt:51.183\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.13018, lr:1.00e-02, fs:0.67424 (r=0.899,p=0.539),  time:26.239, tt:78.717\n",
      "Ep:3, loss:0.00026, loss_test:0.13046, lr:1.00e-02, fs:0.67170 (r=0.899,p=0.536),  time:27.147, tt:108.590\n",
      "Ep:4, loss:0.00026, loss_test:0.13009, lr:1.00e-02, fs:0.66917 (r=0.899,p=0.533),  time:27.848, tt:139.242\n",
      "Ep:5, loss:0.00026, loss_test:0.12841, lr:1.00e-02, fs:0.67170 (r=0.899,p=0.536),  time:28.186, tt:169.118\n",
      "Ep:6, loss:0.00025, loss_test:0.12633, lr:1.00e-02, fs:0.67954 (r=0.889,p=0.550),  time:28.507, tt:199.551\n",
      "Ep:7, loss:0.00025, loss_test:0.12486, lr:1.00e-02, fs:0.68482 (r=0.889,p=0.557),  time:29.183, tt:233.467\n",
      "Ep:8, loss:0.00025, loss_test:0.12368, lr:1.00e-02, fs:0.69020 (r=0.889,p=0.564),  time:29.339, tt:264.055\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00025, loss_test:0.12257, lr:1.00e-02, fs:0.68482 (r=0.889,p=0.557),  time:29.358, tt:293.578\n",
      "Ep:10, loss:0.00024, loss_test:0.12125, lr:1.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:29.633, tt:325.958\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00024, loss_test:0.11932, lr:1.00e-02, fs:0.69020 (r=0.889,p=0.564),  time:29.657, tt:355.885\n",
      "Ep:12, loss:0.00024, loss_test:0.11739, lr:1.00e-02, fs:0.69323 (r=0.879,p=0.572),  time:29.802, tt:387.429\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00024, loss_test:0.11510, lr:1.00e-02, fs:0.69880 (r=0.879,p=0.580),  time:29.922, tt:418.909\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00023, loss_test:0.11334, lr:1.00e-02, fs:0.69355 (r=0.869,p=0.577),  time:29.993, tt:449.898\n",
      "Ep:15, loss:0.00023, loss_test:0.11194, lr:1.00e-02, fs:0.69880 (r=0.879,p=0.580),  time:30.053, tt:480.853\n",
      "Ep:16, loss:0.00022, loss_test:0.11098, lr:1.00e-02, fs:0.69355 (r=0.869,p=0.577),  time:30.073, tt:511.245\n",
      "Ep:17, loss:0.00022, loss_test:0.10944, lr:1.00e-02, fs:0.70732 (r=0.879,p=0.592),  time:30.058, tt:541.045\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00022, loss_test:0.10810, lr:1.00e-02, fs:0.72800 (r=0.919,p=0.603),  time:30.065, tt:571.240\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00021, loss_test:0.10663, lr:1.00e-02, fs:0.73092 (r=0.919,p=0.607),  time:30.048, tt:600.952\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00021, loss_test:0.10565, lr:1.00e-02, fs:0.73171 (r=0.909,p=0.612),  time:30.134, tt:632.817\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00021, loss_test:0.10497, lr:1.00e-02, fs:0.72874 (r=0.909,p=0.608),  time:30.127, tt:662.789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:22, loss:0.00020, loss_test:0.10363, lr:1.00e-02, fs:0.72874 (r=0.909,p=0.608),  time:30.126, tt:692.904\n",
      "Ep:23, loss:0.00020, loss_test:0.10338, lr:1.00e-02, fs:0.73171 (r=0.909,p=0.612),  time:30.130, tt:723.111\n",
      "Ep:24, loss:0.00020, loss_test:0.10277, lr:1.00e-02, fs:0.72653 (r=0.899,p=0.610),  time:30.139, tt:753.469\n",
      "Ep:25, loss:0.00019, loss_test:0.10299, lr:1.00e-02, fs:0.71605 (r=0.879,p=0.604),  time:30.143, tt:783.712\n",
      "Ep:26, loss:0.00019, loss_test:0.10152, lr:1.00e-02, fs:0.72199 (r=0.879,p=0.613),  time:30.182, tt:814.920\n",
      "Ep:27, loss:0.00018, loss_test:0.10250, lr:1.00e-02, fs:0.72199 (r=0.879,p=0.613),  time:30.207, tt:845.787\n",
      "Ep:28, loss:0.00018, loss_test:0.10249, lr:1.00e-02, fs:0.71429 (r=0.859,p=0.612),  time:30.266, tt:877.727\n",
      "Ep:29, loss:0.00017, loss_test:0.10129, lr:1.00e-02, fs:0.72650 (r=0.859,p=0.630),  time:30.342, tt:910.264\n",
      "Ep:30, loss:0.00017, loss_test:0.10269, lr:1.00e-02, fs:0.71245 (r=0.838,p=0.619),  time:30.348, tt:940.797\n",
      "Ep:31, loss:0.00016, loss_test:0.10119, lr:1.00e-02, fs:0.72103 (r=0.848,p=0.627),  time:30.310, tt:969.932\n",
      "Ep:32, loss:0.00016, loss_test:0.10539, lr:9.90e-03, fs:0.70690 (r=0.828,p=0.617),  time:30.306, tt:1000.102\n",
      "Ep:33, loss:0.00015, loss_test:0.09825, lr:9.80e-03, fs:0.73684 (r=0.848,p=0.651),  time:30.288, tt:1029.808\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00015, loss_test:0.10371, lr:9.80e-03, fs:0.69912 (r=0.798,p=0.622),  time:30.309, tt:1060.816\n",
      "Ep:35, loss:0.00014, loss_test:0.09795, lr:9.80e-03, fs:0.73874 (r=0.828,p=0.667),  time:30.374, tt:1093.475\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00014, loss_test:0.10316, lr:9.80e-03, fs:0.71233 (r=0.788,p=0.650),  time:30.354, tt:1123.107\n",
      "Ep:37, loss:0.00013, loss_test:0.09565, lr:9.80e-03, fs:0.74419 (r=0.808,p=0.690),  time:30.338, tt:1152.855\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00014, loss_test:0.10128, lr:9.80e-03, fs:0.71921 (r=0.737,p=0.702),  time:30.339, tt:1183.210\n",
      "Ep:39, loss:0.00013, loss_test:0.11071, lr:9.80e-03, fs:0.69955 (r=0.788,p=0.629),  time:30.337, tt:1213.474\n",
      "Ep:40, loss:0.00013, loss_test:0.09221, lr:9.80e-03, fs:0.76279 (r=0.828,p=0.707),  time:30.363, tt:1244.882\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00013, loss_test:0.09501, lr:9.80e-03, fs:0.71642 (r=0.727,p=0.706),  time:30.379, tt:1275.907\n",
      "Ep:42, loss:0.00012, loss_test:0.10109, lr:9.80e-03, fs:0.70874 (r=0.737,p=0.682),  time:30.389, tt:1306.727\n",
      "Ep:43, loss:0.00011, loss_test:0.09393, lr:9.80e-03, fs:0.75248 (r=0.768,p=0.738),  time:30.383, tt:1336.853\n",
      "Ep:44, loss:0.00011, loss_test:0.10548, lr:9.80e-03, fs:0.73632 (r=0.747,p=0.725),  time:30.372, tt:1366.751\n",
      "Ep:45, loss:0.00010, loss_test:0.09317, lr:9.80e-03, fs:0.77487 (r=0.747,p=0.804),  time:30.392, tt:1398.022\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00010, loss_test:0.09839, lr:9.80e-03, fs:0.74286 (r=0.788,p=0.703),  time:30.355, tt:1426.701\n",
      "Ep:47, loss:0.00009, loss_test:0.09503, lr:9.80e-03, fs:0.75145 (r=0.657,p=0.878),  time:30.352, tt:1456.909\n",
      "Ep:48, loss:0.00009, loss_test:0.09377, lr:9.80e-03, fs:0.75238 (r=0.798,p=0.712),  time:30.364, tt:1487.829\n",
      "Ep:49, loss:0.00008, loss_test:0.09006, lr:9.80e-03, fs:0.78409 (r=0.697,p=0.896),  time:30.379, tt:1518.950\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00008, loss_test:0.09344, lr:9.80e-03, fs:0.77778 (r=0.778,p=0.778),  time:30.366, tt:1548.654\n",
      "Ep:51, loss:0.00007, loss_test:0.09585, lr:9.80e-03, fs:0.76842 (r=0.737,p=0.802),  time:30.363, tt:1578.891\n",
      "Ep:52, loss:0.00007, loss_test:0.08997, lr:9.80e-03, fs:0.80412 (r=0.788,p=0.821),  time:30.387, tt:1610.495\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00006, loss_test:0.09204, lr:9.80e-03, fs:0.77720 (r=0.758,p=0.798),  time:30.385, tt:1640.806\n",
      "Ep:54, loss:0.00006, loss_test:0.08827, lr:9.80e-03, fs:0.79592 (r=0.788,p=0.804),  time:30.399, tt:1671.970\n",
      "Ep:55, loss:0.00006, loss_test:0.08800, lr:9.80e-03, fs:0.81283 (r=0.768,p=0.864),  time:30.414, tt:1703.195\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00006, loss_test:0.08957, lr:9.80e-03, fs:0.79787 (r=0.758,p=0.843),  time:30.449, tt:1735.614\n",
      "Ep:57, loss:0.00005, loss_test:0.08671, lr:9.80e-03, fs:0.78392 (r=0.788,p=0.780),  time:30.453, tt:1766.303\n",
      "Ep:58, loss:0.00005, loss_test:0.09215, lr:9.80e-03, fs:0.79787 (r=0.758,p=0.843),  time:30.491, tt:1798.969\n",
      "Ep:59, loss:0.00005, loss_test:0.08421, lr:9.80e-03, fs:0.82540 (r=0.788,p=0.867),  time:30.487, tt:1829.234\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00005, loss_test:0.09096, lr:9.80e-03, fs:0.82682 (r=0.747,p=0.925),  time:30.492, tt:1860.022\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00005, loss_test:0.08488, lr:9.80e-03, fs:0.81720 (r=0.768,p=0.874),  time:30.497, tt:1890.808\n",
      "Ep:62, loss:0.00004, loss_test:0.08471, lr:9.80e-03, fs:0.81283 (r=0.768,p=0.864),  time:30.518, tt:1922.635\n",
      "Ep:63, loss:0.00004, loss_test:0.09358, lr:9.80e-03, fs:0.82162 (r=0.768,p=0.884),  time:30.517, tt:1953.075\n",
      "Ep:64, loss:0.00004, loss_test:0.08395, lr:9.80e-03, fs:0.81720 (r=0.768,p=0.874),  time:30.514, tt:1983.379\n",
      "Ep:65, loss:0.00004, loss_test:0.08914, lr:9.80e-03, fs:0.83333 (r=0.758,p=0.926),  time:30.513, tt:2013.851\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00004, loss_test:0.08751, lr:9.80e-03, fs:0.80851 (r=0.768,p=0.854),  time:30.516, tt:2044.590\n",
      "Ep:67, loss:0.00004, loss_test:0.08821, lr:9.80e-03, fs:0.83978 (r=0.768,p=0.927),  time:30.536, tt:2076.481\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00003, loss_test:0.08688, lr:9.80e-03, fs:0.82486 (r=0.737,p=0.936),  time:30.557, tt:2108.432\n",
      "Ep:69, loss:0.00003, loss_test:0.08531, lr:9.80e-03, fs:0.83978 (r=0.768,p=0.927),  time:30.565, tt:2139.521\n",
      "Ep:70, loss:0.00003, loss_test:0.08761, lr:9.80e-03, fs:0.84444 (r=0.768,p=0.938),  time:30.572, tt:2170.632\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00003, loss_test:0.08844, lr:9.80e-03, fs:0.81818 (r=0.727,p=0.935),  time:30.574, tt:2201.327\n",
      "Ep:72, loss:0.00003, loss_test:0.09370, lr:9.80e-03, fs:0.83978 (r=0.768,p=0.927),  time:30.568, tt:2231.439\n",
      "Ep:73, loss:0.00003, loss_test:0.09043, lr:9.80e-03, fs:0.83333 (r=0.758,p=0.926),  time:30.574, tt:2262.474\n",
      "Ep:74, loss:0.00003, loss_test:0.08570, lr:9.80e-03, fs:0.85405 (r=0.798,p=0.919),  time:30.611, tt:2295.790\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00005, loss_test:0.08025, lr:9.80e-03, fs:0.81111 (r=0.737,p=0.901),  time:30.608, tt:2326.209\n",
      "Ep:76, loss:0.00004, loss_test:0.09064, lr:9.80e-03, fs:0.81283 (r=0.768,p=0.864),  time:30.621, tt:2357.841\n",
      "Ep:77, loss:0.00003, loss_test:0.09624, lr:9.80e-03, fs:0.73054 (r=0.616,p=0.897),  time:30.611, tt:2387.692\n",
      "Ep:78, loss:0.00004, loss_test:0.10010, lr:9.80e-03, fs:0.79581 (r=0.768,p=0.826),  time:30.606, tt:2417.900\n",
      "Ep:79, loss:0.00003, loss_test:0.09259, lr:9.80e-03, fs:0.74286 (r=0.657,p=0.855),  time:30.612, tt:2448.988\n",
      "Ep:80, loss:0.00003, loss_test:0.10789, lr:9.80e-03, fs:0.82609 (r=0.768,p=0.894),  time:30.628, tt:2480.896\n",
      "Ep:81, loss:0.00003, loss_test:0.08609, lr:9.80e-03, fs:0.83978 (r=0.768,p=0.927),  time:30.634, tt:2511.980\n",
      "Ep:82, loss:0.00003, loss_test:0.08535, lr:9.80e-03, fs:0.83516 (r=0.768,p=0.916),  time:30.637, tt:2542.862\n",
      "Ep:83, loss:0.00002, loss_test:0.08916, lr:9.80e-03, fs:0.83516 (r=0.768,p=0.916),  time:30.645, tt:2574.139\n",
      "Ep:84, loss:0.00002, loss_test:0.08939, lr:9.80e-03, fs:0.83060 (r=0.768,p=0.905),  time:30.636, tt:2604.063\n",
      "Ep:85, loss:0.00002, loss_test:0.09238, lr:9.80e-03, fs:0.83516 (r=0.768,p=0.916),  time:30.639, tt:2634.938\n",
      "Ep:86, loss:0.00002, loss_test:0.08613, lr:9.70e-03, fs:0.84916 (r=0.768,p=0.950),  time:30.659, tt:2667.310\n",
      "Ep:87, loss:0.00002, loss_test:0.09295, lr:9.61e-03, fs:0.84444 (r=0.768,p=0.938),  time:30.670, tt:2698.988\n",
      "Ep:88, loss:0.00002, loss_test:0.08722, lr:9.51e-03, fs:0.84444 (r=0.768,p=0.938),  time:30.679, tt:2730.399\n",
      "Ep:89, loss:0.00002, loss_test:0.09213, lr:9.41e-03, fs:0.82955 (r=0.737,p=0.948),  time:30.673, tt:2760.571\n",
      "Ep:90, loss:0.00002, loss_test:0.09442, lr:9.32e-03, fs:0.83146 (r=0.747,p=0.937),  time:30.677, tt:2791.598\n",
      "Ep:91, loss:0.00001, loss_test:0.08947, lr:9.23e-03, fs:0.84270 (r=0.758,p=0.949),  time:30.682, tt:2822.740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:92, loss:0.00001, loss_test:0.09235, lr:9.14e-03, fs:0.84270 (r=0.758,p=0.949),  time:30.688, tt:2853.956\n",
      "Ep:93, loss:0.00001, loss_test:0.08998, lr:9.04e-03, fs:0.84444 (r=0.768,p=0.938),  time:30.690, tt:2884.878\n",
      "Ep:94, loss:0.00001, loss_test:0.09184, lr:8.95e-03, fs:0.84270 (r=0.758,p=0.949),  time:30.708, tt:2917.300\n",
      "Ep:95, loss:0.00001, loss_test:0.09221, lr:8.86e-03, fs:0.83616 (r=0.747,p=0.949),  time:30.731, tt:2950.176\n",
      "Ep:96, loss:0.00001, loss_test:0.08640, lr:8.78e-03, fs:0.85083 (r=0.778,p=0.939),  time:30.724, tt:2980.191\n",
      "Ep:97, loss:0.00001, loss_test:0.09582, lr:8.69e-03, fs:0.81818 (r=0.727,p=0.935),  time:30.739, tt:3012.468\n",
      "Ep:98, loss:0.00001, loss_test:0.09095, lr:8.60e-03, fs:0.82759 (r=0.727,p=0.960),  time:30.734, tt:3042.670\n",
      "Ep:99, loss:0.00001, loss_test:0.08960, lr:8.51e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.742, tt:3074.244\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00001, loss_test:0.09204, lr:8.51e-03, fs:0.81176 (r=0.697,p=0.972),  time:30.748, tt:3105.556\n",
      "Ep:101, loss:0.00001, loss_test:0.08548, lr:8.51e-03, fs:0.84444 (r=0.768,p=0.938),  time:30.756, tt:3137.103\n",
      "Ep:102, loss:0.00001, loss_test:0.09331, lr:8.51e-03, fs:0.82081 (r=0.717,p=0.959),  time:30.787, tt:3171.095\n",
      "Ep:103, loss:0.00001, loss_test:0.09055, lr:8.51e-03, fs:0.85227 (r=0.758,p=0.974),  time:30.793, tt:3202.482\n",
      "Ep:104, loss:0.00001, loss_test:0.09173, lr:8.51e-03, fs:0.81871 (r=0.707,p=0.972),  time:30.801, tt:3234.070\n",
      "Ep:105, loss:0.00001, loss_test:0.09473, lr:8.51e-03, fs:0.81176 (r=0.697,p=0.972),  time:30.796, tt:3264.354\n",
      "Ep:106, loss:0.00001, loss_test:0.09360, lr:8.51e-03, fs:0.81176 (r=0.697,p=0.972),  time:30.792, tt:3294.794\n",
      "Ep:107, loss:0.00001, loss_test:0.08951, lr:8.51e-03, fs:0.85227 (r=0.758,p=0.974),  time:30.804, tt:3326.812\n",
      "Ep:108, loss:0.00001, loss_test:0.09095, lr:8.51e-03, fs:0.83429 (r=0.737,p=0.961),  time:30.810, tt:3358.252\n",
      "Ep:109, loss:0.00001, loss_test:0.09414, lr:8.51e-03, fs:0.80473 (r=0.687,p=0.971),  time:30.815, tt:3389.597\n",
      "Ep:110, loss:0.00001, loss_test:0.09160, lr:8.51e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.808, tt:3419.679\n",
      "Ep:111, loss:0.00001, loss_test:0.09172, lr:8.43e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.810, tt:3450.734\n",
      "Ep:112, loss:0.00001, loss_test:0.09394, lr:8.35e-03, fs:0.81176 (r=0.697,p=0.972),  time:30.810, tt:3481.579\n",
      "Ep:113, loss:0.00001, loss_test:0.09050, lr:8.26e-03, fs:0.85227 (r=0.758,p=0.974),  time:30.814, tt:3512.836\n",
      "Ep:114, loss:0.00001, loss_test:0.08891, lr:8.18e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.820, tt:3544.282\n",
      "Ep:115, loss:0.00001, loss_test:0.09346, lr:8.10e-03, fs:0.81176 (r=0.697,p=0.972),  time:30.822, tt:3575.362\n",
      "Ep:116, loss:0.00001, loss_test:0.09249, lr:8.02e-03, fs:0.82558 (r=0.717,p=0.973),  time:30.826, tt:3606.640\n",
      "Ep:117, loss:0.00001, loss_test:0.10258, lr:7.94e-03, fs:0.79762 (r=0.677,p=0.971),  time:30.839, tt:3638.956\n",
      "Ep:118, loss:0.00001, loss_test:0.09170, lr:7.86e-03, fs:0.84571 (r=0.747,p=0.974),  time:30.834, tt:3669.280\n",
      "Ep:119, loss:0.00001, loss_test:0.09287, lr:7.78e-03, fs:0.83908 (r=0.737,p=0.973),  time:30.842, tt:3701.076\n",
      "Ep:120, loss:0.00001, loss_test:0.09185, lr:7.70e-03, fs:0.83908 (r=0.737,p=0.973),  time:30.854, tt:3733.373\n",
      "Ep:121, loss:0.00001, loss_test:0.09865, lr:7.62e-03, fs:0.80702 (r=0.697,p=0.958),  time:30.870, tt:3766.145\n",
      "Ep:122, loss:0.00001, loss_test:0.09273, lr:7.55e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.879, tt:3798.097\n",
      "##########Best model found so far##########\n",
      "Ep:123, loss:0.00001, loss_test:0.09972, lr:7.55e-03, fs:0.80702 (r=0.697,p=0.958),  time:30.900, tt:3831.545\n",
      "Ep:124, loss:0.00001, loss_test:0.09198, lr:7.55e-03, fs:0.86034 (r=0.778,p=0.963),  time:30.938, tt:3867.231\n",
      "Ep:125, loss:0.00001, loss_test:0.10107, lr:7.55e-03, fs:0.80702 (r=0.697,p=0.958),  time:30.945, tt:3899.011\n",
      "Ep:126, loss:0.00001, loss_test:0.09554, lr:7.55e-03, fs:0.81176 (r=0.697,p=0.972),  time:30.959, tt:3931.792\n",
      "Ep:127, loss:0.00001, loss_test:0.09398, lr:7.55e-03, fs:0.84270 (r=0.758,p=0.949),  time:30.959, tt:3962.729\n",
      "Ep:128, loss:0.00001, loss_test:0.09859, lr:7.55e-03, fs:0.83908 (r=0.737,p=0.973),  time:30.969, tt:3995.053\n",
      "Ep:129, loss:0.00001, loss_test:0.09731, lr:7.55e-03, fs:0.82558 (r=0.717,p=0.973),  time:30.981, tt:4027.581\n",
      "Ep:130, loss:0.00000, loss_test:0.09495, lr:7.55e-03, fs:0.84571 (r=0.747,p=0.974),  time:30.992, tt:4059.976\n",
      "Ep:131, loss:0.00000, loss_test:0.09569, lr:7.55e-03, fs:0.85227 (r=0.758,p=0.974),  time:30.996, tt:4091.422\n",
      "Ep:132, loss:0.00000, loss_test:0.09574, lr:7.55e-03, fs:0.81176 (r=0.697,p=0.972),  time:30.999, tt:4122.930\n",
      "Ep:133, loss:0.00000, loss_test:0.09715, lr:7.55e-03, fs:0.83237 (r=0.727,p=0.973),  time:30.999, tt:4153.844\n",
      "Ep:134, loss:0.00000, loss_test:0.09257, lr:7.47e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.006, tt:4185.832\n",
      "Ep:135, loss:0.00000, loss_test:0.09947, lr:7.40e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.012, tt:4217.593\n",
      "Ep:136, loss:0.00000, loss_test:0.09890, lr:7.32e-03, fs:0.80702 (r=0.697,p=0.958),  time:31.013, tt:4248.748\n",
      "Ep:137, loss:0.00000, loss_test:0.09635, lr:7.25e-03, fs:0.83237 (r=0.727,p=0.973),  time:31.028, tt:4281.888\n",
      "Ep:138, loss:0.00000, loss_test:0.09542, lr:7.18e-03, fs:0.83237 (r=0.727,p=0.973),  time:31.033, tt:4313.652\n",
      "Ep:139, loss:0.00000, loss_test:0.09913, lr:7.11e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.040, tt:4345.649\n",
      "Ep:140, loss:0.00000, loss_test:0.09692, lr:7.03e-03, fs:0.81871 (r=0.707,p=0.972),  time:31.039, tt:4376.527\n",
      "Ep:141, loss:0.00000, loss_test:0.09378, lr:6.96e-03, fs:0.85227 (r=0.758,p=0.974),  time:31.041, tt:4407.832\n",
      "Ep:142, loss:0.00000, loss_test:0.09819, lr:6.89e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.039, tt:4438.526\n",
      "Ep:143, loss:0.00000, loss_test:0.09585, lr:6.83e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.039, tt:4469.549\n",
      "Ep:144, loss:0.00000, loss_test:0.09914, lr:6.76e-03, fs:0.81871 (r=0.707,p=0.972),  time:31.047, tt:4501.797\n",
      "Ep:145, loss:0.00000, loss_test:0.09496, lr:6.69e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.046, tt:4532.785\n",
      "Ep:146, loss:0.00000, loss_test:0.09734, lr:6.62e-03, fs:0.83237 (r=0.727,p=0.973),  time:31.043, tt:4563.250\n",
      "Ep:147, loss:0.00000, loss_test:0.09800, lr:6.56e-03, fs:0.81871 (r=0.707,p=0.972),  time:31.071, tt:4598.498\n",
      "Ep:148, loss:0.00000, loss_test:0.09923, lr:6.49e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.074, tt:4629.957\n",
      "Ep:149, loss:0.00000, loss_test:0.09665, lr:6.43e-03, fs:0.84571 (r=0.747,p=0.974),  time:31.074, tt:4661.133\n",
      "Ep:150, loss:0.00000, loss_test:0.09578, lr:6.36e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.068, tt:4691.328\n",
      "Ep:151, loss:0.00000, loss_test:0.09596, lr:6.30e-03, fs:0.84571 (r=0.747,p=0.974),  time:31.056, tt:4720.573\n",
      "Ep:152, loss:0.00000, loss_test:0.10005, lr:6.24e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.043, tt:4749.517\n",
      "Ep:153, loss:0.00000, loss_test:0.09706, lr:6.17e-03, fs:0.85227 (r=0.758,p=0.974),  time:31.056, tt:4782.584\n",
      "Ep:154, loss:0.00000, loss_test:0.09684, lr:6.11e-03, fs:0.85227 (r=0.758,p=0.974),  time:31.057, tt:4813.891\n",
      "Ep:155, loss:0.00000, loss_test:0.10319, lr:6.05e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.062, tt:4845.750\n",
      "Ep:156, loss:0.00000, loss_test:0.09944, lr:5.99e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.058, tt:4876.135\n",
      "Ep:157, loss:0.00000, loss_test:0.09933, lr:5.93e-03, fs:0.84746 (r=0.758,p=0.962),  time:31.056, tt:4906.804\n",
      "Ep:158, loss:0.00000, loss_test:0.09449, lr:5.87e-03, fs:0.84746 (r=0.758,p=0.962),  time:31.056, tt:4937.869\n",
      "Ep:159, loss:0.00000, loss_test:0.10195, lr:5.81e-03, fs:0.79042 (r=0.667,p=0.971),  time:31.063, tt:4970.152\n",
      "Ep:160, loss:0.00000, loss_test:0.09836, lr:5.75e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.068, tt:5001.926\n",
      "Ep:161, loss:0.00000, loss_test:0.09695, lr:5.70e-03, fs:0.82558 (r=0.717,p=0.973),  time:31.065, tt:5032.543\n",
      "Ep:162, loss:0.00000, loss_test:0.10001, lr:5.64e-03, fs:0.82558 (r=0.717,p=0.973),  time:31.058, tt:5062.447\n",
      "Ep:163, loss:0.00000, loss_test:0.09529, lr:5.58e-03, fs:0.81871 (r=0.707,p=0.972),  time:31.056, tt:5093.136\n",
      "Ep:164, loss:0.00000, loss_test:0.09752, lr:5.53e-03, fs:0.82558 (r=0.717,p=0.973),  time:31.053, tt:5123.824\n",
      "Ep:165, loss:0.00000, loss_test:0.09756, lr:5.47e-03, fs:0.83237 (r=0.727,p=0.973),  time:31.048, tt:5153.955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:166, loss:0.00000, loss_test:0.09529, lr:5.42e-03, fs:0.82558 (r=0.717,p=0.973),  time:31.048, tt:5185.079\n",
      "Ep:167, loss:0.00000, loss_test:0.09783, lr:5.36e-03, fs:0.81871 (r=0.707,p=0.972),  time:31.047, tt:5215.937\n",
      "Ep:168, loss:0.00000, loss_test:0.09992, lr:5.31e-03, fs:0.83237 (r=0.727,p=0.973),  time:31.045, tt:5246.526\n",
      "Ep:169, loss:0.00000, loss_test:0.09733, lr:5.26e-03, fs:0.81871 (r=0.707,p=0.972),  time:31.042, tt:5277.150\n",
      "Ep:170, loss:0.00000, loss_test:0.09873, lr:5.20e-03, fs:0.83237 (r=0.727,p=0.973),  time:31.037, tt:5307.276\n",
      "Ep:171, loss:0.00000, loss_test:0.09646, lr:5.15e-03, fs:0.83908 (r=0.737,p=0.973),  time:31.041, tt:5339.131\n",
      "Ep:172, loss:0.00000, loss_test:0.09681, lr:5.10e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.033, tt:5368.750\n",
      "Ep:173, loss:0.00000, loss_test:0.09833, lr:5.05e-03, fs:0.83908 (r=0.737,p=0.973),  time:31.027, tt:5398.614\n",
      "Ep:174, loss:0.00000, loss_test:0.09535, lr:5.00e-03, fs:0.82558 (r=0.717,p=0.973),  time:31.025, tt:5429.404\n",
      "Ep:175, loss:0.00000, loss_test:0.09828, lr:4.95e-03, fs:0.85227 (r=0.758,p=0.974),  time:31.025, tt:5460.431\n",
      "Ep:176, loss:0.00000, loss_test:0.09662, lr:4.90e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.025, tt:5491.415\n",
      "Ep:177, loss:0.00000, loss_test:0.09771, lr:4.85e-03, fs:0.82558 (r=0.717,p=0.973),  time:31.031, tt:5523.565\n",
      "Ep:178, loss:0.00000, loss_test:0.09900, lr:4.80e-03, fs:0.82558 (r=0.717,p=0.973),  time:31.035, tt:5555.237\n",
      "Ep:179, loss:0.00000, loss_test:0.09865, lr:4.75e-03, fs:0.84571 (r=0.747,p=0.974),  time:31.031, tt:5585.565\n",
      "Ep:180, loss:0.00000, loss_test:0.09672, lr:4.71e-03, fs:0.83237 (r=0.727,p=0.973),  time:31.039, tt:5618.137\n",
      "Ep:181, loss:0.00000, loss_test:0.09794, lr:4.66e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.050, tt:5651.052\n",
      "Ep:182, loss:0.00000, loss_test:0.09555, lr:4.61e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.053, tt:5682.781\n",
      "Ep:183, loss:0.00000, loss_test:0.09607, lr:4.57e-03, fs:0.83908 (r=0.737,p=0.973),  time:31.057, tt:5714.477\n",
      "Ep:184, loss:0.00000, loss_test:0.09948, lr:4.52e-03, fs:0.84571 (r=0.747,p=0.974),  time:31.063, tt:5746.741\n",
      "Ep:185, loss:0.00000, loss_test:0.09715, lr:4.48e-03, fs:0.82558 (r=0.717,p=0.973),  time:31.068, tt:5778.617\n",
      "Ep:186, loss:0.00000, loss_test:0.09788, lr:4.43e-03, fs:0.84571 (r=0.747,p=0.974),  time:31.068, tt:5809.645\n",
      "Ep:187, loss:0.00000, loss_test:0.09740, lr:4.39e-03, fs:0.82558 (r=0.717,p=0.973),  time:31.066, tt:5840.438\n",
      "Ep:188, loss:0.00000, loss_test:0.09742, lr:4.34e-03, fs:0.82558 (r=0.717,p=0.973),  time:31.065, tt:5871.323\n",
      "Ep:189, loss:0.00000, loss_test:0.09815, lr:4.30e-03, fs:0.83908 (r=0.737,p=0.973),  time:31.063, tt:5902.011\n",
      "Ep:190, loss:0.00000, loss_test:0.09673, lr:4.26e-03, fs:0.83908 (r=0.737,p=0.973),  time:31.061, tt:5932.643\n",
      "Ep:191, loss:0.00000, loss_test:0.09717, lr:4.21e-03, fs:0.85227 (r=0.758,p=0.974),  time:31.056, tt:5962.839\n",
      "Ep:192, loss:0.00000, loss_test:0.09720, lr:4.17e-03, fs:0.85227 (r=0.758,p=0.974),  time:31.058, tt:5994.263\n",
      "Ep:193, loss:0.00000, loss_test:0.09707, lr:4.13e-03, fs:0.82558 (r=0.717,p=0.973),  time:31.060, tt:6025.604\n",
      "Ep:194, loss:0.00000, loss_test:0.09612, lr:4.09e-03, fs:0.84571 (r=0.747,p=0.974),  time:31.066, tt:6057.926\n",
      "Ep:195, loss:0.00000, loss_test:0.09683, lr:4.05e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.071, tt:6089.908\n",
      "Ep:196, loss:0.00000, loss_test:0.09500, lr:4.01e-03, fs:0.82558 (r=0.717,p=0.973),  time:31.071, tt:6121.023\n",
      "Ep:197, loss:0.00000, loss_test:0.09912, lr:3.97e-03, fs:0.79042 (r=0.667,p=0.971),  time:31.053, tt:6148.535\n",
      "Ep:198, loss:0.00000, loss_test:0.09832, lr:3.93e-03, fs:0.81871 (r=0.707,p=0.972),  time:31.037, tt:6176.283\n",
      "Ep:199, loss:0.00000, loss_test:0.09589, lr:3.89e-03, fs:0.82558 (r=0.717,p=0.973),  time:31.014, tt:6202.800\n",
      "Ep:200, loss:0.00000, loss_test:0.09885, lr:3.85e-03, fs:0.85227 (r=0.758,p=0.974),  time:30.987, tt:6228.388\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02025, lr:6.00e-02, fs:0.65882 (r=0.848,p=0.538),  time:21.371, tt:21.371\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02260, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.029, tt:46.057\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02458, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.480, tt:73.439\n",
      "Ep:3, loss:0.00005, loss_test:0.02495, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.454, tt:105.817\n",
      "Ep:4, loss:0.00005, loss_test:0.02438, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.305, tt:136.524\n",
      "Ep:5, loss:0.00005, loss_test:0.02332, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.814, tt:166.886\n",
      "Ep:6, loss:0.00004, loss_test:0.02186, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.919, tt:195.433\n",
      "Ep:7, loss:0.00004, loss_test:0.02025, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:28.219, tt:225.751\n",
      "Ep:8, loss:0.00004, loss_test:0.01893, lr:6.00e-02, fs:0.68364 (r=0.949,p=0.534),  time:28.567, tt:257.099\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01817, lr:6.00e-02, fs:0.68966 (r=0.909,p=0.556),  time:28.763, tt:287.628\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01783, lr:6.00e-02, fs:0.69323 (r=0.879,p=0.572),  time:28.894, tt:317.833\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01756, lr:6.00e-02, fs:0.71545 (r=0.889,p=0.599),  time:29.029, tt:348.351\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01732, lr:6.00e-02, fs:0.73810 (r=0.939,p=0.608),  time:29.131, tt:378.705\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01721, lr:6.00e-02, fs:0.72308 (r=0.949,p=0.584),  time:29.214, tt:409.002\n",
      "Ep:14, loss:0.00003, loss_test:0.01706, lr:6.00e-02, fs:0.72453 (r=0.970,p=0.578),  time:29.362, tt:440.424\n",
      "Ep:15, loss:0.00003, loss_test:0.01682, lr:6.00e-02, fs:0.72453 (r=0.970,p=0.578),  time:29.473, tt:471.567\n",
      "Ep:16, loss:0.00003, loss_test:0.01655, lr:6.00e-02, fs:0.73846 (r=0.970,p=0.596),  time:29.547, tt:502.294\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01633, lr:6.00e-02, fs:0.75889 (r=0.970,p=0.623),  time:29.625, tt:533.253\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01618, lr:6.00e-02, fs:0.76923 (r=0.960,p=0.642),  time:29.701, tt:564.310\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01603, lr:6.00e-02, fs:0.77551 (r=0.960,p=0.651),  time:29.773, tt:595.452\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01585, lr:6.00e-02, fs:0.77551 (r=0.960,p=0.651),  time:29.870, tt:627.280\n",
      "Ep:21, loss:0.00003, loss_test:0.01568, lr:6.00e-02, fs:0.78367 (r=0.970,p=0.658),  time:29.903, tt:657.867\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01556, lr:6.00e-02, fs:0.79012 (r=0.970,p=0.667),  time:29.867, tt:686.940\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01543, lr:6.00e-02, fs:0.79012 (r=0.970,p=0.667),  time:29.872, tt:716.921\n",
      "Ep:24, loss:0.00003, loss_test:0.01531, lr:6.00e-02, fs:0.79668 (r=0.970,p=0.676),  time:29.891, tt:747.283\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01523, lr:6.00e-02, fs:0.79668 (r=0.970,p=0.676),  time:29.858, tt:776.308\n",
      "Ep:26, loss:0.00003, loss_test:0.01517, lr:6.00e-02, fs:0.79167 (r=0.960,p=0.674),  time:29.837, tt:805.592\n",
      "Ep:27, loss:0.00002, loss_test:0.01509, lr:6.00e-02, fs:0.78481 (r=0.939,p=0.674),  time:29.868, tt:836.311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:28, loss:0.00002, loss_test:0.01499, lr:6.00e-02, fs:0.78632 (r=0.929,p=0.681),  time:29.896, tt:866.982\n",
      "Ep:29, loss:0.00002, loss_test:0.01487, lr:6.00e-02, fs:0.78112 (r=0.919,p=0.679),  time:29.917, tt:897.511\n",
      "Ep:30, loss:0.00002, loss_test:0.01475, lr:6.00e-02, fs:0.78448 (r=0.919,p=0.684),  time:29.953, tt:928.534\n",
      "Ep:31, loss:0.00002, loss_test:0.01466, lr:6.00e-02, fs:0.78788 (r=0.919,p=0.689),  time:30.011, tt:960.347\n",
      "Ep:32, loss:0.00002, loss_test:0.01458, lr:6.00e-02, fs:0.78788 (r=0.919,p=0.689),  time:30.040, tt:991.310\n",
      "Ep:33, loss:0.00002, loss_test:0.01451, lr:6.00e-02, fs:0.78448 (r=0.919,p=0.684),  time:30.045, tt:1021.521\n",
      "Ep:34, loss:0.00002, loss_test:0.01444, lr:6.00e-02, fs:0.78788 (r=0.919,p=0.689),  time:30.043, tt:1051.503\n",
      "Ep:35, loss:0.00002, loss_test:0.01438, lr:6.00e-02, fs:0.79476 (r=0.919,p=0.700),  time:30.078, tt:1082.806\n",
      "Ep:36, loss:0.00002, loss_test:0.01431, lr:5.94e-02, fs:0.78947 (r=0.909,p=0.698),  time:30.104, tt:1113.838\n",
      "Ep:37, loss:0.00002, loss_test:0.01425, lr:5.88e-02, fs:0.79295 (r=0.909,p=0.703),  time:30.096, tt:1143.645\n",
      "Ep:38, loss:0.00002, loss_test:0.01417, lr:5.82e-02, fs:0.79295 (r=0.909,p=0.703),  time:30.079, tt:1173.100\n",
      "Ep:39, loss:0.00002, loss_test:0.01412, lr:5.76e-02, fs:0.78761 (r=0.899,p=0.701),  time:30.055, tt:1202.208\n",
      "Ep:40, loss:0.00002, loss_test:0.01407, lr:5.71e-02, fs:0.78222 (r=0.889,p=0.698),  time:30.029, tt:1231.190\n",
      "Ep:41, loss:0.00002, loss_test:0.01401, lr:5.65e-02, fs:0.78222 (r=0.889,p=0.698),  time:30.024, tt:1261.001\n",
      "Ep:42, loss:0.00002, loss_test:0.01396, lr:5.59e-02, fs:0.78222 (r=0.889,p=0.698),  time:30.033, tt:1291.433\n",
      "Ep:43, loss:0.00002, loss_test:0.01392, lr:5.54e-02, fs:0.78222 (r=0.889,p=0.698),  time:30.052, tt:1322.284\n",
      "Ep:44, loss:0.00002, loss_test:0.01387, lr:5.48e-02, fs:0.78222 (r=0.889,p=0.698),  time:30.129, tt:1355.815\n",
      "Ep:45, loss:0.00002, loss_test:0.01383, lr:5.43e-02, fs:0.78924 (r=0.889,p=0.710),  time:30.190, tt:1388.718\n",
      "Ep:46, loss:0.00002, loss_test:0.01379, lr:5.37e-02, fs:0.78924 (r=0.889,p=0.710),  time:30.206, tt:1419.661\n",
      "Ep:47, loss:0.00002, loss_test:0.01375, lr:5.32e-02, fs:0.78924 (r=0.889,p=0.710),  time:30.248, tt:1451.900\n",
      "Ep:48, loss:0.00002, loss_test:0.01371, lr:5.27e-02, fs:0.78924 (r=0.889,p=0.710),  time:30.257, tt:1482.604\n",
      "Ep:49, loss:0.00002, loss_test:0.01367, lr:5.21e-02, fs:0.78924 (r=0.889,p=0.710),  time:30.268, tt:1513.399\n",
      "Ep:50, loss:0.00002, loss_test:0.01365, lr:5.16e-02, fs:0.78924 (r=0.889,p=0.710),  time:30.297, tt:1545.162\n",
      "Ep:51, loss:0.00002, loss_test:0.01362, lr:5.11e-02, fs:0.78924 (r=0.889,p=0.710),  time:30.285, tt:1574.811\n",
      "Ep:52, loss:0.00002, loss_test:0.01358, lr:5.06e-02, fs:0.78924 (r=0.889,p=0.710),  time:30.315, tt:1606.719\n",
      "Ep:53, loss:0.00002, loss_test:0.01356, lr:5.01e-02, fs:0.78924 (r=0.889,p=0.710),  time:30.350, tt:1638.906\n",
      "Ep:54, loss:0.00002, loss_test:0.01353, lr:4.96e-02, fs:0.78924 (r=0.889,p=0.710),  time:30.361, tt:1669.873\n",
      "Ep:55, loss:0.00002, loss_test:0.01351, lr:4.91e-02, fs:0.78924 (r=0.889,p=0.710),  time:30.428, tt:1703.980\n",
      "Ep:56, loss:0.00002, loss_test:0.01350, lr:4.86e-02, fs:0.79279 (r=0.889,p=0.715),  time:30.439, tt:1735.003\n",
      "Ep:57, loss:0.00002, loss_test:0.01346, lr:4.81e-02, fs:0.79638 (r=0.889,p=0.721),  time:30.462, tt:1766.810\n",
      "Ep:58, loss:0.00002, loss_test:0.01345, lr:4.76e-02, fs:0.80365 (r=0.889,p=0.733),  time:30.467, tt:1797.555\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00002, loss_test:0.01344, lr:4.76e-02, fs:0.80000 (r=0.889,p=0.727),  time:30.485, tt:1829.089\n",
      "Ep:60, loss:0.00002, loss_test:0.01342, lr:4.76e-02, fs:0.80000 (r=0.889,p=0.727),  time:30.503, tt:1860.692\n",
      "Ep:61, loss:0.00002, loss_test:0.01340, lr:4.76e-02, fs:0.80184 (r=0.879,p=0.737),  time:30.494, tt:1890.599\n",
      "Ep:62, loss:0.00001, loss_test:0.01338, lr:4.76e-02, fs:0.80184 (r=0.879,p=0.737),  time:30.497, tt:1921.303\n",
      "Ep:63, loss:0.00001, loss_test:0.01336, lr:4.76e-02, fs:0.80184 (r=0.879,p=0.737),  time:30.504, tt:1952.226\n",
      "Ep:64, loss:0.00001, loss_test:0.01333, lr:4.76e-02, fs:0.80184 (r=0.879,p=0.737),  time:30.500, tt:1982.477\n",
      "Ep:65, loss:0.00001, loss_test:0.01328, lr:4.76e-02, fs:0.80184 (r=0.879,p=0.737),  time:30.507, tt:2013.475\n",
      "Ep:66, loss:0.00001, loss_test:0.01325, lr:4.76e-02, fs:0.80184 (r=0.879,p=0.737),  time:30.527, tt:2045.326\n",
      "Ep:67, loss:0.00001, loss_test:0.01323, lr:4.76e-02, fs:0.80184 (r=0.879,p=0.737),  time:30.555, tt:2077.757\n",
      "Ep:68, loss:0.00001, loss_test:0.01320, lr:4.76e-02, fs:0.79630 (r=0.869,p=0.735),  time:30.554, tt:2108.257\n",
      "Ep:69, loss:0.00001, loss_test:0.01318, lr:4.76e-02, fs:0.79630 (r=0.869,p=0.735),  time:30.556, tt:2138.904\n",
      "Ep:70, loss:0.00001, loss_test:0.01316, lr:4.71e-02, fs:0.79630 (r=0.869,p=0.735),  time:30.575, tt:2170.846\n",
      "Ep:71, loss:0.00001, loss_test:0.01314, lr:4.67e-02, fs:0.80000 (r=0.869,p=0.741),  time:30.579, tt:2201.717\n",
      "Ep:72, loss:0.00001, loss_test:0.01313, lr:4.62e-02, fs:0.80000 (r=0.869,p=0.741),  time:30.612, tt:2234.659\n",
      "Ep:73, loss:0.00001, loss_test:0.01310, lr:4.57e-02, fs:0.80000 (r=0.869,p=0.741),  time:30.629, tt:2266.551\n",
      "Ep:74, loss:0.00001, loss_test:0.01308, lr:4.53e-02, fs:0.78873 (r=0.848,p=0.737),  time:30.626, tt:2296.948\n",
      "Ep:75, loss:0.00001, loss_test:0.01305, lr:4.48e-02, fs:0.78873 (r=0.848,p=0.737),  time:30.643, tt:2328.904\n",
      "Ep:76, loss:0.00001, loss_test:0.01304, lr:4.44e-02, fs:0.78873 (r=0.848,p=0.737),  time:30.660, tt:2360.848\n",
      "Ep:77, loss:0.00001, loss_test:0.01301, lr:4.39e-02, fs:0.78873 (r=0.848,p=0.737),  time:30.664, tt:2391.818\n",
      "Ep:78, loss:0.00001, loss_test:0.01300, lr:4.35e-02, fs:0.78873 (r=0.848,p=0.737),  time:30.690, tt:2424.492\n",
      "Ep:79, loss:0.00001, loss_test:0.01298, lr:4.31e-02, fs:0.78873 (r=0.848,p=0.737),  time:30.704, tt:2456.328\n",
      "Ep:80, loss:0.00001, loss_test:0.01297, lr:4.26e-02, fs:0.78873 (r=0.848,p=0.737),  time:30.705, tt:2487.133\n",
      "Ep:81, loss:0.00001, loss_test:0.01295, lr:4.22e-02, fs:0.78873 (r=0.848,p=0.737),  time:30.716, tt:2518.708\n",
      "Ep:82, loss:0.00001, loss_test:0.01293, lr:4.18e-02, fs:0.78873 (r=0.848,p=0.737),  time:30.744, tt:2551.758\n",
      "Ep:83, loss:0.00001, loss_test:0.01290, lr:4.14e-02, fs:0.78873 (r=0.848,p=0.737),  time:30.754, tt:2583.314\n",
      "Ep:84, loss:0.00001, loss_test:0.01288, lr:4.10e-02, fs:0.78873 (r=0.848,p=0.737),  time:30.767, tt:2615.233\n",
      "Ep:85, loss:0.00001, loss_test:0.01287, lr:4.05e-02, fs:0.78873 (r=0.848,p=0.737),  time:30.787, tt:2647.720\n",
      "Ep:86, loss:0.00001, loss_test:0.01287, lr:4.01e-02, fs:0.79245 (r=0.848,p=0.743),  time:30.790, tt:2678.691\n",
      "Ep:87, loss:0.00001, loss_test:0.01286, lr:3.97e-02, fs:0.79245 (r=0.848,p=0.743),  time:30.785, tt:2709.050\n",
      "Ep:88, loss:0.00001, loss_test:0.01285, lr:3.93e-02, fs:0.79245 (r=0.848,p=0.743),  time:30.798, tt:2741.029\n",
      "Ep:89, loss:0.00001, loss_test:0.01282, lr:3.89e-02, fs:0.79245 (r=0.848,p=0.743),  time:30.791, tt:2771.213\n",
      "Ep:90, loss:0.00001, loss_test:0.01279, lr:3.86e-02, fs:0.79245 (r=0.848,p=0.743),  time:30.796, tt:2802.400\n",
      "Ep:91, loss:0.00001, loss_test:0.01279, lr:3.82e-02, fs:0.79245 (r=0.848,p=0.743),  time:30.795, tt:2833.182\n",
      "Ep:92, loss:0.00001, loss_test:0.01281, lr:3.78e-02, fs:0.78673 (r=0.838,p=0.741),  time:30.810, tt:2865.290\n",
      "Ep:93, loss:0.00001, loss_test:0.01282, lr:3.74e-02, fs:0.78673 (r=0.838,p=0.741),  time:30.812, tt:2896.333\n",
      "Ep:94, loss:0.00001, loss_test:0.01279, lr:3.70e-02, fs:0.78673 (r=0.838,p=0.741),  time:30.822, tt:2928.132\n",
      "Ep:95, loss:0.00001, loss_test:0.01276, lr:3.67e-02, fs:0.78673 (r=0.838,p=0.741),  time:30.826, tt:2959.300\n",
      "Ep:96, loss:0.00001, loss_test:0.01276, lr:3.63e-02, fs:0.78673 (r=0.838,p=0.741),  time:30.830, tt:2990.496\n",
      "Ep:97, loss:0.00001, loss_test:0.01275, lr:3.59e-02, fs:0.78673 (r=0.838,p=0.741),  time:30.846, tt:3022.887\n",
      "Ep:98, loss:0.00001, loss_test:0.01273, lr:3.56e-02, fs:0.78673 (r=0.838,p=0.741),  time:30.854, tt:3054.585\n",
      "Ep:99, loss:0.00001, loss_test:0.01273, lr:3.52e-02, fs:0.79245 (r=0.848,p=0.743),  time:30.861, tt:3086.116\n",
      "Ep:100, loss:0.00001, loss_test:0.01273, lr:3.49e-02, fs:0.79621 (r=0.848,p=0.750),  time:30.877, tt:3118.572\n",
      "Ep:101, loss:0.00001, loss_test:0.01274, lr:3.45e-02, fs:0.80000 (r=0.848,p=0.757),  time:30.889, tt:3150.694\n",
      "Ep:102, loss:0.00001, loss_test:0.01273, lr:3.42e-02, fs:0.80000 (r=0.848,p=0.757),  time:30.892, tt:3181.841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:103, loss:0.00001, loss_test:0.01273, lr:3.38e-02, fs:0.80000 (r=0.848,p=0.757),  time:30.904, tt:3214.047\n",
      "Ep:104, loss:0.00001, loss_test:0.01273, lr:3.35e-02, fs:0.80383 (r=0.848,p=0.764),  time:30.912, tt:3245.806\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00001, loss_test:0.01274, lr:3.35e-02, fs:0.80383 (r=0.848,p=0.764),  time:30.909, tt:3276.367\n",
      "Ep:106, loss:0.00001, loss_test:0.01272, lr:3.35e-02, fs:0.80383 (r=0.848,p=0.764),  time:30.922, tt:3308.678\n",
      "Ep:107, loss:0.00001, loss_test:0.01270, lr:3.35e-02, fs:0.80383 (r=0.848,p=0.764),  time:30.924, tt:3339.758\n",
      "Ep:108, loss:0.00001, loss_test:0.01269, lr:3.35e-02, fs:0.80383 (r=0.848,p=0.764),  time:30.938, tt:3372.274\n",
      "Ep:109, loss:0.00001, loss_test:0.01269, lr:3.35e-02, fs:0.79227 (r=0.828,p=0.759),  time:30.944, tt:3403.788\n",
      "Ep:110, loss:0.00001, loss_test:0.01268, lr:3.35e-02, fs:0.79227 (r=0.828,p=0.759),  time:30.949, tt:3435.339\n",
      "Ep:111, loss:0.00001, loss_test:0.01268, lr:3.35e-02, fs:0.79612 (r=0.828,p=0.766),  time:30.958, tt:3467.297\n",
      "Ep:112, loss:0.00001, loss_test:0.01269, lr:3.35e-02, fs:0.79612 (r=0.828,p=0.766),  time:30.957, tt:3498.168\n",
      "Ep:113, loss:0.00001, loss_test:0.01268, lr:3.35e-02, fs:0.80000 (r=0.828,p=0.774),  time:30.952, tt:3528.555\n",
      "Ep:114, loss:0.00001, loss_test:0.01268, lr:3.35e-02, fs:0.80000 (r=0.828,p=0.774),  time:30.980, tt:3562.689\n",
      "Ep:115, loss:0.00001, loss_test:0.01267, lr:3.35e-02, fs:0.80000 (r=0.828,p=0.774),  time:30.989, tt:3594.748\n",
      "Ep:116, loss:0.00001, loss_test:0.01267, lr:3.32e-02, fs:0.80000 (r=0.828,p=0.774),  time:30.994, tt:3626.330\n",
      "Ep:117, loss:0.00001, loss_test:0.01266, lr:3.28e-02, fs:0.80000 (r=0.828,p=0.774),  time:30.988, tt:3656.593\n",
      "Ep:118, loss:0.00001, loss_test:0.01268, lr:3.25e-02, fs:0.80000 (r=0.828,p=0.774),  time:30.983, tt:3686.936\n",
      "Ep:119, loss:0.00001, loss_test:0.01265, lr:3.22e-02, fs:0.80000 (r=0.828,p=0.774),  time:30.985, tt:3718.157\n",
      "Ep:120, loss:0.00001, loss_test:0.01264, lr:3.19e-02, fs:0.80000 (r=0.828,p=0.774),  time:30.992, tt:3750.059\n",
      "Ep:121, loss:0.00001, loss_test:0.01264, lr:3.15e-02, fs:0.80000 (r=0.828,p=0.774),  time:30.980, tt:3779.562\n",
      "Ep:122, loss:0.00001, loss_test:0.01266, lr:3.12e-02, fs:0.80000 (r=0.828,p=0.774),  time:30.990, tt:3811.721\n",
      "Ep:123, loss:0.00001, loss_test:0.01266, lr:3.09e-02, fs:0.80000 (r=0.828,p=0.774),  time:30.993, tt:3843.120\n",
      "Ep:124, loss:0.00001, loss_test:0.01267, lr:3.06e-02, fs:0.80000 (r=0.828,p=0.774),  time:30.994, tt:3874.224\n",
      "Ep:125, loss:0.00001, loss_test:0.01266, lr:3.03e-02, fs:0.80000 (r=0.828,p=0.774),  time:31.005, tt:3906.622\n",
      "Ep:126, loss:0.00001, loss_test:0.01266, lr:3.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:31.017, tt:3939.185\n",
      "##########Best model found so far##########\n",
      "Ep:127, loss:0.00001, loss_test:0.01267, lr:3.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:31.025, tt:3971.153\n",
      "Ep:128, loss:0.00001, loss_test:0.01268, lr:3.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:31.016, tt:4001.112\n",
      "Ep:129, loss:0.00001, loss_test:0.01269, lr:3.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:31.013, tt:4031.747\n",
      "Ep:130, loss:0.00001, loss_test:0.01269, lr:3.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:31.014, tt:4062.878\n",
      "Ep:131, loss:0.00001, loss_test:0.01267, lr:3.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:31.010, tt:4093.317\n",
      "Ep:132, loss:0.00001, loss_test:0.01266, lr:3.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:31.010, tt:4124.285\n",
      "Ep:133, loss:0.00001, loss_test:0.01266, lr:3.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:31.006, tt:4154.782\n",
      "Ep:134, loss:0.00001, loss_test:0.01267, lr:3.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:30.983, tt:4182.726\n",
      "Ep:135, loss:0.00001, loss_test:0.01267, lr:3.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:30.982, tt:4213.584\n",
      "Ep:136, loss:0.00001, loss_test:0.01268, lr:3.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:31.010, tt:4248.359\n",
      "Ep:137, loss:0.00001, loss_test:0.01267, lr:3.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:31.009, tt:4279.186\n",
      "Ep:138, loss:0.00001, loss_test:0.01268, lr:2.97e-02, fs:0.81188 (r=0.828,p=0.796),  time:31.002, tt:4309.237\n",
      "##########Best model found so far##########\n",
      "Ep:139, loss:0.00001, loss_test:0.01270, lr:2.97e-02, fs:0.81188 (r=0.828,p=0.796),  time:31.000, tt:4340.067\n",
      "Ep:140, loss:0.00001, loss_test:0.01271, lr:2.97e-02, fs:0.81188 (r=0.828,p=0.796),  time:31.010, tt:4372.449\n",
      "Ep:141, loss:0.00001, loss_test:0.01271, lr:2.97e-02, fs:0.81188 (r=0.828,p=0.796),  time:31.013, tt:4403.872\n",
      "Ep:142, loss:0.00001, loss_test:0.01273, lr:2.97e-02, fs:0.81188 (r=0.828,p=0.796),  time:31.017, tt:4435.385\n",
      "Ep:143, loss:0.00001, loss_test:0.01272, lr:2.97e-02, fs:0.81188 (r=0.828,p=0.796),  time:31.009, tt:4465.260\n",
      "Ep:144, loss:0.00001, loss_test:0.01272, lr:2.97e-02, fs:0.81188 (r=0.828,p=0.796),  time:31.006, tt:4495.908\n",
      "Ep:145, loss:0.00001, loss_test:0.01274, lr:2.97e-02, fs:0.81592 (r=0.828,p=0.804),  time:31.005, tt:4526.742\n",
      "##########Best model found so far##########\n",
      "Ep:146, loss:0.00001, loss_test:0.01275, lr:2.97e-02, fs:0.81592 (r=0.828,p=0.804),  time:30.998, tt:4556.779\n",
      "Ep:147, loss:0.00001, loss_test:0.01275, lr:2.97e-02, fs:0.81592 (r=0.828,p=0.804),  time:30.990, tt:4586.593\n",
      "Ep:148, loss:0.00001, loss_test:0.01275, lr:2.97e-02, fs:0.81592 (r=0.828,p=0.804),  time:30.985, tt:4616.801\n",
      "Ep:149, loss:0.00001, loss_test:0.01277, lr:2.97e-02, fs:0.81592 (r=0.828,p=0.804),  time:30.977, tt:4646.624\n",
      "Ep:150, loss:0.00001, loss_test:0.01277, lr:2.97e-02, fs:0.81592 (r=0.828,p=0.804),  time:30.970, tt:4676.486\n",
      "Ep:151, loss:0.00001, loss_test:0.01279, lr:2.97e-02, fs:0.81592 (r=0.828,p=0.804),  time:30.963, tt:4706.392\n",
      "Ep:152, loss:0.00001, loss_test:0.01279, lr:2.97e-02, fs:0.81592 (r=0.828,p=0.804),  time:30.959, tt:4736.763\n",
      "Ep:153, loss:0.00001, loss_test:0.01280, lr:2.97e-02, fs:0.82000 (r=0.828,p=0.812),  time:30.959, tt:4767.739\n",
      "##########Best model found so far##########\n",
      "Ep:154, loss:0.00001, loss_test:0.01280, lr:2.97e-02, fs:0.82000 (r=0.828,p=0.812),  time:30.966, tt:4799.659\n",
      "Ep:155, loss:0.00001, loss_test:0.01279, lr:2.97e-02, fs:0.82412 (r=0.828,p=0.820),  time:30.967, tt:4830.831\n",
      "##########Best model found so far##########\n",
      "Ep:156, loss:0.00001, loss_test:0.01281, lr:2.97e-02, fs:0.82412 (r=0.828,p=0.820),  time:30.967, tt:4861.891\n",
      "Ep:157, loss:0.00001, loss_test:0.01283, lr:2.97e-02, fs:0.82828 (r=0.828,p=0.828),  time:30.963, tt:4892.210\n",
      "##########Best model found so far##########\n",
      "Ep:158, loss:0.00001, loss_test:0.01284, lr:2.97e-02, fs:0.82828 (r=0.828,p=0.828),  time:30.954, tt:4921.663\n",
      "Ep:159, loss:0.00001, loss_test:0.01284, lr:2.97e-02, fs:0.83249 (r=0.828,p=0.837),  time:30.947, tt:4951.458\n",
      "##########Best model found so far##########\n",
      "Ep:160, loss:0.00001, loss_test:0.01285, lr:2.97e-02, fs:0.83249 (r=0.828,p=0.837),  time:30.937, tt:4980.865\n",
      "Ep:161, loss:0.00001, loss_test:0.01286, lr:2.97e-02, fs:0.83249 (r=0.828,p=0.837),  time:30.935, tt:5011.415\n",
      "Ep:162, loss:0.00001, loss_test:0.01287, lr:2.97e-02, fs:0.83249 (r=0.828,p=0.837),  time:30.925, tt:5040.766\n",
      "Ep:163, loss:0.00001, loss_test:0.01286, lr:2.97e-02, fs:0.83249 (r=0.828,p=0.837),  time:30.913, tt:5069.708\n",
      "Ep:164, loss:0.00001, loss_test:0.01289, lr:2.97e-02, fs:0.83249 (r=0.828,p=0.837),  time:30.896, tt:5097.851\n",
      "Ep:165, loss:0.00001, loss_test:0.01291, lr:2.97e-02, fs:0.84103 (r=0.828,p=0.854),  time:30.898, tt:5129.018\n",
      "##########Best model found so far##########\n",
      "Ep:166, loss:0.00001, loss_test:0.01291, lr:2.97e-02, fs:0.84103 (r=0.828,p=0.854),  time:30.899, tt:5160.105\n",
      "Ep:167, loss:0.00001, loss_test:0.01291, lr:2.97e-02, fs:0.84103 (r=0.828,p=0.854),  time:30.902, tt:5191.593\n",
      "Ep:168, loss:0.00001, loss_test:0.01291, lr:2.97e-02, fs:0.84103 (r=0.828,p=0.854),  time:30.899, tt:5221.896\n",
      "Ep:169, loss:0.00001, loss_test:0.01295, lr:2.97e-02, fs:0.84103 (r=0.828,p=0.854),  time:30.891, tt:5251.547\n",
      "Ep:170, loss:0.00001, loss_test:0.01295, lr:2.97e-02, fs:0.84103 (r=0.828,p=0.854),  time:30.881, tt:5280.727\n",
      "Ep:171, loss:0.00001, loss_test:0.01296, lr:2.97e-02, fs:0.84103 (r=0.828,p=0.854),  time:30.881, tt:5311.554\n",
      "Ep:172, loss:0.00001, loss_test:0.01296, lr:2.97e-02, fs:0.84103 (r=0.828,p=0.854),  time:30.877, tt:5341.641\n",
      "Ep:173, loss:0.00001, loss_test:0.01297, lr:2.97e-02, fs:0.84103 (r=0.828,p=0.854),  time:30.887, tt:5374.312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:174, loss:0.00001, loss_test:0.01298, lr:2.97e-02, fs:0.84536 (r=0.828,p=0.863),  time:30.885, tt:5404.860\n",
      "##########Best model found so far##########\n",
      "Ep:175, loss:0.00001, loss_test:0.01300, lr:2.97e-02, fs:0.84536 (r=0.828,p=0.863),  time:30.879, tt:5434.751\n",
      "Ep:176, loss:0.00001, loss_test:0.01301, lr:2.97e-02, fs:0.84536 (r=0.828,p=0.863),  time:30.880, tt:5465.738\n",
      "Ep:177, loss:0.00001, loss_test:0.01302, lr:2.97e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.876, tt:5495.916\n",
      "Ep:178, loss:0.00001, loss_test:0.01303, lr:2.97e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.868, tt:5525.387\n",
      "Ep:179, loss:0.00001, loss_test:0.01303, lr:2.97e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.866, tt:5555.822\n",
      "Ep:180, loss:0.00001, loss_test:0.01304, lr:2.97e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.870, tt:5587.457\n",
      "Ep:181, loss:0.00001, loss_test:0.01306, lr:2.97e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.875, tt:5619.315\n",
      "Ep:182, loss:0.00001, loss_test:0.01310, lr:2.97e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.872, tt:5649.586\n",
      "Ep:183, loss:0.00001, loss_test:0.01311, lr:2.97e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.870, tt:5680.019\n",
      "Ep:184, loss:0.00001, loss_test:0.01310, lr:2.97e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.868, tt:5710.514\n",
      "Ep:185, loss:0.00001, loss_test:0.01309, lr:2.97e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.872, tt:5742.172\n",
      "Ep:186, loss:0.00001, loss_test:0.01310, lr:2.94e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.868, tt:5772.383\n",
      "Ep:187, loss:0.00001, loss_test:0.01312, lr:2.91e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.865, tt:5802.681\n",
      "Ep:188, loss:0.00001, loss_test:0.01315, lr:2.88e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.859, tt:5832.276\n",
      "Ep:189, loss:0.00001, loss_test:0.01317, lr:2.85e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.860, tt:5863.327\n",
      "Ep:190, loss:0.00001, loss_test:0.01316, lr:2.82e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.861, tt:5894.440\n",
      "Ep:191, loss:0.00001, loss_test:0.01317, lr:2.80e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.856, tt:5924.335\n",
      "Ep:192, loss:0.00001, loss_test:0.01318, lr:2.77e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.860, tt:5956.007\n",
      "Ep:193, loss:0.00001, loss_test:0.01319, lr:2.74e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.861, tt:5986.982\n",
      "Ep:194, loss:0.00001, loss_test:0.01320, lr:2.71e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.864, tt:6018.492\n",
      "Ep:195, loss:0.00001, loss_test:0.01321, lr:2.69e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.865, tt:6049.483\n",
      "Ep:196, loss:0.00001, loss_test:0.01322, lr:2.66e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.858, tt:6079.069\n",
      "Ep:197, loss:0.00001, loss_test:0.01325, lr:2.63e-02, fs:0.84375 (r=0.818,p=0.871),  time:30.852, tt:6108.740\n",
      "Ep:198, loss:0.00001, loss_test:0.01326, lr:2.61e-02, fs:0.84375 (r=0.818,p=0.871),  time:30.849, tt:6138.947\n",
      "Ep:199, loss:0.00001, loss_test:0.01327, lr:2.58e-02, fs:0.84817 (r=0.818,p=0.880),  time:30.852, tt:6170.314\n",
      "##########Best model found so far##########\n",
      "Ep:200, loss:0.00001, loss_test:0.01329, lr:2.58e-02, fs:0.85417 (r=0.828,p=0.882),  time:30.853, tt:6201.513\n",
      "##########Best model found so far##########\n",
      "Ep:201, loss:0.00001, loss_test:0.01329, lr:2.58e-02, fs:0.84375 (r=0.818,p=0.871),  time:30.852, tt:6232.075\n",
      "Ep:202, loss:0.00001, loss_test:0.01330, lr:2.58e-02, fs:0.84817 (r=0.818,p=0.880),  time:30.845, tt:6261.633\n",
      "Ep:203, loss:0.00001, loss_test:0.01331, lr:2.58e-02, fs:0.84817 (r=0.818,p=0.880),  time:30.835, tt:6290.306\n",
      "Ep:204, loss:0.00001, loss_test:0.01333, lr:2.58e-02, fs:0.85417 (r=0.828,p=0.882),  time:30.828, tt:6319.692\n",
      "Ep:205, loss:0.00001, loss_test:0.01334, lr:2.58e-02, fs:0.85417 (r=0.828,p=0.882),  time:30.832, tt:6351.307\n",
      "Ep:206, loss:0.00001, loss_test:0.01335, lr:2.58e-02, fs:0.85417 (r=0.828,p=0.882),  time:30.832, tt:6382.190\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14356, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.423, tt:24.423\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14250, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.177, tt:52.353\n",
      "Ep:2, loss:0.00028, loss_test:0.14055, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.388, tt:82.164\n",
      "Ep:3, loss:0.00027, loss_test:0.13748, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.083, tt:116.332\n",
      "Ep:4, loss:0.00026, loss_test:0.13253, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:29.513, tt:147.567\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.12512, lr:1.00e-02, fs:0.68657 (r=0.929,p=0.544),  time:29.779, tt:178.673\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.11726, lr:1.00e-02, fs:0.70683 (r=0.889,p=0.587),  time:30.235, tt:211.643\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.11316, lr:1.00e-02, fs:0.68778 (r=0.768,p=0.623),  time:30.521, tt:244.169\n",
      "Ep:8, loss:0.00023, loss_test:0.11112, lr:1.00e-02, fs:0.69683 (r=0.778,p=0.631),  time:30.773, tt:276.956\n",
      "Ep:9, loss:0.00022, loss_test:0.10998, lr:1.00e-02, fs:0.72650 (r=0.859,p=0.630),  time:30.871, tt:308.711\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.10803, lr:1.00e-02, fs:0.73191 (r=0.869,p=0.632),  time:30.977, tt:340.748\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.10389, lr:1.00e-02, fs:0.73684 (r=0.848,p=0.651),  time:31.053, tt:372.634\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.10168, lr:1.00e-02, fs:0.72115 (r=0.758,p=0.688),  time:31.171, tt:405.219\n",
      "Ep:13, loss:0.00020, loss_test:0.09951, lr:1.00e-02, fs:0.75000 (r=0.818,p=0.692),  time:31.146, tt:436.050\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.09750, lr:1.00e-02, fs:0.76712 (r=0.848,p=0.700),  time:31.103, tt:466.547\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.09543, lr:1.00e-02, fs:0.77064 (r=0.848,p=0.706),  time:31.187, tt:498.997\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.09393, lr:1.00e-02, fs:0.77358 (r=0.828,p=0.726),  time:31.169, tt:529.870\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.09244, lr:1.00e-02, fs:0.77982 (r=0.859,p=0.714),  time:31.172, tt:561.095\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.09104, lr:1.00e-02, fs:0.77778 (r=0.848,p=0.718),  time:31.196, tt:592.716\n",
      "Ep:19, loss:0.00017, loss_test:0.08989, lr:1.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:31.250, tt:624.999\n",
      "Ep:20, loss:0.00016, loss_test:0.08887, lr:1.00e-02, fs:0.79630 (r=0.869,p=0.735),  time:31.245, tt:656.155\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.08786, lr:1.00e-02, fs:0.79263 (r=0.869,p=0.729),  time:31.319, tt:689.025\n",
      "Ep:22, loss:0.00015, loss_test:0.08692, lr:1.00e-02, fs:0.77570 (r=0.838,p=0.722),  time:31.280, tt:719.448\n",
      "Ep:23, loss:0.00015, loss_test:0.08604, lr:1.00e-02, fs:0.78505 (r=0.848,p=0.730),  time:31.254, tt:750.088\n",
      "Ep:24, loss:0.00015, loss_test:0.08494, lr:1.00e-02, fs:0.80734 (r=0.889,p=0.739),  time:31.363, tt:784.074\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.08415, lr:1.00e-02, fs:0.81106 (r=0.889,p=0.746),  time:31.424, tt:817.022\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.08355, lr:1.00e-02, fs:0.82569 (r=0.909,p=0.756),  time:31.437, tt:848.810\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.08301, lr:1.00e-02, fs:0.83105 (r=0.919,p=0.758),  time:31.419, tt:879.746\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.08247, lr:1.00e-02, fs:0.82407 (r=0.899,p=0.761),  time:31.447, tt:911.971\n",
      "Ep:29, loss:0.00013, loss_test:0.08147, lr:1.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:31.468, tt:944.035\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:30, loss:0.00013, loss_test:0.08164, lr:1.00e-02, fs:0.81731 (r=0.859,p=0.780),  time:31.480, tt:975.886\n",
      "Ep:31, loss:0.00012, loss_test:0.08075, lr:1.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:31.540, tt:1009.288\n",
      "Ep:32, loss:0.00012, loss_test:0.07954, lr:1.00e-02, fs:0.84932 (r=0.939,p=0.775),  time:31.570, tt:1041.811\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00012, loss_test:0.07919, lr:1.00e-02, fs:0.83568 (r=0.899,p=0.781),  time:31.580, tt:1073.720\n",
      "Ep:34, loss:0.00011, loss_test:0.07851, lr:1.00e-02, fs:0.84404 (r=0.929,p=0.773),  time:31.577, tt:1105.195\n",
      "Ep:35, loss:0.00011, loss_test:0.07742, lr:1.00e-02, fs:0.84793 (r=0.929,p=0.780),  time:31.594, tt:1137.390\n",
      "Ep:36, loss:0.00011, loss_test:0.07670, lr:1.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:31.562, tt:1167.781\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00011, loss_test:0.07614, lr:1.00e-02, fs:0.84112 (r=0.909,p=0.783),  time:31.603, tt:1200.918\n",
      "Ep:38, loss:0.00010, loss_test:0.07519, lr:1.00e-02, fs:0.86512 (r=0.939,p=0.802),  time:31.665, tt:1234.929\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00010, loss_test:0.07282, lr:1.00e-02, fs:0.87671 (r=0.970,p=0.800),  time:31.689, tt:1330.959\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00010, loss_test:0.07202, lr:1.00e-02, fs:0.88263 (r=0.949,p=0.825),  time:31.705, tt:1363.316\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00009, loss_test:0.07142, lr:1.00e-02, fs:0.88785 (r=0.960,p=0.826),  time:31.692, tt:1394.461\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00009, loss_test:0.07039, lr:1.00e-02, fs:0.88785 (r=0.960,p=0.826),  time:31.626, tt:1423.176\n",
      "Ep:45, loss:0.00009, loss_test:0.07039, lr:1.00e-02, fs:0.88372 (r=0.960,p=0.819),  time:31.599, tt:1453.547\n",
      "Ep:46, loss:0.00009, loss_test:0.06954, lr:1.00e-02, fs:0.88785 (r=0.960,p=0.826),  time:31.603, tt:1485.322\n",
      "Ep:47, loss:0.00008, loss_test:0.06889, lr:1.00e-02, fs:0.89302 (r=0.970,p=0.828),  time:31.630, tt:1518.238\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00008, loss_test:0.06878, lr:1.00e-02, fs:0.88679 (r=0.949,p=0.832),  time:31.652, tt:1550.934\n",
      "Ep:49, loss:0.00008, loss_test:0.06794, lr:1.00e-02, fs:0.89720 (r=0.970,p=0.835),  time:31.655, tt:1582.737\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00008, loss_test:0.06827, lr:1.00e-02, fs:0.89100 (r=0.949,p=0.839),  time:31.670, tt:1615.187\n",
      "Ep:51, loss:0.00008, loss_test:0.06732, lr:1.00e-02, fs:0.88785 (r=0.960,p=0.826),  time:31.676, tt:1647.158\n",
      "Ep:52, loss:0.00008, loss_test:0.06748, lr:1.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:31.690, tt:1679.581\n",
      "Ep:53, loss:0.00007, loss_test:0.06608, lr:1.00e-02, fs:0.88889 (r=0.970,p=0.821),  time:31.695, tt:1711.513\n",
      "Ep:54, loss:0.00007, loss_test:0.06616, lr:1.00e-02, fs:0.89524 (r=0.949,p=0.847),  time:31.731, tt:1745.185\n",
      "Ep:55, loss:0.00007, loss_test:0.06554, lr:1.00e-02, fs:0.88889 (r=0.970,p=0.821),  time:31.743, tt:1777.593\n",
      "Ep:56, loss:0.00007, loss_test:0.06629, lr:1.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:31.739, tt:1809.103\n",
      "Ep:57, loss:0.00007, loss_test:0.06432, lr:1.00e-02, fs:0.89302 (r=0.970,p=0.828),  time:31.747, tt:1841.355\n",
      "Ep:58, loss:0.00007, loss_test:0.06610, lr:1.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:31.752, tt:1873.346\n",
      "Ep:59, loss:0.00007, loss_test:0.06369, lr:1.00e-02, fs:0.90141 (r=0.970,p=0.842),  time:31.766, tt:1905.965\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00006, loss_test:0.06617, lr:1.00e-02, fs:0.87500 (r=0.919,p=0.835),  time:31.831, tt:1941.687\n",
      "Ep:61, loss:0.00006, loss_test:0.06297, lr:1.00e-02, fs:0.90141 (r=0.970,p=0.842),  time:31.852, tt:1974.838\n",
      "Ep:62, loss:0.00006, loss_test:0.06523, lr:1.00e-02, fs:0.87500 (r=0.919,p=0.835),  time:31.839, tt:2005.853\n",
      "Ep:63, loss:0.00006, loss_test:0.06354, lr:1.00e-02, fs:0.88462 (r=0.929,p=0.844),  time:31.864, tt:2039.265\n",
      "Ep:64, loss:0.00006, loss_test:0.06392, lr:1.00e-02, fs:0.86957 (r=0.909,p=0.833),  time:31.883, tt:2072.424\n",
      "Ep:65, loss:0.00006, loss_test:0.06388, lr:1.00e-02, fs:0.87923 (r=0.919,p=0.843),  time:31.874, tt:2103.685\n",
      "Ep:66, loss:0.00006, loss_test:0.06167, lr:1.00e-02, fs:0.89423 (r=0.939,p=0.853),  time:31.906, tt:2137.691\n",
      "Ep:67, loss:0.00006, loss_test:0.06462, lr:1.00e-02, fs:0.86829 (r=0.899,p=0.840),  time:31.932, tt:2171.343\n",
      "Ep:68, loss:0.00006, loss_test:0.06189, lr:1.00e-02, fs:0.88889 (r=0.929,p=0.852),  time:31.924, tt:2202.777\n",
      "Ep:69, loss:0.00005, loss_test:0.06372, lr:1.00e-02, fs:0.86829 (r=0.899,p=0.840),  time:31.927, tt:2234.878\n",
      "Ep:70, loss:0.00005, loss_test:0.06106, lr:1.00e-02, fs:0.88571 (r=0.939,p=0.838),  time:31.942, tt:2267.861\n",
      "Ep:71, loss:0.00005, loss_test:0.06499, lr:9.90e-03, fs:0.86139 (r=0.879,p=0.845),  time:31.923, tt:2298.439\n",
      "Ep:72, loss:0.00005, loss_test:0.06137, lr:9.80e-03, fs:0.87500 (r=0.919,p=0.835),  time:31.931, tt:2330.947\n",
      "Ep:73, loss:0.00005, loss_test:0.06234, lr:9.70e-03, fs:0.86139 (r=0.879,p=0.845),  time:31.940, tt:2363.530\n",
      "Ep:74, loss:0.00005, loss_test:0.06181, lr:9.61e-03, fs:0.86275 (r=0.889,p=0.838),  time:31.949, tt:2396.194\n",
      "Ep:75, loss:0.00005, loss_test:0.06147, lr:9.51e-03, fs:0.86275 (r=0.889,p=0.838),  time:31.988, tt:2431.106\n",
      "Ep:76, loss:0.00005, loss_test:0.06257, lr:9.41e-03, fs:0.85714 (r=0.879,p=0.837),  time:31.976, tt:2462.139\n",
      "Ep:77, loss:0.00005, loss_test:0.06196, lr:9.32e-03, fs:0.86567 (r=0.879,p=0.853),  time:31.979, tt:2494.398\n",
      "Ep:78, loss:0.00005, loss_test:0.06138, lr:9.23e-03, fs:0.85714 (r=0.879,p=0.837),  time:31.965, tt:2525.217\n",
      "Ep:79, loss:0.00005, loss_test:0.06062, lr:9.14e-03, fs:0.86139 (r=0.879,p=0.845),  time:31.956, tt:2556.493\n",
      "Ep:80, loss:0.00005, loss_test:0.06224, lr:9.04e-03, fs:0.86567 (r=0.879,p=0.853),  time:31.949, tt:2587.867\n",
      "Ep:81, loss:0.00004, loss_test:0.06054, lr:8.95e-03, fs:0.87923 (r=0.919,p=0.843),  time:31.936, tt:2618.768\n",
      "Ep:82, loss:0.00004, loss_test:0.06278, lr:8.86e-03, fs:0.86567 (r=0.879,p=0.853),  time:31.928, tt:2650.036\n",
      "Ep:83, loss:0.00004, loss_test:0.06074, lr:8.78e-03, fs:0.86275 (r=0.889,p=0.838),  time:31.940, tt:2682.946\n",
      "Ep:84, loss:0.00004, loss_test:0.06175, lr:8.69e-03, fs:0.87000 (r=0.879,p=0.861),  time:31.940, tt:2714.864\n",
      "Ep:85, loss:0.00004, loss_test:0.06032, lr:8.60e-03, fs:0.87129 (r=0.889,p=0.854),  time:31.941, tt:2746.967\n",
      "Ep:86, loss:0.00004, loss_test:0.06276, lr:8.51e-03, fs:0.85714 (r=0.879,p=0.837),  time:31.934, tt:2778.301\n",
      "Ep:87, loss:0.00004, loss_test:0.06071, lr:8.43e-03, fs:0.87000 (r=0.879,p=0.861),  time:31.938, tt:2810.569\n",
      "Ep:88, loss:0.00004, loss_test:0.06188, lr:8.35e-03, fs:0.86139 (r=0.879,p=0.845),  time:31.914, tt:2840.309\n",
      "Ep:89, loss:0.00004, loss_test:0.06160, lr:8.26e-03, fs:0.87000 (r=0.879,p=0.861),  time:31.893, tt:2870.372\n",
      "Ep:90, loss:0.00004, loss_test:0.06039, lr:8.18e-03, fs:0.87129 (r=0.889,p=0.854),  time:31.892, tt:2902.163\n",
      "Ep:91, loss:0.00004, loss_test:0.06222, lr:8.10e-03, fs:0.87000 (r=0.879,p=0.861),  time:31.892, tt:2934.062\n",
      "Ep:92, loss:0.00004, loss_test:0.06088, lr:8.02e-03, fs:0.87000 (r=0.879,p=0.861),  time:31.882, tt:2965.068\n",
      "Ep:93, loss:0.00004, loss_test:0.06255, lr:7.94e-03, fs:0.86139 (r=0.879,p=0.845),  time:31.904, tt:2998.935\n",
      "Ep:94, loss:0.00004, loss_test:0.06084, lr:7.86e-03, fs:0.87000 (r=0.879,p=0.861),  time:31.891, tt:3029.617\n",
      "Ep:95, loss:0.00004, loss_test:0.06219, lr:7.78e-03, fs:0.87000 (r=0.879,p=0.861),  time:31.877, tt:3060.233\n",
      "Ep:96, loss:0.00004, loss_test:0.06205, lr:7.70e-03, fs:0.87000 (r=0.879,p=0.861),  time:31.869, tt:3091.265\n",
      "Ep:97, loss:0.00004, loss_test:0.06114, lr:7.62e-03, fs:0.87000 (r=0.879,p=0.861),  time:31.856, tt:3121.890\n",
      "Ep:98, loss:0.00004, loss_test:0.06251, lr:7.55e-03, fs:0.86139 (r=0.879,p=0.845),  time:31.848, tt:3152.921\n",
      "Ep:99, loss:0.00004, loss_test:0.06144, lr:7.47e-03, fs:0.87879 (r=0.879,p=0.879),  time:31.852, tt:3185.220\n",
      "Ep:100, loss:0.00004, loss_test:0.06277, lr:7.40e-03, fs:0.87000 (r=0.879,p=0.861),  time:31.845, tt:3216.372\n",
      "Ep:101, loss:0.00003, loss_test:0.06208, lr:7.32e-03, fs:0.87000 (r=0.879,p=0.861),  time:31.836, tt:3247.319\n",
      "Ep:102, loss:0.00003, loss_test:0.06131, lr:7.25e-03, fs:0.87437 (r=0.879,p=0.870),  time:31.842, tt:3279.703\n",
      "Ep:103, loss:0.00003, loss_test:0.06377, lr:7.18e-03, fs:0.86567 (r=0.879,p=0.853),  time:31.833, tt:3310.583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:104, loss:0.00003, loss_test:0.06167, lr:7.11e-03, fs:0.87000 (r=0.879,p=0.861),  time:31.830, tt:3342.181\n",
      "Ep:105, loss:0.00003, loss_test:0.06239, lr:7.03e-03, fs:0.87000 (r=0.879,p=0.861),  time:31.837, tt:3374.705\n",
      "Ep:106, loss:0.00003, loss_test:0.06293, lr:6.96e-03, fs:0.87000 (r=0.879,p=0.861),  time:31.816, tt:3404.340\n",
      "Ep:107, loss:0.00003, loss_test:0.06182, lr:6.89e-03, fs:0.87000 (r=0.879,p=0.861),  time:31.815, tt:3436.047\n",
      "Ep:108, loss:0.00003, loss_test:0.06366, lr:6.83e-03, fs:0.87000 (r=0.879,p=0.861),  time:31.818, tt:3468.189\n",
      "Ep:109, loss:0.00003, loss_test:0.06199, lr:6.76e-03, fs:0.87000 (r=0.879,p=0.861),  time:31.811, tt:3499.237\n",
      "Ep:110, loss:0.00003, loss_test:0.06392, lr:6.69e-03, fs:0.87000 (r=0.879,p=0.861),  time:31.789, tt:3528.585\n",
      "Ep:111, loss:0.00003, loss_test:0.06257, lr:6.62e-03, fs:0.87000 (r=0.879,p=0.861),  time:31.768, tt:3558.047\n",
      "Ep:112, loss:0.00003, loss_test:0.06193, lr:6.56e-03, fs:0.87000 (r=0.879,p=0.861),  time:31.754, tt:3588.168\n",
      "Ep:113, loss:0.00003, loss_test:0.06312, lr:6.49e-03, fs:0.87000 (r=0.879,p=0.861),  time:31.748, tt:3619.227\n",
      "Ep:114, loss:0.00003, loss_test:0.06247, lr:6.43e-03, fs:0.87000 (r=0.879,p=0.861),  time:31.742, tt:3650.284\n",
      "Ep:115, loss:0.00003, loss_test:0.06283, lr:6.36e-03, fs:0.87000 (r=0.879,p=0.861),  time:31.739, tt:3681.679\n",
      "Ep:116, loss:0.00003, loss_test:0.06294, lr:6.30e-03, fs:0.87437 (r=0.879,p=0.870),  time:31.733, tt:3712.769\n",
      "Ep:117, loss:0.00003, loss_test:0.06255, lr:6.24e-03, fs:0.87000 (r=0.879,p=0.861),  time:31.728, tt:3743.900\n",
      "Ep:118, loss:0.00003, loss_test:0.06346, lr:6.17e-03, fs:0.87000 (r=0.879,p=0.861),  time:31.733, tt:3776.259\n",
      "Ep:119, loss:0.00003, loss_test:0.06323, lr:6.11e-03, fs:0.87437 (r=0.879,p=0.870),  time:31.737, tt:3808.437\n",
      "Ep:120, loss:0.00003, loss_test:0.06282, lr:6.05e-03, fs:0.87000 (r=0.879,p=0.861),  time:31.742, tt:3840.745\n",
      "Ep:121, loss:0.00003, loss_test:0.06313, lr:5.99e-03, fs:0.87000 (r=0.879,p=0.861),  time:31.748, tt:3873.219\n",
      "Ep:122, loss:0.00003, loss_test:0.06308, lr:5.93e-03, fs:0.87437 (r=0.879,p=0.870),  time:31.747, tt:3904.881\n",
      "Ep:123, loss:0.00003, loss_test:0.06297, lr:5.87e-03, fs:0.87437 (r=0.879,p=0.870),  time:31.748, tt:3936.740\n",
      "Ep:124, loss:0.00003, loss_test:0.06435, lr:5.81e-03, fs:0.87437 (r=0.879,p=0.870),  time:31.750, tt:3968.779\n",
      "Ep:125, loss:0.00003, loss_test:0.06312, lr:5.75e-03, fs:0.87437 (r=0.879,p=0.870),  time:31.750, tt:4000.472\n",
      "Ep:126, loss:0.00003, loss_test:0.06361, lr:5.70e-03, fs:0.86294 (r=0.859,p=0.867),  time:31.750, tt:4032.202\n",
      "Ep:127, loss:0.00003, loss_test:0.06385, lr:5.64e-03, fs:0.86869 (r=0.869,p=0.869),  time:31.765, tt:4065.873\n",
      "Ep:128, loss:0.00003, loss_test:0.06274, lr:5.58e-03, fs:0.87437 (r=0.879,p=0.870),  time:31.770, tt:4098.297\n",
      "Ep:129, loss:0.00003, loss_test:0.06517, lr:5.53e-03, fs:0.86869 (r=0.869,p=0.869),  time:31.760, tt:4128.811\n",
      "Ep:130, loss:0.00003, loss_test:0.06413, lr:5.47e-03, fs:0.85128 (r=0.838,p=0.865),  time:31.763, tt:4161.011\n",
      "Ep:131, loss:0.00003, loss_test:0.06244, lr:5.42e-03, fs:0.86869 (r=0.869,p=0.869),  time:31.769, tt:4193.500\n",
      "Ep:132, loss:0.00003, loss_test:0.06463, lr:5.36e-03, fs:0.86869 (r=0.869,p=0.869),  time:31.778, tt:4226.459\n",
      "Ep:133, loss:0.00003, loss_test:0.06328, lr:5.31e-03, fs:0.86869 (r=0.869,p=0.869),  time:31.780, tt:4258.462\n",
      "Ep:134, loss:0.00003, loss_test:0.06380, lr:5.26e-03, fs:0.84536 (r=0.828,p=0.863),  time:31.768, tt:4288.689\n",
      "Ep:135, loss:0.00002, loss_test:0.06444, lr:5.20e-03, fs:0.86294 (r=0.859,p=0.867),  time:31.774, tt:4321.261\n",
      "Ep:136, loss:0.00002, loss_test:0.06331, lr:5.15e-03, fs:0.86294 (r=0.859,p=0.867),  time:31.756, tt:4350.629\n",
      "Ep:137, loss:0.00002, loss_test:0.06352, lr:5.10e-03, fs:0.86294 (r=0.859,p=0.867),  time:31.755, tt:4382.200\n",
      "Ep:138, loss:0.00002, loss_test:0.06498, lr:5.05e-03, fs:0.82105 (r=0.788,p=0.857),  time:31.750, tt:4413.231\n",
      "Ep:139, loss:0.00002, loss_test:0.06239, lr:5.00e-03, fs:0.86294 (r=0.859,p=0.867),  time:31.755, tt:4445.694\n",
      "Ep:140, loss:0.00002, loss_test:0.06465, lr:4.95e-03, fs:0.83333 (r=0.808,p=0.860),  time:31.761, tt:4478.232\n",
      "Ep:141, loss:0.00002, loss_test:0.06527, lr:4.90e-03, fs:0.82105 (r=0.788,p=0.857),  time:31.761, tt:4510.132\n",
      "Ep:142, loss:0.00002, loss_test:0.06187, lr:4.85e-03, fs:0.86010 (r=0.838,p=0.883),  time:31.761, tt:4541.822\n",
      "Ep:143, loss:0.00002, loss_test:0.06508, lr:4.80e-03, fs:0.82105 (r=0.788,p=0.857),  time:31.793, tt:4578.237\n",
      "Ep:144, loss:0.00002, loss_test:0.06450, lr:4.75e-03, fs:0.84536 (r=0.828,p=0.863),  time:31.798, tt:4610.711\n",
      "Ep:145, loss:0.00002, loss_test:0.06230, lr:4.71e-03, fs:0.85714 (r=0.818,p=0.900),  time:31.796, tt:4642.276\n",
      "Ep:146, loss:0.00002, loss_test:0.06489, lr:4.66e-03, fs:0.81481 (r=0.778,p=0.856),  time:31.798, tt:4674.287\n",
      "Ep:147, loss:0.00002, loss_test:0.06339, lr:4.61e-03, fs:0.85128 (r=0.838,p=0.865),  time:31.796, tt:4705.841\n",
      "Ep:148, loss:0.00002, loss_test:0.06331, lr:4.57e-03, fs:0.83158 (r=0.798,p=0.868),  time:31.808, tt:4739.392\n",
      "Ep:149, loss:0.00002, loss_test:0.06457, lr:4.52e-03, fs:0.82609 (r=0.768,p=0.894),  time:31.807, tt:4771.084\n",
      "Ep:150, loss:0.00002, loss_test:0.06370, lr:4.48e-03, fs:0.82723 (r=0.798,p=0.859),  time:31.804, tt:4802.398\n",
      "Ep:151, loss:0.00002, loss_test:0.06435, lr:4.43e-03, fs:0.82540 (r=0.788,p=0.867),  time:31.808, tt:4834.841\n",
      "Ep:152, loss:0.00002, loss_test:0.06418, lr:4.39e-03, fs:0.82796 (r=0.778,p=0.885),  time:31.812, tt:4867.267\n",
      "Ep:153, loss:0.00002, loss_test:0.06349, lr:4.34e-03, fs:0.83871 (r=0.788,p=0.897),  time:31.807, tt:4898.303\n",
      "Ep:154, loss:0.00002, loss_test:0.06383, lr:4.30e-03, fs:0.83422 (r=0.788,p=0.886),  time:31.808, tt:4930.235\n",
      "Ep:155, loss:0.00002, loss_test:0.06362, lr:4.26e-03, fs:0.83422 (r=0.788,p=0.886),  time:31.816, tt:4963.267\n",
      "Ep:156, loss:0.00002, loss_test:0.06324, lr:4.21e-03, fs:0.83696 (r=0.778,p=0.906),  time:31.814, tt:4994.798\n",
      "Ep:157, loss:0.00002, loss_test:0.06441, lr:4.17e-03, fs:0.82796 (r=0.778,p=0.885),  time:31.807, tt:5025.581\n",
      "Ep:158, loss:0.00002, loss_test:0.06253, lr:4.13e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.807, tt:5057.276\n",
      "Ep:159, loss:0.00002, loss_test:0.06486, lr:4.09e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.800, tt:5087.939\n",
      "Ep:160, loss:0.00002, loss_test:0.06413, lr:4.05e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.800, tt:5119.766\n",
      "Ep:161, loss:0.00002, loss_test:0.06316, lr:4.01e-03, fs:0.83422 (r=0.788,p=0.886),  time:31.800, tt:5151.633\n",
      "Ep:162, loss:0.00002, loss_test:0.06394, lr:3.97e-03, fs:0.83696 (r=0.778,p=0.906),  time:31.801, tt:5183.580\n",
      "Ep:163, loss:0.00002, loss_test:0.06343, lr:3.93e-03, fs:0.83696 (r=0.778,p=0.906),  time:31.799, tt:5215.087\n",
      "Ep:164, loss:0.00002, loss_test:0.06377, lr:3.89e-03, fs:0.83696 (r=0.778,p=0.906),  time:31.805, tt:5247.887\n",
      "Ep:165, loss:0.00002, loss_test:0.06356, lr:3.85e-03, fs:0.83696 (r=0.778,p=0.906),  time:31.809, tt:5280.335\n",
      "Ep:166, loss:0.00002, loss_test:0.06303, lr:3.81e-03, fs:0.84153 (r=0.778,p=0.917),  time:31.809, tt:5312.067\n",
      "Ep:167, loss:0.00002, loss_test:0.06412, lr:3.77e-03, fs:0.83243 (r=0.778,p=0.895),  time:31.812, tt:5344.474\n",
      "Ep:168, loss:0.00002, loss_test:0.06289, lr:3.73e-03, fs:0.83696 (r=0.778,p=0.906),  time:31.820, tt:5377.540\n",
      "Ep:169, loss:0.00002, loss_test:0.06371, lr:3.70e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.833, tt:5411.603\n",
      "Ep:170, loss:0.00002, loss_test:0.06371, lr:3.66e-03, fs:0.83696 (r=0.778,p=0.906),  time:31.828, tt:5442.634\n",
      "Ep:171, loss:0.00002, loss_test:0.06364, lr:3.62e-03, fs:0.83696 (r=0.778,p=0.906),  time:31.834, tt:5475.377\n",
      "Ep:172, loss:0.00002, loss_test:0.06319, lr:3.59e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.826, tt:5505.899\n",
      "Ep:173, loss:0.00002, loss_test:0.06347, lr:3.55e-03, fs:0.83696 (r=0.778,p=0.906),  time:31.827, tt:5537.868\n",
      "Ep:174, loss:0.00002, loss_test:0.06369, lr:3.52e-03, fs:0.83696 (r=0.778,p=0.906),  time:31.828, tt:5569.907\n",
      "Ep:175, loss:0.00002, loss_test:0.06334, lr:3.48e-03, fs:0.83516 (r=0.768,p=0.916),  time:31.832, tt:5602.402\n",
      "Ep:176, loss:0.00002, loss_test:0.06426, lr:3.45e-03, fs:0.83516 (r=0.768,p=0.916),  time:31.827, tt:5633.320\n",
      "Ep:177, loss:0.00002, loss_test:0.06314, lr:3.41e-03, fs:0.83696 (r=0.778,p=0.906),  time:31.829, tt:5665.579\n",
      "Ep:178, loss:0.00002, loss_test:0.06352, lr:3.38e-03, fs:0.83696 (r=0.778,p=0.906),  time:31.831, tt:5697.795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:179, loss:0.00002, loss_test:0.06394, lr:3.34e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.825, tt:5728.534\n",
      "Ep:180, loss:0.00002, loss_test:0.06290, lr:3.31e-03, fs:0.83696 (r=0.778,p=0.906),  time:31.826, tt:5760.463\n",
      "Ep:181, loss:0.00002, loss_test:0.06340, lr:3.28e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.825, tt:5792.190\n",
      "Ep:182, loss:0.00002, loss_test:0.06288, lr:3.24e-03, fs:0.83696 (r=0.778,p=0.906),  time:31.815, tt:5822.065\n",
      "Ep:183, loss:0.00002, loss_test:0.06314, lr:3.21e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.818, tt:5854.439\n",
      "Ep:184, loss:0.00002, loss_test:0.06435, lr:3.18e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.819, tt:5886.577\n",
      "Ep:185, loss:0.00002, loss_test:0.06222, lr:3.15e-03, fs:0.83696 (r=0.778,p=0.906),  time:31.814, tt:5917.336\n",
      "Ep:186, loss:0.00002, loss_test:0.06297, lr:3.12e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.816, tt:5949.632\n",
      "Ep:187, loss:0.00002, loss_test:0.06454, lr:3.09e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.817, tt:5981.560\n",
      "Ep:188, loss:0.00002, loss_test:0.06272, lr:3.05e-03, fs:0.83696 (r=0.778,p=0.906),  time:31.818, tt:6013.583\n",
      "Ep:189, loss:0.00002, loss_test:0.06281, lr:3.02e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.818, tt:6045.458\n",
      "Ep:190, loss:0.00002, loss_test:0.06395, lr:2.99e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.821, tt:6077.785\n",
      "Ep:191, loss:0.00002, loss_test:0.06273, lr:2.96e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.817, tt:6108.780\n",
      "Ep:192, loss:0.00002, loss_test:0.06282, lr:2.93e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.809, tt:6139.199\n",
      "Ep:193, loss:0.00002, loss_test:0.06369, lr:2.90e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.809, tt:6170.862\n",
      "Ep:194, loss:0.00002, loss_test:0.06339, lr:2.88e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.810, tt:6203.008\n",
      "Ep:195, loss:0.00002, loss_test:0.06262, lr:2.85e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.806, tt:6233.967\n",
      "Ep:196, loss:0.00002, loss_test:0.06382, lr:2.82e-03, fs:0.83516 (r=0.768,p=0.916),  time:31.799, tt:6264.369\n",
      "Ep:197, loss:0.00002, loss_test:0.06341, lr:2.79e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.798, tt:6295.984\n",
      "Ep:198, loss:0.00002, loss_test:0.06265, lr:2.76e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.798, tt:6327.811\n",
      "Ep:199, loss:0.00002, loss_test:0.06384, lr:2.73e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.800, tt:6359.911\n",
      "Ep:200, loss:0.00002, loss_test:0.06330, lr:2.71e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.794, tt:6390.694\n",
      "Ep:201, loss:0.00002, loss_test:0.06264, lr:2.68e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.787, tt:6420.973\n",
      "Ep:202, loss:0.00002, loss_test:0.06349, lr:2.65e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.779, tt:6451.076\n",
      "Ep:203, loss:0.00002, loss_test:0.06364, lr:2.63e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.768, tt:6480.716\n",
      "Ep:204, loss:0.00002, loss_test:0.06283, lr:2.60e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.753, tt:6509.279\n",
      "Ep:205, loss:0.00002, loss_test:0.06388, lr:2.57e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.739, tt:6538.258\n",
      "Ep:206, loss:0.00002, loss_test:0.06284, lr:2.55e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.727, tt:6567.549\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.01970, lr:6.00e-02, fs:0.65863 (r=0.828,p=0.547),  time:24.973, tt:24.973\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02196, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.834, tt:49.669\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02392, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.164, tt:78.491\n",
      "Ep:3, loss:0.00005, loss_test:0.02435, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.840, tt:107.361\n",
      "Ep:4, loss:0.00005, loss_test:0.02391, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.729, tt:138.644\n",
      "Ep:5, loss:0.00004, loss_test:0.02280, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.135, tt:168.808\n",
      "Ep:6, loss:0.00004, loss_test:0.02129, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:28.454, tt:199.175\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01981, lr:6.00e-02, fs:0.68056 (r=0.990,p=0.519),  time:28.799, tt:230.392\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01877, lr:6.00e-02, fs:0.67153 (r=0.929,p=0.526),  time:29.112, tt:262.010\n",
      "Ep:9, loss:0.00004, loss_test:0.01827, lr:6.00e-02, fs:0.71654 (r=0.919,p=0.587),  time:29.293, tt:292.931\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01792, lr:6.00e-02, fs:0.72065 (r=0.899,p=0.601),  time:29.402, tt:323.426\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01754, lr:6.00e-02, fs:0.72000 (r=0.909,p=0.596),  time:29.438, tt:353.251\n",
      "Ep:12, loss:0.00003, loss_test:0.01725, lr:6.00e-02, fs:0.72374 (r=0.939,p=0.589),  time:29.367, tt:381.771\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01714, lr:6.00e-02, fs:0.73208 (r=0.980,p=0.584),  time:29.454, tt:412.352\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01703, lr:6.00e-02, fs:0.73962 (r=0.990,p=0.590),  time:29.674, tt:445.104\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01675, lr:6.00e-02, fs:0.73962 (r=0.990,p=0.590),  time:29.721, tt:475.529\n",
      "Ep:16, loss:0.00003, loss_test:0.01644, lr:6.00e-02, fs:0.74809 (r=0.990,p=0.601),  time:29.814, tt:506.830\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01624, lr:6.00e-02, fs:0.75486 (r=0.980,p=0.614),  time:29.796, tt:536.335\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01609, lr:6.00e-02, fs:0.76000 (r=0.960,p=0.629),  time:29.815, tt:566.481\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01599, lr:6.00e-02, fs:0.75200 (r=0.949,p=0.623),  time:29.855, tt:597.106\n",
      "Ep:20, loss:0.00003, loss_test:0.01590, lr:6.00e-02, fs:0.74900 (r=0.949,p=0.618),  time:29.849, tt:626.822\n",
      "Ep:21, loss:0.00003, loss_test:0.01581, lr:6.00e-02, fs:0.74603 (r=0.949,p=0.614),  time:29.886, tt:657.489\n",
      "Ep:22, loss:0.00003, loss_test:0.01568, lr:6.00e-02, fs:0.75200 (r=0.949,p=0.623),  time:29.895, tt:687.580\n",
      "Ep:23, loss:0.00003, loss_test:0.01557, lr:6.00e-02, fs:0.75502 (r=0.949,p=0.627),  time:29.991, tt:719.778\n",
      "Ep:24, loss:0.00003, loss_test:0.01547, lr:6.00e-02, fs:0.76113 (r=0.949,p=0.635),  time:30.069, tt:751.721\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01537, lr:6.00e-02, fs:0.76613 (r=0.960,p=0.638),  time:30.053, tt:781.390\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01526, lr:6.00e-02, fs:0.76613 (r=0.960,p=0.638),  time:30.072, tt:811.934\n",
      "Ep:27, loss:0.00003, loss_test:0.01517, lr:6.00e-02, fs:0.77733 (r=0.970,p=0.649),  time:30.117, tt:843.285\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01507, lr:6.00e-02, fs:0.79012 (r=0.970,p=0.667),  time:30.150, tt:874.341\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01497, lr:6.00e-02, fs:0.79339 (r=0.970,p=0.671),  time:30.162, tt:904.866\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01489, lr:6.00e-02, fs:0.79832 (r=0.960,p=0.683),  time:30.191, tt:935.921\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01481, lr:6.00e-02, fs:0.79832 (r=0.960,p=0.683),  time:30.249, tt:967.955\n",
      "Ep:32, loss:0.00002, loss_test:0.01472, lr:6.00e-02, fs:0.79832 (r=0.960,p=0.683),  time:30.295, tt:999.726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:33, loss:0.00002, loss_test:0.01465, lr:6.00e-02, fs:0.79832 (r=0.960,p=0.683),  time:30.327, tt:1031.134\n",
      "Ep:34, loss:0.00002, loss_test:0.01459, lr:6.00e-02, fs:0.80169 (r=0.960,p=0.688),  time:30.331, tt:1061.590\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01453, lr:6.00e-02, fs:0.80508 (r=0.960,p=0.693),  time:30.365, tt:1093.142\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01445, lr:6.00e-02, fs:0.81356 (r=0.970,p=0.701),  time:30.384, tt:1124.199\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01438, lr:6.00e-02, fs:0.81702 (r=0.970,p=0.706),  time:30.387, tt:1154.704\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01431, lr:6.00e-02, fs:0.81702 (r=0.970,p=0.706),  time:30.396, tt:1185.440\n",
      "Ep:39, loss:0.00002, loss_test:0.01426, lr:6.00e-02, fs:0.81897 (r=0.960,p=0.714),  time:30.398, tt:1215.906\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01421, lr:6.00e-02, fs:0.82251 (r=0.960,p=0.720),  time:30.375, tt:1245.363\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01415, lr:6.00e-02, fs:0.82251 (r=0.960,p=0.720),  time:30.357, tt:1274.976\n",
      "Ep:42, loss:0.00002, loss_test:0.01411, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:30.354, tt:1305.239\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01407, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:30.372, tt:1336.350\n",
      "Ep:44, loss:0.00002, loss_test:0.01403, lr:6.00e-02, fs:0.82969 (r=0.960,p=0.731),  time:30.381, tt:1367.157\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01398, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:30.378, tt:1397.387\n",
      "Ep:46, loss:0.00002, loss_test:0.01395, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:30.415, tt:1429.498\n",
      "Ep:47, loss:0.00002, loss_test:0.01391, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:30.414, tt:1459.873\n",
      "Ep:48, loss:0.00002, loss_test:0.01390, lr:6.00e-02, fs:0.82969 (r=0.960,p=0.731),  time:30.417, tt:1490.456\n",
      "Ep:49, loss:0.00002, loss_test:0.01386, lr:6.00e-02, fs:0.82969 (r=0.960,p=0.731),  time:30.426, tt:1521.311\n",
      "Ep:50, loss:0.00002, loss_test:0.01384, lr:6.00e-02, fs:0.83700 (r=0.960,p=0.742),  time:30.414, tt:1551.102\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01380, lr:6.00e-02, fs:0.83556 (r=0.949,p=0.746),  time:30.415, tt:1581.565\n",
      "Ep:52, loss:0.00002, loss_test:0.01376, lr:6.00e-02, fs:0.83556 (r=0.949,p=0.746),  time:30.395, tt:1610.916\n",
      "Ep:53, loss:0.00002, loss_test:0.01371, lr:6.00e-02, fs:0.83556 (r=0.949,p=0.746),  time:30.416, tt:1642.476\n",
      "Ep:54, loss:0.00002, loss_test:0.01367, lr:6.00e-02, fs:0.83556 (r=0.949,p=0.746),  time:30.408, tt:1672.448\n",
      "Ep:55, loss:0.00002, loss_test:0.01361, lr:6.00e-02, fs:0.83186 (r=0.949,p=0.740),  time:30.405, tt:1702.704\n",
      "Ep:56, loss:0.00002, loss_test:0.01357, lr:6.00e-02, fs:0.83929 (r=0.949,p=0.752),  time:30.392, tt:1732.327\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00002, loss_test:0.01355, lr:6.00e-02, fs:0.83784 (r=0.939,p=0.756),  time:30.390, tt:1762.619\n",
      "Ep:58, loss:0.00002, loss_test:0.01350, lr:6.00e-02, fs:0.83784 (r=0.939,p=0.756),  time:30.361, tt:1791.322\n",
      "Ep:59, loss:0.00002, loss_test:0.01348, lr:6.00e-02, fs:0.84163 (r=0.939,p=0.762),  time:30.357, tt:1821.433\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00002, loss_test:0.01344, lr:6.00e-02, fs:0.83784 (r=0.939,p=0.756),  time:30.377, tt:1853.015\n",
      "Ep:61, loss:0.00002, loss_test:0.01342, lr:6.00e-02, fs:0.84163 (r=0.939,p=0.762),  time:30.392, tt:1884.326\n",
      "Ep:62, loss:0.00002, loss_test:0.01336, lr:6.00e-02, fs:0.84685 (r=0.949,p=0.764),  time:30.375, tt:1913.652\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00002, loss_test:0.01330, lr:6.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:30.397, tt:1945.385\n",
      "Ep:64, loss:0.00002, loss_test:0.01325, lr:6.00e-02, fs:0.85586 (r=0.960,p=0.772),  time:30.403, tt:1976.226\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00002, loss_test:0.01326, lr:6.00e-02, fs:0.85068 (r=0.949,p=0.770),  time:30.408, tt:2006.905\n",
      "Ep:66, loss:0.00002, loss_test:0.01322, lr:6.00e-02, fs:0.85455 (r=0.949,p=0.777),  time:30.413, tt:2037.672\n",
      "Ep:67, loss:0.00002, loss_test:0.01317, lr:6.00e-02, fs:0.86364 (r=0.960,p=0.785),  time:30.410, tt:2067.903\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00002, loss_test:0.01313, lr:6.00e-02, fs:0.85973 (r=0.960,p=0.779),  time:30.413, tt:2098.522\n",
      "Ep:69, loss:0.00001, loss_test:0.01310, lr:6.00e-02, fs:0.86758 (r=0.960,p=0.792),  time:30.419, tt:2129.351\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.01307, lr:6.00e-02, fs:0.85973 (r=0.960,p=0.779),  time:30.417, tt:2159.611\n",
      "Ep:71, loss:0.00001, loss_test:0.01303, lr:6.00e-02, fs:0.86364 (r=0.960,p=0.785),  time:30.426, tt:2190.674\n",
      "Ep:72, loss:0.00001, loss_test:0.01302, lr:6.00e-02, fs:0.86636 (r=0.949,p=0.797),  time:30.399, tt:2219.147\n",
      "Ep:73, loss:0.00001, loss_test:0.01299, lr:6.00e-02, fs:0.86512 (r=0.939,p=0.802),  time:30.422, tt:2251.261\n",
      "Ep:74, loss:0.00001, loss_test:0.01295, lr:6.00e-02, fs:0.86512 (r=0.939,p=0.802),  time:30.441, tt:2283.086\n",
      "Ep:75, loss:0.00001, loss_test:0.01291, lr:6.00e-02, fs:0.86512 (r=0.939,p=0.802),  time:30.454, tt:2314.469\n",
      "Ep:76, loss:0.00001, loss_test:0.01290, lr:6.00e-02, fs:0.85981 (r=0.929,p=0.800),  time:30.462, tt:2345.552\n",
      "Ep:77, loss:0.00001, loss_test:0.01287, lr:6.00e-02, fs:0.85446 (r=0.919,p=0.798),  time:30.461, tt:2375.923\n",
      "Ep:78, loss:0.00001, loss_test:0.01285, lr:6.00e-02, fs:0.84906 (r=0.909,p=0.796),  time:30.450, tt:2405.541\n",
      "Ep:79, loss:0.00001, loss_test:0.01280, lr:6.00e-02, fs:0.84507 (r=0.909,p=0.789),  time:30.437, tt:2434.993\n",
      "Ep:80, loss:0.00001, loss_test:0.01276, lr:6.00e-02, fs:0.84906 (r=0.909,p=0.796),  time:30.429, tt:2464.736\n",
      "Ep:81, loss:0.00001, loss_test:0.01272, lr:5.94e-02, fs:0.84762 (r=0.899,p=0.802),  time:30.425, tt:2494.874\n",
      "Ep:82, loss:0.00001, loss_test:0.01271, lr:5.88e-02, fs:0.84360 (r=0.899,p=0.795),  time:30.414, tt:2524.385\n",
      "Ep:83, loss:0.00001, loss_test:0.01272, lr:5.82e-02, fs:0.84360 (r=0.899,p=0.795),  time:30.411, tt:2554.557\n",
      "Ep:84, loss:0.00001, loss_test:0.01270, lr:5.76e-02, fs:0.83810 (r=0.889,p=0.793),  time:30.413, tt:2585.109\n",
      "Ep:85, loss:0.00001, loss_test:0.01266, lr:5.71e-02, fs:0.83254 (r=0.879,p=0.791),  time:30.426, tt:2616.601\n",
      "Ep:86, loss:0.00001, loss_test:0.01264, lr:5.65e-02, fs:0.83254 (r=0.879,p=0.791),  time:30.429, tt:2647.343\n",
      "Ep:87, loss:0.00001, loss_test:0.01263, lr:5.59e-02, fs:0.83254 (r=0.879,p=0.791),  time:30.423, tt:2677.266\n",
      "Ep:88, loss:0.00001, loss_test:0.01261, lr:5.54e-02, fs:0.83254 (r=0.879,p=0.791),  time:30.424, tt:2707.765\n",
      "Ep:89, loss:0.00001, loss_test:0.01258, lr:5.48e-02, fs:0.83254 (r=0.879,p=0.791),  time:30.432, tt:2738.891\n",
      "Ep:90, loss:0.00001, loss_test:0.01262, lr:5.43e-02, fs:0.83654 (r=0.879,p=0.798),  time:30.429, tt:2769.060\n",
      "Ep:91, loss:0.00001, loss_test:0.01259, lr:5.37e-02, fs:0.83654 (r=0.879,p=0.798),  time:30.427, tt:2799.312\n",
      "Ep:92, loss:0.00001, loss_test:0.01256, lr:5.32e-02, fs:0.83654 (r=0.879,p=0.798),  time:30.432, tt:2830.184\n",
      "Ep:93, loss:0.00001, loss_test:0.01257, lr:5.27e-02, fs:0.84211 (r=0.889,p=0.800),  time:30.436, tt:2861.019\n",
      "Ep:94, loss:0.00001, loss_test:0.01258, lr:5.21e-02, fs:0.84615 (r=0.889,p=0.807),  time:30.434, tt:2891.183\n",
      "Ep:95, loss:0.00001, loss_test:0.01255, lr:5.16e-02, fs:0.84615 (r=0.889,p=0.807),  time:30.433, tt:2921.545\n",
      "Ep:96, loss:0.00001, loss_test:0.01251, lr:5.11e-02, fs:0.84615 (r=0.889,p=0.807),  time:30.424, tt:2951.140\n",
      "Ep:97, loss:0.00001, loss_test:0.01253, lr:5.06e-02, fs:0.84615 (r=0.889,p=0.807),  time:30.403, tt:2979.495\n",
      "Ep:98, loss:0.00001, loss_test:0.01252, lr:5.01e-02, fs:0.84615 (r=0.889,p=0.807),  time:30.416, tt:3011.214\n",
      "Ep:99, loss:0.00001, loss_test:0.01251, lr:4.96e-02, fs:0.84615 (r=0.889,p=0.807),  time:30.404, tt:3040.417\n",
      "Ep:100, loss:0.00001, loss_test:0.01249, lr:4.91e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.414, tt:3071.812\n",
      "Ep:101, loss:0.00001, loss_test:0.01249, lr:4.86e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.426, tt:3103.476\n",
      "Ep:102, loss:0.00001, loss_test:0.01247, lr:4.81e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.424, tt:3133.692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:103, loss:0.00001, loss_test:0.01248, lr:4.76e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.432, tt:3164.950\n",
      "Ep:104, loss:0.00001, loss_test:0.01249, lr:4.71e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.429, tt:3195.009\n",
      "Ep:105, loss:0.00001, loss_test:0.01247, lr:4.67e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.440, tt:3226.596\n",
      "Ep:106, loss:0.00001, loss_test:0.01246, lr:4.62e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.449, tt:3257.995\n",
      "Ep:107, loss:0.00001, loss_test:0.01245, lr:4.57e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.443, tt:3287.811\n",
      "Ep:108, loss:0.00001, loss_test:0.01244, lr:4.53e-02, fs:0.84615 (r=0.889,p=0.807),  time:30.429, tt:3316.774\n",
      "Ep:109, loss:0.00001, loss_test:0.01244, lr:4.48e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.409, tt:3344.947\n",
      "Ep:110, loss:0.00001, loss_test:0.01248, lr:4.44e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.403, tt:3374.762\n",
      "Ep:111, loss:0.00001, loss_test:0.01249, lr:4.39e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.391, tt:3403.837\n",
      "Ep:112, loss:0.00001, loss_test:0.01250, lr:4.35e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.376, tt:3432.532\n",
      "Ep:113, loss:0.00001, loss_test:0.01246, lr:4.31e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.357, tt:3460.652\n",
      "Ep:114, loss:0.00001, loss_test:0.01243, lr:4.26e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.342, tt:3489.300\n",
      "Ep:115, loss:0.00001, loss_test:0.01249, lr:4.22e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.327, tt:3517.951\n",
      "Ep:116, loss:0.00001, loss_test:0.01249, lr:4.18e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.316, tt:3547.026\n",
      "Ep:117, loss:0.00001, loss_test:0.01247, lr:4.14e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.311, tt:3576.677\n",
      "Ep:118, loss:0.00001, loss_test:0.01246, lr:4.10e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.304, tt:3606.223\n",
      "Ep:119, loss:0.00001, loss_test:0.01247, lr:4.05e-02, fs:0.84615 (r=0.889,p=0.807),  time:30.296, tt:3635.538\n",
      "Ep:120, loss:0.00001, loss_test:0.01248, lr:4.01e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.286, tt:3664.646\n",
      "Ep:121, loss:0.00001, loss_test:0.01248, lr:3.97e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.282, tt:3694.365\n",
      "Ep:122, loss:0.00001, loss_test:0.01249, lr:3.93e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.276, tt:3723.903\n",
      "Ep:123, loss:0.00001, loss_test:0.01247, lr:3.89e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.279, tt:3754.534\n",
      "Ep:124, loss:0.00001, loss_test:0.01249, lr:3.86e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.284, tt:3785.440\n",
      "Ep:125, loss:0.00001, loss_test:0.01251, lr:3.82e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.271, tt:3814.118\n",
      "Ep:126, loss:0.00001, loss_test:0.01252, lr:3.78e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.276, tt:3845.039\n",
      "Ep:127, loss:0.00001, loss_test:0.01252, lr:3.74e-02, fs:0.85437 (r=0.889,p=0.822),  time:30.276, tt:3875.287\n",
      "Ep:128, loss:0.00001, loss_test:0.01250, lr:3.70e-02, fs:0.85437 (r=0.889,p=0.822),  time:30.280, tt:3906.150\n",
      "Ep:129, loss:0.00001, loss_test:0.01254, lr:3.67e-02, fs:0.85437 (r=0.889,p=0.822),  time:30.294, tt:3938.266\n",
      "Ep:130, loss:0.00001, loss_test:0.01254, lr:3.63e-02, fs:0.85437 (r=0.889,p=0.822),  time:30.297, tt:3968.878\n",
      "Ep:131, loss:0.00001, loss_test:0.01253, lr:3.59e-02, fs:0.86275 (r=0.889,p=0.838),  time:30.299, tt:3999.437\n",
      "Ep:132, loss:0.00001, loss_test:0.01256, lr:3.56e-02, fs:0.86700 (r=0.889,p=0.846),  time:30.305, tt:4030.503\n",
      "Ep:133, loss:0.00001, loss_test:0.01256, lr:3.52e-02, fs:0.86700 (r=0.889,p=0.846),  time:30.301, tt:4060.323\n",
      "Ep:134, loss:0.00001, loss_test:0.01258, lr:3.49e-02, fs:0.86700 (r=0.889,p=0.846),  time:30.305, tt:4091.241\n",
      "Ep:135, loss:0.00001, loss_test:0.01257, lr:3.45e-02, fs:0.86700 (r=0.889,p=0.846),  time:30.309, tt:4121.981\n",
      "Ep:136, loss:0.00001, loss_test:0.01258, lr:3.42e-02, fs:0.86700 (r=0.889,p=0.846),  time:30.307, tt:4152.024\n",
      "Ep:137, loss:0.00001, loss_test:0.01259, lr:3.38e-02, fs:0.86700 (r=0.889,p=0.846),  time:30.304, tt:4181.951\n",
      "Ep:138, loss:0.00001, loss_test:0.01260, lr:3.35e-02, fs:0.86700 (r=0.889,p=0.846),  time:30.310, tt:4213.028\n",
      "Ep:139, loss:0.00001, loss_test:0.01257, lr:3.32e-02, fs:0.86700 (r=0.889,p=0.846),  time:30.311, tt:4243.502\n",
      "Ep:140, loss:0.00001, loss_test:0.01257, lr:3.28e-02, fs:0.86275 (r=0.889,p=0.838),  time:30.305, tt:4273.065\n",
      "Ep:141, loss:0.00001, loss_test:0.01262, lr:3.25e-02, fs:0.87129 (r=0.889,p=0.854),  time:30.306, tt:4303.383\n",
      "##########Best model found so far##########\n",
      "Ep:142, loss:0.00001, loss_test:0.01266, lr:3.25e-02, fs:0.87129 (r=0.889,p=0.854),  time:30.313, tt:4334.723\n",
      "Ep:143, loss:0.00001, loss_test:0.01266, lr:3.25e-02, fs:0.87129 (r=0.889,p=0.854),  time:30.307, tt:4364.137\n",
      "Ep:144, loss:0.00001, loss_test:0.01265, lr:3.25e-02, fs:0.87129 (r=0.889,p=0.854),  time:30.307, tt:4394.532\n",
      "Ep:145, loss:0.00001, loss_test:0.01265, lr:3.25e-02, fs:0.87129 (r=0.889,p=0.854),  time:30.314, tt:4425.911\n",
      "Ep:146, loss:0.00001, loss_test:0.01268, lr:3.25e-02, fs:0.87129 (r=0.889,p=0.854),  time:30.318, tt:4456.715\n",
      "Ep:147, loss:0.00001, loss_test:0.01270, lr:3.25e-02, fs:0.87129 (r=0.889,p=0.854),  time:30.311, tt:4486.065\n",
      "Ep:148, loss:0.00001, loss_test:0.01269, lr:3.25e-02, fs:0.87562 (r=0.889,p=0.863),  time:30.305, tt:4515.392\n",
      "##########Best model found so far##########\n",
      "Ep:149, loss:0.00001, loss_test:0.01269, lr:3.25e-02, fs:0.87562 (r=0.889,p=0.863),  time:30.303, tt:4545.473\n",
      "Ep:150, loss:0.00001, loss_test:0.01269, lr:3.25e-02, fs:0.87562 (r=0.889,p=0.863),  time:30.301, tt:4575.492\n",
      "Ep:151, loss:0.00001, loss_test:0.01269, lr:3.25e-02, fs:0.87562 (r=0.889,p=0.863),  time:30.303, tt:4606.051\n",
      "Ep:152, loss:0.00001, loss_test:0.01274, lr:3.25e-02, fs:0.87562 (r=0.889,p=0.863),  time:30.306, tt:4636.847\n",
      "Ep:153, loss:0.00001, loss_test:0.01277, lr:3.25e-02, fs:0.87562 (r=0.889,p=0.863),  time:30.296, tt:4665.594\n",
      "Ep:154, loss:0.00001, loss_test:0.01278, lr:3.25e-02, fs:0.87562 (r=0.889,p=0.863),  time:30.291, tt:4695.071\n",
      "Ep:155, loss:0.00001, loss_test:0.01278, lr:3.25e-02, fs:0.87562 (r=0.889,p=0.863),  time:30.286, tt:4724.691\n",
      "Ep:156, loss:0.00001, loss_test:0.01277, lr:3.25e-02, fs:0.87562 (r=0.889,p=0.863),  time:30.297, tt:4756.679\n",
      "Ep:157, loss:0.00001, loss_test:0.01277, lr:3.25e-02, fs:0.87562 (r=0.889,p=0.863),  time:30.305, tt:4788.161\n",
      "Ep:158, loss:0.00001, loss_test:0.01278, lr:3.25e-02, fs:0.88000 (r=0.889,p=0.871),  time:30.318, tt:4820.576\n",
      "##########Best model found so far##########\n",
      "Ep:159, loss:0.00001, loss_test:0.01280, lr:3.25e-02, fs:0.87562 (r=0.889,p=0.863),  time:30.315, tt:4850.339\n",
      "Ep:160, loss:0.00001, loss_test:0.01288, lr:3.25e-02, fs:0.88442 (r=0.889,p=0.880),  time:30.320, tt:4881.597\n",
      "##########Best model found so far##########\n",
      "Ep:161, loss:0.00001, loss_test:0.01285, lr:3.25e-02, fs:0.88000 (r=0.889,p=0.871),  time:30.322, tt:4912.105\n",
      "Ep:162, loss:0.00001, loss_test:0.01284, lr:3.25e-02, fs:0.88442 (r=0.889,p=0.880),  time:30.319, tt:4941.957\n",
      "Ep:163, loss:0.00001, loss_test:0.01286, lr:3.25e-02, fs:0.88442 (r=0.889,p=0.880),  time:30.317, tt:4971.953\n",
      "Ep:164, loss:0.00001, loss_test:0.01288, lr:3.25e-02, fs:0.88442 (r=0.889,p=0.880),  time:30.312, tt:5001.491\n",
      "Ep:165, loss:0.00001, loss_test:0.01290, lr:3.25e-02, fs:0.88442 (r=0.889,p=0.880),  time:30.315, tt:5032.222\n",
      "Ep:166, loss:0.00001, loss_test:0.01292, lr:3.25e-02, fs:0.88442 (r=0.889,p=0.880),  time:30.314, tt:5062.393\n",
      "Ep:167, loss:0.00001, loss_test:0.01293, lr:3.25e-02, fs:0.88442 (r=0.889,p=0.880),  time:30.318, tt:5093.348\n",
      "Ep:168, loss:0.00001, loss_test:0.01293, lr:3.25e-02, fs:0.88442 (r=0.889,p=0.880),  time:30.315, tt:5123.264\n",
      "Ep:169, loss:0.00001, loss_test:0.01296, lr:3.25e-02, fs:0.88442 (r=0.889,p=0.880),  time:30.309, tt:5152.448\n",
      "Ep:170, loss:0.00001, loss_test:0.01295, lr:3.25e-02, fs:0.88442 (r=0.889,p=0.880),  time:30.311, tt:5183.148\n",
      "Ep:171, loss:0.00001, loss_test:0.01300, lr:3.25e-02, fs:0.88442 (r=0.889,p=0.880),  time:30.314, tt:5213.967\n",
      "Ep:172, loss:0.00001, loss_test:0.01301, lr:3.22e-02, fs:0.88889 (r=0.889,p=0.889),  time:30.315, tt:5244.457\n",
      "##########Best model found so far##########\n",
      "Ep:173, loss:0.00001, loss_test:0.01302, lr:3.22e-02, fs:0.88442 (r=0.889,p=0.880),  time:30.315, tt:5274.809\n",
      "Ep:174, loss:0.00001, loss_test:0.01302, lr:3.22e-02, fs:0.88889 (r=0.889,p=0.889),  time:30.315, tt:5305.048\n",
      "Ep:175, loss:0.00001, loss_test:0.01305, lr:3.22e-02, fs:0.88889 (r=0.889,p=0.889),  time:30.312, tt:5334.839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:176, loss:0.00001, loss_test:0.01308, lr:3.22e-02, fs:0.89340 (r=0.889,p=0.898),  time:30.312, tt:5365.293\n",
      "##########Best model found so far##########\n",
      "Ep:177, loss:0.00001, loss_test:0.01310, lr:3.22e-02, fs:0.89340 (r=0.889,p=0.898),  time:30.309, tt:5394.921\n",
      "Ep:178, loss:0.00001, loss_test:0.01311, lr:3.22e-02, fs:0.89340 (r=0.889,p=0.898),  time:30.310, tt:5425.475\n",
      "Ep:179, loss:0.00001, loss_test:0.01312, lr:3.22e-02, fs:0.89340 (r=0.889,p=0.898),  time:30.311, tt:5456.009\n",
      "Ep:180, loss:0.00001, loss_test:0.01312, lr:3.22e-02, fs:0.89340 (r=0.889,p=0.898),  time:30.309, tt:5485.921\n",
      "Ep:181, loss:0.00001, loss_test:0.01313, lr:3.22e-02, fs:0.89340 (r=0.889,p=0.898),  time:30.302, tt:5515.044\n",
      "Ep:182, loss:0.00001, loss_test:0.01315, lr:3.22e-02, fs:0.89340 (r=0.889,p=0.898),  time:30.298, tt:5544.475\n",
      "Ep:183, loss:0.00001, loss_test:0.01319, lr:3.22e-02, fs:0.89340 (r=0.889,p=0.898),  time:30.296, tt:5574.390\n",
      "Ep:184, loss:0.00001, loss_test:0.01323, lr:3.22e-02, fs:0.89340 (r=0.889,p=0.898),  time:30.292, tt:5603.944\n",
      "Ep:185, loss:0.00001, loss_test:0.01324, lr:3.22e-02, fs:0.89340 (r=0.889,p=0.898),  time:30.285, tt:5633.037\n",
      "Ep:186, loss:0.00001, loss_test:0.01321, lr:3.22e-02, fs:0.89340 (r=0.889,p=0.898),  time:30.280, tt:5662.432\n",
      "Ep:187, loss:0.00001, loss_test:0.01323, lr:3.22e-02, fs:0.89340 (r=0.889,p=0.898),  time:30.293, tt:5695.032\n",
      "Ep:188, loss:0.00001, loss_test:0.01327, lr:3.19e-02, fs:0.89340 (r=0.889,p=0.898),  time:30.294, tt:5725.574\n",
      "Ep:189, loss:0.00001, loss_test:0.01328, lr:3.15e-02, fs:0.89340 (r=0.889,p=0.898),  time:30.300, tt:5756.989\n",
      "Ep:190, loss:0.00001, loss_test:0.01330, lr:3.12e-02, fs:0.89340 (r=0.889,p=0.898),  time:30.296, tt:5786.615\n",
      "Ep:191, loss:0.00001, loss_test:0.01334, lr:3.09e-02, fs:0.89796 (r=0.889,p=0.907),  time:30.305, tt:5818.550\n",
      "##########Best model found so far##########\n",
      "Ep:192, loss:0.00001, loss_test:0.01334, lr:3.09e-02, fs:0.89796 (r=0.889,p=0.907),  time:30.313, tt:5850.427\n",
      "Ep:193, loss:0.00001, loss_test:0.01336, lr:3.09e-02, fs:0.90256 (r=0.889,p=0.917),  time:30.323, tt:5882.668\n",
      "##########Best model found so far##########\n",
      "Ep:194, loss:0.00001, loss_test:0.01339, lr:3.09e-02, fs:0.89691 (r=0.879,p=0.916),  time:30.322, tt:5912.723\n",
      "Ep:195, loss:0.00001, loss_test:0.01340, lr:3.09e-02, fs:0.89691 (r=0.879,p=0.916),  time:30.325, tt:5943.694\n",
      "Ep:196, loss:0.00001, loss_test:0.01343, lr:3.09e-02, fs:0.89691 (r=0.879,p=0.916),  time:30.323, tt:5973.681\n",
      "Ep:197, loss:0.00001, loss_test:0.01345, lr:3.09e-02, fs:0.89691 (r=0.879,p=0.916),  time:30.326, tt:6004.476\n",
      "Ep:198, loss:0.00001, loss_test:0.01345, lr:3.09e-02, fs:0.88542 (r=0.859,p=0.914),  time:30.324, tt:6034.402\n",
      "Ep:199, loss:0.00001, loss_test:0.01348, lr:3.09e-02, fs:0.87368 (r=0.838,p=0.912),  time:30.321, tt:6064.298\n",
      "Ep:200, loss:0.00001, loss_test:0.01351, lr:3.09e-02, fs:0.87368 (r=0.838,p=0.912),  time:30.328, tt:6095.928\n",
      "Ep:201, loss:0.00001, loss_test:0.01352, lr:3.09e-02, fs:0.87368 (r=0.838,p=0.912),  time:30.325, tt:6125.594\n",
      "Ep:202, loss:0.00001, loss_test:0.01352, lr:3.09e-02, fs:0.87368 (r=0.838,p=0.912),  time:30.325, tt:6155.874\n",
      "Ep:203, loss:0.00001, loss_test:0.01355, lr:3.09e-02, fs:0.87368 (r=0.838,p=0.912),  time:30.329, tt:6187.202\n",
      "Ep:204, loss:0.00001, loss_test:0.01361, lr:3.09e-02, fs:0.87368 (r=0.838,p=0.912),  time:30.325, tt:6216.669\n",
      "Ep:205, loss:0.00001, loss_test:0.01365, lr:3.06e-02, fs:0.87831 (r=0.838,p=0.922),  time:30.334, tt:6248.794\n",
      "Ep:206, loss:0.00001, loss_test:0.01363, lr:3.03e-02, fs:0.87831 (r=0.838,p=0.922),  time:30.336, tt:6279.602\n",
      "Ep:207, loss:0.00001, loss_test:0.01364, lr:3.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:30.326, tt:6307.757\n",
      "Ep:208, loss:0.00001, loss_test:0.01365, lr:2.97e-02, fs:0.87368 (r=0.838,p=0.912),  time:30.324, tt:6337.681\n",
      "Ep:209, loss:0.00001, loss_test:0.01367, lr:2.94e-02, fs:0.87831 (r=0.838,p=0.922),  time:30.318, tt:6366.867\n",
      "Ep:210, loss:0.00001, loss_test:0.01371, lr:2.91e-02, fs:0.87831 (r=0.838,p=0.922),  time:30.309, tt:6395.245\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13907, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:28.441, tt:28.441\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13602, lr:1.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:29.708, tt:59.416\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.13093, lr:1.00e-02, fs:0.66901 (r=0.960,p=0.514),  time:29.429, tt:88.286\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00025, loss_test:0.12429, lr:1.00e-02, fs:0.67416 (r=0.909,p=0.536),  time:29.877, tt:119.508\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00024, loss_test:0.11754, lr:1.00e-02, fs:0.66667 (r=0.808,p=0.567),  time:30.568, tt:152.839\n",
      "Ep:5, loss:0.00023, loss_test:0.11415, lr:1.00e-02, fs:0.67556 (r=0.768,p=0.603),  time:30.643, tt:183.855\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00022, loss_test:0.11196, lr:1.00e-02, fs:0.69643 (r=0.788,p=0.624),  time:31.065, tt:217.457\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00022, loss_test:0.10981, lr:1.00e-02, fs:0.72000 (r=0.818,p=0.643),  time:31.262, tt:250.099\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00021, loss_test:0.10691, lr:1.00e-02, fs:0.73303 (r=0.818,p=0.664),  time:31.448, tt:283.029\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.10415, lr:1.00e-02, fs:0.71429 (r=0.758,p=0.676),  time:31.618, tt:316.178\n",
      "Ep:10, loss:0.00020, loss_test:0.10157, lr:1.00e-02, fs:0.71770 (r=0.758,p=0.682),  time:31.757, tt:349.330\n",
      "Ep:11, loss:0.00019, loss_test:0.09958, lr:1.00e-02, fs:0.74074 (r=0.808,p=0.684),  time:31.897, tt:382.766\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.09797, lr:1.00e-02, fs:0.76018 (r=0.848,p=0.689),  time:31.984, tt:415.798\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.09622, lr:1.00e-02, fs:0.76279 (r=0.828,p=0.707),  time:32.115, tt:449.603\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.09416, lr:1.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:32.219, tt:483.284\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.09225, lr:1.00e-02, fs:0.79091 (r=0.879,p=0.719),  time:32.440, tt:519.038\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.09129, lr:1.00e-02, fs:0.79070 (r=0.859,p=0.733),  time:32.485, tt:552.244\n",
      "Ep:17, loss:0.00016, loss_test:0.09050, lr:1.00e-02, fs:0.79070 (r=0.859,p=0.733),  time:32.546, tt:585.822\n",
      "Ep:18, loss:0.00016, loss_test:0.08937, lr:1.00e-02, fs:0.80189 (r=0.859,p=0.752),  time:32.606, tt:619.512\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00015, loss_test:0.08827, lr:1.00e-02, fs:0.80189 (r=0.859,p=0.752),  time:32.609, tt:652.189\n",
      "Ep:20, loss:0.00015, loss_test:0.08782, lr:1.00e-02, fs:0.82192 (r=0.909,p=0.750),  time:32.617, tt:684.964\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00014, loss_test:0.08710, lr:1.00e-02, fs:0.81481 (r=0.889,p=0.752),  time:32.674, tt:718.826\n",
      "Ep:22, loss:0.00014, loss_test:0.08610, lr:1.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:32.689, tt:751.844\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.08507, lr:1.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:32.629, tt:783.084\n",
      "Ep:24, loss:0.00013, loss_test:0.08423, lr:1.00e-02, fs:0.82075 (r=0.879,p=0.770),  time:32.652, tt:816.295\n",
      "Ep:25, loss:0.00013, loss_test:0.08351, lr:1.00e-02, fs:0.83721 (r=0.909,p=0.776),  time:32.681, tt:849.711\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00012, loss_test:0.08323, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:32.706, tt:883.052\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00012, loss_test:0.08236, lr:1.00e-02, fs:0.85047 (r=0.919,p=0.791),  time:32.735, tt:916.575\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:28, loss:0.00012, loss_test:0.08179, lr:1.00e-02, fs:0.82927 (r=0.859,p=0.802),  time:32.746, tt:949.621\n",
      "Ep:29, loss:0.00011, loss_test:0.08107, lr:1.00e-02, fs:0.85446 (r=0.919,p=0.798),  time:32.770, tt:983.105\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00011, loss_test:0.08041, lr:1.00e-02, fs:0.84615 (r=0.889,p=0.807),  time:32.753, tt:1015.352\n",
      "Ep:31, loss:0.00011, loss_test:0.07954, lr:1.00e-02, fs:0.85167 (r=0.899,p=0.809),  time:32.788, tt:1049.211\n",
      "Ep:32, loss:0.00011, loss_test:0.07905, lr:1.00e-02, fs:0.85714 (r=0.909,p=0.811),  time:32.801, tt:1082.418\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00010, loss_test:0.07844, lr:1.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:32.811, tt:1115.578\n",
      "Ep:34, loss:0.00010, loss_test:0.07781, lr:1.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:32.830, tt:1149.047\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00010, loss_test:0.07719, lr:1.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:32.905, tt:1184.576\n",
      "Ep:36, loss:0.00010, loss_test:0.07657, lr:1.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:32.931, tt:1218.431\n",
      "Ep:37, loss:0.00009, loss_test:0.07598, lr:1.00e-02, fs:0.86256 (r=0.919,p=0.812),  time:32.916, tt:1250.814\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.07585, lr:1.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:32.925, tt:1284.082\n",
      "Ep:39, loss:0.00009, loss_test:0.07522, lr:1.00e-02, fs:0.85714 (r=0.909,p=0.811),  time:32.939, tt:1317.554\n",
      "Ep:40, loss:0.00009, loss_test:0.07412, lr:1.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:32.918, tt:1349.631\n",
      "Ep:41, loss:0.00009, loss_test:0.07336, lr:1.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:32.898, tt:1381.714\n",
      "Ep:42, loss:0.00009, loss_test:0.07281, lr:1.00e-02, fs:0.87324 (r=0.939,p=0.816),  time:32.849, tt:1412.489\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00008, loss_test:0.07274, lr:1.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:32.836, tt:1444.789\n",
      "Ep:44, loss:0.00008, loss_test:0.07225, lr:1.00e-02, fs:0.87963 (r=0.960,p=0.812),  time:32.837, tt:1477.649\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00008, loss_test:0.07101, lr:1.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:32.806, tt:1509.079\n",
      "Ep:46, loss:0.00008, loss_test:0.07039, lr:1.00e-02, fs:0.87204 (r=0.929,p=0.821),  time:32.820, tt:1542.518\n",
      "Ep:47, loss:0.00008, loss_test:0.06999, lr:1.00e-02, fs:0.85714 (r=0.879,p=0.837),  time:32.798, tt:1574.281\n",
      "Ep:48, loss:0.00008, loss_test:0.06934, lr:1.00e-02, fs:0.85577 (r=0.899,p=0.817),  time:32.799, tt:1607.136\n",
      "Ep:49, loss:0.00007, loss_test:0.06977, lr:1.00e-02, fs:0.85000 (r=0.859,p=0.842),  time:32.789, tt:1639.426\n",
      "Ep:50, loss:0.00007, loss_test:0.06783, lr:1.00e-02, fs:0.88152 (r=0.939,p=0.830),  time:32.791, tt:1672.330\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00007, loss_test:0.06773, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:32.790, tt:1705.069\n",
      "Ep:52, loss:0.00007, loss_test:0.06721, lr:1.00e-02, fs:0.89202 (r=0.960,p=0.833),  time:32.797, tt:1738.260\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00007, loss_test:0.06745, lr:1.00e-02, fs:0.85572 (r=0.869,p=0.843),  time:32.786, tt:1770.419\n",
      "Ep:54, loss:0.00007, loss_test:0.06506, lr:1.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:32.788, tt:1803.323\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00007, loss_test:0.06555, lr:1.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:32.803, tt:1836.958\n",
      "Ep:56, loss:0.00006, loss_test:0.06473, lr:1.00e-02, fs:0.89623 (r=0.960,p=0.841),  time:32.778, tt:1868.337\n",
      "Ep:57, loss:0.00006, loss_test:0.06518, lr:1.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:32.766, tt:1900.436\n",
      "Ep:58, loss:0.00006, loss_test:0.06380, lr:1.00e-02, fs:0.89524 (r=0.949,p=0.847),  time:32.748, tt:1932.135\n",
      "Ep:59, loss:0.00006, loss_test:0.06311, lr:1.00e-02, fs:0.88350 (r=0.919,p=0.850),  time:32.733, tt:1963.998\n",
      "Ep:60, loss:0.00006, loss_test:0.06354, lr:1.00e-02, fs:0.87255 (r=0.899,p=0.848),  time:32.717, tt:1995.766\n",
      "Ep:61, loss:0.00006, loss_test:0.06256, lr:1.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:32.697, tt:2027.233\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00006, loss_test:0.06212, lr:1.00e-02, fs:0.86700 (r=0.889,p=0.846),  time:32.698, tt:2059.966\n",
      "Ep:63, loss:0.00006, loss_test:0.06211, lr:1.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:32.672, tt:2091.038\n",
      "Ep:64, loss:0.00005, loss_test:0.06317, lr:1.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:32.662, tt:2123.041\n",
      "Ep:65, loss:0.00006, loss_test:0.06173, lr:1.00e-02, fs:0.90654 (r=0.980,p=0.843),  time:32.655, tt:2155.241\n",
      "Ep:66, loss:0.00005, loss_test:0.06063, lr:1.00e-02, fs:0.89340 (r=0.889,p=0.898),  time:32.652, tt:2187.708\n",
      "Ep:67, loss:0.00005, loss_test:0.05994, lr:1.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:32.661, tt:2220.955\n",
      "Ep:68, loss:0.00005, loss_test:0.05901, lr:1.00e-02, fs:0.91346 (r=0.960,p=0.872),  time:32.650, tt:2252.878\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00005, loss_test:0.05963, lr:1.00e-02, fs:0.90385 (r=0.949,p=0.862),  time:32.650, tt:2285.467\n",
      "Ep:70, loss:0.00005, loss_test:0.05835, lr:1.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:32.650, tt:2318.170\n",
      "Ep:71, loss:0.00005, loss_test:0.05767, lr:1.00e-02, fs:0.91262 (r=0.949,p=0.879),  time:32.634, tt:2349.678\n",
      "Ep:72, loss:0.00005, loss_test:0.05878, lr:1.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:32.650, tt:2383.478\n",
      "Ep:73, loss:0.00005, loss_test:0.05734, lr:1.00e-02, fs:0.93269 (r=0.980,p=0.890),  time:32.660, tt:2416.833\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00005, loss_test:0.05753, lr:1.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:32.661, tt:2449.575\n",
      "Ep:75, loss:0.00004, loss_test:0.05629, lr:1.00e-02, fs:0.94686 (r=0.990,p=0.907),  time:32.662, tt:2482.299\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00004, loss_test:0.05730, lr:1.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:32.673, tt:2515.826\n",
      "Ep:77, loss:0.00004, loss_test:0.05604, lr:1.00e-02, fs:0.94175 (r=0.980,p=0.907),  time:32.676, tt:2548.764\n",
      "Ep:78, loss:0.00004, loss_test:0.05598, lr:1.00e-02, fs:0.93720 (r=0.980,p=0.898),  time:32.670, tt:2580.899\n",
      "Ep:79, loss:0.00004, loss_test:0.05558, lr:1.00e-02, fs:0.93720 (r=0.980,p=0.898),  time:32.673, tt:2613.806\n",
      "Ep:80, loss:0.00004, loss_test:0.05520, lr:1.00e-02, fs:0.94686 (r=0.990,p=0.907),  time:32.678, tt:2646.958\n",
      "Ep:81, loss:0.00004, loss_test:0.05679, lr:1.00e-02, fs:0.90816 (r=0.899,p=0.918),  time:32.648, tt:2677.141\n",
      "Ep:82, loss:0.00004, loss_test:0.05359, lr:1.00e-02, fs:0.94686 (r=0.990,p=0.907),  time:32.650, tt:2709.973\n",
      "Ep:83, loss:0.00004, loss_test:0.05790, lr:1.00e-02, fs:0.90256 (r=0.889,p=0.917),  time:32.642, tt:2741.967\n",
      "Ep:84, loss:0.00004, loss_test:0.05332, lr:1.00e-02, fs:0.94686 (r=0.990,p=0.907),  time:32.645, tt:2774.799\n",
      "Ep:85, loss:0.00004, loss_test:0.05748, lr:1.00e-02, fs:0.90256 (r=0.889,p=0.917),  time:32.648, tt:2807.742\n",
      "Ep:86, loss:0.00004, loss_test:0.05392, lr:1.00e-02, fs:0.93000 (r=0.939,p=0.921),  time:32.646, tt:2840.191\n",
      "Ep:87, loss:0.00004, loss_test:0.05599, lr:9.90e-03, fs:0.93137 (r=0.960,p=0.905),  time:32.638, tt:2872.109\n",
      "Ep:88, loss:0.00004, loss_test:0.05296, lr:9.80e-03, fs:0.93532 (r=0.949,p=0.922),  time:32.645, tt:2905.392\n",
      "Ep:89, loss:0.00003, loss_test:0.05478, lr:9.70e-03, fs:0.93137 (r=0.960,p=0.905),  time:32.654, tt:2938.856\n",
      "Ep:90, loss:0.00003, loss_test:0.05286, lr:9.61e-03, fs:0.93532 (r=0.949,p=0.922),  time:32.664, tt:2972.400\n",
      "Ep:91, loss:0.00003, loss_test:0.05481, lr:9.51e-03, fs:0.93000 (r=0.939,p=0.921),  time:32.663, tt:3004.979\n",
      "Ep:92, loss:0.00003, loss_test:0.05251, lr:9.41e-03, fs:0.94059 (r=0.960,p=0.922),  time:32.665, tt:3037.870\n",
      "Ep:93, loss:0.00003, loss_test:0.05310, lr:9.32e-03, fs:0.92462 (r=0.929,p=0.920),  time:32.695, tt:3073.353\n",
      "Ep:94, loss:0.00003, loss_test:0.05219, lr:9.23e-03, fs:0.93000 (r=0.939,p=0.921),  time:32.704, tt:3106.860\n",
      "Ep:95, loss:0.00003, loss_test:0.05389, lr:9.14e-03, fs:0.90722 (r=0.889,p=0.926),  time:32.704, tt:3139.621\n",
      "Ep:96, loss:0.00003, loss_test:0.05203, lr:9.04e-03, fs:0.92462 (r=0.929,p=0.920),  time:32.714, tt:3173.296\n",
      "Ep:97, loss:0.00003, loss_test:0.05210, lr:8.95e-03, fs:0.92929 (r=0.929,p=0.929),  time:32.713, tt:3205.843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:98, loss:0.00003, loss_test:0.05273, lr:8.86e-03, fs:0.93532 (r=0.949,p=0.922),  time:32.721, tt:3239.418\n",
      "Ep:99, loss:0.00003, loss_test:0.05293, lr:8.78e-03, fs:0.91282 (r=0.899,p=0.927),  time:32.729, tt:3272.897\n",
      "Ep:100, loss:0.00003, loss_test:0.05268, lr:8.69e-03, fs:0.92386 (r=0.919,p=0.929),  time:32.740, tt:3306.748\n",
      "Ep:101, loss:0.00003, loss_test:0.05145, lr:8.60e-03, fs:0.94581 (r=0.970,p=0.923),  time:32.734, tt:3338.848\n",
      "Ep:102, loss:0.00003, loss_test:0.05305, lr:8.51e-03, fs:0.91282 (r=0.899,p=0.927),  time:32.729, tt:3371.075\n",
      "Ep:103, loss:0.00003, loss_test:0.05145, lr:8.43e-03, fs:0.95098 (r=0.980,p=0.924),  time:32.736, tt:3404.545\n",
      "##########Best model found so far##########\n",
      "Ep:104, loss:0.00003, loss_test:0.05199, lr:8.43e-03, fs:0.94527 (r=0.960,p=0.931),  time:32.734, tt:3437.027\n",
      "Ep:105, loss:0.00003, loss_test:0.05200, lr:8.43e-03, fs:0.91837 (r=0.909,p=0.928),  time:32.737, tt:3470.107\n",
      "Ep:106, loss:0.00003, loss_test:0.05238, lr:8.43e-03, fs:0.90155 (r=0.879,p=0.926),  time:32.723, tt:3501.362\n",
      "Ep:107, loss:0.00003, loss_test:0.05215, lr:8.43e-03, fs:0.93467 (r=0.939,p=0.930),  time:32.723, tt:3534.085\n",
      "Ep:108, loss:0.00002, loss_test:0.05225, lr:8.43e-03, fs:0.90722 (r=0.889,p=0.926),  time:32.742, tt:3568.872\n",
      "Ep:109, loss:0.00002, loss_test:0.05172, lr:8.43e-03, fs:0.94527 (r=0.960,p=0.931),  time:32.744, tt:3601.838\n",
      "Ep:110, loss:0.00002, loss_test:0.05294, lr:8.43e-03, fs:0.90625 (r=0.879,p=0.935),  time:32.749, tt:3635.113\n",
      "Ep:111, loss:0.00002, loss_test:0.05125, lr:8.43e-03, fs:0.94527 (r=0.960,p=0.931),  time:32.733, tt:3666.103\n",
      "Ep:112, loss:0.00002, loss_test:0.05351, lr:8.43e-03, fs:0.89583 (r=0.869,p=0.925),  time:32.735, tt:3699.093\n",
      "Ep:113, loss:0.00002, loss_test:0.05275, lr:8.43e-03, fs:0.89583 (r=0.869,p=0.925),  time:32.716, tt:3729.612\n",
      "Ep:114, loss:0.00002, loss_test:0.05181, lr:8.43e-03, fs:0.90722 (r=0.889,p=0.926),  time:32.683, tt:3758.583\n",
      "Ep:115, loss:0.00002, loss_test:0.05300, lr:8.35e-03, fs:0.89474 (r=0.859,p=0.934),  time:32.645, tt:3786.819\n",
      "Ep:116, loss:0.00002, loss_test:0.05170, lr:8.26e-03, fs:0.90722 (r=0.889,p=0.926),  time:32.643, tt:3819.193\n",
      "Ep:117, loss:0.00002, loss_test:0.05327, lr:8.18e-03, fs:0.88298 (r=0.838,p=0.933),  time:32.631, tt:3850.400\n",
      "Ep:118, loss:0.00002, loss_test:0.05221, lr:8.10e-03, fs:0.90625 (r=0.879,p=0.935),  time:32.625, tt:3882.327\n",
      "Ep:119, loss:0.00002, loss_test:0.05297, lr:8.02e-03, fs:0.89947 (r=0.859,p=0.944),  time:32.611, tt:3913.319\n",
      "Ep:120, loss:0.00002, loss_test:0.05266, lr:7.94e-03, fs:0.89474 (r=0.859,p=0.934),  time:32.606, tt:3945.309\n",
      "Ep:121, loss:0.00002, loss_test:0.05355, lr:7.86e-03, fs:0.88770 (r=0.838,p=0.943),  time:32.596, tt:3976.752\n",
      "Ep:122, loss:0.00002, loss_test:0.05270, lr:7.78e-03, fs:0.89474 (r=0.859,p=0.934),  time:32.586, tt:4008.107\n",
      "Ep:123, loss:0.00002, loss_test:0.05350, lr:7.70e-03, fs:0.88770 (r=0.838,p=0.943),  time:32.578, tt:4039.718\n",
      "Ep:124, loss:0.00002, loss_test:0.05310, lr:7.62e-03, fs:0.90155 (r=0.879,p=0.926),  time:32.581, tt:4072.677\n",
      "Ep:125, loss:0.00002, loss_test:0.05466, lr:7.55e-03, fs:0.86957 (r=0.808,p=0.941),  time:32.571, tt:4103.997\n",
      "Ep:126, loss:0.00002, loss_test:0.05302, lr:7.47e-03, fs:0.88770 (r=0.838,p=0.943),  time:32.575, tt:4137.054\n",
      "Ep:127, loss:0.00002, loss_test:0.05435, lr:7.40e-03, fs:0.88172 (r=0.828,p=0.943),  time:32.575, tt:4169.649\n",
      "Ep:128, loss:0.00002, loss_test:0.05427, lr:7.32e-03, fs:0.88172 (r=0.828,p=0.943),  time:32.586, tt:4203.545\n",
      "Ep:129, loss:0.00002, loss_test:0.05303, lr:7.25e-03, fs:0.88770 (r=0.838,p=0.943),  time:32.612, tt:4239.592\n",
      "Ep:130, loss:0.00002, loss_test:0.05622, lr:7.18e-03, fs:0.86957 (r=0.808,p=0.941),  time:32.611, tt:4272.046\n",
      "Ep:131, loss:0.00002, loss_test:0.05344, lr:7.11e-03, fs:0.88770 (r=0.838,p=0.943),  time:32.613, tt:4304.950\n",
      "Ep:132, loss:0.00002, loss_test:0.05406, lr:7.03e-03, fs:0.86957 (r=0.808,p=0.941),  time:32.602, tt:4336.028\n",
      "Ep:133, loss:0.00002, loss_test:0.05465, lr:6.96e-03, fs:0.88172 (r=0.828,p=0.943),  time:32.609, tt:4369.631\n",
      "Ep:134, loss:0.00002, loss_test:0.05462, lr:6.89e-03, fs:0.86957 (r=0.808,p=0.941),  time:32.610, tt:4402.333\n",
      "Ep:135, loss:0.00002, loss_test:0.05364, lr:6.83e-03, fs:0.88770 (r=0.838,p=0.943),  time:32.607, tt:4434.489\n",
      "Ep:136, loss:0.00002, loss_test:0.05452, lr:6.76e-03, fs:0.86957 (r=0.808,p=0.941),  time:32.607, tt:4467.196\n",
      "Ep:137, loss:0.00002, loss_test:0.05416, lr:6.69e-03, fs:0.87568 (r=0.818,p=0.942),  time:32.606, tt:4499.691\n",
      "Ep:138, loss:0.00002, loss_test:0.05430, lr:6.62e-03, fs:0.87568 (r=0.818,p=0.942),  time:32.604, tt:4531.910\n",
      "Ep:139, loss:0.00002, loss_test:0.05440, lr:6.56e-03, fs:0.86957 (r=0.808,p=0.941),  time:32.600, tt:4564.034\n",
      "Ep:140, loss:0.00002, loss_test:0.05495, lr:6.49e-03, fs:0.88043 (r=0.818,p=0.953),  time:32.599, tt:4596.444\n",
      "Ep:141, loss:0.00002, loss_test:0.05484, lr:6.43e-03, fs:0.86957 (r=0.808,p=0.941),  time:32.590, tt:4627.735\n",
      "Ep:142, loss:0.00002, loss_test:0.05468, lr:6.36e-03, fs:0.88043 (r=0.818,p=0.953),  time:32.582, tt:4659.166\n",
      "Ep:143, loss:0.00002, loss_test:0.05526, lr:6.30e-03, fs:0.86957 (r=0.808,p=0.941),  time:32.588, tt:4692.660\n",
      "Ep:144, loss:0.00002, loss_test:0.05425, lr:6.24e-03, fs:0.86957 (r=0.808,p=0.941),  time:32.600, tt:4727.063\n",
      "Ep:145, loss:0.00002, loss_test:0.05576, lr:6.17e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.595, tt:4758.838\n",
      "Ep:146, loss:0.00002, loss_test:0.05443, lr:6.11e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.600, tt:4792.180\n",
      "Ep:147, loss:0.00001, loss_test:0.05483, lr:6.05e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.605, tt:4825.508\n",
      "Ep:148, loss:0.00001, loss_test:0.05529, lr:5.99e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.588, tt:4855.551\n",
      "Ep:149, loss:0.00001, loss_test:0.05475, lr:5.93e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.585, tt:4887.773\n",
      "Ep:150, loss:0.00001, loss_test:0.05561, lr:5.87e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.614, tt:4924.783\n",
      "Ep:151, loss:0.00001, loss_test:0.05438, lr:5.81e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.620, tt:4958.309\n",
      "Ep:152, loss:0.00001, loss_test:0.05537, lr:5.75e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.619, tt:4990.728\n",
      "Ep:153, loss:0.00001, loss_test:0.05449, lr:5.70e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.617, tt:5023.030\n",
      "Ep:154, loss:0.00001, loss_test:0.05537, lr:5.64e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.616, tt:5055.486\n",
      "Ep:155, loss:0.00001, loss_test:0.05464, lr:5.58e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.617, tt:5088.253\n",
      "Ep:156, loss:0.00001, loss_test:0.05499, lr:5.53e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.617, tt:5120.912\n",
      "Ep:157, loss:0.00001, loss_test:0.05666, lr:5.47e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.604, tt:5151.420\n",
      "Ep:158, loss:0.00001, loss_test:0.05472, lr:5.42e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.609, tt:5184.887\n",
      "Ep:159, loss:0.00001, loss_test:0.05656, lr:5.36e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.596, tt:5215.402\n",
      "Ep:160, loss:0.00001, loss_test:0.05490, lr:5.31e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.590, tt:5246.977\n",
      "Ep:161, loss:0.00001, loss_test:0.05675, lr:5.26e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.591, tt:5279.721\n",
      "Ep:162, loss:0.00001, loss_test:0.05501, lr:5.20e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.587, tt:5311.681\n",
      "Ep:163, loss:0.00001, loss_test:0.05659, lr:5.15e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.589, tt:5344.611\n",
      "Ep:164, loss:0.00001, loss_test:0.05691, lr:5.10e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.585, tt:5376.578\n",
      "Ep:165, loss:0.00001, loss_test:0.05509, lr:5.05e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.568, tt:5406.309\n",
      "Ep:166, loss:0.00001, loss_test:0.05643, lr:5.00e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.561, tt:5437.613\n",
      "Ep:167, loss:0.00001, loss_test:0.05581, lr:4.95e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.552, tt:5468.684\n",
      "Ep:168, loss:0.00001, loss_test:0.05622, lr:4.90e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.535, tt:5498.334\n",
      "Ep:169, loss:0.00001, loss_test:0.05539, lr:4.85e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.515, tt:5527.546\n",
      "Ep:170, loss:0.00001, loss_test:0.05652, lr:4.80e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.501, tt:5557.717\n",
      "Ep:171, loss:0.00001, loss_test:0.05711, lr:4.75e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.501, tt:5590.229\n",
      "Ep:172, loss:0.00001, loss_test:0.05558, lr:4.71e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.501, tt:5622.725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:173, loss:0.00001, loss_test:0.05595, lr:4.66e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.495, tt:5654.192\n",
      "Ep:174, loss:0.00001, loss_test:0.05663, lr:4.61e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.489, tt:5685.620\n",
      "Ep:175, loss:0.00001, loss_test:0.05711, lr:4.57e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.478, tt:5716.135\n",
      "Ep:176, loss:0.00001, loss_test:0.05558, lr:4.52e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.476, tt:5748.170\n",
      "Ep:177, loss:0.00001, loss_test:0.05703, lr:4.48e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.470, tt:5779.613\n",
      "Ep:178, loss:0.00001, loss_test:0.05677, lr:4.43e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.471, tt:5812.387\n",
      "Ep:179, loss:0.00001, loss_test:0.05583, lr:4.39e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.469, tt:5844.455\n",
      "Ep:180, loss:0.00001, loss_test:0.05771, lr:4.34e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.467, tt:5876.574\n",
      "Ep:181, loss:0.00001, loss_test:0.05642, lr:4.30e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.461, tt:5907.953\n",
      "Ep:182, loss:0.00001, loss_test:0.05649, lr:4.26e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.456, tt:5939.387\n",
      "Ep:183, loss:0.00001, loss_test:0.05593, lr:4.21e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.452, tt:5971.239\n",
      "Ep:184, loss:0.00001, loss_test:0.05702, lr:4.17e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.451, tt:6003.503\n",
      "Ep:185, loss:0.00001, loss_test:0.05772, lr:4.13e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.448, tt:6035.281\n",
      "Ep:186, loss:0.00001, loss_test:0.05609, lr:4.09e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.448, tt:6067.785\n",
      "Ep:187, loss:0.00001, loss_test:0.05781, lr:4.05e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.445, tt:6099.711\n",
      "Ep:188, loss:0.00001, loss_test:0.05700, lr:4.01e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.449, tt:6132.870\n",
      "Ep:189, loss:0.00001, loss_test:0.05681, lr:3.97e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.456, tt:6166.592\n",
      "Ep:190, loss:0.00001, loss_test:0.05700, lr:3.93e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.457, tt:6199.256\n",
      "Ep:191, loss:0.00001, loss_test:0.05637, lr:3.89e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.455, tt:6231.271\n",
      "Ep:192, loss:0.00001, loss_test:0.05677, lr:3.85e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.454, tt:6263.582\n",
      "Ep:193, loss:0.00001, loss_test:0.05662, lr:3.81e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.453, tt:6295.855\n",
      "Ep:194, loss:0.00001, loss_test:0.05722, lr:3.77e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.455, tt:6328.679\n",
      "Ep:195, loss:0.00001, loss_test:0.05723, lr:3.73e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.453, tt:6360.793\n",
      "Ep:196, loss:0.00001, loss_test:0.05644, lr:3.70e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.455, tt:6393.704\n",
      "Ep:197, loss:0.00001, loss_test:0.05764, lr:3.66e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.454, tt:6425.818\n",
      "Ep:198, loss:0.00001, loss_test:0.05750, lr:3.62e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.440, tt:6455.580\n",
      "Ep:199, loss:0.00001, loss_test:0.05692, lr:3.59e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.441, tt:6488.147\n",
      "Ep:200, loss:0.00001, loss_test:0.05785, lr:3.55e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.430, tt:6518.376\n",
      "Ep:201, loss:0.00001, loss_test:0.05645, lr:3.52e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.424, tt:6549.619\n",
      "Ep:202, loss:0.00001, loss_test:0.05747, lr:3.48e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.424, tt:6582.023\n",
      "Ep:203, loss:0.00001, loss_test:0.05792, lr:3.45e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.432, tt:6616.062\n",
      "Ep:204, loss:0.00001, loss_test:0.05640, lr:3.41e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.420, tt:6646.040\n",
      "Ep:205, loss:0.00001, loss_test:0.05765, lr:3.38e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.416, tt:6677.774\n",
      "Ep:206, loss:0.00001, loss_test:0.05767, lr:3.34e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.407, tt:6708.213\n",
      "Ep:207, loss:0.00001, loss_test:0.05675, lr:3.31e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.410, tt:6741.312\n",
      "Ep:208, loss:0.00001, loss_test:0.05752, lr:3.28e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.398, tt:6771.170\n",
      "Ep:209, loss:0.00001, loss_test:0.05780, lr:3.24e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.384, tt:6800.634\n",
      "Ep:210, loss:0.00001, loss_test:0.05654, lr:3.21e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.363, tt:6828.599\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.01991, lr:6.00e-02, fs:0.65079 (r=0.828,p=0.536),  time:21.632, tt:21.632\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02187, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.686, tt:47.371\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02364, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.446, tt:79.338\n",
      "Ep:3, loss:0.00005, loss_test:0.02398, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.451, tt:109.803\n",
      "Ep:4, loss:0.00005, loss_test:0.02337, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.556, tt:137.782\n",
      "Ep:5, loss:0.00004, loss_test:0.02221, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.768, tt:166.605\n",
      "Ep:6, loss:0.00004, loss_test:0.02075, lr:6.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:27.666, tt:193.665\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01943, lr:6.00e-02, fs:0.68310 (r=0.980,p=0.524),  time:28.160, tt:225.282\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01853, lr:6.00e-02, fs:0.67897 (r=0.929,p=0.535),  time:28.285, tt:254.568\n",
      "Ep:9, loss:0.00004, loss_test:0.01804, lr:6.00e-02, fs:0.65587 (r=0.818,p=0.547),  time:28.355, tt:283.555\n",
      "Ep:10, loss:0.00004, loss_test:0.01770, lr:6.00e-02, fs:0.67769 (r=0.828,p=0.573),  time:28.595, tt:314.546\n",
      "Ep:11, loss:0.00004, loss_test:0.01740, lr:6.00e-02, fs:0.69076 (r=0.869,p=0.573),  time:28.652, tt:343.822\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01719, lr:6.00e-02, fs:0.72031 (r=0.949,p=0.580),  time:28.680, tt:372.840\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01710, lr:6.00e-02, fs:0.71212 (r=0.949,p=0.570),  time:28.742, tt:402.387\n",
      "Ep:14, loss:0.00003, loss_test:0.01699, lr:6.00e-02, fs:0.72180 (r=0.970,p=0.575),  time:28.917, tt:433.754\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01676, lr:6.00e-02, fs:0.72243 (r=0.960,p=0.579),  time:29.055, tt:464.883\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01651, lr:6.00e-02, fs:0.73077 (r=0.960,p=0.590),  time:29.136, tt:495.319\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01631, lr:6.00e-02, fs:0.73643 (r=0.960,p=0.597),  time:29.196, tt:525.529\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01617, lr:6.00e-02, fs:0.73810 (r=0.939,p=0.608),  time:29.293, tt:556.561\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01605, lr:6.00e-02, fs:0.74194 (r=0.929,p=0.617),  time:29.422, tt:588.435\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01594, lr:6.00e-02, fs:0.73684 (r=0.919,p=0.615),  time:29.507, tt:619.640\n",
      "Ep:21, loss:0.00003, loss_test:0.01583, lr:6.00e-02, fs:0.74494 (r=0.929,p=0.622),  time:29.537, tt:649.812\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01570, lr:6.00e-02, fs:0.74797 (r=0.929,p=0.626),  time:29.508, tt:678.685\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01554, lr:6.00e-02, fs:0.75918 (r=0.939,p=0.637),  time:29.539, tt:708.926\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:24, loss:0.00003, loss_test:0.01539, lr:6.00e-02, fs:0.77049 (r=0.949,p=0.648),  time:29.554, tt:738.840\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01527, lr:6.00e-02, fs:0.77686 (r=0.949,p=0.657),  time:29.648, tt:770.852\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01516, lr:6.00e-02, fs:0.77686 (r=0.949,p=0.657),  time:29.662, tt:800.875\n",
      "Ep:27, loss:0.00003, loss_test:0.01506, lr:6.00e-02, fs:0.77686 (r=0.949,p=0.657),  time:29.719, tt:832.130\n",
      "Ep:28, loss:0.00003, loss_test:0.01496, lr:6.00e-02, fs:0.78333 (r=0.949,p=0.667),  time:29.767, tt:863.248\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01485, lr:6.00e-02, fs:0.78661 (r=0.949,p=0.671),  time:29.810, tt:894.311\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01475, lr:6.00e-02, fs:0.78992 (r=0.949,p=0.676),  time:29.781, tt:923.200\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01465, lr:6.00e-02, fs:0.78814 (r=0.939,p=0.679),  time:29.818, tt:954.184\n",
      "Ep:32, loss:0.00002, loss_test:0.01456, lr:6.00e-02, fs:0.79487 (r=0.939,p=0.689),  time:29.790, tt:983.073\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01447, lr:6.00e-02, fs:0.79828 (r=0.939,p=0.694),  time:29.818, tt:1013.819\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01438, lr:6.00e-02, fs:0.80172 (r=0.939,p=0.699),  time:29.832, tt:1044.124\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01430, lr:6.00e-02, fs:0.80519 (r=0.939,p=0.705),  time:29.842, tt:1074.297\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01422, lr:6.00e-02, fs:0.80519 (r=0.939,p=0.705),  time:29.816, tt:1103.190\n",
      "Ep:37, loss:0.00002, loss_test:0.01419, lr:6.00e-02, fs:0.80519 (r=0.939,p=0.705),  time:29.859, tt:1134.646\n",
      "Ep:38, loss:0.00002, loss_test:0.01416, lr:6.00e-02, fs:0.80870 (r=0.939,p=0.710),  time:29.848, tt:1164.073\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01414, lr:6.00e-02, fs:0.80870 (r=0.939,p=0.710),  time:29.865, tt:1194.582\n",
      "Ep:40, loss:0.00002, loss_test:0.01409, lr:6.00e-02, fs:0.80870 (r=0.939,p=0.710),  time:29.879, tt:1225.029\n",
      "Ep:41, loss:0.00002, loss_test:0.01403, lr:6.00e-02, fs:0.80870 (r=0.939,p=0.710),  time:29.861, tt:1254.172\n",
      "Ep:42, loss:0.00002, loss_test:0.01397, lr:6.00e-02, fs:0.80870 (r=0.939,p=0.710),  time:29.854, tt:1283.719\n",
      "Ep:43, loss:0.00002, loss_test:0.01393, lr:6.00e-02, fs:0.80870 (r=0.939,p=0.710),  time:29.876, tt:1314.562\n",
      "Ep:44, loss:0.00002, loss_test:0.01390, lr:6.00e-02, fs:0.80870 (r=0.939,p=0.710),  time:29.882, tt:1344.670\n",
      "Ep:45, loss:0.00002, loss_test:0.01384, lr:6.00e-02, fs:0.81579 (r=0.939,p=0.721),  time:29.905, tt:1375.642\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01379, lr:6.00e-02, fs:0.81416 (r=0.929,p=0.724),  time:29.909, tt:1405.739\n",
      "Ep:47, loss:0.00002, loss_test:0.01375, lr:6.00e-02, fs:0.81416 (r=0.929,p=0.724),  time:29.924, tt:1436.356\n",
      "Ep:48, loss:0.00002, loss_test:0.01372, lr:6.00e-02, fs:0.81416 (r=0.929,p=0.724),  time:29.914, tt:1465.763\n",
      "Ep:49, loss:0.00002, loss_test:0.01366, lr:6.00e-02, fs:0.81778 (r=0.929,p=0.730),  time:29.944, tt:1497.217\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01360, lr:6.00e-02, fs:0.81778 (r=0.929,p=0.730),  time:29.942, tt:1527.016\n",
      "Ep:51, loss:0.00002, loss_test:0.01359, lr:6.00e-02, fs:0.81614 (r=0.919,p=0.734),  time:29.925, tt:1556.092\n",
      "Ep:52, loss:0.00002, loss_test:0.01355, lr:6.00e-02, fs:0.81250 (r=0.919,p=0.728),  time:29.931, tt:1586.367\n",
      "Ep:53, loss:0.00002, loss_test:0.01352, lr:6.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:29.926, tt:1616.001\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.01349, lr:6.00e-02, fs:0.82511 (r=0.929,p=0.742),  time:29.939, tt:1646.636\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.01347, lr:6.00e-02, fs:0.83258 (r=0.929,p=0.754),  time:29.950, tt:1677.204\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.01346, lr:6.00e-02, fs:0.83258 (r=0.929,p=0.754),  time:29.951, tt:1707.219\n",
      "Ep:57, loss:0.00002, loss_test:0.01339, lr:6.00e-02, fs:0.83258 (r=0.929,p=0.754),  time:29.973, tt:1738.410\n",
      "Ep:58, loss:0.00002, loss_test:0.01334, lr:6.00e-02, fs:0.83258 (r=0.929,p=0.754),  time:29.990, tt:1769.412\n",
      "Ep:59, loss:0.00002, loss_test:0.01334, lr:6.00e-02, fs:0.83258 (r=0.929,p=0.754),  time:29.990, tt:1799.383\n",
      "Ep:60, loss:0.00002, loss_test:0.01328, lr:6.00e-02, fs:0.83258 (r=0.929,p=0.754),  time:30.002, tt:1830.143\n",
      "Ep:61, loss:0.00002, loss_test:0.01327, lr:6.00e-02, fs:0.82727 (r=0.919,p=0.752),  time:30.001, tt:1860.075\n",
      "Ep:62, loss:0.00002, loss_test:0.01324, lr:6.00e-02, fs:0.82727 (r=0.919,p=0.752),  time:30.001, tt:1890.037\n",
      "Ep:63, loss:0.00002, loss_test:0.01319, lr:6.00e-02, fs:0.82727 (r=0.919,p=0.752),  time:30.030, tt:1921.912\n",
      "Ep:64, loss:0.00002, loss_test:0.01315, lr:6.00e-02, fs:0.82353 (r=0.919,p=0.746),  time:30.024, tt:1951.538\n",
      "Ep:65, loss:0.00001, loss_test:0.01316, lr:6.00e-02, fs:0.83105 (r=0.919,p=0.758),  time:30.039, tt:1982.561\n",
      "Ep:66, loss:0.00001, loss_test:0.01310, lr:6.00e-02, fs:0.83105 (r=0.919,p=0.758),  time:30.036, tt:2012.439\n",
      "Ep:67, loss:0.00001, loss_test:0.01309, lr:5.94e-02, fs:0.83105 (r=0.919,p=0.758),  time:30.048, tt:2043.268\n",
      "Ep:68, loss:0.00001, loss_test:0.01307, lr:5.88e-02, fs:0.83486 (r=0.919,p=0.765),  time:30.049, tt:2073.401\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01306, lr:5.88e-02, fs:0.83486 (r=0.919,p=0.765),  time:30.072, tt:2105.017\n",
      "Ep:70, loss:0.00001, loss_test:0.01303, lr:5.88e-02, fs:0.83486 (r=0.919,p=0.765),  time:30.071, tt:2135.020\n",
      "Ep:71, loss:0.00001, loss_test:0.01304, lr:5.88e-02, fs:0.83486 (r=0.919,p=0.765),  time:30.079, tt:2165.715\n",
      "Ep:72, loss:0.00001, loss_test:0.01298, lr:5.88e-02, fs:0.83486 (r=0.919,p=0.765),  time:30.093, tt:2196.803\n",
      "Ep:73, loss:0.00001, loss_test:0.01293, lr:5.88e-02, fs:0.82791 (r=0.899,p=0.767),  time:30.114, tt:2228.465\n",
      "Ep:74, loss:0.00001, loss_test:0.01290, lr:5.88e-02, fs:0.82791 (r=0.899,p=0.767),  time:30.117, tt:2258.745\n",
      "Ep:75, loss:0.00001, loss_test:0.01290, lr:5.88e-02, fs:0.82791 (r=0.899,p=0.767),  time:30.146, tt:2291.124\n",
      "Ep:76, loss:0.00001, loss_test:0.01284, lr:5.88e-02, fs:0.82407 (r=0.899,p=0.761),  time:30.126, tt:2319.668\n",
      "Ep:77, loss:0.00001, loss_test:0.01283, lr:5.88e-02, fs:0.82791 (r=0.899,p=0.767),  time:30.142, tt:2351.071\n",
      "Ep:78, loss:0.00001, loss_test:0.01285, lr:5.88e-02, fs:0.82791 (r=0.899,p=0.767),  time:30.149, tt:2381.779\n",
      "Ep:79, loss:0.00001, loss_test:0.01281, lr:5.88e-02, fs:0.83178 (r=0.899,p=0.774),  time:30.135, tt:2410.801\n",
      "Ep:80, loss:0.00001, loss_test:0.01280, lr:5.82e-02, fs:0.83019 (r=0.889,p=0.779),  time:30.147, tt:2441.936\n",
      "Ep:81, loss:0.00001, loss_test:0.01278, lr:5.76e-02, fs:0.83019 (r=0.889,p=0.779),  time:30.158, tt:2472.992\n",
      "Ep:82, loss:0.00001, loss_test:0.01276, lr:5.71e-02, fs:0.83568 (r=0.899,p=0.781),  time:30.177, tt:2504.711\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.01274, lr:5.71e-02, fs:0.83019 (r=0.889,p=0.779),  time:30.174, tt:2534.657\n",
      "Ep:84, loss:0.00001, loss_test:0.01271, lr:5.71e-02, fs:0.83019 (r=0.889,p=0.779),  time:30.182, tt:2565.451\n",
      "Ep:85, loss:0.00001, loss_test:0.01271, lr:5.71e-02, fs:0.82857 (r=0.879,p=0.784),  time:30.187, tt:2596.103\n",
      "Ep:86, loss:0.00001, loss_test:0.01273, lr:5.71e-02, fs:0.82857 (r=0.879,p=0.784),  time:30.204, tt:2627.779\n",
      "Ep:87, loss:0.00001, loss_test:0.01272, lr:5.71e-02, fs:0.82857 (r=0.879,p=0.784),  time:30.217, tt:2659.111\n",
      "Ep:88, loss:0.00001, loss_test:0.01271, lr:5.71e-02, fs:0.82857 (r=0.879,p=0.784),  time:30.206, tt:2688.355\n",
      "Ep:89, loss:0.00001, loss_test:0.01269, lr:5.71e-02, fs:0.82857 (r=0.879,p=0.784),  time:30.209, tt:2718.778\n",
      "Ep:90, loss:0.00001, loss_test:0.01266, lr:5.71e-02, fs:0.82297 (r=0.869,p=0.782),  time:30.216, tt:2749.637\n",
      "Ep:91, loss:0.00001, loss_test:0.01266, lr:5.71e-02, fs:0.80583 (r=0.838,p=0.776),  time:30.228, tt:2780.936\n",
      "Ep:92, loss:0.00001, loss_test:0.01264, lr:5.71e-02, fs:0.80976 (r=0.838,p=0.783),  time:30.229, tt:2811.295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:93, loss:0.00001, loss_test:0.01258, lr:5.71e-02, fs:0.81553 (r=0.848,p=0.785),  time:30.224, tt:2841.050\n",
      "Ep:94, loss:0.00001, loss_test:0.01259, lr:5.65e-02, fs:0.80976 (r=0.838,p=0.783),  time:30.240, tt:2872.758\n",
      "Ep:95, loss:0.00001, loss_test:0.01260, lr:5.59e-02, fs:0.80392 (r=0.828,p=0.781),  time:30.245, tt:2903.476\n",
      "Ep:96, loss:0.00001, loss_test:0.01255, lr:5.54e-02, fs:0.80976 (r=0.838,p=0.783),  time:30.254, tt:2934.644\n",
      "Ep:97, loss:0.00001, loss_test:0.01256, lr:5.48e-02, fs:0.80788 (r=0.828,p=0.788),  time:30.247, tt:2964.219\n",
      "Ep:98, loss:0.00001, loss_test:0.01258, lr:5.43e-02, fs:0.80788 (r=0.828,p=0.788),  time:30.236, tt:2993.406\n",
      "Ep:99, loss:0.00001, loss_test:0.01253, lr:5.37e-02, fs:0.81188 (r=0.828,p=0.796),  time:30.228, tt:3022.828\n",
      "Ep:100, loss:0.00001, loss_test:0.01250, lr:5.32e-02, fs:0.81188 (r=0.828,p=0.796),  time:30.224, tt:3052.612\n",
      "Ep:101, loss:0.00001, loss_test:0.01253, lr:5.27e-02, fs:0.81188 (r=0.828,p=0.796),  time:30.218, tt:3082.203\n",
      "Ep:102, loss:0.00001, loss_test:0.01256, lr:5.21e-02, fs:0.81407 (r=0.818,p=0.810),  time:30.234, tt:3114.069\n",
      "Ep:103, loss:0.00001, loss_test:0.01251, lr:5.16e-02, fs:0.81592 (r=0.828,p=0.804),  time:30.241, tt:3145.116\n",
      "Ep:104, loss:0.00001, loss_test:0.01250, lr:5.11e-02, fs:0.82412 (r=0.828,p=0.820),  time:30.265, tt:3177.871\n",
      "Ep:105, loss:0.00001, loss_test:0.01252, lr:5.06e-02, fs:0.82653 (r=0.818,p=0.835),  time:30.274, tt:3209.097\n",
      "Ep:106, loss:0.00001, loss_test:0.01254, lr:5.01e-02, fs:0.82653 (r=0.818,p=0.835),  time:30.274, tt:3239.337\n",
      "Ep:107, loss:0.00001, loss_test:0.01252, lr:4.96e-02, fs:0.82653 (r=0.818,p=0.835),  time:30.263, tt:3268.456\n",
      "Ep:108, loss:0.00001, loss_test:0.01249, lr:4.91e-02, fs:0.82653 (r=0.818,p=0.835),  time:30.261, tt:3298.469\n",
      "Ep:109, loss:0.00001, loss_test:0.01249, lr:4.86e-02, fs:0.82653 (r=0.818,p=0.835),  time:30.241, tt:3326.540\n",
      "Ep:110, loss:0.00001, loss_test:0.01256, lr:4.81e-02, fs:0.83077 (r=0.818,p=0.844),  time:30.247, tt:3357.364\n",
      "Ep:111, loss:0.00001, loss_test:0.01256, lr:4.76e-02, fs:0.83077 (r=0.818,p=0.844),  time:30.239, tt:3386.823\n",
      "Ep:112, loss:0.00001, loss_test:0.01249, lr:4.71e-02, fs:0.83077 (r=0.818,p=0.844),  time:30.242, tt:3417.346\n",
      "Ep:113, loss:0.00001, loss_test:0.01255, lr:4.67e-02, fs:0.83505 (r=0.818,p=0.853),  time:30.250, tt:3448.517\n",
      "Ep:114, loss:0.00001, loss_test:0.01255, lr:4.62e-02, fs:0.83505 (r=0.818,p=0.853),  time:30.236, tt:3477.166\n",
      "Ep:115, loss:0.00001, loss_test:0.01252, lr:4.57e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.235, tt:3507.242\n",
      "##########Best model found so far##########\n",
      "Ep:116, loss:0.00001, loss_test:0.01251, lr:4.57e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.229, tt:3536.760\n",
      "Ep:117, loss:0.00001, loss_test:0.01256, lr:4.57e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.228, tt:3566.939\n",
      "Ep:118, loss:0.00001, loss_test:0.01256, lr:4.57e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.225, tt:3596.815\n",
      "Ep:119, loss:0.00001, loss_test:0.01254, lr:4.57e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.225, tt:3626.953\n",
      "Ep:120, loss:0.00001, loss_test:0.01257, lr:4.57e-02, fs:0.82723 (r=0.798,p=0.859),  time:30.233, tt:3658.232\n",
      "Ep:121, loss:0.00001, loss_test:0.01257, lr:4.57e-02, fs:0.82723 (r=0.798,p=0.859),  time:30.247, tt:3690.159\n",
      "Ep:122, loss:0.00001, loss_test:0.01257, lr:4.57e-02, fs:0.82723 (r=0.798,p=0.859),  time:30.251, tt:3720.822\n",
      "Ep:123, loss:0.00001, loss_test:0.01254, lr:4.57e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.248, tt:3750.706\n",
      "Ep:124, loss:0.00001, loss_test:0.01259, lr:4.57e-02, fs:0.82723 (r=0.798,p=0.859),  time:30.259, tt:3782.368\n",
      "Ep:125, loss:0.00001, loss_test:0.01263, lr:4.57e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.286, tt:3816.068\n",
      "Ep:126, loss:0.00001, loss_test:0.01263, lr:4.57e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.284, tt:3846.056\n",
      "Ep:127, loss:0.00001, loss_test:0.01260, lr:4.53e-02, fs:0.82723 (r=0.798,p=0.859),  time:30.284, tt:3876.368\n",
      "Ep:128, loss:0.00001, loss_test:0.01267, lr:4.48e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.296, tt:3908.170\n",
      "Ep:129, loss:0.00001, loss_test:0.01267, lr:4.44e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.304, tt:3939.548\n",
      "Ep:130, loss:0.00001, loss_test:0.01264, lr:4.39e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.321, tt:3972.051\n",
      "Ep:131, loss:0.00001, loss_test:0.01266, lr:4.35e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.320, tt:4002.190\n",
      "Ep:132, loss:0.00001, loss_test:0.01271, lr:4.31e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.320, tt:4032.520\n",
      "Ep:133, loss:0.00001, loss_test:0.01274, lr:4.26e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.322, tt:4063.194\n",
      "Ep:134, loss:0.00001, loss_test:0.01270, lr:4.22e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.317, tt:4092.805\n",
      "Ep:135, loss:0.00001, loss_test:0.01270, lr:4.18e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.317, tt:4123.084\n",
      "Ep:136, loss:0.00001, loss_test:0.01271, lr:4.14e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.315, tt:4153.202\n",
      "Ep:137, loss:0.00001, loss_test:0.01275, lr:4.10e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.318, tt:4183.865\n",
      "Ep:138, loss:0.00001, loss_test:0.01278, lr:4.05e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.322, tt:4214.804\n",
      "Ep:139, loss:0.00001, loss_test:0.01276, lr:4.01e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.324, tt:4245.371\n",
      "Ep:140, loss:0.00001, loss_test:0.01275, lr:3.97e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.324, tt:4275.687\n",
      "Ep:141, loss:0.00001, loss_test:0.01281, lr:3.93e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.323, tt:4305.814\n",
      "Ep:142, loss:0.00001, loss_test:0.01285, lr:3.89e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.319, tt:4335.618\n",
      "Ep:143, loss:0.00001, loss_test:0.01281, lr:3.86e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.320, tt:4366.125\n",
      "Ep:144, loss:0.00001, loss_test:0.01283, lr:3.82e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.322, tt:4396.696\n",
      "Ep:145, loss:0.00001, loss_test:0.01287, lr:3.78e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.325, tt:4427.519\n",
      "Ep:146, loss:0.00001, loss_test:0.01289, lr:3.74e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.329, tt:4458.349\n",
      "Ep:147, loss:0.00001, loss_test:0.01290, lr:3.70e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.331, tt:4488.932\n",
      "Ep:148, loss:0.00001, loss_test:0.01291, lr:3.67e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.323, tt:4518.149\n",
      "Ep:149, loss:0.00001, loss_test:0.01292, lr:3.63e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.321, tt:4548.096\n",
      "Ep:150, loss:0.00001, loss_test:0.01294, lr:3.59e-02, fs:0.81915 (r=0.778,p=0.865),  time:30.313, tt:4577.266\n",
      "Ep:151, loss:0.00001, loss_test:0.01295, lr:3.56e-02, fs:0.81915 (r=0.778,p=0.865),  time:30.309, tt:4606.898\n",
      "Ep:152, loss:0.00001, loss_test:0.01294, lr:3.52e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.304, tt:4636.492\n",
      "Ep:153, loss:0.00001, loss_test:0.01299, lr:3.49e-02, fs:0.81915 (r=0.778,p=0.865),  time:30.306, tt:4667.156\n",
      "Ep:154, loss:0.00001, loss_test:0.01297, lr:3.45e-02, fs:0.81915 (r=0.778,p=0.865),  time:30.301, tt:4696.611\n",
      "Ep:155, loss:0.00001, loss_test:0.01298, lr:3.42e-02, fs:0.81915 (r=0.778,p=0.865),  time:30.300, tt:4726.769\n",
      "Ep:156, loss:0.00001, loss_test:0.01302, lr:3.38e-02, fs:0.81915 (r=0.778,p=0.865),  time:30.302, tt:4757.480\n",
      "Ep:157, loss:0.00001, loss_test:0.01303, lr:3.35e-02, fs:0.81720 (r=0.768,p=0.874),  time:30.300, tt:4787.475\n",
      "Ep:158, loss:0.00001, loss_test:0.01306, lr:3.32e-02, fs:0.81720 (r=0.768,p=0.874),  time:30.291, tt:4816.298\n",
      "Ep:159, loss:0.00001, loss_test:0.01306, lr:3.28e-02, fs:0.81720 (r=0.768,p=0.874),  time:30.289, tt:4846.221\n",
      "Ep:160, loss:0.00001, loss_test:0.01306, lr:3.25e-02, fs:0.81720 (r=0.768,p=0.874),  time:30.289, tt:4876.517\n",
      "Ep:161, loss:0.00001, loss_test:0.01309, lr:3.22e-02, fs:0.81720 (r=0.768,p=0.874),  time:30.294, tt:4907.604\n",
      "Ep:162, loss:0.00001, loss_test:0.01311, lr:3.19e-02, fs:0.81720 (r=0.768,p=0.874),  time:30.293, tt:4937.746\n",
      "Ep:163, loss:0.00001, loss_test:0.01312, lr:3.15e-02, fs:0.81720 (r=0.768,p=0.874),  time:30.289, tt:4967.324\n",
      "Ep:164, loss:0.00001, loss_test:0.01312, lr:3.12e-02, fs:0.81720 (r=0.768,p=0.874),  time:30.290, tt:4997.931\n",
      "Ep:165, loss:0.00001, loss_test:0.01312, lr:3.09e-02, fs:0.81720 (r=0.768,p=0.874),  time:30.287, tt:5027.598\n",
      "Ep:166, loss:0.00001, loss_test:0.01315, lr:3.06e-02, fs:0.82353 (r=0.778,p=0.875),  time:30.292, tt:5058.758\n",
      "Ep:167, loss:0.00001, loss_test:0.01314, lr:3.03e-02, fs:0.81720 (r=0.768,p=0.874),  time:30.283, tt:5087.558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:168, loss:0.00001, loss_test:0.01315, lr:3.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:30.288, tt:5118.622\n",
      "Ep:169, loss:0.00001, loss_test:0.01320, lr:2.97e-02, fs:0.82353 (r=0.778,p=0.875),  time:30.300, tt:5151.031\n",
      "Ep:170, loss:0.00001, loss_test:0.01320, lr:2.94e-02, fs:0.82353 (r=0.778,p=0.875),  time:30.296, tt:5180.642\n",
      "Ep:171, loss:0.00001, loss_test:0.01321, lr:2.91e-02, fs:0.82353 (r=0.778,p=0.875),  time:30.300, tt:5211.655\n",
      "Ep:172, loss:0.00001, loss_test:0.01322, lr:2.88e-02, fs:0.81720 (r=0.768,p=0.874),  time:30.301, tt:5242.029\n",
      "Ep:173, loss:0.00001, loss_test:0.01327, lr:2.85e-02, fs:0.82353 (r=0.778,p=0.875),  time:30.296, tt:5271.448\n",
      "Ep:174, loss:0.00001, loss_test:0.01327, lr:2.82e-02, fs:0.82353 (r=0.778,p=0.875),  time:30.302, tt:5302.788\n",
      "Ep:175, loss:0.00001, loss_test:0.01327, lr:2.80e-02, fs:0.82353 (r=0.778,p=0.875),  time:30.301, tt:5332.939\n",
      "Ep:176, loss:0.00001, loss_test:0.01327, lr:2.77e-02, fs:0.82796 (r=0.778,p=0.885),  time:30.299, tt:5362.955\n",
      "Ep:177, loss:0.00001, loss_test:0.01329, lr:2.74e-02, fs:0.82796 (r=0.778,p=0.885),  time:30.303, tt:5393.882\n",
      "Ep:178, loss:0.00001, loss_test:0.01333, lr:2.71e-02, fs:0.82796 (r=0.778,p=0.885),  time:30.304, tt:5424.352\n",
      "Ep:179, loss:0.00001, loss_test:0.01331, lr:2.69e-02, fs:0.82796 (r=0.778,p=0.885),  time:30.305, tt:5454.831\n",
      "Ep:180, loss:0.00001, loss_test:0.01330, lr:2.66e-02, fs:0.82162 (r=0.768,p=0.884),  time:30.305, tt:5485.130\n",
      "Ep:181, loss:0.00001, loss_test:0.01332, lr:2.63e-02, fs:0.82796 (r=0.778,p=0.885),  time:30.301, tt:5514.850\n",
      "Ep:182, loss:0.00001, loss_test:0.01337, lr:2.61e-02, fs:0.82796 (r=0.778,p=0.885),  time:30.293, tt:5543.616\n",
      "Ep:183, loss:0.00000, loss_test:0.01337, lr:2.58e-02, fs:0.82796 (r=0.778,p=0.885),  time:30.296, tt:5574.465\n",
      "Ep:184, loss:0.00000, loss_test:0.01335, lr:2.55e-02, fs:0.82796 (r=0.778,p=0.885),  time:30.296, tt:5604.713\n",
      "Ep:185, loss:0.00000, loss_test:0.01336, lr:2.53e-02, fs:0.82796 (r=0.778,p=0.885),  time:30.291, tt:5634.120\n",
      "Ep:186, loss:0.00000, loss_test:0.01340, lr:2.50e-02, fs:0.82162 (r=0.768,p=0.884),  time:30.297, tt:5665.467\n",
      "Ep:187, loss:0.00000, loss_test:0.01341, lr:2.48e-02, fs:0.82162 (r=0.768,p=0.884),  time:30.296, tt:5695.618\n",
      "Ep:188, loss:0.00000, loss_test:0.01340, lr:2.45e-02, fs:0.82162 (r=0.768,p=0.884),  time:30.295, tt:5725.841\n",
      "Ep:189, loss:0.00000, loss_test:0.01341, lr:2.43e-02, fs:0.82162 (r=0.768,p=0.884),  time:30.301, tt:5757.120\n",
      "Ep:190, loss:0.00000, loss_test:0.01343, lr:2.40e-02, fs:0.82162 (r=0.768,p=0.884),  time:30.294, tt:5786.207\n",
      "Ep:191, loss:0.00000, loss_test:0.01344, lr:2.38e-02, fs:0.81522 (r=0.758,p=0.882),  time:30.308, tt:5819.170\n",
      "Ep:192, loss:0.00000, loss_test:0.01347, lr:2.36e-02, fs:0.82162 (r=0.768,p=0.884),  time:30.308, tt:5849.492\n",
      "Ep:193, loss:0.00000, loss_test:0.01349, lr:2.33e-02, fs:0.82162 (r=0.768,p=0.884),  time:30.312, tt:5880.487\n",
      "Ep:194, loss:0.00000, loss_test:0.01348, lr:2.31e-02, fs:0.82162 (r=0.768,p=0.884),  time:30.307, tt:5909.802\n",
      "Ep:195, loss:0.00000, loss_test:0.01349, lr:2.29e-02, fs:0.82162 (r=0.768,p=0.884),  time:30.303, tt:5939.465\n",
      "Ep:196, loss:0.00000, loss_test:0.01351, lr:2.26e-02, fs:0.82162 (r=0.768,p=0.884),  time:30.303, tt:5969.655\n",
      "Ep:197, loss:0.00000, loss_test:0.01351, lr:2.24e-02, fs:0.82162 (r=0.768,p=0.884),  time:30.297, tt:5998.783\n",
      "Ep:198, loss:0.00000, loss_test:0.01354, lr:2.22e-02, fs:0.81522 (r=0.758,p=0.882),  time:30.290, tt:6027.769\n",
      "Ep:199, loss:0.00000, loss_test:0.01354, lr:2.20e-02, fs:0.81967 (r=0.758,p=0.893),  time:30.291, tt:6058.144\n",
      "Ep:200, loss:0.00000, loss_test:0.01354, lr:2.17e-02, fs:0.81967 (r=0.758,p=0.893),  time:30.286, tt:6087.570\n",
      "Ep:201, loss:0.00000, loss_test:0.01357, lr:2.15e-02, fs:0.82418 (r=0.758,p=0.904),  time:30.282, tt:6117.042\n",
      "Ep:202, loss:0.00000, loss_test:0.01358, lr:2.13e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.284, tt:6147.581\n",
      "Ep:203, loss:0.00000, loss_test:0.01360, lr:2.11e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.286, tt:6178.324\n",
      "Ep:204, loss:0.00000, loss_test:0.01359, lr:2.09e-02, fs:0.82418 (r=0.758,p=0.904),  time:30.295, tt:6210.539\n",
      "Ep:205, loss:0.00000, loss_test:0.01359, lr:2.07e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.305, tt:6242.749\n",
      "Ep:206, loss:0.00000, loss_test:0.01361, lr:2.05e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.308, tt:6273.820\n",
      "Ep:207, loss:0.00000, loss_test:0.01362, lr:2.03e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.315, tt:6305.508\n",
      "Ep:208, loss:0.00000, loss_test:0.01365, lr:2.01e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.311, tt:6335.051\n",
      "Ep:209, loss:0.00000, loss_test:0.01364, lr:1.99e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.310, tt:6365.018\n",
      "Ep:210, loss:0.00000, loss_test:0.01364, lr:1.97e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.292, tt:6391.601\n",
      "Ep:211, loss:0.00000, loss_test:0.01366, lr:1.95e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.282, tt:6419.875\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14363, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.906, tt:31.906\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14260, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.546, tt:63.092\n",
      "Ep:2, loss:0.00027, loss_test:0.14078, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.235, tt:93.704\n",
      "Ep:3, loss:0.00027, loss_test:0.13785, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:31.728, tt:126.911\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.13318, lr:1.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:32.110, tt:160.549\n",
      "Ep:5, loss:0.00025, loss_test:0.12613, lr:1.00e-02, fs:0.66165 (r=0.889,p=0.527),  time:31.827, tt:190.959\n",
      "Ep:9, loss:0.00022, loss_test:0.11125, lr:1.00e-02, fs:0.69787 (r=0.828,p=0.603),  time:32.242, tt:322.422\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.10900, lr:1.00e-02, fs:0.73043 (r=0.848,p=0.641),  time:32.198, tt:354.183\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.10535, lr:1.00e-02, fs:0.72222 (r=0.788,p=0.667),  time:32.292, tt:387.505\n",
      "Ep:12, loss:0.00020, loss_test:0.10292, lr:1.00e-02, fs:0.71498 (r=0.747,p=0.685),  time:32.296, tt:419.847\n",
      "Ep:13, loss:0.00020, loss_test:0.10076, lr:1.00e-02, fs:0.73585 (r=0.788,p=0.690),  time:32.365, tt:453.106\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.09900, lr:1.00e-02, fs:0.77626 (r=0.859,p=0.708),  time:32.219, tt:483.292\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.09703, lr:1.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:32.310, tt:516.964\n",
      "Ep:16, loss:0.00018, loss_test:0.09611, lr:1.00e-02, fs:0.76190 (r=0.808,p=0.721),  time:32.303, tt:549.157\n",
      "Ep:17, loss:0.00018, loss_test:0.09514, lr:1.00e-02, fs:0.76190 (r=0.808,p=0.721),  time:32.288, tt:581.180\n",
      "Ep:18, loss:0.00017, loss_test:0.09362, lr:1.00e-02, fs:0.75962 (r=0.798,p=0.725),  time:32.289, tt:613.499\n",
      "Ep:19, loss:0.00017, loss_test:0.09227, lr:1.00e-02, fs:0.77358 (r=0.828,p=0.726),  time:32.290, tt:645.806\n",
      "Ep:20, loss:0.00016, loss_test:0.09140, lr:1.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:32.272, tt:677.710\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.09043, lr:1.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:32.248, tt:709.461\n",
      "Ep:22, loss:0.00015, loss_test:0.08933, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:32.252, tt:741.788\n",
      "Ep:23, loss:0.00015, loss_test:0.08813, lr:1.00e-02, fs:0.78899 (r=0.869,p=0.723),  time:32.266, tt:774.375\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.08689, lr:1.00e-02, fs:0.79621 (r=0.848,p=0.750),  time:32.216, tt:805.403\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.08592, lr:1.00e-02, fs:0.82407 (r=0.899,p=0.761),  time:32.137, tt:835.565\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:26, loss:0.00014, loss_test:0.08495, lr:1.00e-02, fs:0.83333 (r=0.909,p=0.769),  time:32.186, tt:869.014\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.08421, lr:1.00e-02, fs:0.83254 (r=0.879,p=0.791),  time:32.214, tt:901.999\n",
      "Ep:28, loss:0.00013, loss_test:0.08330, lr:1.00e-02, fs:0.83721 (r=0.909,p=0.776),  time:32.201, tt:933.821\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.08274, lr:1.00e-02, fs:0.84762 (r=0.899,p=0.802),  time:32.209, tt:966.266\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00013, loss_test:0.08159, lr:1.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:32.250, tt:999.749\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.08139, lr:1.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:32.228, tt:1031.309\n",
      "Ep:32, loss:0.00012, loss_test:0.08019, lr:1.00e-02, fs:0.85167 (r=0.899,p=0.809),  time:32.203, tt:1062.690\n",
      "Ep:33, loss:0.00012, loss_test:0.07890, lr:1.00e-02, fs:0.85714 (r=0.909,p=0.811),  time:32.208, tt:1095.070\n",
      "Ep:34, loss:0.00011, loss_test:0.07862, lr:1.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:32.201, tt:1127.052\n",
      "Ep:35, loss:0.00011, loss_test:0.07707, lr:1.00e-02, fs:0.86667 (r=0.919,p=0.820),  time:32.197, tt:1159.080\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00011, loss_test:0.07678, lr:1.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:32.236, tt:1192.719\n",
      "Ep:37, loss:0.00010, loss_test:0.07479, lr:1.00e-02, fs:0.87379 (r=0.909,p=0.841),  time:32.220, tt:1224.365\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00010, loss_test:0.07442, lr:1.00e-02, fs:0.86957 (r=0.909,p=0.833),  time:32.254, tt:1257.907\n",
      "Ep:39, loss:0.00010, loss_test:0.07268, lr:1.00e-02, fs:0.88571 (r=0.939,p=0.838),  time:32.248, tt:1289.912\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00010, loss_test:0.07336, lr:1.00e-02, fs:0.86829 (r=0.899,p=0.840),  time:32.260, tt:1322.643\n",
      "Ep:41, loss:0.00009, loss_test:0.07101, lr:1.00e-02, fs:0.89720 (r=0.970,p=0.835),  time:32.232, tt:1353.735\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00009, loss_test:0.07038, lr:1.00e-02, fs:0.87923 (r=0.919,p=0.843),  time:32.208, tt:1384.964\n",
      "Ep:43, loss:0.00009, loss_test:0.07026, lr:1.00e-02, fs:0.88462 (r=0.929,p=0.844),  time:32.220, tt:1417.684\n",
      "Ep:44, loss:0.00009, loss_test:0.06863, lr:1.00e-02, fs:0.91163 (r=0.990,p=0.845),  time:32.197, tt:1448.871\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00009, loss_test:0.06898, lr:1.00e-02, fs:0.87923 (r=0.919,p=0.843),  time:32.174, tt:1479.996\n",
      "Ep:46, loss:0.00008, loss_test:0.06676, lr:1.00e-02, fs:0.90654 (r=0.980,p=0.843),  time:32.171, tt:1512.032\n",
      "Ep:47, loss:0.00008, loss_test:0.06853, lr:1.00e-02, fs:0.88889 (r=0.929,p=0.852),  time:32.153, tt:1543.344\n",
      "Ep:48, loss:0.00008, loss_test:0.06562, lr:1.00e-02, fs:0.91080 (r=0.980,p=0.851),  time:32.160, tt:1575.829\n",
      "Ep:49, loss:0.00008, loss_test:0.06645, lr:1.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:32.119, tt:1605.932\n",
      "Ep:50, loss:0.00007, loss_test:0.06459, lr:1.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:32.094, tt:1636.787\n",
      "Ep:51, loss:0.00007, loss_test:0.06400, lr:1.00e-02, fs:0.91080 (r=0.980,p=0.851),  time:32.085, tt:1668.427\n",
      "Ep:52, loss:0.00007, loss_test:0.06301, lr:1.00e-02, fs:0.92019 (r=0.990,p=0.860),  time:32.097, tt:1701.137\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00007, loss_test:0.06444, lr:1.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:32.105, tt:1733.696\n",
      "Ep:54, loss:0.00007, loss_test:0.06324, lr:1.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:32.098, tt:1765.380\n",
      "Ep:55, loss:0.00007, loss_test:0.06146, lr:1.00e-02, fs:0.91589 (r=0.990,p=0.852),  time:32.082, tt:1796.581\n",
      "Ep:56, loss:0.00007, loss_test:0.06243, lr:1.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:32.083, tt:1828.728\n",
      "Ep:57, loss:0.00006, loss_test:0.06094, lr:1.00e-02, fs:0.92453 (r=0.990,p=0.867),  time:32.075, tt:1860.367\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00006, loss_test:0.06137, lr:1.00e-02, fs:0.92453 (r=0.990,p=0.867),  time:32.067, tt:1891.937\n",
      "Ep:59, loss:0.00006, loss_test:0.06462, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:32.057, tt:1923.420\n",
      "Ep:60, loss:0.00006, loss_test:0.05960, lr:1.00e-02, fs:0.92019 (r=0.990,p=0.860),  time:32.062, tt:1955.779\n",
      "Ep:61, loss:0.00006, loss_test:0.06435, lr:1.00e-02, fs:0.88670 (r=0.909,p=0.865),  time:32.059, tt:1987.650\n",
      "Ep:62, loss:0.00006, loss_test:0.05843, lr:1.00e-02, fs:0.92019 (r=0.990,p=0.860),  time:32.049, tt:2019.057\n",
      "Ep:63, loss:0.00006, loss_test:0.06230, lr:1.00e-02, fs:0.88670 (r=0.909,p=0.865),  time:32.050, tt:2051.168\n",
      "Ep:64, loss:0.00006, loss_test:0.05712, lr:1.00e-02, fs:0.92453 (r=0.990,p=0.867),  time:32.025, tt:2081.600\n",
      "Ep:65, loss:0.00005, loss_test:0.06036, lr:1.00e-02, fs:0.91943 (r=0.980,p=0.866),  time:32.007, tt:2112.459\n",
      "Ep:66, loss:0.00005, loss_test:0.05622, lr:1.00e-02, fs:0.92453 (r=0.990,p=0.867),  time:31.954, tt:2140.899\n",
      "Ep:67, loss:0.00005, loss_test:0.05885, lr:1.00e-02, fs:0.92453 (r=0.990,p=0.867),  time:31.956, tt:2173.013\n",
      "Ep:68, loss:0.00005, loss_test:0.05479, lr:1.00e-02, fs:0.92019 (r=0.990,p=0.860),  time:31.970, tt:2205.964\n",
      "Ep:69, loss:0.00005, loss_test:0.05820, lr:9.90e-03, fs:0.92233 (r=0.960,p=0.888),  time:31.966, tt:2237.604\n",
      "Ep:70, loss:0.00005, loss_test:0.05446, lr:9.80e-03, fs:0.92453 (r=0.990,p=0.867),  time:31.967, tt:2269.635\n",
      "Ep:71, loss:0.00005, loss_test:0.05828, lr:9.70e-03, fs:0.92537 (r=0.939,p=0.912),  time:31.970, tt:2301.845\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00005, loss_test:0.05428, lr:9.70e-03, fs:0.92453 (r=0.990,p=0.867),  time:31.951, tt:2332.455\n",
      "Ep:73, loss:0.00004, loss_test:0.05680, lr:9.70e-03, fs:0.93720 (r=0.980,p=0.898),  time:31.951, tt:2364.345\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00004, loss_test:0.05430, lr:9.70e-03, fs:0.94231 (r=0.990,p=0.899),  time:31.951, tt:2396.315\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00004, loss_test:0.05557, lr:9.70e-03, fs:0.94175 (r=0.980,p=0.907),  time:31.944, tt:2427.775\n",
      "Ep:76, loss:0.00004, loss_test:0.05326, lr:9.70e-03, fs:0.95146 (r=0.990,p=0.916),  time:31.911, tt:2457.138\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00004, loss_test:0.05526, lr:9.70e-03, fs:0.95098 (r=0.980,p=0.924),  time:31.902, tt:2488.320\n",
      "Ep:78, loss:0.00004, loss_test:0.05313, lr:9.70e-03, fs:0.95146 (r=0.990,p=0.916),  time:31.887, tt:2519.038\n",
      "Ep:79, loss:0.00004, loss_test:0.05521, lr:9.70e-03, fs:0.93659 (r=0.970,p=0.906),  time:31.883, tt:2550.605\n",
      "Ep:80, loss:0.00004, loss_test:0.05548, lr:9.70e-03, fs:0.95098 (r=0.980,p=0.924),  time:31.877, tt:2582.033\n",
      "Ep:81, loss:0.00004, loss_test:0.05410, lr:9.70e-03, fs:0.94634 (r=0.980,p=0.915),  time:31.871, tt:2613.388\n",
      "Ep:82, loss:0.00004, loss_test:0.05338, lr:9.70e-03, fs:0.95567 (r=0.980,p=0.933),  time:31.860, tt:2644.379\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00004, loss_test:0.05405, lr:9.70e-03, fs:0.95098 (r=0.980,p=0.924),  time:31.855, tt:2675.827\n",
      "Ep:84, loss:0.00003, loss_test:0.05433, lr:9.70e-03, fs:0.95098 (r=0.980,p=0.924),  time:31.846, tt:2706.895\n",
      "Ep:85, loss:0.00003, loss_test:0.05203, lr:9.70e-03, fs:0.95567 (r=0.980,p=0.933),  time:31.830, tt:2737.405\n",
      "Ep:86, loss:0.00003, loss_test:0.05382, lr:9.70e-03, fs:0.95098 (r=0.980,p=0.924),  time:31.824, tt:2768.660\n",
      "Ep:87, loss:0.00003, loss_test:0.05327, lr:9.70e-03, fs:0.94581 (r=0.970,p=0.923),  time:31.824, tt:2800.483\n",
      "Ep:88, loss:0.00003, loss_test:0.05434, lr:9.70e-03, fs:0.92929 (r=0.929,p=0.929),  time:31.813, tt:2831.314\n",
      "Ep:89, loss:0.00003, loss_test:0.05197, lr:9.70e-03, fs:0.95567 (r=0.980,p=0.933),  time:31.811, tt:2863.030\n",
      "Ep:90, loss:0.00003, loss_test:0.05442, lr:9.70e-03, fs:0.92857 (r=0.919,p=0.938),  time:31.805, tt:2894.219\n",
      "Ep:91, loss:0.00003, loss_test:0.05238, lr:9.70e-03, fs:0.94581 (r=0.970,p=0.923),  time:31.807, tt:2926.211\n",
      "Ep:92, loss:0.00003, loss_test:0.05277, lr:9.70e-03, fs:0.94059 (r=0.960,p=0.922),  time:31.805, tt:2957.842\n",
      "Ep:93, loss:0.00003, loss_test:0.05254, lr:9.70e-03, fs:0.92462 (r=0.929,p=0.920),  time:31.795, tt:2988.733\n",
      "Ep:94, loss:0.00003, loss_test:0.05140, lr:9.61e-03, fs:0.94581 (r=0.970,p=0.923),  time:31.798, tt:3020.787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:95, loss:0.00003, loss_test:0.05153, lr:9.51e-03, fs:0.95567 (r=0.980,p=0.933),  time:31.789, tt:3051.718\n",
      "Ep:96, loss:0.00003, loss_test:0.05314, lr:9.41e-03, fs:0.92929 (r=0.929,p=0.929),  time:31.790, tt:3083.653\n",
      "Ep:97, loss:0.00003, loss_test:0.05298, lr:9.32e-03, fs:0.91837 (r=0.909,p=0.928),  time:31.783, tt:3114.700\n",
      "Ep:98, loss:0.00003, loss_test:0.05136, lr:9.23e-03, fs:0.92929 (r=0.929,p=0.929),  time:31.781, tt:3146.359\n",
      "Ep:99, loss:0.00002, loss_test:0.05144, lr:9.14e-03, fs:0.91919 (r=0.919,p=0.919),  time:31.757, tt:3175.682\n",
      "Ep:100, loss:0.00002, loss_test:0.05247, lr:9.04e-03, fs:0.93000 (r=0.939,p=0.921),  time:31.752, tt:3206.902\n",
      "Ep:101, loss:0.00002, loss_test:0.05205, lr:8.95e-03, fs:0.91371 (r=0.909,p=0.918),  time:31.733, tt:3236.798\n",
      "Ep:102, loss:0.00002, loss_test:0.05291, lr:8.86e-03, fs:0.92929 (r=0.929,p=0.929),  time:31.733, tt:3268.473\n",
      "Ep:103, loss:0.00002, loss_test:0.05079, lr:8.78e-03, fs:0.92462 (r=0.929,p=0.920),  time:31.729, tt:3299.796\n",
      "Ep:104, loss:0.00002, loss_test:0.05209, lr:8.69e-03, fs:0.92386 (r=0.919,p=0.929),  time:31.730, tt:3331.656\n",
      "Ep:105, loss:0.00002, loss_test:0.04982, lr:8.60e-03, fs:0.93000 (r=0.939,p=0.921),  time:31.722, tt:3362.583\n",
      "Ep:106, loss:0.00002, loss_test:0.05187, lr:8.51e-03, fs:0.90816 (r=0.899,p=0.918),  time:31.719, tt:3393.929\n",
      "Ep:107, loss:0.00002, loss_test:0.05062, lr:8.43e-03, fs:0.92462 (r=0.929,p=0.920),  time:31.712, tt:3424.944\n",
      "Ep:108, loss:0.00002, loss_test:0.05239, lr:8.35e-03, fs:0.90722 (r=0.889,p=0.926),  time:31.713, tt:3456.754\n",
      "Ep:109, loss:0.00002, loss_test:0.05175, lr:8.26e-03, fs:0.91837 (r=0.909,p=0.928),  time:31.713, tt:3488.431\n",
      "Ep:110, loss:0.00002, loss_test:0.05157, lr:8.18e-03, fs:0.93000 (r=0.939,p=0.921),  time:31.709, tt:3519.753\n",
      "Ep:111, loss:0.00002, loss_test:0.05217, lr:8.10e-03, fs:0.91282 (r=0.899,p=0.927),  time:31.690, tt:3549.265\n",
      "Ep:112, loss:0.00002, loss_test:0.05134, lr:8.02e-03, fs:0.92386 (r=0.919,p=0.929),  time:31.673, tt:3579.055\n",
      "Ep:113, loss:0.00002, loss_test:0.05124, lr:7.94e-03, fs:0.91371 (r=0.909,p=0.918),  time:31.663, tt:3609.579\n",
      "Ep:114, loss:0.00002, loss_test:0.05173, lr:7.86e-03, fs:0.92929 (r=0.929,p=0.929),  time:31.659, tt:3640.770\n",
      "Ep:115, loss:0.00002, loss_test:0.05171, lr:7.78e-03, fs:0.91837 (r=0.909,p=0.928),  time:31.664, tt:3673.074\n",
      "Ep:116, loss:0.00002, loss_test:0.05055, lr:7.70e-03, fs:0.93000 (r=0.939,p=0.921),  time:31.658, tt:3703.942\n",
      "Ep:117, loss:0.00002, loss_test:0.05254, lr:7.62e-03, fs:0.91753 (r=0.899,p=0.937),  time:31.659, tt:3735.781\n",
      "Ep:118, loss:0.00002, loss_test:0.05055, lr:7.55e-03, fs:0.93000 (r=0.939,p=0.921),  time:31.662, tt:3767.827\n",
      "Ep:119, loss:0.00002, loss_test:0.05172, lr:7.47e-03, fs:0.91837 (r=0.909,p=0.928),  time:31.670, tt:3800.394\n",
      "Ep:120, loss:0.00002, loss_test:0.05138, lr:7.40e-03, fs:0.92929 (r=0.929,p=0.929),  time:31.671, tt:3832.189\n",
      "Ep:121, loss:0.00002, loss_test:0.05145, lr:7.32e-03, fs:0.91837 (r=0.909,p=0.928),  time:31.672, tt:3863.939\n",
      "Ep:122, loss:0.00002, loss_test:0.05189, lr:7.25e-03, fs:0.93467 (r=0.939,p=0.930),  time:31.677, tt:3896.214\n",
      "Ep:123, loss:0.00002, loss_test:0.05305, lr:7.18e-03, fs:0.90722 (r=0.889,p=0.926),  time:31.682, tt:3928.589\n",
      "Ep:124, loss:0.00002, loss_test:0.04975, lr:7.11e-03, fs:0.93000 (r=0.939,p=0.921),  time:31.685, tt:3960.617\n",
      "Ep:125, loss:0.00002, loss_test:0.05491, lr:7.03e-03, fs:0.85246 (r=0.788,p=0.929),  time:31.691, tt:3993.060\n",
      "Ep:126, loss:0.00002, loss_test:0.05155, lr:6.96e-03, fs:0.91837 (r=0.909,p=0.928),  time:31.706, tt:4026.711\n",
      "Ep:127, loss:0.00002, loss_test:0.05295, lr:6.89e-03, fs:0.90722 (r=0.889,p=0.926),  time:31.714, tt:4059.394\n",
      "Ep:128, loss:0.00002, loss_test:0.05360, lr:6.83e-03, fs:0.89474 (r=0.859,p=0.934),  time:31.711, tt:4090.669\n",
      "Ep:129, loss:0.00002, loss_test:0.04956, lr:6.76e-03, fs:0.93532 (r=0.949,p=0.922),  time:31.722, tt:4123.844\n",
      "Ep:130, loss:0.00002, loss_test:0.05426, lr:6.69e-03, fs:0.89474 (r=0.859,p=0.934),  time:31.726, tt:4156.171\n",
      "Ep:131, loss:0.00002, loss_test:0.05191, lr:6.62e-03, fs:0.91753 (r=0.899,p=0.937),  time:31.722, tt:4187.321\n",
      "Ep:132, loss:0.00001, loss_test:0.05241, lr:6.56e-03, fs:0.91282 (r=0.899,p=0.927),  time:31.723, tt:4219.164\n",
      "Ep:133, loss:0.00001, loss_test:0.05236, lr:6.49e-03, fs:0.90722 (r=0.889,p=0.926),  time:31.735, tt:4252.454\n",
      "Ep:134, loss:0.00001, loss_test:0.05168, lr:6.43e-03, fs:0.92386 (r=0.919,p=0.929),  time:31.738, tt:4284.654\n",
      "Ep:135, loss:0.00001, loss_test:0.05167, lr:6.36e-03, fs:0.91753 (r=0.899,p=0.937),  time:31.736, tt:4316.038\n",
      "Ep:136, loss:0.00001, loss_test:0.05248, lr:6.30e-03, fs:0.91192 (r=0.889,p=0.936),  time:31.739, tt:4348.276\n",
      "Ep:137, loss:0.00001, loss_test:0.05118, lr:6.24e-03, fs:0.92386 (r=0.919,p=0.929),  time:31.744, tt:4380.608\n",
      "Ep:138, loss:0.00001, loss_test:0.05254, lr:6.17e-03, fs:0.90625 (r=0.879,p=0.935),  time:31.745, tt:4412.515\n",
      "Ep:139, loss:0.00001, loss_test:0.05211, lr:6.11e-03, fs:0.91753 (r=0.899,p=0.937),  time:31.751, tt:4445.163\n",
      "Ep:140, loss:0.00001, loss_test:0.05297, lr:6.05e-03, fs:0.90052 (r=0.869,p=0.935),  time:31.756, tt:4477.627\n",
      "Ep:141, loss:0.00001, loss_test:0.05304, lr:5.99e-03, fs:0.89474 (r=0.859,p=0.934),  time:31.758, tt:4509.673\n",
      "Ep:142, loss:0.00001, loss_test:0.05084, lr:5.93e-03, fs:0.91371 (r=0.909,p=0.918),  time:31.760, tt:4541.700\n",
      "Ep:143, loss:0.00001, loss_test:0.05493, lr:5.87e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.778, tt:4576.027\n",
      "Ep:144, loss:0.00001, loss_test:0.05202, lr:5.81e-03, fs:0.91753 (r=0.899,p=0.937),  time:31.786, tt:4609.011\n",
      "Ep:145, loss:0.00001, loss_test:0.05181, lr:5.75e-03, fs:0.92308 (r=0.909,p=0.938),  time:31.806, tt:4643.698\n",
      "Ep:146, loss:0.00001, loss_test:0.05362, lr:5.70e-03, fs:0.86957 (r=0.808,p=0.941),  time:31.822, tt:4677.770\n",
      "Ep:147, loss:0.00001, loss_test:0.05192, lr:5.64e-03, fs:0.91192 (r=0.889,p=0.936),  time:31.832, tt:4711.085\n",
      "Ep:148, loss:0.00001, loss_test:0.05334, lr:5.58e-03, fs:0.88298 (r=0.838,p=0.933),  time:31.832, tt:4743.011\n",
      "Ep:149, loss:0.00001, loss_test:0.05263, lr:5.53e-03, fs:0.90526 (r=0.869,p=0.945),  time:31.841, tt:4776.200\n",
      "Ep:150, loss:0.00001, loss_test:0.05175, lr:5.47e-03, fs:0.91753 (r=0.899,p=0.937),  time:31.840, tt:4807.859\n",
      "Ep:151, loss:0.00001, loss_test:0.05324, lr:5.42e-03, fs:0.88172 (r=0.828,p=0.943),  time:31.845, tt:4840.386\n",
      "Ep:152, loss:0.00001, loss_test:0.05230, lr:5.36e-03, fs:0.90052 (r=0.869,p=0.935),  time:31.843, tt:4871.938\n",
      "Ep:153, loss:0.00001, loss_test:0.05214, lr:5.31e-03, fs:0.92228 (r=0.899,p=0.947),  time:31.848, tt:4904.622\n",
      "Ep:154, loss:0.00001, loss_test:0.05366, lr:5.26e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.850, tt:4936.704\n",
      "Ep:155, loss:0.00001, loss_test:0.05284, lr:5.20e-03, fs:0.89947 (r=0.859,p=0.944),  time:31.854, tt:4969.290\n",
      "Ep:156, loss:0.00001, loss_test:0.05225, lr:5.15e-03, fs:0.91192 (r=0.889,p=0.936),  time:31.861, tt:5002.195\n",
      "Ep:157, loss:0.00001, loss_test:0.05396, lr:5.10e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.854, tt:5032.926\n",
      "Ep:158, loss:0.00001, loss_test:0.05198, lr:5.05e-03, fs:0.91192 (r=0.889,p=0.936),  time:31.864, tt:5066.380\n",
      "Ep:159, loss:0.00001, loss_test:0.05266, lr:5.00e-03, fs:0.88889 (r=0.848,p=0.933),  time:31.865, tt:5098.444\n",
      "Ep:160, loss:0.00001, loss_test:0.05323, lr:4.95e-03, fs:0.86957 (r=0.808,p=0.941),  time:31.858, tt:5129.162\n",
      "Ep:161, loss:0.00001, loss_test:0.05320, lr:4.90e-03, fs:0.88172 (r=0.828,p=0.943),  time:31.859, tt:5161.146\n",
      "Ep:162, loss:0.00001, loss_test:0.05256, lr:4.85e-03, fs:0.88889 (r=0.848,p=0.933),  time:31.854, tt:5192.198\n",
      "Ep:163, loss:0.00001, loss_test:0.05249, lr:4.80e-03, fs:0.90052 (r=0.869,p=0.935),  time:31.857, tt:5224.505\n",
      "Ep:164, loss:0.00001, loss_test:0.05285, lr:4.75e-03, fs:0.87568 (r=0.818,p=0.942),  time:31.857, tt:5256.471\n",
      "Ep:165, loss:0.00001, loss_test:0.05231, lr:4.71e-03, fs:0.89474 (r=0.859,p=0.934),  time:31.858, tt:5288.406\n",
      "Ep:166, loss:0.00001, loss_test:0.05261, lr:4.66e-03, fs:0.89474 (r=0.859,p=0.934),  time:31.872, tt:5322.573\n",
      "Ep:167, loss:0.00001, loss_test:0.05284, lr:4.61e-03, fs:0.86486 (r=0.808,p=0.930),  time:31.872, tt:5354.433\n",
      "Ep:168, loss:0.00001, loss_test:0.05288, lr:4.57e-03, fs:0.85714 (r=0.788,p=0.940),  time:31.879, tt:5387.616\n",
      "Ep:169, loss:0.00001, loss_test:0.05313, lr:4.52e-03, fs:0.86486 (r=0.808,p=0.930),  time:31.879, tt:5419.427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:170, loss:0.00001, loss_test:0.05242, lr:4.48e-03, fs:0.88889 (r=0.848,p=0.933),  time:31.877, tt:5450.993\n",
      "Ep:171, loss:0.00001, loss_test:0.05365, lr:4.43e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.885, tt:5484.252\n",
      "Ep:172, loss:0.00001, loss_test:0.05401, lr:4.39e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.880, tt:5515.252\n",
      "Ep:173, loss:0.00001, loss_test:0.05280, lr:4.34e-03, fs:0.85870 (r=0.798,p=0.929),  time:31.880, tt:5547.190\n",
      "Ep:174, loss:0.00001, loss_test:0.05320, lr:4.30e-03, fs:0.87097 (r=0.818,p=0.931),  time:31.880, tt:5578.918\n",
      "Ep:175, loss:0.00001, loss_test:0.05307, lr:4.26e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.880, tt:5610.826\n",
      "Ep:176, loss:0.00001, loss_test:0.05362, lr:4.21e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.890, tt:5644.614\n",
      "Ep:177, loss:0.00001, loss_test:0.05214, lr:4.17e-03, fs:0.90052 (r=0.869,p=0.935),  time:31.889, tt:5676.312\n",
      "Ep:178, loss:0.00001, loss_test:0.05342, lr:4.13e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.882, tt:5706.880\n",
      "Ep:179, loss:0.00001, loss_test:0.05359, lr:4.09e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.885, tt:5739.303\n",
      "Ep:180, loss:0.00001, loss_test:0.05248, lr:4.05e-03, fs:0.89474 (r=0.859,p=0.934),  time:31.887, tt:5771.621\n",
      "Ep:181, loss:0.00001, loss_test:0.05391, lr:4.01e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.884, tt:5802.828\n",
      "Ep:182, loss:0.00001, loss_test:0.05330, lr:3.97e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.879, tt:5833.802\n",
      "Ep:183, loss:0.00001, loss_test:0.05272, lr:3.93e-03, fs:0.85870 (r=0.798,p=0.929),  time:31.880, tt:5865.886\n",
      "Ep:184, loss:0.00001, loss_test:0.05409, lr:3.89e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.882, tt:5898.254\n",
      "Ep:185, loss:0.00001, loss_test:0.05341, lr:3.85e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.879, tt:5929.461\n",
      "Ep:186, loss:0.00001, loss_test:0.05267, lr:3.81e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.877, tt:5961.091\n",
      "Ep:187, loss:0.00001, loss_test:0.05378, lr:3.77e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.900, tt:5997.226\n",
      "Ep:188, loss:0.00001, loss_test:0.05312, lr:3.73e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.899, tt:6028.924\n",
      "Ep:189, loss:0.00001, loss_test:0.05301, lr:3.70e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.900, tt:6060.976\n",
      "Ep:190, loss:0.00001, loss_test:0.05391, lr:3.66e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.907, tt:6094.331\n",
      "Ep:191, loss:0.00001, loss_test:0.05441, lr:3.62e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.916, tt:6127.813\n",
      "Ep:192, loss:0.00001, loss_test:0.05352, lr:3.59e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.922, tt:6160.890\n",
      "Ep:193, loss:0.00001, loss_test:0.05288, lr:3.55e-03, fs:0.85870 (r=0.798,p=0.929),  time:31.923, tt:6193.137\n",
      "Ep:194, loss:0.00001, loss_test:0.05433, lr:3.52e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.924, tt:6225.164\n",
      "Ep:195, loss:0.00001, loss_test:0.05338, lr:3.48e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.926, tt:6257.510\n",
      "Ep:196, loss:0.00001, loss_test:0.05291, lr:3.45e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.929, tt:6289.992\n",
      "Ep:197, loss:0.00001, loss_test:0.05332, lr:3.41e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.933, tt:6322.824\n",
      "Ep:198, loss:0.00001, loss_test:0.05289, lr:3.38e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.937, tt:6355.390\n",
      "Ep:199, loss:0.00001, loss_test:0.05327, lr:3.34e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.938, tt:6387.522\n",
      "Ep:200, loss:0.00001, loss_test:0.05354, lr:3.31e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.937, tt:6419.290\n",
      "Ep:201, loss:0.00001, loss_test:0.05263, lr:3.28e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.942, tt:6452.333\n",
      "Ep:202, loss:0.00001, loss_test:0.05340, lr:3.24e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.944, tt:6484.695\n",
      "Ep:203, loss:0.00001, loss_test:0.05331, lr:3.21e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.950, tt:6517.726\n",
      "Ep:204, loss:0.00001, loss_test:0.05248, lr:3.18e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.955, tt:6550.738\n",
      "Ep:205, loss:0.00001, loss_test:0.05335, lr:3.15e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.952, tt:6582.049\n",
      "Ep:206, loss:0.00001, loss_test:0.05351, lr:3.12e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.955, tt:6614.778\n",
      "Ep:207, loss:0.00001, loss_test:0.05351, lr:3.09e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.948, tt:6645.245\n",
      "Ep:208, loss:0.00001, loss_test:0.05294, lr:3.05e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.961, tt:6679.840\n",
      "Ep:209, loss:0.00001, loss_test:0.05308, lr:3.02e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.968, tt:6713.363\n",
      "Ep:210, loss:0.00001, loss_test:0.05323, lr:2.99e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.949, tt:6741.306\n",
      "Ep:211, loss:0.00001, loss_test:0.05276, lr:2.96e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.911, tt:6765.125\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00010, loss_test:0.01991, lr:6.00e-02, fs:0.67188 (r=0.869,p=0.548),  time:28.809, tt:28.809\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02327, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.575, tt:57.150\n",
      "Ep:2, loss:0.00005, loss_test:0.02650, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.002, tt:87.005\n",
      "Ep:3, loss:0.00005, loss_test:0.02798, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.551, tt:118.205\n",
      "Ep:4, loss:0.00005, loss_test:0.02853, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.166, tt:145.832\n",
      "Ep:5, loss:0.00006, loss_test:0.02851, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.939, tt:173.636\n",
      "Ep:6, loss:0.00005, loss_test:0.02804, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.837, tt:201.856\n",
      "Ep:7, loss:0.00005, loss_test:0.02718, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.961, tt:231.687\n",
      "Ep:8, loss:0.00005, loss_test:0.02597, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.228, tt:263.049\n",
      "Ep:9, loss:0.00005, loss_test:0.02448, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.185, tt:291.852\n",
      "Ep:10, loss:0.00005, loss_test:0.02285, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.409, tt:323.494\n",
      "Ep:11, loss:0.00004, loss_test:0.02120, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:29.527, tt:354.322\n",
      "Ep:12, loss:0.00004, loss_test:0.01978, lr:5.94e-02, fs:0.67128 (r=0.980,p=0.511),  time:29.616, tt:385.009\n",
      "Ep:13, loss:0.00004, loss_test:0.01883, lr:5.88e-02, fs:0.68148 (r=0.929,p=0.538),  time:29.637, tt:414.916\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01842, lr:5.88e-02, fs:0.67188 (r=0.869,p=0.548),  time:29.772, tt:446.577\n",
      "Ep:15, loss:0.00004, loss_test:0.01818, lr:5.88e-02, fs:0.70492 (r=0.869,p=0.593),  time:29.909, tt:478.544\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.01777, lr:5.88e-02, fs:0.70833 (r=0.859,p=0.603),  time:29.896, tt:508.233\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.01729, lr:5.88e-02, fs:0.71255 (r=0.889,p=0.595),  time:29.840, tt:537.122\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01694, lr:5.88e-02, fs:0.72374 (r=0.939,p=0.589),  time:29.947, tt:569.001\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01670, lr:5.88e-02, fs:0.73485 (r=0.980,p=0.588),  time:29.982, tt:599.639\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01648, lr:5.88e-02, fs:0.73764 (r=0.980,p=0.591),  time:30.029, tt:630.606\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01622, lr:5.88e-02, fs:0.74330 (r=0.980,p=0.599),  time:30.050, tt:661.100\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01594, lr:5.88e-02, fs:0.75781 (r=0.980,p=0.618),  time:30.047, tt:691.089\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:23, loss:0.00003, loss_test:0.01568, lr:5.88e-02, fs:0.76494 (r=0.970,p=0.632),  time:30.075, tt:721.803\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01548, lr:5.88e-02, fs:0.77236 (r=0.960,p=0.646),  time:30.068, tt:751.712\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01534, lr:5.88e-02, fs:0.78838 (r=0.960,p=0.669),  time:30.086, tt:782.245\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01520, lr:5.88e-02, fs:0.79668 (r=0.970,p=0.676),  time:30.068, tt:811.830\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01507, lr:5.88e-02, fs:0.80000 (r=0.970,p=0.681),  time:30.121, tt:843.387\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01494, lr:5.88e-02, fs:0.80498 (r=0.980,p=0.683),  time:30.102, tt:872.968\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01482, lr:5.88e-02, fs:0.79675 (r=0.990,p=0.667),  time:30.129, tt:903.880\n",
      "Ep:30, loss:0.00003, loss_test:0.01469, lr:5.88e-02, fs:0.80000 (r=0.990,p=0.671),  time:30.085, tt:932.623\n",
      "Ep:31, loss:0.00003, loss_test:0.01457, lr:5.88e-02, fs:0.80658 (r=0.990,p=0.681),  time:30.151, tt:964.830\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01447, lr:5.88e-02, fs:0.81667 (r=0.990,p=0.695),  time:30.161, tt:995.302\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01438, lr:5.88e-02, fs:0.83404 (r=0.990,p=0.721),  time:30.203, tt:1026.919\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01428, lr:5.88e-02, fs:0.84120 (r=0.990,p=0.731),  time:30.229, tt:1058.005\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01418, lr:5.88e-02, fs:0.84120 (r=0.990,p=0.731),  time:30.223, tt:1088.013\n",
      "Ep:36, loss:0.00002, loss_test:0.01406, lr:5.88e-02, fs:0.83761 (r=0.990,p=0.726),  time:30.219, tt:1118.104\n",
      "Ep:37, loss:0.00002, loss_test:0.01394, lr:5.88e-02, fs:0.83761 (r=0.990,p=0.726),  time:30.230, tt:1148.757\n",
      "Ep:38, loss:0.00002, loss_test:0.01382, lr:5.88e-02, fs:0.84120 (r=0.990,p=0.731),  time:30.241, tt:1179.381\n",
      "Ep:39, loss:0.00002, loss_test:0.01372, lr:5.88e-02, fs:0.84120 (r=0.990,p=0.731),  time:30.197, tt:1207.896\n",
      "Ep:40, loss:0.00002, loss_test:0.01363, lr:5.88e-02, fs:0.84483 (r=0.990,p=0.737),  time:30.193, tt:1237.906\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01355, lr:5.88e-02, fs:0.84483 (r=0.990,p=0.737),  time:30.198, tt:1268.307\n",
      "Ep:42, loss:0.00002, loss_test:0.01347, lr:5.88e-02, fs:0.85965 (r=0.990,p=0.760),  time:30.189, tt:1298.110\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01338, lr:5.88e-02, fs:0.85841 (r=0.980,p=0.764),  time:30.181, tt:1327.953\n",
      "Ep:44, loss:0.00002, loss_test:0.01330, lr:5.88e-02, fs:0.85202 (r=0.960,p=0.766),  time:30.163, tt:1357.356\n",
      "Ep:45, loss:0.00002, loss_test:0.01322, lr:5.88e-02, fs:0.85202 (r=0.960,p=0.766),  time:30.161, tt:1387.387\n",
      "Ep:46, loss:0.00002, loss_test:0.01315, lr:5.88e-02, fs:0.85714 (r=0.970,p=0.768),  time:30.141, tt:1416.621\n",
      "Ep:47, loss:0.00002, loss_test:0.01309, lr:5.88e-02, fs:0.85714 (r=0.970,p=0.768),  time:30.117, tt:1445.606\n",
      "Ep:48, loss:0.00002, loss_test:0.01304, lr:5.88e-02, fs:0.85714 (r=0.970,p=0.768),  time:30.085, tt:1474.185\n",
      "Ep:49, loss:0.00002, loss_test:0.01300, lr:5.88e-02, fs:0.85714 (r=0.970,p=0.768),  time:30.108, tt:1505.417\n",
      "Ep:50, loss:0.00002, loss_test:0.01297, lr:5.88e-02, fs:0.85714 (r=0.970,p=0.768),  time:30.126, tt:1536.401\n",
      "Ep:51, loss:0.00002, loss_test:0.01294, lr:5.88e-02, fs:0.86486 (r=0.970,p=0.780),  time:30.080, tt:1564.144\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01292, lr:5.88e-02, fs:0.86758 (r=0.960,p=0.792),  time:30.079, tt:1594.203\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01290, lr:5.88e-02, fs:0.87156 (r=0.960,p=0.798),  time:30.059, tt:1623.207\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.01288, lr:5.88e-02, fs:0.87156 (r=0.960,p=0.798),  time:30.086, tt:1654.754\n",
      "Ep:55, loss:0.00002, loss_test:0.01285, lr:5.88e-02, fs:0.86758 (r=0.960,p=0.792),  time:30.083, tt:1684.653\n",
      "Ep:56, loss:0.00002, loss_test:0.01284, lr:5.88e-02, fs:0.86758 (r=0.960,p=0.792),  time:30.092, tt:1715.216\n",
      "Ep:57, loss:0.00002, loss_test:0.01282, lr:5.88e-02, fs:0.87156 (r=0.960,p=0.798),  time:30.104, tt:1746.008\n",
      "Ep:58, loss:0.00001, loss_test:0.01281, lr:5.88e-02, fs:0.87156 (r=0.960,p=0.798),  time:30.111, tt:1776.567\n",
      "Ep:59, loss:0.00001, loss_test:0.01280, lr:5.88e-02, fs:0.87156 (r=0.960,p=0.798),  time:30.115, tt:1806.918\n",
      "Ep:60, loss:0.00001, loss_test:0.01280, lr:5.88e-02, fs:0.87156 (r=0.960,p=0.798),  time:30.114, tt:1836.924\n",
      "Ep:61, loss:0.00001, loss_test:0.01280, lr:5.88e-02, fs:0.86512 (r=0.939,p=0.802),  time:30.137, tt:1868.475\n",
      "Ep:62, loss:0.00001, loss_test:0.01280, lr:5.88e-02, fs:0.86916 (r=0.939,p=0.809),  time:30.148, tt:1899.317\n",
      "Ep:63, loss:0.00001, loss_test:0.01279, lr:5.88e-02, fs:0.86916 (r=0.939,p=0.809),  time:30.136, tt:1928.696\n",
      "Ep:64, loss:0.00001, loss_test:0.01279, lr:5.88e-02, fs:0.87324 (r=0.939,p=0.816),  time:30.131, tt:1958.524\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.01279, lr:5.88e-02, fs:0.87324 (r=0.939,p=0.816),  time:30.151, tt:1989.989\n",
      "Ep:66, loss:0.00001, loss_test:0.01279, lr:5.88e-02, fs:0.87736 (r=0.939,p=0.823),  time:30.179, tt:2022.021\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01279, lr:5.88e-02, fs:0.87736 (r=0.939,p=0.823),  time:30.165, tt:2051.243\n",
      "Ep:68, loss:0.00001, loss_test:0.01279, lr:5.88e-02, fs:0.88571 (r=0.939,p=0.838),  time:30.168, tt:2081.603\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01280, lr:5.88e-02, fs:0.88571 (r=0.939,p=0.838),  time:30.189, tt:2113.261\n",
      "Ep:70, loss:0.00001, loss_test:0.01281, lr:5.88e-02, fs:0.88571 (r=0.939,p=0.838),  time:30.191, tt:2143.589\n",
      "Ep:71, loss:0.00001, loss_test:0.01284, lr:5.88e-02, fs:0.88462 (r=0.929,p=0.844),  time:30.166, tt:2171.969\n",
      "Ep:72, loss:0.00001, loss_test:0.01283, lr:5.88e-02, fs:0.88889 (r=0.929,p=0.852),  time:30.159, tt:2201.601\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.01284, lr:5.88e-02, fs:0.88350 (r=0.919,p=0.850),  time:30.136, tt:2230.065\n",
      "Ep:74, loss:0.00001, loss_test:0.01284, lr:5.88e-02, fs:0.88780 (r=0.919,p=0.858),  time:30.140, tt:2260.465\n",
      "Ep:75, loss:0.00001, loss_test:0.01286, lr:5.88e-02, fs:0.88780 (r=0.919,p=0.858),  time:30.122, tt:2289.269\n",
      "Ep:76, loss:0.00001, loss_test:0.01289, lr:5.88e-02, fs:0.89216 (r=0.919,p=0.867),  time:30.121, tt:2319.324\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.01289, lr:5.88e-02, fs:0.89655 (r=0.919,p=0.875),  time:30.110, tt:2348.585\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.01292, lr:5.88e-02, fs:0.89109 (r=0.909,p=0.874),  time:30.110, tt:2378.680\n",
      "Ep:79, loss:0.00001, loss_test:0.01293, lr:5.88e-02, fs:0.88557 (r=0.899,p=0.873),  time:30.085, tt:2406.839\n",
      "Ep:80, loss:0.00001, loss_test:0.01294, lr:5.88e-02, fs:0.88557 (r=0.899,p=0.873),  time:30.089, tt:2437.246\n",
      "Ep:81, loss:0.00001, loss_test:0.01296, lr:5.88e-02, fs:0.88000 (r=0.889,p=0.871),  time:30.087, tt:2467.157\n",
      "Ep:82, loss:0.00001, loss_test:0.01298, lr:5.88e-02, fs:0.88000 (r=0.889,p=0.871),  time:30.091, tt:2497.573\n",
      "Ep:83, loss:0.00001, loss_test:0.01300, lr:5.88e-02, fs:0.88000 (r=0.889,p=0.871),  time:30.094, tt:2527.924\n",
      "Ep:84, loss:0.00001, loss_test:0.01301, lr:5.88e-02, fs:0.87437 (r=0.879,p=0.870),  time:30.094, tt:2557.983\n",
      "Ep:85, loss:0.00001, loss_test:0.01304, lr:5.88e-02, fs:0.87437 (r=0.879,p=0.870),  time:30.104, tt:2588.961\n",
      "Ep:86, loss:0.00001, loss_test:0.01307, lr:5.88e-02, fs:0.86869 (r=0.869,p=0.869),  time:30.105, tt:2619.094\n",
      "Ep:87, loss:0.00001, loss_test:0.01309, lr:5.88e-02, fs:0.86869 (r=0.869,p=0.869),  time:30.112, tt:2649.890\n",
      "Ep:88, loss:0.00001, loss_test:0.01310, lr:5.88e-02, fs:0.86869 (r=0.869,p=0.869),  time:30.123, tt:2680.935\n",
      "Ep:89, loss:0.00001, loss_test:0.01311, lr:5.82e-02, fs:0.86869 (r=0.869,p=0.869),  time:30.123, tt:2711.077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:90, loss:0.00001, loss_test:0.01312, lr:5.76e-02, fs:0.86869 (r=0.869,p=0.869),  time:30.131, tt:2741.921\n",
      "Ep:91, loss:0.00001, loss_test:0.01314, lr:5.71e-02, fs:0.86869 (r=0.869,p=0.869),  time:30.144, tt:2773.277\n",
      "Ep:92, loss:0.00001, loss_test:0.01316, lr:5.65e-02, fs:0.86735 (r=0.859,p=0.876),  time:30.146, tt:2803.560\n",
      "Ep:93, loss:0.00001, loss_test:0.01319, lr:5.59e-02, fs:0.86735 (r=0.859,p=0.876),  time:30.138, tt:2832.976\n",
      "Ep:94, loss:0.00001, loss_test:0.01322, lr:5.54e-02, fs:0.86735 (r=0.859,p=0.876),  time:30.150, tt:2864.282\n",
      "Ep:95, loss:0.00001, loss_test:0.01325, lr:5.48e-02, fs:0.87179 (r=0.859,p=0.885),  time:30.149, tt:2894.325\n",
      "Ep:96, loss:0.00001, loss_test:0.01328, lr:5.43e-02, fs:0.87179 (r=0.859,p=0.885),  time:30.151, tt:2924.689\n",
      "Ep:97, loss:0.00001, loss_test:0.01330, lr:5.37e-02, fs:0.87179 (r=0.859,p=0.885),  time:30.157, tt:2955.426\n",
      "Ep:98, loss:0.00001, loss_test:0.01334, lr:5.32e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.156, tt:2985.421\n",
      "Ep:99, loss:0.00001, loss_test:0.01336, lr:5.27e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.168, tt:3016.770\n",
      "Ep:100, loss:0.00001, loss_test:0.01338, lr:5.21e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.165, tt:3046.657\n",
      "Ep:101, loss:0.00001, loss_test:0.01339, lr:5.16e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.173, tt:3077.644\n",
      "Ep:102, loss:0.00001, loss_test:0.01340, lr:5.11e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.165, tt:3106.972\n",
      "Ep:103, loss:0.00001, loss_test:0.01342, lr:5.06e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.161, tt:3136.759\n",
      "Ep:104, loss:0.00001, loss_test:0.01344, lr:5.01e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.170, tt:3167.814\n",
      "Ep:105, loss:0.00001, loss_test:0.01347, lr:4.96e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.166, tt:3197.633\n",
      "Ep:106, loss:0.00001, loss_test:0.01350, lr:4.91e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.163, tt:3227.400\n",
      "Ep:107, loss:0.00001, loss_test:0.01353, lr:4.86e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.149, tt:3256.142\n",
      "Ep:108, loss:0.00001, loss_test:0.01355, lr:4.81e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.142, tt:3285.488\n",
      "Ep:109, loss:0.00001, loss_test:0.01358, lr:4.76e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.145, tt:3315.948\n",
      "Ep:110, loss:0.00001, loss_test:0.01359, lr:4.71e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.151, tt:3346.791\n",
      "Ep:111, loss:0.00001, loss_test:0.01361, lr:4.67e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.152, tt:3377.019\n",
      "Ep:112, loss:0.00001, loss_test:0.01364, lr:4.62e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.163, tt:3408.475\n",
      "Ep:113, loss:0.00001, loss_test:0.01366, lr:4.57e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.170, tt:3439.326\n",
      "Ep:114, loss:0.00001, loss_test:0.01369, lr:4.53e-02, fs:0.86911 (r=0.838,p=0.902),  time:30.162, tt:3468.610\n",
      "Ep:115, loss:0.00001, loss_test:0.01371, lr:4.48e-02, fs:0.86911 (r=0.838,p=0.902),  time:30.169, tt:3499.644\n",
      "Ep:116, loss:0.00001, loss_test:0.01372, lr:4.44e-02, fs:0.86911 (r=0.838,p=0.902),  time:30.181, tt:3531.135\n",
      "Ep:117, loss:0.00001, loss_test:0.01374, lr:4.39e-02, fs:0.86911 (r=0.838,p=0.902),  time:30.179, tt:3561.134\n",
      "Ep:118, loss:0.00001, loss_test:0.01374, lr:4.35e-02, fs:0.86911 (r=0.838,p=0.902),  time:30.188, tt:3592.363\n",
      "Ep:119, loss:0.00001, loss_test:0.01378, lr:4.31e-02, fs:0.86911 (r=0.838,p=0.902),  time:30.195, tt:3623.349\n",
      "Ep:120, loss:0.00001, loss_test:0.01380, lr:4.26e-02, fs:0.87368 (r=0.838,p=0.912),  time:30.180, tt:3651.820\n",
      "Ep:121, loss:0.00001, loss_test:0.01382, lr:4.22e-02, fs:0.87368 (r=0.838,p=0.912),  time:30.189, tt:3682.999\n",
      "Ep:122, loss:0.00001, loss_test:0.01384, lr:4.18e-02, fs:0.87368 (r=0.838,p=0.912),  time:30.182, tt:3712.383\n",
      "Ep:123, loss:0.00001, loss_test:0.01386, lr:4.14e-02, fs:0.87368 (r=0.838,p=0.912),  time:30.180, tt:3742.314\n",
      "Ep:124, loss:0.00001, loss_test:0.01389, lr:4.10e-02, fs:0.87368 (r=0.838,p=0.912),  time:30.188, tt:3773.506\n",
      "Ep:125, loss:0.00001, loss_test:0.01392, lr:4.05e-02, fs:0.87368 (r=0.838,p=0.912),  time:30.184, tt:3803.145\n",
      "Ep:126, loss:0.00001, loss_test:0.01393, lr:4.01e-02, fs:0.87831 (r=0.838,p=0.922),  time:30.198, tt:3835.182\n",
      "Ep:127, loss:0.00001, loss_test:0.01395, lr:3.97e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.197, tt:3865.214\n",
      "Ep:128, loss:0.00001, loss_test:0.01396, lr:3.93e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.200, tt:3895.805\n",
      "Ep:129, loss:0.00001, loss_test:0.01399, lr:3.89e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.204, tt:3926.582\n",
      "Ep:130, loss:0.00001, loss_test:0.01400, lr:3.86e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.202, tt:3956.522\n",
      "Ep:131, loss:0.00001, loss_test:0.01402, lr:3.82e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.204, tt:3986.911\n",
      "Ep:132, loss:0.00001, loss_test:0.01403, lr:3.78e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.205, tt:4017.281\n",
      "Ep:133, loss:0.00001, loss_test:0.01404, lr:3.74e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.217, tt:4049.141\n",
      "Ep:134, loss:0.00001, loss_test:0.01406, lr:3.70e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.222, tt:4079.924\n",
      "Ep:135, loss:0.00001, loss_test:0.01408, lr:3.67e-02, fs:0.87097 (r=0.818,p=0.931),  time:30.230, tt:4111.307\n",
      "Ep:136, loss:0.00001, loss_test:0.01411, lr:3.63e-02, fs:0.87097 (r=0.818,p=0.931),  time:30.223, tt:4140.525\n",
      "Ep:137, loss:0.00001, loss_test:0.01412, lr:3.59e-02, fs:0.87097 (r=0.818,p=0.931),  time:30.230, tt:4171.760\n",
      "Ep:138, loss:0.00001, loss_test:0.01414, lr:3.56e-02, fs:0.87568 (r=0.818,p=0.942),  time:30.218, tt:4200.350\n",
      "Ep:139, loss:0.00001, loss_test:0.01415, lr:3.52e-02, fs:0.87568 (r=0.818,p=0.942),  time:30.223, tt:4231.158\n",
      "Ep:140, loss:0.00001, loss_test:0.01418, lr:3.49e-02, fs:0.87568 (r=0.818,p=0.942),  time:30.241, tt:4263.968\n",
      "Ep:141, loss:0.00001, loss_test:0.01418, lr:3.45e-02, fs:0.87568 (r=0.818,p=0.942),  time:30.247, tt:4295.139\n",
      "Ep:142, loss:0.00001, loss_test:0.01420, lr:3.42e-02, fs:0.87568 (r=0.818,p=0.942),  time:30.261, tt:4327.370\n",
      "Ep:143, loss:0.00001, loss_test:0.01421, lr:3.38e-02, fs:0.87568 (r=0.818,p=0.942),  time:30.258, tt:4357.165\n",
      "Ep:144, loss:0.00001, loss_test:0.01423, lr:3.35e-02, fs:0.87568 (r=0.818,p=0.942),  time:30.254, tt:4386.869\n",
      "Ep:145, loss:0.00001, loss_test:0.01425, lr:3.32e-02, fs:0.87568 (r=0.818,p=0.942),  time:30.254, tt:4417.145\n",
      "Ep:146, loss:0.00001, loss_test:0.01426, lr:3.28e-02, fs:0.87568 (r=0.818,p=0.942),  time:30.245, tt:4445.976\n",
      "Ep:147, loss:0.00001, loss_test:0.01427, lr:3.25e-02, fs:0.87568 (r=0.818,p=0.942),  time:30.241, tt:4475.611\n",
      "Ep:148, loss:0.00001, loss_test:0.01429, lr:3.22e-02, fs:0.87568 (r=0.818,p=0.942),  time:30.239, tt:4505.636\n",
      "Ep:149, loss:0.00000, loss_test:0.01431, lr:3.19e-02, fs:0.87568 (r=0.818,p=0.942),  time:30.239, tt:4535.858\n",
      "Ep:150, loss:0.00000, loss_test:0.01432, lr:3.15e-02, fs:0.87568 (r=0.818,p=0.942),  time:30.247, tt:4567.329\n",
      "Ep:151, loss:0.00000, loss_test:0.01434, lr:3.12e-02, fs:0.87568 (r=0.818,p=0.942),  time:30.247, tt:4597.598\n",
      "Ep:152, loss:0.00000, loss_test:0.01436, lr:3.09e-02, fs:0.87568 (r=0.818,p=0.942),  time:30.246, tt:4627.612\n",
      "Ep:153, loss:0.00000, loss_test:0.01437, lr:3.06e-02, fs:0.87568 (r=0.818,p=0.942),  time:30.251, tt:4658.720\n",
      "Ep:154, loss:0.00000, loss_test:0.01438, lr:3.03e-02, fs:0.87568 (r=0.818,p=0.942),  time:30.250, tt:4688.703\n",
      "Ep:155, loss:0.00000, loss_test:0.01439, lr:3.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:30.248, tt:4718.622\n",
      "Ep:156, loss:0.00000, loss_test:0.01440, lr:2.97e-02, fs:0.87568 (r=0.818,p=0.942),  time:30.251, tt:4749.385\n",
      "Ep:157, loss:0.00000, loss_test:0.01442, lr:2.94e-02, fs:0.87568 (r=0.818,p=0.942),  time:30.249, tt:4779.329\n",
      "Ep:158, loss:0.00000, loss_test:0.01444, lr:2.91e-02, fs:0.86957 (r=0.808,p=0.941),  time:30.254, tt:4810.437\n",
      "Ep:159, loss:0.00000, loss_test:0.01445, lr:2.88e-02, fs:0.86957 (r=0.808,p=0.941),  time:30.253, tt:4840.434\n",
      "Ep:160, loss:0.00000, loss_test:0.01446, lr:2.85e-02, fs:0.86957 (r=0.808,p=0.941),  time:30.253, tt:4870.741\n",
      "Ep:161, loss:0.00000, loss_test:0.01448, lr:2.82e-02, fs:0.86957 (r=0.808,p=0.941),  time:30.261, tt:4902.256\n",
      "Ep:162, loss:0.00000, loss_test:0.01449, lr:2.80e-02, fs:0.86957 (r=0.808,p=0.941),  time:30.261, tt:4932.480\n",
      "Ep:163, loss:0.00000, loss_test:0.01450, lr:2.77e-02, fs:0.86957 (r=0.808,p=0.941),  time:30.263, tt:4963.111\n",
      "Ep:164, loss:0.00000, loss_test:0.01451, lr:2.74e-02, fs:0.86957 (r=0.808,p=0.941),  time:30.275, tt:4995.338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:165, loss:0.00000, loss_test:0.01453, lr:2.71e-02, fs:0.86957 (r=0.808,p=0.941),  time:30.274, tt:5025.444\n",
      "Ep:166, loss:0.00000, loss_test:0.01454, lr:2.69e-02, fs:0.86957 (r=0.808,p=0.941),  time:30.268, tt:5054.816\n",
      "Ep:167, loss:0.00000, loss_test:0.01455, lr:2.66e-02, fs:0.86339 (r=0.798,p=0.940),  time:30.274, tt:5086.044\n",
      "Ep:168, loss:0.00000, loss_test:0.01457, lr:2.63e-02, fs:0.85714 (r=0.788,p=0.940),  time:30.272, tt:5115.934\n",
      "Ep:169, loss:0.00000, loss_test:0.01459, lr:2.61e-02, fs:0.85714 (r=0.788,p=0.940),  time:30.263, tt:5144.702\n",
      "Ep:170, loss:0.00000, loss_test:0.01460, lr:2.58e-02, fs:0.85714 (r=0.788,p=0.940),  time:30.267, tt:5175.612\n",
      "Ep:171, loss:0.00000, loss_test:0.01461, lr:2.55e-02, fs:0.85714 (r=0.788,p=0.940),  time:30.262, tt:5205.067\n",
      "Ep:172, loss:0.00000, loss_test:0.01463, lr:2.53e-02, fs:0.85714 (r=0.788,p=0.940),  time:30.266, tt:5236.070\n",
      "Ep:173, loss:0.00000, loss_test:0.01464, lr:2.50e-02, fs:0.85714 (r=0.788,p=0.940),  time:30.265, tt:5266.073\n",
      "Ep:174, loss:0.00000, loss_test:0.01465, lr:2.48e-02, fs:0.86188 (r=0.788,p=0.951),  time:30.263, tt:5295.943\n",
      "Ep:175, loss:0.00000, loss_test:0.01467, lr:2.45e-02, fs:0.86188 (r=0.788,p=0.951),  time:30.264, tt:5326.462\n",
      "Ep:176, loss:0.00000, loss_test:0.01467, lr:2.43e-02, fs:0.86188 (r=0.788,p=0.951),  time:30.272, tt:5358.096\n",
      "Ep:177, loss:0.00000, loss_test:0.01468, lr:2.40e-02, fs:0.86188 (r=0.788,p=0.951),  time:30.268, tt:5387.684\n",
      "Ep:178, loss:0.00000, loss_test:0.01470, lr:2.38e-02, fs:0.86188 (r=0.788,p=0.951),  time:30.262, tt:5416.815\n",
      "Ep:179, loss:0.00000, loss_test:0.01471, lr:2.36e-02, fs:0.85556 (r=0.778,p=0.951),  time:30.273, tt:5449.074\n",
      "Ep:180, loss:0.00000, loss_test:0.01472, lr:2.33e-02, fs:0.85556 (r=0.778,p=0.951),  time:30.286, tt:5481.694\n",
      "Ep:181, loss:0.00000, loss_test:0.01473, lr:2.31e-02, fs:0.85556 (r=0.778,p=0.951),  time:30.289, tt:5512.668\n",
      "Ep:182, loss:0.00000, loss_test:0.01474, lr:2.29e-02, fs:0.85556 (r=0.778,p=0.951),  time:30.289, tt:5542.921\n",
      "Ep:183, loss:0.00000, loss_test:0.01475, lr:2.26e-02, fs:0.85556 (r=0.778,p=0.951),  time:30.288, tt:5573.079\n",
      "Ep:184, loss:0.00000, loss_test:0.01477, lr:2.24e-02, fs:0.85556 (r=0.778,p=0.951),  time:30.293, tt:5604.138\n",
      "Ep:185, loss:0.00000, loss_test:0.01479, lr:2.22e-02, fs:0.85556 (r=0.778,p=0.951),  time:30.278, tt:5631.781\n",
      "Ep:186, loss:0.00000, loss_test:0.01480, lr:2.20e-02, fs:0.84916 (r=0.768,p=0.950),  time:30.283, tt:5663.008\n",
      "Ep:187, loss:0.00000, loss_test:0.01480, lr:2.17e-02, fs:0.85556 (r=0.778,p=0.951),  time:30.292, tt:5694.914\n",
      "Ep:188, loss:0.00000, loss_test:0.01482, lr:2.15e-02, fs:0.85556 (r=0.778,p=0.951),  time:30.303, tt:5727.225\n",
      "Ep:189, loss:0.00000, loss_test:0.01483, lr:2.13e-02, fs:0.84916 (r=0.768,p=0.950),  time:30.309, tt:5758.744\n",
      "Ep:190, loss:0.00000, loss_test:0.01484, lr:2.11e-02, fs:0.84916 (r=0.768,p=0.950),  time:30.302, tt:5787.774\n",
      "Ep:191, loss:0.00000, loss_test:0.01485, lr:2.09e-02, fs:0.84916 (r=0.768,p=0.950),  time:30.300, tt:5817.636\n",
      "Ep:192, loss:0.00000, loss_test:0.01486, lr:2.07e-02, fs:0.84916 (r=0.768,p=0.950),  time:30.301, tt:5848.079\n",
      "Ep:193, loss:0.00000, loss_test:0.01487, lr:2.05e-02, fs:0.84916 (r=0.768,p=0.950),  time:30.303, tt:5878.834\n",
      "Ep:194, loss:0.00000, loss_test:0.01488, lr:2.03e-02, fs:0.84916 (r=0.768,p=0.950),  time:30.296, tt:5907.639\n",
      "Ep:195, loss:0.00000, loss_test:0.01489, lr:2.01e-02, fs:0.84916 (r=0.768,p=0.950),  time:30.291, tt:5937.061\n",
      "Ep:196, loss:0.00000, loss_test:0.01491, lr:1.99e-02, fs:0.84916 (r=0.768,p=0.950),  time:30.295, tt:5968.061\n",
      "Ep:197, loss:0.00000, loss_test:0.01491, lr:1.97e-02, fs:0.84916 (r=0.768,p=0.950),  time:30.286, tt:5996.564\n",
      "Ep:198, loss:0.00000, loss_test:0.01493, lr:1.95e-02, fs:0.84916 (r=0.768,p=0.950),  time:30.280, tt:6025.727\n",
      "Ep:199, loss:0.00000, loss_test:0.01493, lr:1.93e-02, fs:0.84916 (r=0.768,p=0.950),  time:30.277, tt:6055.470\n",
      "Ep:200, loss:0.00000, loss_test:0.01495, lr:1.91e-02, fs:0.84916 (r=0.768,p=0.950),  time:30.256, tt:6081.465\n",
      "Ep:201, loss:0.00000, loss_test:0.01495, lr:1.89e-02, fs:0.84916 (r=0.768,p=0.950),  time:30.243, tt:6108.996\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.14306, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.431, tt:28.431\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14159, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.092, tt:58.185\n",
      "Ep:2, loss:0.00027, loss_test:0.13898, lr:1.00e-02, fs:0.65763 (r=0.980,p=0.495),  time:28.832, tt:86.496\n",
      "Ep:3, loss:0.00026, loss_test:0.13479, lr:1.00e-02, fs:0.64964 (r=0.899,p=0.509),  time:29.280, tt:117.119\n",
      "Ep:4, loss:0.00025, loss_test:0.12857, lr:1.00e-02, fs:0.65546 (r=0.788,p=0.561),  time:29.668, tt:148.338\n",
      "Ep:5, loss:0.00024, loss_test:0.12472, lr:1.00e-02, fs:0.58696 (r=0.545,p=0.635),  time:29.887, tt:179.324\n",
      "Ep:6, loss:0.00023, loss_test:0.12251, lr:1.00e-02, fs:0.58333 (r=0.495,p=0.710),  time:29.939, tt:209.574\n",
      "Ep:7, loss:0.00022, loss_test:0.11961, lr:1.00e-02, fs:0.63158 (r=0.606,p=0.659),  time:29.867, tt:238.937\n",
      "Ep:8, loss:0.00021, loss_test:0.11838, lr:1.00e-02, fs:0.67299 (r=0.717,p=0.634),  time:30.083, tt:270.748\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.11498, lr:1.00e-02, fs:0.69268 (r=0.717,p=0.670),  time:30.274, tt:302.745\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.11088, lr:1.00e-02, fs:0.68508 (r=0.626,p=0.756),  time:30.397, tt:334.370\n",
      "Ep:11, loss:0.00019, loss_test:0.11010, lr:1.00e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.469, tt:365.630\n",
      "Ep:12, loss:0.00019, loss_test:0.10895, lr:1.00e-02, fs:0.67016 (r=0.646,p=0.696),  time:30.610, tt:397.937\n",
      "Ep:13, loss:0.00018, loss_test:0.10785, lr:1.00e-02, fs:0.66321 (r=0.646,p=0.681),  time:30.676, tt:429.468\n",
      "Ep:14, loss:0.00017, loss_test:0.10687, lr:1.00e-02, fs:0.70056 (r=0.626,p=0.795),  time:30.754, tt:461.303\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.10557, lr:1.00e-02, fs:0.68966 (r=0.606,p=0.800),  time:30.747, tt:491.952\n",
      "Ep:16, loss:0.00016, loss_test:0.10332, lr:1.00e-02, fs:0.72432 (r=0.677,p=0.779),  time:30.738, tt:522.539\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.10199, lr:1.00e-02, fs:0.73913 (r=0.687,p=0.800),  time:30.712, tt:552.818\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.10222, lr:1.00e-02, fs:0.71264 (r=0.626,p=0.827),  time:30.873, tt:586.591\n",
      "Ep:19, loss:0.00014, loss_test:0.10107, lr:1.00e-02, fs:0.72316 (r=0.646,p=0.821),  time:30.911, tt:618.225\n",
      "Ep:20, loss:0.00014, loss_test:0.09968, lr:1.00e-02, fs:0.72131 (r=0.667,p=0.786),  time:30.983, tt:650.637\n",
      "Ep:21, loss:0.00013, loss_test:0.09842, lr:1.00e-02, fs:0.75000 (r=0.667,p=0.857),  time:31.001, tt:682.012\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00013, loss_test:0.09690, lr:1.00e-02, fs:0.78889 (r=0.717,p=0.877),  time:31.081, tt:714.857\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.09584, lr:1.00e-02, fs:0.78453 (r=0.717,p=0.866),  time:31.136, tt:747.270\n",
      "Ep:24, loss:0.00012, loss_test:0.09520, lr:1.00e-02, fs:0.78409 (r=0.697,p=0.896),  time:31.142, tt:778.559\n",
      "Ep:25, loss:0.00011, loss_test:0.09393, lr:1.00e-02, fs:0.78409 (r=0.697,p=0.896),  time:31.171, tt:810.451\n",
      "Ep:26, loss:0.00011, loss_test:0.09262, lr:1.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:31.200, tt:842.398\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00011, loss_test:0.09165, lr:1.00e-02, fs:0.80226 (r=0.717,p=0.910),  time:31.230, tt:874.443\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00010, loss_test:0.09077, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:31.280, tt:907.123\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00010, loss_test:0.09011, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:31.281, tt:938.429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:30, loss:0.00010, loss_test:0.08971, lr:1.00e-02, fs:0.80682 (r=0.717,p=0.922),  time:31.307, tt:970.525\n",
      "Ep:31, loss:0.00009, loss_test:0.08848, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:31.305, tt:1001.752\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00009, loss_test:0.08794, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:31.307, tt:1033.129\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00009, loss_test:0.08764, lr:1.00e-02, fs:0.83146 (r=0.747,p=0.937),  time:31.333, tt:1065.337\n",
      "Ep:34, loss:0.00008, loss_test:0.08721, lr:1.00e-02, fs:0.83799 (r=0.758,p=0.938),  time:31.333, tt:1096.661\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00008, loss_test:0.08677, lr:1.00e-02, fs:0.83146 (r=0.747,p=0.937),  time:31.304, tt:1126.949\n",
      "Ep:36, loss:0.00008, loss_test:0.08628, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:31.348, tt:1159.880\n",
      "Ep:37, loss:0.00008, loss_test:0.08563, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:31.330, tt:1190.534\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00008, loss_test:0.08505, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:31.356, tt:1222.872\n",
      "Ep:39, loss:0.00007, loss_test:0.08483, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:31.366, tt:1254.635\n",
      "Ep:40, loss:0.00007, loss_test:0.08447, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:31.418, tt:1288.153\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00007, loss_test:0.08437, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:31.460, tt:1321.325\n",
      "Ep:42, loss:0.00007, loss_test:0.08414, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:31.495, tt:1354.296\n",
      "Ep:43, loss:0.00007, loss_test:0.08355, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:31.527, tt:1387.183\n",
      "Ep:44, loss:0.00006, loss_test:0.08338, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:31.525, tt:1418.610\n",
      "Ep:45, loss:0.00006, loss_test:0.08308, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:31.540, tt:1450.825\n",
      "Ep:46, loss:0.00006, loss_test:0.08292, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:31.555, tt:1483.069\n",
      "Ep:47, loss:0.00006, loss_test:0.08307, lr:1.00e-02, fs:0.80682 (r=0.717,p=0.922),  time:31.575, tt:1515.583\n",
      "Ep:48, loss:0.00006, loss_test:0.08217, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:31.589, tt:1547.866\n",
      "Ep:49, loss:0.00006, loss_test:0.08215, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:31.623, tt:1581.140\n",
      "Ep:50, loss:0.00005, loss_test:0.08265, lr:1.00e-02, fs:0.80682 (r=0.717,p=0.922),  time:31.641, tt:1613.667\n",
      "Ep:51, loss:0.00005, loss_test:0.08180, lr:1.00e-02, fs:0.81356 (r=0.727,p=0.923),  time:31.692, tt:1647.958\n",
      "Ep:52, loss:0.00005, loss_test:0.08194, lr:9.90e-03, fs:0.80682 (r=0.717,p=0.922),  time:31.707, tt:1680.481\n",
      "Ep:53, loss:0.00005, loss_test:0.08179, lr:9.80e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.715, tt:1712.591\n",
      "Ep:54, loss:0.00005, loss_test:0.08171, lr:9.70e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.707, tt:1743.877\n",
      "Ep:55, loss:0.00005, loss_test:0.08210, lr:9.61e-03, fs:0.76471 (r=0.657,p=0.915),  time:31.721, tt:1776.358\n",
      "Ep:56, loss:0.00005, loss_test:0.08119, lr:9.51e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.715, tt:1807.757\n",
      "Ep:57, loss:0.00005, loss_test:0.08096, lr:9.41e-03, fs:0.78363 (r=0.677,p=0.931),  time:31.735, tt:1840.633\n",
      "Ep:58, loss:0.00005, loss_test:0.08120, lr:9.32e-03, fs:0.76923 (r=0.657,p=0.929),  time:31.738, tt:1872.529\n",
      "Ep:59, loss:0.00004, loss_test:0.08163, lr:9.23e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.720, tt:1903.203\n",
      "Ep:60, loss:0.00004, loss_test:0.08132, lr:9.14e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.732, tt:1935.625\n",
      "Ep:61, loss:0.00004, loss_test:0.08087, lr:9.04e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.736, tt:1967.656\n",
      "Ep:62, loss:0.00004, loss_test:0.08038, lr:8.95e-03, fs:0.75294 (r=0.646,p=0.901),  time:31.730, tt:1998.964\n",
      "Ep:63, loss:0.00004, loss_test:0.08174, lr:8.86e-03, fs:0.75449 (r=0.636,p=0.926),  time:31.717, tt:2029.875\n",
      "Ep:64, loss:0.00004, loss_test:0.08082, lr:8.78e-03, fs:0.75449 (r=0.636,p=0.926),  time:31.684, tt:2059.455\n",
      "Ep:65, loss:0.00004, loss_test:0.07974, lr:8.69e-03, fs:0.75294 (r=0.646,p=0.901),  time:31.701, tt:2092.234\n",
      "Ep:66, loss:0.00004, loss_test:0.08144, lr:8.60e-03, fs:0.75449 (r=0.636,p=0.926),  time:31.716, tt:2124.944\n",
      "Ep:67, loss:0.00004, loss_test:0.08157, lr:8.51e-03, fs:0.75449 (r=0.636,p=0.926),  time:31.730, tt:2157.671\n",
      "Ep:68, loss:0.00004, loss_test:0.07972, lr:8.43e-03, fs:0.75294 (r=0.646,p=0.901),  time:31.733, tt:2189.550\n",
      "Ep:69, loss:0.00004, loss_test:0.08126, lr:8.35e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.750, tt:2222.533\n",
      "Ep:70, loss:0.00004, loss_test:0.08137, lr:8.26e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.750, tt:2254.277\n",
      "Ep:71, loss:0.00003, loss_test:0.07995, lr:8.18e-03, fs:0.75000 (r=0.636,p=0.913),  time:31.762, tt:2286.841\n",
      "Ep:72, loss:0.00003, loss_test:0.08077, lr:8.10e-03, fs:0.75449 (r=0.636,p=0.926),  time:31.781, tt:2319.989\n",
      "Ep:73, loss:0.00003, loss_test:0.08139, lr:8.02e-03, fs:0.75449 (r=0.636,p=0.926),  time:31.776, tt:2351.403\n",
      "Ep:74, loss:0.00003, loss_test:0.08007, lr:7.94e-03, fs:0.75000 (r=0.636,p=0.913),  time:31.803, tt:2385.235\n",
      "Ep:75, loss:0.00003, loss_test:0.07991, lr:7.86e-03, fs:0.75449 (r=0.636,p=0.926),  time:31.789, tt:2415.994\n",
      "Ep:76, loss:0.00003, loss_test:0.08059, lr:7.78e-03, fs:0.75152 (r=0.626,p=0.939),  time:31.800, tt:2448.570\n",
      "Ep:77, loss:0.00003, loss_test:0.08032, lr:7.70e-03, fs:0.75000 (r=0.636,p=0.913),  time:31.773, tt:2478.320\n",
      "Ep:78, loss:0.00003, loss_test:0.08013, lr:7.62e-03, fs:0.75000 (r=0.636,p=0.913),  time:31.772, tt:2509.954\n",
      "Ep:79, loss:0.00003, loss_test:0.08054, lr:7.55e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.775, tt:2541.971\n",
      "Ep:80, loss:0.00003, loss_test:0.07997, lr:7.47e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.779, tt:2574.111\n",
      "Ep:81, loss:0.00003, loss_test:0.08010, lr:7.40e-03, fs:0.75000 (r=0.636,p=0.913),  time:31.778, tt:2605.835\n",
      "Ep:82, loss:0.00003, loss_test:0.08041, lr:7.32e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.784, tt:2638.091\n",
      "Ep:83, loss:0.00003, loss_test:0.08027, lr:7.25e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.805, tt:2671.617\n",
      "Ep:84, loss:0.00003, loss_test:0.08042, lr:7.18e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.834, tt:2705.892\n",
      "Ep:85, loss:0.00003, loss_test:0.08010, lr:7.11e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.838, tt:2738.096\n",
      "Ep:86, loss:0.00003, loss_test:0.08052, lr:7.03e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.860, tt:2771.820\n",
      "Ep:87, loss:0.00003, loss_test:0.07998, lr:6.96e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.885, tt:2805.874\n",
      "Ep:88, loss:0.00003, loss_test:0.08016, lr:6.89e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.887, tt:2837.906\n",
      "Ep:89, loss:0.00003, loss_test:0.07995, lr:6.83e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.885, tt:2869.613\n",
      "Ep:90, loss:0.00003, loss_test:0.08025, lr:6.76e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.876, tt:2900.711\n",
      "Ep:91, loss:0.00003, loss_test:0.08010, lr:6.69e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.892, tt:2934.046\n",
      "Ep:92, loss:0.00002, loss_test:0.07999, lr:6.62e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.890, tt:2965.786\n",
      "Ep:93, loss:0.00002, loss_test:0.08045, lr:6.56e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.890, tt:2997.645\n",
      "Ep:94, loss:0.00002, loss_test:0.08015, lr:6.49e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.891, tt:3029.647\n",
      "Ep:95, loss:0.00002, loss_test:0.08036, lr:6.43e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.904, tt:3062.742\n",
      "Ep:96, loss:0.00002, loss_test:0.08029, lr:6.36e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.905, tt:3094.770\n",
      "Ep:97, loss:0.00002, loss_test:0.08028, lr:6.30e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.901, tt:3126.325\n",
      "Ep:98, loss:0.00002, loss_test:0.08023, lr:6.24e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.905, tt:3158.599\n",
      "Ep:99, loss:0.00002, loss_test:0.08026, lr:6.17e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.901, tt:3190.102\n",
      "Ep:100, loss:0.00002, loss_test:0.08134, lr:6.11e-03, fs:0.74390 (r=0.616,p=0.938),  time:31.910, tt:3222.895\n",
      "Ep:101, loss:0.00002, loss_test:0.08061, lr:6.05e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.921, tt:3255.938\n",
      "Ep:102, loss:0.00002, loss_test:0.08002, lr:5.99e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.933, tt:3289.110\n",
      "Ep:103, loss:0.00002, loss_test:0.08061, lr:5.93e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.950, tt:3322.789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:104, loss:0.00002, loss_test:0.08042, lr:5.87e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.937, tt:3353.411\n",
      "Ep:105, loss:0.00002, loss_test:0.08075, lr:5.81e-03, fs:0.73939 (r=0.616,p=0.924),  time:31.936, tt:3385.232\n",
      "Ep:106, loss:0.00002, loss_test:0.08052, lr:5.75e-03, fs:0.73939 (r=0.616,p=0.924),  time:31.918, tt:3415.182\n",
      "Ep:107, loss:0.00002, loss_test:0.08033, lr:5.70e-03, fs:0.73939 (r=0.616,p=0.924),  time:31.921, tt:3447.493\n",
      "Ep:108, loss:0.00002, loss_test:0.08119, lr:5.64e-03, fs:0.73939 (r=0.616,p=0.924),  time:31.926, tt:3479.883\n",
      "Ep:109, loss:0.00002, loss_test:0.08114, lr:5.58e-03, fs:0.73939 (r=0.616,p=0.924),  time:31.925, tt:3511.702\n",
      "Ep:110, loss:0.00002, loss_test:0.08038, lr:5.53e-03, fs:0.73939 (r=0.616,p=0.924),  time:31.919, tt:3542.982\n",
      "Ep:111, loss:0.00002, loss_test:0.08075, lr:5.47e-03, fs:0.73939 (r=0.616,p=0.924),  time:31.921, tt:3575.188\n",
      "Ep:112, loss:0.00002, loss_test:0.08091, lr:5.42e-03, fs:0.73939 (r=0.616,p=0.924),  time:31.925, tt:3607.559\n",
      "Ep:113, loss:0.00002, loss_test:0.08088, lr:5.36e-03, fs:0.73939 (r=0.616,p=0.924),  time:31.920, tt:3638.829\n",
      "Ep:114, loss:0.00002, loss_test:0.08082, lr:5.31e-03, fs:0.73171 (r=0.606,p=0.923),  time:31.919, tt:3670.704\n",
      "Ep:115, loss:0.00002, loss_test:0.08110, lr:5.26e-03, fs:0.73171 (r=0.606,p=0.923),  time:31.927, tt:3703.528\n",
      "Ep:116, loss:0.00002, loss_test:0.08124, lr:5.20e-03, fs:0.73171 (r=0.606,p=0.923),  time:31.926, tt:3735.347\n",
      "Ep:117, loss:0.00002, loss_test:0.08139, lr:5.15e-03, fs:0.73171 (r=0.606,p=0.923),  time:31.924, tt:3767.030\n",
      "Ep:118, loss:0.00002, loss_test:0.08110, lr:5.10e-03, fs:0.73171 (r=0.606,p=0.923),  time:31.919, tt:3798.407\n",
      "Ep:119, loss:0.00002, loss_test:0.08114, lr:5.05e-03, fs:0.73171 (r=0.606,p=0.923),  time:31.899, tt:3827.859\n",
      "Ep:120, loss:0.00002, loss_test:0.08129, lr:5.00e-03, fs:0.73171 (r=0.606,p=0.923),  time:31.882, tt:3857.770\n",
      "Ep:121, loss:0.00002, loss_test:0.08125, lr:4.95e-03, fs:0.73171 (r=0.606,p=0.923),  time:31.887, tt:3890.158\n",
      "Ep:122, loss:0.00002, loss_test:0.08137, lr:4.90e-03, fs:0.73171 (r=0.606,p=0.923),  time:31.897, tt:3923.367\n",
      "Ep:123, loss:0.00002, loss_test:0.08157, lr:4.85e-03, fs:0.73620 (r=0.606,p=0.938),  time:31.905, tt:3956.259\n",
      "Ep:124, loss:0.00002, loss_test:0.08111, lr:4.80e-03, fs:0.73171 (r=0.606,p=0.923),  time:31.919, tt:3989.839\n",
      "Ep:125, loss:0.00002, loss_test:0.08165, lr:4.75e-03, fs:0.73171 (r=0.606,p=0.923),  time:31.920, tt:4021.876\n",
      "Ep:126, loss:0.00002, loss_test:0.08149, lr:4.71e-03, fs:0.73171 (r=0.606,p=0.923),  time:31.915, tt:4053.267\n",
      "Ep:127, loss:0.00002, loss_test:0.08129, lr:4.66e-03, fs:0.73171 (r=0.606,p=0.923),  time:31.924, tt:4086.245\n",
      "Ep:128, loss:0.00002, loss_test:0.08150, lr:4.61e-03, fs:0.73620 (r=0.606,p=0.938),  time:31.918, tt:4117.459\n",
      "Ep:129, loss:0.00002, loss_test:0.08115, lr:4.57e-03, fs:0.73171 (r=0.606,p=0.923),  time:31.935, tt:4151.551\n",
      "Ep:130, loss:0.00002, loss_test:0.08155, lr:4.52e-03, fs:0.73620 (r=0.606,p=0.938),  time:31.927, tt:4182.378\n",
      "Ep:131, loss:0.00002, loss_test:0.08144, lr:4.48e-03, fs:0.73171 (r=0.606,p=0.923),  time:31.914, tt:4212.596\n",
      "Ep:132, loss:0.00002, loss_test:0.08135, lr:4.43e-03, fs:0.73171 (r=0.606,p=0.923),  time:31.904, tt:4243.171\n",
      "Ep:133, loss:0.00002, loss_test:0.08155, lr:4.39e-03, fs:0.73620 (r=0.606,p=0.938),  time:31.896, tt:4274.131\n",
      "Ep:134, loss:0.00002, loss_test:0.08146, lr:4.34e-03, fs:0.73620 (r=0.606,p=0.938),  time:31.893, tt:4305.550\n",
      "Ep:135, loss:0.00002, loss_test:0.08164, lr:4.30e-03, fs:0.73620 (r=0.606,p=0.938),  time:31.899, tt:4338.202\n",
      "Ep:136, loss:0.00002, loss_test:0.08159, lr:4.26e-03, fs:0.73620 (r=0.606,p=0.938),  time:31.897, tt:4369.841\n",
      "Ep:137, loss:0.00002, loss_test:0.08163, lr:4.21e-03, fs:0.73620 (r=0.606,p=0.938),  time:31.905, tt:4402.864\n",
      "Ep:138, loss:0.00002, loss_test:0.08113, lr:4.17e-03, fs:0.73171 (r=0.606,p=0.923),  time:31.895, tt:4433.346\n",
      "Ep:139, loss:0.00002, loss_test:0.08189, lr:4.13e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.905, tt:4466.746\n",
      "Ep:140, loss:0.00002, loss_test:0.08267, lr:4.09e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.907, tt:4498.902\n",
      "Ep:141, loss:0.00002, loss_test:0.08214, lr:4.05e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.907, tt:4530.850\n",
      "Ep:142, loss:0.00002, loss_test:0.08140, lr:4.01e-03, fs:0.73171 (r=0.606,p=0.923),  time:31.927, tt:4565.629\n",
      "Ep:143, loss:0.00002, loss_test:0.08139, lr:3.97e-03, fs:0.73620 (r=0.606,p=0.938),  time:31.941, tt:4599.448\n",
      "Ep:144, loss:0.00002, loss_test:0.08177, lr:3.93e-03, fs:0.73620 (r=0.606,p=0.938),  time:31.926, tt:4629.208\n",
      "Ep:145, loss:0.00001, loss_test:0.08184, lr:3.89e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.929, tt:4661.639\n",
      "Ep:146, loss:0.00001, loss_test:0.08182, lr:3.85e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.927, tt:4693.196\n",
      "Ep:147, loss:0.00001, loss_test:0.08173, lr:3.81e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.914, tt:4723.340\n",
      "Ep:148, loss:0.00001, loss_test:0.08145, lr:3.77e-03, fs:0.73620 (r=0.606,p=0.938),  time:31.914, tt:4755.232\n",
      "Ep:149, loss:0.00001, loss_test:0.08213, lr:3.73e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.900, tt:4784.982\n",
      "Ep:150, loss:0.00001, loss_test:0.08230, lr:3.70e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.899, tt:4816.789\n",
      "Ep:151, loss:0.00001, loss_test:0.08195, lr:3.66e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.881, tt:4845.980\n",
      "Ep:152, loss:0.00001, loss_test:0.08176, lr:3.62e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.876, tt:4876.978\n",
      "Ep:153, loss:0.00001, loss_test:0.08186, lr:3.59e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.884, tt:4910.141\n",
      "Ep:154, loss:0.00001, loss_test:0.08192, lr:3.55e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.874, tt:4940.540\n",
      "Ep:155, loss:0.00001, loss_test:0.08200, lr:3.52e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.865, tt:4970.960\n",
      "Ep:156, loss:0.00001, loss_test:0.08221, lr:3.48e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.880, tt:5005.170\n",
      "Ep:157, loss:0.00001, loss_test:0.08195, lr:3.45e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.878, tt:5036.748\n",
      "Ep:158, loss:0.00001, loss_test:0.08202, lr:3.41e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.878, tt:5068.583\n",
      "Ep:159, loss:0.00001, loss_test:0.08217, lr:3.38e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.884, tt:5101.366\n",
      "Ep:160, loss:0.00001, loss_test:0.08194, lr:3.34e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.881, tt:5132.818\n",
      "Ep:161, loss:0.00001, loss_test:0.08206, lr:3.31e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.881, tt:5164.716\n",
      "Ep:162, loss:0.00001, loss_test:0.08236, lr:3.28e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.884, tt:5197.020\n",
      "Ep:163, loss:0.00001, loss_test:0.08219, lr:3.24e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.884, tt:5228.899\n",
      "Ep:164, loss:0.00001, loss_test:0.08214, lr:3.21e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.888, tt:5261.574\n",
      "Ep:165, loss:0.00001, loss_test:0.08225, lr:3.18e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.890, tt:5293.744\n",
      "Ep:166, loss:0.00001, loss_test:0.08211, lr:3.15e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.889, tt:5325.535\n",
      "Ep:167, loss:0.00001, loss_test:0.08216, lr:3.12e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.893, tt:5357.998\n",
      "Ep:168, loss:0.00001, loss_test:0.08234, lr:3.09e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.900, tt:5391.049\n",
      "Ep:169, loss:0.00001, loss_test:0.08228, lr:3.05e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.897, tt:5422.453\n",
      "Ep:170, loss:0.00001, loss_test:0.08232, lr:3.02e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.889, tt:5453.076\n",
      "Ep:171, loss:0.00001, loss_test:0.08254, lr:2.99e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.882, tt:5483.783\n",
      "Ep:172, loss:0.00001, loss_test:0.08243, lr:2.96e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.874, tt:5514.284\n",
      "Ep:173, loss:0.00001, loss_test:0.08222, lr:2.93e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.870, tt:5545.419\n",
      "Ep:174, loss:0.00001, loss_test:0.08261, lr:2.90e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.869, tt:5577.073\n",
      "Ep:175, loss:0.00001, loss_test:0.08272, lr:2.88e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.864, tt:5608.148\n",
      "Ep:176, loss:0.00001, loss_test:0.08251, lr:2.85e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.866, tt:5640.294\n",
      "Ep:177, loss:0.00001, loss_test:0.08236, lr:2.82e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.865, tt:5671.883\n",
      "Ep:178, loss:0.00001, loss_test:0.08258, lr:2.79e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.868, tt:5704.394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:179, loss:0.00001, loss_test:0.08264, lr:2.76e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.872, tt:5736.917\n",
      "Ep:180, loss:0.00001, loss_test:0.08265, lr:2.73e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.875, tt:5769.431\n",
      "Ep:181, loss:0.00001, loss_test:0.08266, lr:2.71e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.873, tt:5800.799\n",
      "Ep:182, loss:0.00001, loss_test:0.08265, lr:2.68e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.876, tt:5833.354\n",
      "Ep:183, loss:0.00001, loss_test:0.08273, lr:2.65e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.871, tt:5864.177\n",
      "Ep:184, loss:0.00001, loss_test:0.08281, lr:2.63e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.873, tt:5896.497\n",
      "Ep:185, loss:0.00001, loss_test:0.08268, lr:2.60e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.867, tt:5927.222\n",
      "Ep:186, loss:0.00001, loss_test:0.08272, lr:2.57e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.873, tt:5960.197\n",
      "Ep:187, loss:0.00001, loss_test:0.08283, lr:2.55e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.868, tt:5991.140\n",
      "Ep:188, loss:0.00001, loss_test:0.08284, lr:2.52e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.870, tt:6023.368\n",
      "Ep:189, loss:0.00001, loss_test:0.08286, lr:2.50e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.865, tt:6054.418\n",
      "Ep:190, loss:0.00001, loss_test:0.08279, lr:2.47e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.867, tt:6086.647\n",
      "Ep:191, loss:0.00001, loss_test:0.08289, lr:2.45e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.870, tt:6119.062\n",
      "Ep:192, loss:0.00001, loss_test:0.08290, lr:2.42e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.861, tt:6149.150\n",
      "Ep:193, loss:0.00001, loss_test:0.08296, lr:2.40e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.857, tt:6180.225\n",
      "Ep:194, loss:0.00001, loss_test:0.08316, lr:2.38e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.847, tt:6210.128\n",
      "Ep:195, loss:0.00001, loss_test:0.08302, lr:2.35e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.847, tt:6242.031\n",
      "Ep:196, loss:0.00001, loss_test:0.08295, lr:2.33e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.834, tt:6271.233\n",
      "Ep:197, loss:0.00001, loss_test:0.08290, lr:2.31e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.825, tt:6301.277\n",
      "Ep:198, loss:0.00001, loss_test:0.08314, lr:2.28e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.795, tt:6327.296\n",
      "Ep:199, loss:0.00001, loss_test:0.08334, lr:2.26e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.775, tt:6355.095\n",
      "Ep:200, loss:0.00001, loss_test:0.08325, lr:2.24e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.756, tt:6382.926\n",
      "Ep:201, loss:0.00001, loss_test:0.08311, lr:2.21e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.732, tt:6409.938\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02094, lr:6.00e-02, fs:0.63374 (r=0.778,p=0.535),  time:20.888, tt:20.888\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02157, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:22.188, tt:44.376\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02326, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.042, tt:69.126\n",
      "Ep:3, loss:0.00004, loss_test:0.02368, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.686, tt:94.744\n",
      "Ep:4, loss:0.00004, loss_test:0.02315, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.740, tt:118.699\n",
      "Ep:5, loss:0.00004, loss_test:0.02203, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.553, tt:141.318\n",
      "Ep:6, loss:0.00004, loss_test:0.02067, lr:6.00e-02, fs:0.67577 (r=1.000,p=0.510),  time:23.603, tt:165.219\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01955, lr:6.00e-02, fs:0.66426 (r=0.929,p=0.517),  time:23.618, tt:188.947\n",
      "Ep:8, loss:0.00004, loss_test:0.01897, lr:6.00e-02, fs:0.70079 (r=0.899,p=0.574),  time:23.840, tt:214.563\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01884, lr:6.00e-02, fs:0.69959 (r=0.859,p=0.590),  time:24.002, tt:240.025\n",
      "Ep:10, loss:0.00004, loss_test:0.01866, lr:6.00e-02, fs:0.68908 (r=0.828,p=0.590),  time:24.116, tt:265.272\n",
      "Ep:11, loss:0.00004, loss_test:0.01825, lr:6.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:24.177, tt:290.124\n",
      "Ep:12, loss:0.00004, loss_test:0.01799, lr:6.00e-02, fs:0.70588 (r=0.909,p=0.577),  time:24.280, tt:315.639\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01788, lr:6.00e-02, fs:0.70992 (r=0.939,p=0.571),  time:24.423, tt:341.921\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01774, lr:6.00e-02, fs:0.70943 (r=0.949,p=0.566),  time:24.473, tt:367.102\n",
      "Ep:15, loss:0.00003, loss_test:0.01750, lr:6.00e-02, fs:0.71212 (r=0.949,p=0.570),  time:24.544, tt:392.712\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01721, lr:6.00e-02, fs:0.72656 (r=0.939,p=0.592),  time:24.658, tt:419.190\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01704, lr:6.00e-02, fs:0.73251 (r=0.899,p=0.618),  time:24.705, tt:444.698\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01695, lr:6.00e-02, fs:0.71967 (r=0.869,p=0.614),  time:24.700, tt:469.291\n",
      "Ep:19, loss:0.00003, loss_test:0.01680, lr:6.00e-02, fs:0.73109 (r=0.879,p=0.626),  time:24.743, tt:494.863\n",
      "Ep:20, loss:0.00003, loss_test:0.01662, lr:6.00e-02, fs:0.75000 (r=0.909,p=0.638),  time:24.785, tt:520.489\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01648, lr:6.00e-02, fs:0.77236 (r=0.960,p=0.646),  time:24.832, tt:546.307\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01639, lr:6.00e-02, fs:0.76735 (r=0.949,p=0.644),  time:24.872, tt:572.045\n",
      "Ep:23, loss:0.00003, loss_test:0.01631, lr:6.00e-02, fs:0.77108 (r=0.970,p=0.640),  time:24.943, tt:598.620\n",
      "Ep:24, loss:0.00003, loss_test:0.01622, lr:6.00e-02, fs:0.77366 (r=0.949,p=0.653),  time:25.080, tt:627.012\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01615, lr:6.00e-02, fs:0.76987 (r=0.929,p=0.657),  time:25.089, tt:652.312\n",
      "Ep:26, loss:0.00003, loss_test:0.01607, lr:6.00e-02, fs:0.77966 (r=0.929,p=0.672),  time:25.071, tt:676.913\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01600, lr:6.00e-02, fs:0.77778 (r=0.919,p=0.674),  time:25.083, tt:702.338\n",
      "Ep:28, loss:0.00002, loss_test:0.01594, lr:6.00e-02, fs:0.77391 (r=0.899,p=0.679),  time:25.110, tt:728.193\n",
      "Ep:29, loss:0.00002, loss_test:0.01585, lr:6.00e-02, fs:0.77586 (r=0.909,p=0.677),  time:25.134, tt:754.020\n",
      "Ep:30, loss:0.00002, loss_test:0.01574, lr:6.00e-02, fs:0.77778 (r=0.919,p=0.674),  time:25.113, tt:778.511\n",
      "Ep:31, loss:0.00002, loss_test:0.01560, lr:6.00e-02, fs:0.77586 (r=0.909,p=0.677),  time:25.101, tt:803.238\n",
      "Ep:32, loss:0.00002, loss_test:0.01547, lr:6.00e-02, fs:0.77922 (r=0.909,p=0.682),  time:25.123, tt:829.054\n",
      "Ep:33, loss:0.00002, loss_test:0.01534, lr:6.00e-02, fs:0.78970 (r=0.929,p=0.687),  time:25.152, tt:855.153\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01527, lr:6.00e-02, fs:0.78448 (r=0.919,p=0.684),  time:25.184, tt:881.443\n",
      "Ep:35, loss:0.00002, loss_test:0.01521, lr:6.00e-02, fs:0.78448 (r=0.919,p=0.684),  time:25.178, tt:906.414\n",
      "Ep:36, loss:0.00002, loss_test:0.01513, lr:6.00e-02, fs:0.78603 (r=0.909,p=0.692),  time:25.208, tt:932.678\n",
      "Ep:37, loss:0.00002, loss_test:0.01504, lr:6.00e-02, fs:0.78603 (r=0.909,p=0.692),  time:25.211, tt:958.003\n",
      "Ep:38, loss:0.00002, loss_test:0.01497, lr:6.00e-02, fs:0.79295 (r=0.909,p=0.703),  time:25.222, tt:983.644\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01490, lr:6.00e-02, fs:0.79295 (r=0.909,p=0.703),  time:25.213, tt:1008.529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:40, loss:0.00002, loss_test:0.01485, lr:6.00e-02, fs:0.80357 (r=0.909,p=0.720),  time:25.236, tt:1034.692\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01483, lr:6.00e-02, fs:0.79821 (r=0.899,p=0.718),  time:25.292, tt:1062.257\n",
      "Ep:42, loss:0.00002, loss_test:0.01476, lr:6.00e-02, fs:0.79821 (r=0.899,p=0.718),  time:25.288, tt:1087.367\n",
      "Ep:43, loss:0.00002, loss_test:0.01470, lr:6.00e-02, fs:0.79821 (r=0.899,p=0.718),  time:25.301, tt:1113.223\n",
      "Ep:44, loss:0.00002, loss_test:0.01463, lr:6.00e-02, fs:0.79279 (r=0.889,p=0.715),  time:25.318, tt:1139.289\n",
      "Ep:45, loss:0.00002, loss_test:0.01457, lr:6.00e-02, fs:0.79279 (r=0.889,p=0.715),  time:25.320, tt:1164.697\n",
      "Ep:46, loss:0.00002, loss_test:0.01452, lr:6.00e-02, fs:0.79452 (r=0.879,p=0.725),  time:25.324, tt:1190.248\n",
      "Ep:47, loss:0.00002, loss_test:0.01444, lr:6.00e-02, fs:0.79452 (r=0.879,p=0.725),  time:25.325, tt:1215.591\n",
      "Ep:48, loss:0.00002, loss_test:0.01437, lr:6.00e-02, fs:0.80556 (r=0.879,p=0.744),  time:25.348, tt:1242.066\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01434, lr:6.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:25.356, tt:1267.811\n",
      "Ep:50, loss:0.00002, loss_test:0.01431, lr:6.00e-02, fs:0.80189 (r=0.859,p=0.752),  time:25.355, tt:1293.087\n",
      "Ep:51, loss:0.00002, loss_test:0.01427, lr:6.00e-02, fs:0.79621 (r=0.848,p=0.750),  time:25.367, tt:1319.086\n",
      "Ep:52, loss:0.00001, loss_test:0.01420, lr:6.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:25.365, tt:1344.364\n",
      "Ep:53, loss:0.00001, loss_test:0.01414, lr:6.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:25.371, tt:1370.011\n",
      "Ep:54, loss:0.00001, loss_test:0.01408, lr:6.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:25.377, tt:1395.749\n",
      "Ep:55, loss:0.00001, loss_test:0.01404, lr:6.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:25.387, tt:1421.644\n",
      "Ep:56, loss:0.00001, loss_test:0.01401, lr:6.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:25.387, tt:1447.084\n",
      "Ep:57, loss:0.00001, loss_test:0.01398, lr:6.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:25.383, tt:1472.239\n",
      "Ep:58, loss:0.00001, loss_test:0.01390, lr:6.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:25.377, tt:1497.214\n",
      "Ep:59, loss:0.00001, loss_test:0.01388, lr:6.00e-02, fs:0.79612 (r=0.828,p=0.766),  time:25.366, tt:1521.946\n",
      "Ep:60, loss:0.00001, loss_test:0.01383, lr:5.94e-02, fs:0.80000 (r=0.828,p=0.774),  time:25.357, tt:1546.762\n",
      "Ep:61, loss:0.00001, loss_test:0.01377, lr:5.88e-02, fs:0.80000 (r=0.828,p=0.774),  time:25.344, tt:1571.344\n",
      "Ep:62, loss:0.00001, loss_test:0.01374, lr:5.82e-02, fs:0.80392 (r=0.828,p=0.781),  time:25.334, tt:1596.064\n",
      "Ep:63, loss:0.00001, loss_test:0.01369, lr:5.76e-02, fs:0.79803 (r=0.818,p=0.779),  time:25.323, tt:1620.662\n",
      "Ep:64, loss:0.00001, loss_test:0.01364, lr:5.71e-02, fs:0.79803 (r=0.818,p=0.779),  time:25.334, tt:1646.733\n",
      "Ep:65, loss:0.00001, loss_test:0.01363, lr:5.65e-02, fs:0.79000 (r=0.798,p=0.782),  time:25.345, tt:1672.744\n",
      "Ep:66, loss:0.00001, loss_test:0.01360, lr:5.59e-02, fs:0.80612 (r=0.798,p=0.814),  time:25.349, tt:1698.416\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01354, lr:5.59e-02, fs:0.80612 (r=0.798,p=0.814),  time:25.363, tt:1724.717\n",
      "Ep:68, loss:0.00001, loss_test:0.01355, lr:5.59e-02, fs:0.81026 (r=0.798,p=0.823),  time:25.356, tt:1749.569\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01352, lr:5.59e-02, fs:0.80412 (r=0.788,p=0.821),  time:25.365, tt:1775.561\n",
      "Ep:70, loss:0.00001, loss_test:0.01350, lr:5.59e-02, fs:0.81250 (r=0.788,p=0.839),  time:25.366, tt:1800.992\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00001, loss_test:0.01347, lr:5.59e-02, fs:0.81250 (r=0.788,p=0.839),  time:25.385, tt:1827.740\n",
      "Ep:72, loss:0.00001, loss_test:0.01344, lr:5.59e-02, fs:0.81675 (r=0.788,p=0.848),  time:25.378, tt:1852.579\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.01340, lr:5.59e-02, fs:0.81675 (r=0.788,p=0.848),  time:25.366, tt:1877.051\n",
      "Ep:74, loss:0.00001, loss_test:0.01337, lr:5.59e-02, fs:0.81675 (r=0.788,p=0.848),  time:25.376, tt:1903.218\n",
      "Ep:75, loss:0.00001, loss_test:0.01336, lr:5.59e-02, fs:0.81675 (r=0.788,p=0.848),  time:25.376, tt:1928.614\n",
      "Ep:76, loss:0.00001, loss_test:0.01336, lr:5.59e-02, fs:0.81053 (r=0.778,p=0.846),  time:25.384, tt:1954.581\n",
      "Ep:77, loss:0.00001, loss_test:0.01338, lr:5.59e-02, fs:0.81053 (r=0.778,p=0.846),  time:25.386, tt:1980.139\n",
      "Ep:78, loss:0.00001, loss_test:0.01333, lr:5.59e-02, fs:0.81481 (r=0.778,p=0.856),  time:25.379, tt:2004.958\n",
      "Ep:79, loss:0.00001, loss_test:0.01329, lr:5.59e-02, fs:0.81481 (r=0.778,p=0.856),  time:25.389, tt:2031.131\n",
      "Ep:80, loss:0.00001, loss_test:0.01328, lr:5.59e-02, fs:0.81481 (r=0.778,p=0.856),  time:25.383, tt:2055.990\n",
      "Ep:81, loss:0.00001, loss_test:0.01330, lr:5.59e-02, fs:0.81915 (r=0.778,p=0.865),  time:25.365, tt:2079.894\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.01330, lr:5.59e-02, fs:0.81915 (r=0.778,p=0.865),  time:25.366, tt:2105.352\n",
      "Ep:83, loss:0.00001, loss_test:0.01327, lr:5.59e-02, fs:0.82353 (r=0.778,p=0.875),  time:25.359, tt:2130.184\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00001, loss_test:0.01325, lr:5.59e-02, fs:0.81915 (r=0.778,p=0.865),  time:25.368, tt:2156.296\n",
      "Ep:85, loss:0.00001, loss_test:0.01325, lr:5.59e-02, fs:0.82353 (r=0.778,p=0.875),  time:25.370, tt:2181.807\n",
      "Ep:86, loss:0.00001, loss_test:0.01325, lr:5.59e-02, fs:0.82353 (r=0.778,p=0.875),  time:25.376, tt:2207.738\n",
      "Ep:87, loss:0.00001, loss_test:0.01323, lr:5.59e-02, fs:0.82353 (r=0.778,p=0.875),  time:25.373, tt:2232.836\n",
      "Ep:88, loss:0.00001, loss_test:0.01323, lr:5.59e-02, fs:0.82353 (r=0.778,p=0.875),  time:25.370, tt:2257.942\n",
      "Ep:89, loss:0.00001, loss_test:0.01321, lr:5.59e-02, fs:0.82353 (r=0.778,p=0.875),  time:25.380, tt:2284.217\n",
      "Ep:90, loss:0.00001, loss_test:0.01325, lr:5.59e-02, fs:0.82353 (r=0.778,p=0.875),  time:25.386, tt:2310.148\n",
      "Ep:91, loss:0.00001, loss_test:0.01328, lr:5.59e-02, fs:0.83243 (r=0.778,p=0.895),  time:25.389, tt:2335.790\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00001, loss_test:0.01327, lr:5.59e-02, fs:0.82796 (r=0.778,p=0.885),  time:25.397, tt:2361.884\n",
      "Ep:93, loss:0.00001, loss_test:0.01326, lr:5.59e-02, fs:0.82796 (r=0.778,p=0.885),  time:25.405, tt:2388.034\n",
      "Ep:94, loss:0.00001, loss_test:0.01324, lr:5.59e-02, fs:0.82796 (r=0.778,p=0.885),  time:25.409, tt:2413.827\n",
      "Ep:95, loss:0.00001, loss_test:0.01325, lr:5.59e-02, fs:0.83243 (r=0.778,p=0.895),  time:25.405, tt:2438.842\n",
      "Ep:96, loss:0.00001, loss_test:0.01324, lr:5.59e-02, fs:0.83696 (r=0.778,p=0.906),  time:25.424, tt:2466.169\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00001, loss_test:0.01323, lr:5.59e-02, fs:0.83696 (r=0.778,p=0.906),  time:25.434, tt:2492.500\n",
      "Ep:98, loss:0.00001, loss_test:0.01324, lr:5.59e-02, fs:0.83696 (r=0.778,p=0.906),  time:25.435, tt:2518.099\n",
      "Ep:99, loss:0.00001, loss_test:0.01325, lr:5.59e-02, fs:0.83696 (r=0.778,p=0.906),  time:25.437, tt:2543.683\n",
      "Ep:100, loss:0.00001, loss_test:0.01323, lr:5.59e-02, fs:0.83696 (r=0.778,p=0.906),  time:25.449, tt:2570.314\n",
      "Ep:101, loss:0.00001, loss_test:0.01325, lr:5.59e-02, fs:0.84153 (r=0.778,p=0.917),  time:25.451, tt:2595.978\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00001, loss_test:0.01327, lr:5.59e-02, fs:0.84153 (r=0.778,p=0.917),  time:25.481, tt:2624.535\n",
      "Ep:103, loss:0.00001, loss_test:0.01329, lr:5.59e-02, fs:0.84153 (r=0.778,p=0.917),  time:25.491, tt:2651.096\n",
      "Ep:104, loss:0.00001, loss_test:0.01331, lr:5.59e-02, fs:0.84615 (r=0.778,p=0.928),  time:25.501, tt:2677.612\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00001, loss_test:0.01329, lr:5.59e-02, fs:0.84615 (r=0.778,p=0.928),  time:25.505, tt:2703.571\n",
      "Ep:106, loss:0.00001, loss_test:0.01329, lr:5.59e-02, fs:0.84615 (r=0.778,p=0.928),  time:25.523, tt:2730.994\n",
      "Ep:107, loss:0.00001, loss_test:0.01332, lr:5.59e-02, fs:0.84615 (r=0.778,p=0.928),  time:25.523, tt:2756.521\n",
      "Ep:108, loss:0.00001, loss_test:0.01333, lr:5.59e-02, fs:0.84615 (r=0.778,p=0.928),  time:25.526, tt:2782.327\n",
      "Ep:109, loss:0.00001, loss_test:0.01335, lr:5.59e-02, fs:0.84615 (r=0.778,p=0.928),  time:25.517, tt:2806.878\n",
      "Ep:110, loss:0.00001, loss_test:0.01338, lr:5.59e-02, fs:0.84615 (r=0.778,p=0.928),  time:25.516, tt:2832.277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:111, loss:0.00001, loss_test:0.01339, lr:5.59e-02, fs:0.84615 (r=0.778,p=0.928),  time:25.521, tt:2858.405\n",
      "Ep:112, loss:0.00001, loss_test:0.01336, lr:5.59e-02, fs:0.84615 (r=0.778,p=0.928),  time:25.526, tt:2884.436\n",
      "Ep:113, loss:0.00001, loss_test:0.01341, lr:5.59e-02, fs:0.84615 (r=0.778,p=0.928),  time:25.526, tt:2910.015\n",
      "Ep:114, loss:0.00001, loss_test:0.01343, lr:5.59e-02, fs:0.84615 (r=0.778,p=0.928),  time:25.524, tt:2935.315\n",
      "Ep:115, loss:0.00001, loss_test:0.01343, lr:5.59e-02, fs:0.84615 (r=0.778,p=0.928),  time:25.520, tt:2960.353\n",
      "Ep:116, loss:0.00001, loss_test:0.01347, lr:5.54e-02, fs:0.85083 (r=0.778,p=0.939),  time:25.528, tt:2986.720\n",
      "##########Best model found so far##########\n",
      "Ep:117, loss:0.00001, loss_test:0.01350, lr:5.54e-02, fs:0.85083 (r=0.778,p=0.939),  time:25.529, tt:3012.389\n",
      "Ep:118, loss:0.00001, loss_test:0.01351, lr:5.54e-02, fs:0.85556 (r=0.778,p=0.951),  time:25.530, tt:3038.113\n",
      "##########Best model found so far##########\n",
      "Ep:119, loss:0.00001, loss_test:0.01354, lr:5.54e-02, fs:0.85556 (r=0.778,p=0.951),  time:25.531, tt:3063.730\n",
      "Ep:120, loss:0.00001, loss_test:0.01357, lr:5.54e-02, fs:0.85556 (r=0.778,p=0.951),  time:25.528, tt:3088.862\n",
      "Ep:121, loss:0.00001, loss_test:0.01359, lr:5.54e-02, fs:0.85556 (r=0.778,p=0.951),  time:25.535, tt:3115.302\n",
      "Ep:122, loss:0.00001, loss_test:0.01359, lr:5.54e-02, fs:0.85556 (r=0.778,p=0.951),  time:25.542, tt:3141.717\n",
      "Ep:123, loss:0.00001, loss_test:0.01362, lr:5.54e-02, fs:0.85556 (r=0.778,p=0.951),  time:25.541, tt:3167.103\n",
      "Ep:124, loss:0.00001, loss_test:0.01365, lr:5.54e-02, fs:0.85556 (r=0.778,p=0.951),  time:25.544, tt:3193.018\n",
      "Ep:125, loss:0.00001, loss_test:0.01366, lr:5.54e-02, fs:0.85556 (r=0.778,p=0.951),  time:25.551, tt:3219.382\n",
      "Ep:126, loss:0.00001, loss_test:0.01366, lr:5.54e-02, fs:0.85556 (r=0.778,p=0.951),  time:25.557, tt:3245.686\n",
      "Ep:127, loss:0.00001, loss_test:0.01368, lr:5.54e-02, fs:0.86034 (r=0.778,p=0.963),  time:25.563, tt:3272.114\n",
      "##########Best model found so far##########\n",
      "Ep:128, loss:0.00001, loss_test:0.01374, lr:5.54e-02, fs:0.86034 (r=0.778,p=0.963),  time:25.588, tt:3300.794\n",
      "Ep:129, loss:0.00001, loss_test:0.01375, lr:5.54e-02, fs:0.86034 (r=0.778,p=0.963),  time:25.586, tt:3326.238\n",
      "Ep:130, loss:0.00001, loss_test:0.01380, lr:5.54e-02, fs:0.86517 (r=0.778,p=0.975),  time:25.592, tt:3352.537\n",
      "##########Best model found so far##########\n",
      "Ep:131, loss:0.00001, loss_test:0.01381, lr:5.54e-02, fs:0.86517 (r=0.778,p=0.975),  time:25.591, tt:3377.999\n",
      "Ep:132, loss:0.00001, loss_test:0.01385, lr:5.54e-02, fs:0.86517 (r=0.778,p=0.975),  time:25.607, tt:3405.678\n",
      "Ep:133, loss:0.00001, loss_test:0.01391, lr:5.54e-02, fs:0.86517 (r=0.778,p=0.975),  time:25.599, tt:3430.219\n",
      "Ep:134, loss:0.00000, loss_test:0.01394, lr:5.54e-02, fs:0.86517 (r=0.778,p=0.975),  time:25.607, tt:3456.973\n",
      "Ep:135, loss:0.00000, loss_test:0.01397, lr:5.54e-02, fs:0.87006 (r=0.778,p=0.987),  time:25.610, tt:3482.912\n",
      "##########Best model found so far##########\n",
      "Ep:136, loss:0.00000, loss_test:0.01400, lr:5.54e-02, fs:0.87006 (r=0.778,p=0.987),  time:25.600, tt:3507.150\n",
      "Ep:137, loss:0.00000, loss_test:0.01405, lr:5.54e-02, fs:0.87006 (r=0.778,p=0.987),  time:25.583, tt:3530.514\n",
      "Ep:138, loss:0.00000, loss_test:0.01410, lr:5.54e-02, fs:0.87006 (r=0.778,p=0.987),  time:25.589, tt:3556.835\n",
      "Ep:139, loss:0.00000, loss_test:0.01409, lr:5.54e-02, fs:0.87006 (r=0.778,p=0.987),  time:25.588, tt:3582.338\n",
      "Ep:140, loss:0.00000, loss_test:0.01413, lr:5.54e-02, fs:0.87006 (r=0.778,p=0.987),  time:25.590, tt:3608.201\n",
      "Ep:141, loss:0.00000, loss_test:0.01415, lr:5.54e-02, fs:0.87006 (r=0.778,p=0.987),  time:25.584, tt:3632.909\n",
      "Ep:142, loss:0.00000, loss_test:0.01419, lr:5.54e-02, fs:0.87006 (r=0.778,p=0.987),  time:25.579, tt:3657.752\n",
      "Ep:143, loss:0.00000, loss_test:0.01422, lr:5.54e-02, fs:0.87006 (r=0.778,p=0.987),  time:25.575, tt:3682.835\n",
      "Ep:144, loss:0.00000, loss_test:0.01427, lr:5.54e-02, fs:0.87006 (r=0.778,p=0.987),  time:25.575, tt:3708.334\n",
      "Ep:145, loss:0.00000, loss_test:0.01429, lr:5.54e-02, fs:0.87006 (r=0.778,p=0.987),  time:25.569, tt:3733.134\n",
      "Ep:146, loss:0.00000, loss_test:0.01435, lr:5.54e-02, fs:0.87006 (r=0.778,p=0.987),  time:25.572, tt:3759.112\n",
      "Ep:147, loss:0.00000, loss_test:0.01441, lr:5.48e-02, fs:0.87006 (r=0.778,p=0.987),  time:25.576, tt:3785.228\n",
      "Ep:148, loss:0.00000, loss_test:0.01446, lr:5.43e-02, fs:0.87006 (r=0.778,p=0.987),  time:25.579, tt:3811.200\n",
      "Ep:149, loss:0.00000, loss_test:0.01448, lr:5.37e-02, fs:0.87006 (r=0.778,p=0.987),  time:25.579, tt:3836.778\n",
      "Ep:150, loss:0.00000, loss_test:0.01452, lr:5.32e-02, fs:0.87006 (r=0.778,p=0.987),  time:25.577, tt:3862.117\n",
      "Ep:151, loss:0.00000, loss_test:0.01453, lr:5.27e-02, fs:0.87006 (r=0.778,p=0.987),  time:25.588, tt:3889.452\n",
      "Ep:152, loss:0.00000, loss_test:0.01458, lr:5.21e-02, fs:0.87006 (r=0.778,p=0.987),  time:25.592, tt:3915.647\n",
      "Ep:153, loss:0.00000, loss_test:0.01458, lr:5.16e-02, fs:0.87006 (r=0.778,p=0.987),  time:25.601, tt:3942.559\n",
      "Ep:154, loss:0.00000, loss_test:0.01463, lr:5.11e-02, fs:0.87006 (r=0.778,p=0.987),  time:25.629, tt:3972.495\n",
      "Ep:155, loss:0.00000, loss_test:0.01465, lr:5.06e-02, fs:0.87006 (r=0.778,p=0.987),  time:25.636, tt:3999.169\n",
      "Ep:156, loss:0.00000, loss_test:0.01471, lr:5.01e-02, fs:0.87006 (r=0.778,p=0.987),  time:25.638, tt:4025.211\n",
      "Ep:157, loss:0.00000, loss_test:0.01476, lr:4.96e-02, fs:0.87006 (r=0.778,p=0.987),  time:25.634, tt:4050.226\n",
      "Ep:158, loss:0.00000, loss_test:0.01479, lr:4.91e-02, fs:0.87006 (r=0.778,p=0.987),  time:25.633, tt:4075.633\n",
      "Ep:159, loss:0.00000, loss_test:0.01483, lr:4.86e-02, fs:0.87006 (r=0.778,p=0.987),  time:25.634, tt:4101.474\n",
      "Ep:160, loss:0.00000, loss_test:0.01486, lr:4.81e-02, fs:0.87006 (r=0.778,p=0.987),  time:25.635, tt:4127.309\n",
      "Ep:161, loss:0.00000, loss_test:0.01488, lr:4.76e-02, fs:0.87006 (r=0.778,p=0.987),  time:25.628, tt:4151.659\n",
      "Ep:162, loss:0.00000, loss_test:0.01495, lr:4.71e-02, fs:0.87500 (r=0.778,p=1.000),  time:25.630, tt:4177.650\n",
      "##########Best model found so far##########\n",
      "Ep:163, loss:0.00000, loss_test:0.01499, lr:4.71e-02, fs:0.87500 (r=0.778,p=1.000),  time:25.632, tt:4203.709\n",
      "Ep:164, loss:0.00000, loss_test:0.01501, lr:4.71e-02, fs:0.87500 (r=0.778,p=1.000),  time:25.632, tt:4229.360\n",
      "Ep:165, loss:0.00000, loss_test:0.01503, lr:4.71e-02, fs:0.87006 (r=0.778,p=0.987),  time:25.625, tt:4253.792\n",
      "Ep:166, loss:0.00000, loss_test:0.01505, lr:4.71e-02, fs:0.87500 (r=0.778,p=1.000),  time:25.623, tt:4278.994\n",
      "Ep:167, loss:0.00000, loss_test:0.01512, lr:4.71e-02, fs:0.86857 (r=0.768,p=1.000),  time:25.622, tt:4304.454\n",
      "Ep:168, loss:0.00000, loss_test:0.01511, lr:4.71e-02, fs:0.87500 (r=0.778,p=1.000),  time:25.626, tt:4330.729\n",
      "Ep:169, loss:0.00000, loss_test:0.01515, lr:4.71e-02, fs:0.86857 (r=0.768,p=1.000),  time:25.619, tt:4355.299\n",
      "Ep:170, loss:0.00000, loss_test:0.01522, lr:4.71e-02, fs:0.86857 (r=0.768,p=1.000),  time:25.622, tt:4381.350\n",
      "Ep:171, loss:0.00000, loss_test:0.01524, lr:4.71e-02, fs:0.86857 (r=0.768,p=1.000),  time:25.622, tt:4407.069\n",
      "Ep:172, loss:0.00000, loss_test:0.01525, lr:4.71e-02, fs:0.86857 (r=0.768,p=1.000),  time:25.617, tt:4431.751\n",
      "Ep:173, loss:0.00000, loss_test:0.01531, lr:4.71e-02, fs:0.86857 (r=0.768,p=1.000),  time:25.618, tt:4457.510\n",
      "Ep:174, loss:0.00000, loss_test:0.01533, lr:4.67e-02, fs:0.86857 (r=0.768,p=1.000),  time:25.621, tt:4483.598\n",
      "Ep:175, loss:0.00000, loss_test:0.01538, lr:4.62e-02, fs:0.86857 (r=0.768,p=1.000),  time:25.616, tt:4508.346\n",
      "Ep:176, loss:0.00000, loss_test:0.01542, lr:4.57e-02, fs:0.86857 (r=0.768,p=1.000),  time:25.617, tt:4534.212\n",
      "Ep:177, loss:0.00000, loss_test:0.01544, lr:4.53e-02, fs:0.86207 (r=0.758,p=1.000),  time:25.612, tt:4558.930\n",
      "Ep:178, loss:0.00000, loss_test:0.01549, lr:4.48e-02, fs:0.85549 (r=0.747,p=1.000),  time:25.606, tt:4583.425\n",
      "Ep:179, loss:0.00000, loss_test:0.01552, lr:4.44e-02, fs:0.84884 (r=0.737,p=1.000),  time:25.605, tt:4608.939\n",
      "Ep:180, loss:0.00000, loss_test:0.01554, lr:4.39e-02, fs:0.84884 (r=0.737,p=1.000),  time:25.628, tt:4638.747\n",
      "Ep:181, loss:0.00000, loss_test:0.01558, lr:4.35e-02, fs:0.84211 (r=0.727,p=1.000),  time:25.626, tt:4663.967\n",
      "Ep:182, loss:0.00000, loss_test:0.01562, lr:4.31e-02, fs:0.84211 (r=0.727,p=1.000),  time:25.627, tt:4689.713\n",
      "Ep:183, loss:0.00000, loss_test:0.01565, lr:4.26e-02, fs:0.83529 (r=0.717,p=1.000),  time:25.629, tt:4715.672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:184, loss:0.00000, loss_test:0.01567, lr:4.22e-02, fs:0.82143 (r=0.697,p=1.000),  time:25.636, tt:4742.687\n",
      "Ep:185, loss:0.00000, loss_test:0.01570, lr:4.18e-02, fs:0.80723 (r=0.677,p=1.000),  time:25.633, tt:4767.715\n",
      "Ep:186, loss:0.00000, loss_test:0.01573, lr:4.14e-02, fs:0.80000 (r=0.667,p=1.000),  time:25.631, tt:4793.028\n",
      "Ep:187, loss:0.00000, loss_test:0.01578, lr:4.10e-02, fs:0.79268 (r=0.657,p=1.000),  time:25.636, tt:4819.476\n",
      "Ep:188, loss:0.00000, loss_test:0.01580, lr:4.05e-02, fs:0.79268 (r=0.657,p=1.000),  time:25.635, tt:4845.094\n",
      "Ep:189, loss:0.00000, loss_test:0.01583, lr:4.01e-02, fs:0.79268 (r=0.657,p=1.000),  time:25.645, tt:4872.479\n",
      "Ep:190, loss:0.00000, loss_test:0.01586, lr:3.97e-02, fs:0.79268 (r=0.657,p=1.000),  time:25.646, tt:4898.387\n",
      "Ep:191, loss:0.00000, loss_test:0.01588, lr:3.93e-02, fs:0.79268 (r=0.657,p=1.000),  time:25.643, tt:4923.382\n",
      "Ep:192, loss:0.00000, loss_test:0.01591, lr:3.89e-02, fs:0.79268 (r=0.657,p=1.000),  time:25.646, tt:4949.633\n",
      "Ep:193, loss:0.00000, loss_test:0.01593, lr:3.86e-02, fs:0.79268 (r=0.657,p=1.000),  time:25.645, tt:4975.104\n",
      "Ep:194, loss:0.00000, loss_test:0.01597, lr:3.82e-02, fs:0.79268 (r=0.657,p=1.000),  time:25.635, tt:4998.917\n",
      "Ep:195, loss:0.00000, loss_test:0.01599, lr:3.78e-02, fs:0.79268 (r=0.657,p=1.000),  time:25.641, tt:5025.670\n",
      "Ep:196, loss:0.00000, loss_test:0.01603, lr:3.74e-02, fs:0.79268 (r=0.657,p=1.000),  time:25.628, tt:5048.694\n",
      "Ep:197, loss:0.00000, loss_test:0.01606, lr:3.70e-02, fs:0.79268 (r=0.657,p=1.000),  time:25.621, tt:5072.964\n",
      "Ep:198, loss:0.00000, loss_test:0.01607, lr:3.67e-02, fs:0.78528 (r=0.646,p=1.000),  time:25.622, tt:5098.698\n",
      "Ep:199, loss:0.00000, loss_test:0.01610, lr:3.63e-02, fs:0.78528 (r=0.646,p=1.000),  time:25.619, tt:5123.704\n",
      "Ep:200, loss:0.00000, loss_test:0.01615, lr:3.59e-02, fs:0.78528 (r=0.646,p=1.000),  time:25.601, tt:5145.739\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13746, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:26.200, tt:26.200\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.13297, lr:1.00e-02, fs:0.66197 (r=0.949,p=0.508),  time:26.351, tt:52.702\n",
      "Ep:2, loss:0.00025, loss_test:0.12412, lr:1.00e-02, fs:0.68526 (r=0.869,p=0.566),  time:26.001, tt:78.004\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00024, loss_test:0.11823, lr:1.00e-02, fs:0.64840 (r=0.717,p=0.592),  time:26.120, tt:104.480\n",
      "Ep:4, loss:0.00023, loss_test:0.11771, lr:1.00e-02, fs:0.65049 (r=0.677,p=0.626),  time:26.884, tt:134.418\n",
      "Ep:5, loss:0.00023, loss_test:0.11608, lr:1.00e-02, fs:0.68778 (r=0.768,p=0.623),  time:27.095, tt:162.572\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00022, loss_test:0.11620, lr:1.00e-02, fs:0.67797 (r=0.808,p=0.584),  time:27.201, tt:190.410\n",
      "Ep:7, loss:0.00022, loss_test:0.11369, lr:1.00e-02, fs:0.68696 (r=0.798,p=0.603),  time:27.195, tt:217.562\n",
      "Ep:8, loss:0.00021, loss_test:0.10927, lr:1.00e-02, fs:0.69524 (r=0.737,p=0.658),  time:27.147, tt:244.326\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.10824, lr:1.00e-02, fs:0.68020 (r=0.677,p=0.684),  time:27.327, tt:273.275\n",
      "Ep:10, loss:0.00020, loss_test:0.10747, lr:1.00e-02, fs:0.69608 (r=0.717,p=0.676),  time:27.411, tt:301.526\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.10633, lr:1.00e-02, fs:0.72986 (r=0.778,p=0.688),  time:27.522, tt:330.264\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.10419, lr:1.00e-02, fs:0.73934 (r=0.788,p=0.696),  time:27.546, tt:358.101\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.10212, lr:1.00e-02, fs:0.71921 (r=0.737,p=0.702),  time:27.415, tt:383.806\n",
      "Ep:14, loss:0.00018, loss_test:0.10088, lr:1.00e-02, fs:0.73529 (r=0.758,p=0.714),  time:27.396, tt:410.933\n",
      "Ep:15, loss:0.00018, loss_test:0.09946, lr:1.00e-02, fs:0.73267 (r=0.747,p=0.718),  time:27.374, tt:437.987\n",
      "Ep:16, loss:0.00017, loss_test:0.09880, lr:1.00e-02, fs:0.73267 (r=0.747,p=0.718),  time:27.261, tt:463.434\n",
      "Ep:17, loss:0.00017, loss_test:0.09833, lr:1.00e-02, fs:0.71429 (r=0.707,p=0.722),  time:27.301, tt:491.412\n",
      "Ep:18, loss:0.00016, loss_test:0.09706, lr:1.00e-02, fs:0.74257 (r=0.758,p=0.728),  time:27.332, tt:519.316\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.09542, lr:1.00e-02, fs:0.73737 (r=0.737,p=0.737),  time:27.320, tt:546.394\n",
      "Ep:20, loss:0.00015, loss_test:0.09452, lr:1.00e-02, fs:0.74112 (r=0.737,p=0.745),  time:27.316, tt:573.641\n",
      "Ep:21, loss:0.00015, loss_test:0.09326, lr:1.00e-02, fs:0.76768 (r=0.768,p=0.768),  time:27.325, tt:601.153\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00014, loss_test:0.09251, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:27.292, tt:627.725\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.09196, lr:1.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:27.250, tt:653.999\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00013, loss_test:0.09074, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:27.275, tt:681.870\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00013, loss_test:0.08957, lr:1.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:27.282, tt:709.340\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.08910, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:27.315, tt:737.510\n",
      "Ep:27, loss:0.00012, loss_test:0.08777, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:27.334, tt:765.357\n",
      "Ep:28, loss:0.00012, loss_test:0.08724, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:27.250, tt:790.264\n",
      "Ep:29, loss:0.00011, loss_test:0.08661, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:27.296, tt:818.880\n",
      "Ep:30, loss:0.00011, loss_test:0.08539, lr:1.00e-02, fs:0.83744 (r=0.859,p=0.817),  time:27.277, tt:845.584\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00011, loss_test:0.08439, lr:1.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:27.327, tt:874.465\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00010, loss_test:0.08321, lr:1.00e-02, fs:0.85437 (r=0.889,p=0.822),  time:27.309, tt:901.203\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00010, loss_test:0.08248, lr:1.00e-02, fs:0.84729 (r=0.869,p=0.827),  time:27.290, tt:927.865\n",
      "Ep:34, loss:0.00010, loss_test:0.08189, lr:1.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:27.290, tt:955.141\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00010, loss_test:0.08122, lr:1.00e-02, fs:0.85149 (r=0.869,p=0.835),  time:27.286, tt:982.302\n",
      "Ep:36, loss:0.00009, loss_test:0.07990, lr:1.00e-02, fs:0.88263 (r=0.949,p=0.825),  time:27.297, tt:1010.001\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00009, loss_test:0.08077, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:27.308, tt:1037.714\n",
      "Ep:38, loss:0.00009, loss_test:0.07958, lr:1.00e-02, fs:0.88263 (r=0.949,p=0.825),  time:27.293, tt:1064.433\n",
      "Ep:39, loss:0.00008, loss_test:0.07913, lr:1.00e-02, fs:0.87000 (r=0.879,p=0.861),  time:27.284, tt:1091.356\n",
      "Ep:40, loss:0.00008, loss_test:0.07901, lr:1.00e-02, fs:0.88462 (r=0.929,p=0.844),  time:27.289, tt:1118.856\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00008, loss_test:0.07798, lr:1.00e-02, fs:0.88557 (r=0.899,p=0.873),  time:27.296, tt:1146.423\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00008, loss_test:0.07771, lr:1.00e-02, fs:0.88557 (r=0.899,p=0.873),  time:27.300, tt:1173.896\n",
      "Ep:43, loss:0.00008, loss_test:0.07691, lr:1.00e-02, fs:0.89320 (r=0.929,p=0.860),  time:27.310, tt:1201.647\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00007, loss_test:0.07692, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:27.317, tt:1229.284\n",
      "Ep:45, loss:0.00007, loss_test:0.07685, lr:1.00e-02, fs:0.88679 (r=0.949,p=0.832),  time:27.313, tt:1256.383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:46, loss:0.00007, loss_test:0.07741, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:27.347, tt:1285.304\n",
      "Ep:47, loss:0.00007, loss_test:0.07606, lr:1.00e-02, fs:0.88889 (r=0.929,p=0.852),  time:27.357, tt:1313.120\n",
      "Ep:48, loss:0.00007, loss_test:0.07600, lr:1.00e-02, fs:0.88660 (r=0.869,p=0.905),  time:27.354, tt:1340.331\n",
      "Ep:49, loss:0.00006, loss_test:0.07589, lr:1.00e-02, fs:0.89796 (r=0.889,p=0.907),  time:27.340, tt:1367.012\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00006, loss_test:0.07593, lr:1.00e-02, fs:0.89320 (r=0.929,p=0.860),  time:27.358, tt:1395.273\n",
      "Ep:51, loss:0.00006, loss_test:0.07490, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:27.366, tt:1423.052\n",
      "Ep:52, loss:0.00006, loss_test:0.07472, lr:1.00e-02, fs:0.92000 (r=0.929,p=0.911),  time:27.355, tt:1449.796\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00006, loss_test:0.07397, lr:1.00e-02, fs:0.90155 (r=0.879,p=0.926),  time:27.414, tt:1480.375\n",
      "Ep:54, loss:0.00006, loss_test:0.07434, lr:1.00e-02, fs:0.89796 (r=0.889,p=0.907),  time:27.377, tt:1505.721\n",
      "Ep:55, loss:0.00005, loss_test:0.07401, lr:1.00e-02, fs:0.89583 (r=0.869,p=0.925),  time:27.391, tt:1533.906\n",
      "Ep:56, loss:0.00005, loss_test:0.07361, lr:1.00e-02, fs:0.91282 (r=0.899,p=0.927),  time:27.403, tt:1561.950\n",
      "Ep:57, loss:0.00005, loss_test:0.07366, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:27.403, tt:1589.352\n",
      "Ep:58, loss:0.00005, loss_test:0.07289, lr:1.00e-02, fs:0.89583 (r=0.869,p=0.925),  time:27.404, tt:1616.823\n",
      "Ep:59, loss:0.00005, loss_test:0.07334, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:27.418, tt:1645.095\n",
      "Ep:60, loss:0.00005, loss_test:0.07202, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:27.402, tt:1671.530\n",
      "Ep:61, loss:0.00005, loss_test:0.07407, lr:1.00e-02, fs:0.89005 (r=0.859,p=0.924),  time:27.397, tt:1698.637\n",
      "Ep:62, loss:0.00005, loss_test:0.07254, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:27.391, tt:1725.644\n",
      "Ep:63, loss:0.00004, loss_test:0.07250, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:27.380, tt:1752.296\n",
      "Ep:64, loss:0.00004, loss_test:0.07271, lr:9.90e-03, fs:0.86631 (r=0.818,p=0.920),  time:27.383, tt:1779.867\n",
      "Ep:65, loss:0.00004, loss_test:0.07238, lr:9.80e-03, fs:0.79310 (r=0.697,p=0.920),  time:27.410, tt:1809.087\n",
      "Ep:66, loss:0.00004, loss_test:0.07328, lr:9.70e-03, fs:0.84153 (r=0.778,p=0.917),  time:27.414, tt:1836.744\n",
      "Ep:67, loss:0.00004, loss_test:0.07220, lr:9.61e-03, fs:0.81143 (r=0.717,p=0.934),  time:27.431, tt:1865.291\n",
      "Ep:68, loss:0.00004, loss_test:0.07255, lr:9.51e-03, fs:0.82873 (r=0.758,p=0.915),  time:27.433, tt:1892.877\n",
      "Ep:69, loss:0.00004, loss_test:0.07154, lr:9.41e-03, fs:0.82682 (r=0.747,p=0.925),  time:27.427, tt:1919.908\n",
      "Ep:70, loss:0.00004, loss_test:0.07348, lr:9.32e-03, fs:0.72727 (r=0.606,p=0.909),  time:27.402, tt:1945.532\n",
      "Ep:71, loss:0.00004, loss_test:0.07143, lr:9.23e-03, fs:0.84324 (r=0.788,p=0.907),  time:27.385, tt:1971.731\n",
      "Ep:72, loss:0.00004, loss_test:0.07278, lr:9.14e-03, fs:0.75449 (r=0.636,p=0.926),  time:27.385, tt:1999.106\n",
      "Ep:73, loss:0.00003, loss_test:0.07262, lr:9.04e-03, fs:0.75740 (r=0.646,p=0.914),  time:27.395, tt:2027.246\n",
      "Ep:74, loss:0.00003, loss_test:0.07212, lr:8.95e-03, fs:0.78161 (r=0.687,p=0.907),  time:27.394, tt:2054.526\n",
      "Ep:75, loss:0.00003, loss_test:0.07214, lr:8.86e-03, fs:0.75740 (r=0.646,p=0.914),  time:27.388, tt:2081.505\n",
      "Ep:76, loss:0.00003, loss_test:0.07244, lr:8.78e-03, fs:0.77457 (r=0.677,p=0.905),  time:27.379, tt:2108.176\n",
      "Ep:77, loss:0.00003, loss_test:0.07228, lr:8.69e-03, fs:0.76190 (r=0.646,p=0.928),  time:27.373, tt:2135.087\n",
      "Ep:78, loss:0.00003, loss_test:0.07198, lr:8.60e-03, fs:0.76471 (r=0.657,p=0.915),  time:27.389, tt:2163.737\n",
      "Ep:79, loss:0.00003, loss_test:0.07246, lr:8.51e-03, fs:0.76190 (r=0.646,p=0.928),  time:27.392, tt:2191.348\n",
      "Ep:80, loss:0.00003, loss_test:0.07249, lr:8.43e-03, fs:0.76647 (r=0.646,p=0.941),  time:27.383, tt:2217.992\n",
      "Ep:81, loss:0.00003, loss_test:0.07237, lr:8.35e-03, fs:0.75740 (r=0.646,p=0.914),  time:27.361, tt:2243.595\n",
      "Ep:82, loss:0.00003, loss_test:0.07323, lr:8.26e-03, fs:0.70807 (r=0.576,p=0.919),  time:27.355, tt:2270.460\n",
      "Ep:83, loss:0.00003, loss_test:0.07255, lr:8.18e-03, fs:0.75740 (r=0.646,p=0.914),  time:27.360, tt:2298.243\n",
      "Ep:84, loss:0.00003, loss_test:0.07309, lr:8.10e-03, fs:0.73620 (r=0.606,p=0.938),  time:27.370, tt:2326.470\n",
      "Ep:85, loss:0.00003, loss_test:0.07262, lr:8.02e-03, fs:0.74699 (r=0.626,p=0.925),  time:27.370, tt:2353.782\n",
      "Ep:86, loss:0.00003, loss_test:0.07273, lr:7.94e-03, fs:0.74390 (r=0.616,p=0.938),  time:27.378, tt:2381.866\n",
      "Ep:87, loss:0.00003, loss_test:0.07270, lr:7.86e-03, fs:0.74251 (r=0.626,p=0.912),  time:27.380, tt:2409.465\n",
      "Ep:88, loss:0.00003, loss_test:0.07366, lr:7.78e-03, fs:0.72050 (r=0.586,p=0.935),  time:27.381, tt:2436.917\n",
      "Ep:89, loss:0.00003, loss_test:0.07231, lr:7.70e-03, fs:0.75740 (r=0.646,p=0.914),  time:27.375, tt:2463.772\n",
      "Ep:90, loss:0.00003, loss_test:0.07425, lr:7.62e-03, fs:0.70440 (r=0.566,p=0.933),  time:27.373, tt:2490.978\n",
      "Ep:91, loss:0.00003, loss_test:0.07340, lr:7.55e-03, fs:0.73292 (r=0.596,p=0.952),  time:27.385, tt:2519.438\n",
      "Ep:92, loss:0.00002, loss_test:0.07277, lr:7.47e-03, fs:0.73620 (r=0.606,p=0.938),  time:27.403, tt:2548.473\n",
      "Ep:93, loss:0.00002, loss_test:0.07368, lr:7.40e-03, fs:0.72500 (r=0.586,p=0.951),  time:27.382, tt:2573.864\n",
      "Ep:94, loss:0.00002, loss_test:0.07343, lr:7.32e-03, fs:0.70886 (r=0.566,p=0.949),  time:27.379, tt:2600.972\n",
      "Ep:95, loss:0.00002, loss_test:0.07236, lr:7.25e-03, fs:0.73171 (r=0.606,p=0.923),  time:27.357, tt:2626.319\n",
      "Ep:96, loss:0.00002, loss_test:0.07382, lr:7.18e-03, fs:0.70886 (r=0.566,p=0.949),  time:27.363, tt:2654.250\n",
      "Ep:97, loss:0.00002, loss_test:0.07317, lr:7.11e-03, fs:0.72500 (r=0.586,p=0.951),  time:27.369, tt:2682.128\n",
      "Ep:98, loss:0.00002, loss_test:0.07331, lr:7.03e-03, fs:0.71698 (r=0.576,p=0.950),  time:27.368, tt:2709.403\n",
      "Ep:99, loss:0.00002, loss_test:0.07379, lr:6.96e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.379, tt:2737.901\n",
      "Ep:100, loss:0.00002, loss_test:0.07312, lr:6.89e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.384, tt:2765.785\n",
      "Ep:101, loss:0.00002, loss_test:0.07312, lr:6.83e-03, fs:0.71698 (r=0.576,p=0.950),  time:27.389, tt:2793.692\n",
      "Ep:102, loss:0.00002, loss_test:0.07410, lr:6.76e-03, fs:0.72152 (r=0.576,p=0.966),  time:27.398, tt:2821.982\n",
      "Ep:103, loss:0.00002, loss_test:0.07393, lr:6.69e-03, fs:0.72152 (r=0.576,p=0.966),  time:27.395, tt:2849.118\n",
      "Ep:104, loss:0.00002, loss_test:0.07341, lr:6.62e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.376, tt:2874.449\n",
      "Ep:105, loss:0.00002, loss_test:0.07401, lr:6.56e-03, fs:0.72152 (r=0.576,p=0.966),  time:27.366, tt:2900.769\n",
      "Ep:106, loss:0.00002, loss_test:0.07360, lr:6.49e-03, fs:0.72152 (r=0.576,p=0.966),  time:27.353, tt:2926.777\n",
      "Ep:107, loss:0.00002, loss_test:0.07359, lr:6.43e-03, fs:0.72152 (r=0.576,p=0.966),  time:27.354, tt:2954.281\n",
      "Ep:108, loss:0.00002, loss_test:0.07391, lr:6.36e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.351, tt:2981.204\n",
      "Ep:109, loss:0.00002, loss_test:0.07399, lr:6.30e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.345, tt:3007.988\n",
      "Ep:110, loss:0.00002, loss_test:0.07387, lr:6.24e-03, fs:0.72152 (r=0.576,p=0.966),  time:27.358, tt:3036.695\n",
      "Ep:111, loss:0.00002, loss_test:0.07408, lr:6.17e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.361, tt:3064.449\n",
      "Ep:112, loss:0.00002, loss_test:0.07401, lr:6.11e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.372, tt:3093.083\n",
      "Ep:113, loss:0.00002, loss_test:0.07418, lr:6.05e-03, fs:0.72152 (r=0.576,p=0.966),  time:27.376, tt:3120.878\n",
      "Ep:114, loss:0.00002, loss_test:0.07373, lr:5.99e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.377, tt:3148.348\n",
      "Ep:115, loss:0.00002, loss_test:0.07418, lr:5.93e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.374, tt:3175.426\n",
      "Ep:116, loss:0.00002, loss_test:0.07400, lr:5.87e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.363, tt:3201.489\n",
      "Ep:117, loss:0.00002, loss_test:0.07437, lr:5.81e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.345, tt:3226.739\n",
      "Ep:118, loss:0.00002, loss_test:0.07446, lr:5.75e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.344, tt:3253.947\n",
      "Ep:119, loss:0.00002, loss_test:0.07440, lr:5.70e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.335, tt:3280.178\n",
      "Ep:120, loss:0.00002, loss_test:0.07439, lr:5.64e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.331, tt:3307.082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:121, loss:0.00002, loss_test:0.07412, lr:5.58e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.322, tt:3333.321\n",
      "Ep:122, loss:0.00002, loss_test:0.07528, lr:5.53e-03, fs:0.71338 (r=0.566,p=0.966),  time:27.324, tt:3360.843\n",
      "Ep:123, loss:0.00002, loss_test:0.07440, lr:5.47e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.321, tt:3387.802\n",
      "Ep:124, loss:0.00002, loss_test:0.07465, lr:5.42e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.335, tt:3416.908\n",
      "Ep:125, loss:0.00002, loss_test:0.07475, lr:5.36e-03, fs:0.72152 (r=0.576,p=0.966),  time:27.342, tt:3445.035\n",
      "Ep:126, loss:0.00002, loss_test:0.07487, lr:5.31e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.330, tt:3470.894\n",
      "Ep:127, loss:0.00002, loss_test:0.07593, lr:5.26e-03, fs:0.70513 (r=0.556,p=0.965),  time:27.360, tt:3502.051\n",
      "Ep:128, loss:0.00002, loss_test:0.07443, lr:5.20e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.359, tt:3529.357\n",
      "Ep:129, loss:0.00002, loss_test:0.07482, lr:5.15e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.351, tt:3555.568\n",
      "Ep:130, loss:0.00002, loss_test:0.07570, lr:5.10e-03, fs:0.71338 (r=0.566,p=0.966),  time:27.348, tt:3582.603\n",
      "Ep:131, loss:0.00002, loss_test:0.07491, lr:5.05e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.348, tt:3609.918\n",
      "Ep:132, loss:0.00001, loss_test:0.07540, lr:5.00e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.352, tt:3637.792\n",
      "Ep:133, loss:0.00001, loss_test:0.07546, lr:4.95e-03, fs:0.72152 (r=0.576,p=0.966),  time:27.351, tt:3665.016\n",
      "Ep:134, loss:0.00001, loss_test:0.07454, lr:4.90e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.339, tt:3690.812\n",
      "Ep:135, loss:0.00001, loss_test:0.07531, lr:4.85e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.353, tt:3719.992\n",
      "Ep:136, loss:0.00001, loss_test:0.07582, lr:4.80e-03, fs:0.72152 (r=0.576,p=0.966),  time:27.353, tt:3747.365\n",
      "Ep:137, loss:0.00001, loss_test:0.07485, lr:4.75e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.353, tt:3774.749\n",
      "Ep:138, loss:0.00001, loss_test:0.07518, lr:4.71e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.349, tt:3801.568\n",
      "Ep:139, loss:0.00001, loss_test:0.07592, lr:4.66e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.345, tt:3828.239\n",
      "Ep:140, loss:0.00001, loss_test:0.07519, lr:4.61e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.351, tt:3856.429\n",
      "Ep:141, loss:0.00001, loss_test:0.07547, lr:4.57e-03, fs:0.72152 (r=0.576,p=0.966),  time:27.337, tt:3881.875\n",
      "Ep:142, loss:0.00001, loss_test:0.07528, lr:4.52e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.337, tt:3909.194\n",
      "Ep:143, loss:0.00001, loss_test:0.07528, lr:4.48e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.329, tt:3935.440\n",
      "Ep:144, loss:0.00001, loss_test:0.07537, lr:4.43e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.321, tt:3961.603\n",
      "Ep:145, loss:0.00001, loss_test:0.07527, lr:4.39e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.320, tt:3988.762\n",
      "Ep:146, loss:0.00001, loss_test:0.07566, lr:4.34e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.305, tt:4013.788\n",
      "Ep:147, loss:0.00001, loss_test:0.07529, lr:4.30e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.308, tt:4041.655\n",
      "Ep:148, loss:0.00001, loss_test:0.07529, lr:4.26e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.301, tt:4067.790\n",
      "Ep:149, loss:0.00001, loss_test:0.07562, lr:4.21e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.294, tt:4094.165\n",
      "Ep:150, loss:0.00001, loss_test:0.07520, lr:4.17e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.302, tt:4122.676\n",
      "Ep:151, loss:0.00001, loss_test:0.07503, lr:4.13e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.295, tt:4148.839\n",
      "Ep:152, loss:0.00001, loss_test:0.07518, lr:4.09e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.289, tt:4175.212\n",
      "Ep:153, loss:0.00001, loss_test:0.07540, lr:4.05e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.292, tt:4202.963\n",
      "Ep:154, loss:0.00001, loss_test:0.07569, lr:4.01e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.284, tt:4228.988\n",
      "Ep:155, loss:0.00001, loss_test:0.07533, lr:3.97e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.282, tt:4255.968\n",
      "Ep:156, loss:0.00001, loss_test:0.07518, lr:3.93e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.282, tt:4283.247\n",
      "Ep:157, loss:0.00001, loss_test:0.07563, lr:3.89e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.281, tt:4310.379\n",
      "Ep:158, loss:0.00001, loss_test:0.07538, lr:3.85e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.278, tt:4337.219\n",
      "Ep:159, loss:0.00001, loss_test:0.07543, lr:3.81e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.279, tt:4364.580\n",
      "Ep:160, loss:0.00001, loss_test:0.07542, lr:3.77e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.280, tt:4392.085\n",
      "Ep:161, loss:0.00001, loss_test:0.07559, lr:3.73e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.291, tt:4421.133\n",
      "Ep:162, loss:0.00001, loss_test:0.07567, lr:3.70e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.291, tt:4448.425\n",
      "Ep:163, loss:0.00001, loss_test:0.07559, lr:3.66e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.301, tt:4477.366\n",
      "Ep:164, loss:0.00001, loss_test:0.07556, lr:3.62e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.307, tt:4505.613\n",
      "Ep:165, loss:0.00001, loss_test:0.07544, lr:3.59e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.306, tt:4532.753\n",
      "Ep:166, loss:0.00001, loss_test:0.07566, lr:3.55e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.310, tt:4560.716\n",
      "Ep:167, loss:0.00001, loss_test:0.07593, lr:3.52e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.313, tt:4588.607\n",
      "Ep:168, loss:0.00001, loss_test:0.07545, lr:3.48e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.319, tt:4616.930\n",
      "Ep:169, loss:0.00001, loss_test:0.07590, lr:3.45e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.313, tt:4643.129\n",
      "Ep:170, loss:0.00001, loss_test:0.07583, lr:3.41e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.323, tt:4672.257\n",
      "Ep:171, loss:0.00001, loss_test:0.07512, lr:3.38e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.327, tt:4700.236\n",
      "Ep:172, loss:0.00001, loss_test:0.07560, lr:3.34e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.328, tt:4727.752\n",
      "Ep:173, loss:0.00001, loss_test:0.07581, lr:3.31e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.320, tt:4753.605\n",
      "Ep:174, loss:0.00001, loss_test:0.07547, lr:3.28e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.325, tt:4781.955\n",
      "Ep:175, loss:0.00001, loss_test:0.07573, lr:3.24e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.332, tt:4810.478\n",
      "Ep:176, loss:0.00001, loss_test:0.07562, lr:3.21e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.330, tt:4837.447\n",
      "Ep:177, loss:0.00001, loss_test:0.07533, lr:3.18e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.318, tt:4862.612\n",
      "Ep:178, loss:0.00001, loss_test:0.07592, lr:3.15e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.297, tt:4886.223\n",
      "Ep:179, loss:0.00001, loss_test:0.07641, lr:3.12e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.288, tt:4911.834\n",
      "Ep:180, loss:0.00001, loss_test:0.07584, lr:3.09e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.282, tt:4938.029\n",
      "Ep:181, loss:0.00001, loss_test:0.07544, lr:3.05e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.286, tt:4966.125\n",
      "Ep:182, loss:0.00001, loss_test:0.07570, lr:3.02e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.287, tt:4993.439\n",
      "Ep:183, loss:0.00001, loss_test:0.07563, lr:2.99e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.292, tt:5021.746\n",
      "Ep:184, loss:0.00001, loss_test:0.07578, lr:2.96e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.286, tt:5047.996\n",
      "Ep:185, loss:0.00001, loss_test:0.07613, lr:2.93e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.284, tt:5074.873\n",
      "Ep:186, loss:0.00001, loss_test:0.07611, lr:2.90e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.288, tt:5102.912\n",
      "Ep:187, loss:0.00001, loss_test:0.07569, lr:2.88e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.289, tt:5130.303\n",
      "Ep:188, loss:0.00001, loss_test:0.07590, lr:2.85e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.291, tt:5157.949\n",
      "Ep:189, loss:0.00001, loss_test:0.07605, lr:2.82e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.296, tt:5186.160\n",
      "Ep:190, loss:0.00001, loss_test:0.07579, lr:2.79e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.306, tt:5215.504\n",
      "Ep:191, loss:0.00001, loss_test:0.07616, lr:2.76e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.305, tt:5242.600\n",
      "Ep:192, loss:0.00001, loss_test:0.07629, lr:2.73e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.304, tt:5269.647\n",
      "Ep:193, loss:0.00001, loss_test:0.07572, lr:2.71e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.289, tt:5294.110\n",
      "Ep:194, loss:0.00001, loss_test:0.07564, lr:2.68e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.270, tt:5317.725\n",
      "Ep:195, loss:0.00001, loss_test:0.07639, lr:2.65e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.257, tt:5342.430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:196, loss:0.00001, loss_test:0.07631, lr:2.63e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.241, tt:5366.396\n",
      "Ep:197, loss:0.00001, loss_test:0.07587, lr:2.60e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.211, tt:5387.794\n",
      "Ep:198, loss:0.00001, loss_test:0.07601, lr:2.57e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.189, tt:5410.690\n",
      "Ep:199, loss:0.00001, loss_test:0.07601, lr:2.55e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.169, tt:5433.749\n",
      "Ep:200, loss:0.00001, loss_test:0.07568, lr:2.52e-03, fs:0.72956 (r=0.586,p=0.967),  time:27.154, tt:5457.915\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00009, loss_test:0.02217, lr:6.00e-02, fs:0.65428 (r=0.889,p=0.518),  time:31.280, tt:31.280\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02631, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.593, tt:65.186\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02855, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.991, tt:98.972\n",
      "Ep:3, loss:0.00005, loss_test:0.02900, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.875, tt:131.500\n",
      "Ep:4, loss:0.00005, loss_test:0.02843, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.600, tt:163.000\n",
      "Ep:5, loss:0.00005, loss_test:0.02712, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.952, tt:197.711\n",
      "Ep:6, loss:0.00005, loss_test:0.02506, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.454, tt:234.175\n",
      "Ep:7, loss:0.00005, loss_test:0.02290, lr:6.00e-02, fs:0.65753 (r=0.970,p=0.497),  time:33.877, tt:271.020\n",
      "Ep:8, loss:0.00005, loss_test:0.02129, lr:6.00e-02, fs:0.67626 (r=0.949,p=0.525),  time:34.180, tt:307.621\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.02020, lr:6.00e-02, fs:0.67669 (r=0.909,p=0.539),  time:34.316, tt:343.164\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01959, lr:6.00e-02, fs:0.69231 (r=0.909,p=0.559),  time:34.395, tt:378.347\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01936, lr:6.00e-02, fs:0.70189 (r=0.939,p=0.560),  time:34.414, tt:412.963\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01921, lr:6.00e-02, fs:0.69403 (r=0.939,p=0.550),  time:34.555, tt:449.215\n",
      "Ep:13, loss:0.00004, loss_test:0.01889, lr:6.00e-02, fs:0.69925 (r=0.939,p=0.557),  time:34.458, tt:482.419\n",
      "Ep:14, loss:0.00004, loss_test:0.01849, lr:6.00e-02, fs:0.69962 (r=0.929,p=0.561),  time:34.448, tt:516.722\n",
      "Ep:15, loss:0.00004, loss_test:0.01818, lr:6.00e-02, fs:0.69962 (r=0.929,p=0.561),  time:34.440, tt:551.037\n",
      "Ep:16, loss:0.00004, loss_test:0.01791, lr:6.00e-02, fs:0.70498 (r=0.929,p=0.568),  time:34.295, tt:583.012\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.01766, lr:6.00e-02, fs:0.71815 (r=0.939,p=0.581),  time:34.319, tt:617.736\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.01736, lr:6.00e-02, fs:0.73152 (r=0.949,p=0.595),  time:34.303, tt:651.749\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01705, lr:6.00e-02, fs:0.73152 (r=0.949,p=0.595),  time:34.239, tt:684.771\n",
      "Ep:20, loss:0.00003, loss_test:0.01672, lr:6.00e-02, fs:0.74016 (r=0.949,p=0.606),  time:34.205, tt:718.312\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01641, lr:6.00e-02, fs:0.73810 (r=0.939,p=0.608),  time:34.338, tt:755.430\n",
      "Ep:22, loss:0.00003, loss_test:0.01612, lr:6.00e-02, fs:0.74104 (r=0.939,p=0.612),  time:34.270, tt:788.202\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01583, lr:6.00e-02, fs:0.74900 (r=0.949,p=0.618),  time:34.223, tt:821.349\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01555, lr:6.00e-02, fs:0.76305 (r=0.960,p=0.633),  time:34.228, tt:855.692\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01529, lr:6.00e-02, fs:0.77236 (r=0.960,p=0.646),  time:34.242, tt:890.292\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01505, lr:6.00e-02, fs:0.77551 (r=0.960,p=0.651),  time:34.253, tt:924.834\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01481, lr:6.00e-02, fs:0.77049 (r=0.949,p=0.648),  time:34.258, tt:959.214\n",
      "Ep:28, loss:0.00003, loss_test:0.01458, lr:6.00e-02, fs:0.78661 (r=0.949,p=0.671),  time:34.300, tt:994.685\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01435, lr:6.00e-02, fs:0.79325 (r=0.949,p=0.681),  time:34.279, tt:1028.373\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01413, lr:6.00e-02, fs:0.79832 (r=0.960,p=0.683),  time:34.323, tt:1064.010\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01393, lr:6.00e-02, fs:0.80851 (r=0.960,p=0.699),  time:34.305, tt:1097.761\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01372, lr:6.00e-02, fs:0.81702 (r=0.970,p=0.706),  time:34.315, tt:1132.398\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01353, lr:6.00e-02, fs:0.81702 (r=0.970,p=0.706),  time:34.288, tt:1165.791\n",
      "Ep:34, loss:0.00002, loss_test:0.01334, lr:6.00e-02, fs:0.82403 (r=0.970,p=0.716),  time:34.315, tt:1201.042\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01315, lr:6.00e-02, fs:0.82906 (r=0.980,p=0.719),  time:34.306, tt:1235.034\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01295, lr:6.00e-02, fs:0.83621 (r=0.980,p=0.729),  time:34.372, tt:1271.762\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01276, lr:6.00e-02, fs:0.83983 (r=0.980,p=0.735),  time:34.399, tt:1307.149\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01262, lr:6.00e-02, fs:0.83983 (r=0.980,p=0.735),  time:34.420, tt:1342.399\n",
      "Ep:39, loss:0.00002, loss_test:0.01248, lr:6.00e-02, fs:0.84348 (r=0.980,p=0.740),  time:34.458, tt:1378.306\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01233, lr:6.00e-02, fs:0.84348 (r=0.980,p=0.740),  time:34.462, tt:1412.949\n",
      "Ep:41, loss:0.00002, loss_test:0.01221, lr:6.00e-02, fs:0.85965 (r=0.990,p=0.760),  time:34.484, tt:1448.344\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01211, lr:6.00e-02, fs:0.86344 (r=0.990,p=0.766),  time:34.523, tt:1484.502\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01199, lr:6.00e-02, fs:0.86344 (r=0.990,p=0.766),  time:34.560, tt:1520.626\n",
      "Ep:44, loss:0.00002, loss_test:0.01190, lr:6.00e-02, fs:0.86344 (r=0.990,p=0.766),  time:34.579, tt:1556.072\n",
      "Ep:45, loss:0.00002, loss_test:0.01186, lr:6.00e-02, fs:0.86344 (r=0.990,p=0.766),  time:34.621, tt:1592.571\n",
      "Ep:46, loss:0.00002, loss_test:0.01182, lr:6.00e-02, fs:0.86344 (r=0.990,p=0.766),  time:34.627, tt:1627.449\n",
      "Ep:47, loss:0.00002, loss_test:0.01178, lr:6.00e-02, fs:0.86726 (r=0.990,p=0.772),  time:34.637, tt:1662.556\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01176, lr:6.00e-02, fs:0.86726 (r=0.990,p=0.772),  time:34.664, tt:1698.531\n",
      "Ep:49, loss:0.00002, loss_test:0.01170, lr:6.00e-02, fs:0.86344 (r=0.990,p=0.766),  time:34.666, tt:1733.292\n",
      "Ep:50, loss:0.00002, loss_test:0.01165, lr:6.00e-02, fs:0.86726 (r=0.990,p=0.772),  time:34.708, tt:1770.096\n",
      "Ep:51, loss:0.00001, loss_test:0.01158, lr:6.00e-02, fs:0.86344 (r=0.990,p=0.766),  time:34.704, tt:1804.594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:52, loss:0.00001, loss_test:0.01156, lr:6.00e-02, fs:0.86344 (r=0.990,p=0.766),  time:34.716, tt:1839.970\n",
      "Ep:53, loss:0.00001, loss_test:0.01154, lr:6.00e-02, fs:0.86222 (r=0.980,p=0.770),  time:34.735, tt:1875.711\n",
      "Ep:54, loss:0.00001, loss_test:0.01152, lr:6.00e-02, fs:0.86222 (r=0.980,p=0.770),  time:34.736, tt:1910.465\n",
      "Ep:55, loss:0.00001, loss_test:0.01146, lr:6.00e-02, fs:0.86222 (r=0.980,p=0.770),  time:34.772, tt:1947.220\n",
      "Ep:56, loss:0.00001, loss_test:0.01144, lr:6.00e-02, fs:0.86607 (r=0.980,p=0.776),  time:34.784, tt:1982.671\n",
      "Ep:57, loss:0.00001, loss_test:0.01138, lr:6.00e-02, fs:0.86607 (r=0.980,p=0.776),  time:34.810, tt:2018.978\n",
      "Ep:58, loss:0.00001, loss_test:0.01133, lr:6.00e-02, fs:0.86607 (r=0.980,p=0.776),  time:34.830, tt:2054.969\n",
      "Ep:59, loss:0.00001, loss_test:0.01136, lr:5.94e-02, fs:0.86607 (r=0.980,p=0.776),  time:34.837, tt:2090.235\n",
      "Ep:60, loss:0.00001, loss_test:0.01134, lr:5.88e-02, fs:0.86607 (r=0.980,p=0.776),  time:34.850, tt:2125.873\n",
      "Ep:61, loss:0.00001, loss_test:0.01128, lr:5.82e-02, fs:0.86099 (r=0.970,p=0.774),  time:34.883, tt:2162.757\n",
      "Ep:62, loss:0.00001, loss_test:0.01125, lr:5.76e-02, fs:0.85973 (r=0.960,p=0.779),  time:34.893, tt:2198.263\n",
      "Ep:63, loss:0.00001, loss_test:0.01125, lr:5.71e-02, fs:0.86758 (r=0.960,p=0.792),  time:34.898, tt:2233.486\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01122, lr:5.71e-02, fs:0.86364 (r=0.960,p=0.785),  time:34.903, tt:2268.665\n",
      "Ep:65, loss:0.00001, loss_test:0.01120, lr:5.71e-02, fs:0.86758 (r=0.960,p=0.792),  time:34.923, tt:2304.936\n",
      "Ep:66, loss:0.00001, loss_test:0.01115, lr:5.71e-02, fs:0.86758 (r=0.960,p=0.792),  time:34.956, tt:2342.071\n",
      "Ep:67, loss:0.00001, loss_test:0.01110, lr:5.71e-02, fs:0.86758 (r=0.960,p=0.792),  time:34.965, tt:2377.621\n",
      "Ep:68, loss:0.00001, loss_test:0.01115, lr:5.71e-02, fs:0.87156 (r=0.960,p=0.798),  time:34.978, tt:2413.451\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01113, lr:5.71e-02, fs:0.87156 (r=0.960,p=0.798),  time:35.007, tt:2450.495\n",
      "Ep:70, loss:0.00001, loss_test:0.01111, lr:5.71e-02, fs:0.87156 (r=0.960,p=0.798),  time:35.026, tt:2486.847\n",
      "Ep:71, loss:0.00001, loss_test:0.01110, lr:5.71e-02, fs:0.87156 (r=0.960,p=0.798),  time:35.032, tt:2522.323\n",
      "Ep:72, loss:0.00001, loss_test:0.01112, lr:5.71e-02, fs:0.87156 (r=0.960,p=0.798),  time:35.033, tt:2557.423\n",
      "Ep:73, loss:0.00001, loss_test:0.01109, lr:5.71e-02, fs:0.87156 (r=0.960,p=0.798),  time:35.034, tt:2592.489\n",
      "Ep:74, loss:0.00001, loss_test:0.01115, lr:5.71e-02, fs:0.87963 (r=0.960,p=0.812),  time:35.028, tt:2627.132\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00001, loss_test:0.01109, lr:5.71e-02, fs:0.87963 (r=0.960,p=0.812),  time:35.044, tt:2663.346\n",
      "Ep:76, loss:0.00001, loss_test:0.01111, lr:5.71e-02, fs:0.87963 (r=0.960,p=0.812),  time:35.039, tt:2697.985\n",
      "Ep:77, loss:0.00001, loss_test:0.01113, lr:5.71e-02, fs:0.88372 (r=0.960,p=0.819),  time:35.025, tt:2731.954\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.01113, lr:5.71e-02, fs:0.88372 (r=0.960,p=0.819),  time:35.016, tt:2766.285\n",
      "Ep:79, loss:0.00001, loss_test:0.01116, lr:5.71e-02, fs:0.88785 (r=0.960,p=0.826),  time:35.014, tt:2801.125\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.01121, lr:5.71e-02, fs:0.88785 (r=0.960,p=0.826),  time:35.003, tt:2835.276\n",
      "Ep:81, loss:0.00001, loss_test:0.01123, lr:5.71e-02, fs:0.89202 (r=0.960,p=0.833),  time:34.990, tt:2869.155\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.01125, lr:5.71e-02, fs:0.89202 (r=0.960,p=0.833),  time:34.993, tt:2904.378\n",
      "Ep:83, loss:0.00001, loss_test:0.01130, lr:5.71e-02, fs:0.89202 (r=0.960,p=0.833),  time:34.970, tt:2937.493\n",
      "Ep:84, loss:0.00001, loss_test:0.01133, lr:5.71e-02, fs:0.89202 (r=0.960,p=0.833),  time:34.958, tt:2971.431\n",
      "Ep:85, loss:0.00001, loss_test:0.01140, lr:5.71e-02, fs:0.89623 (r=0.960,p=0.841),  time:34.939, tt:3004.746\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00001, loss_test:0.01134, lr:5.71e-02, fs:0.89202 (r=0.960,p=0.833),  time:34.904, tt:3036.605\n",
      "Ep:87, loss:0.00001, loss_test:0.01146, lr:5.71e-02, fs:0.90047 (r=0.960,p=0.848),  time:34.880, tt:3069.477\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00001, loss_test:0.01142, lr:5.71e-02, fs:0.89202 (r=0.960,p=0.833),  time:34.882, tt:3104.531\n",
      "Ep:89, loss:0.00001, loss_test:0.01157, lr:5.71e-02, fs:0.88995 (r=0.939,p=0.845),  time:34.895, tt:3140.554\n",
      "Ep:90, loss:0.00001, loss_test:0.01151, lr:5.71e-02, fs:0.90476 (r=0.960,p=0.856),  time:34.875, tt:3173.608\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00001, loss_test:0.01164, lr:5.71e-02, fs:0.88995 (r=0.939,p=0.845),  time:34.860, tt:3207.153\n",
      "Ep:92, loss:0.00001, loss_test:0.01162, lr:5.71e-02, fs:0.90821 (r=0.949,p=0.870),  time:34.854, tt:3241.466\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00001, loss_test:0.01180, lr:5.71e-02, fs:0.88889 (r=0.929,p=0.852),  time:34.856, tt:3276.426\n",
      "Ep:94, loss:0.00001, loss_test:0.01178, lr:5.71e-02, fs:0.90099 (r=0.919,p=0.883),  time:34.854, tt:3311.152\n",
      "Ep:95, loss:0.00001, loss_test:0.01193, lr:5.71e-02, fs:0.88889 (r=0.929,p=0.852),  time:34.849, tt:3345.483\n",
      "Ep:96, loss:0.00001, loss_test:0.01181, lr:5.71e-02, fs:0.89000 (r=0.899,p=0.881),  time:34.855, tt:3380.981\n",
      "Ep:97, loss:0.00001, loss_test:0.01211, lr:5.71e-02, fs:0.89320 (r=0.929,p=0.860),  time:34.888, tt:3419.001\n",
      "Ep:98, loss:0.00001, loss_test:0.01190, lr:5.71e-02, fs:0.87879 (r=0.879,p=0.879),  time:34.886, tt:3453.750\n",
      "Ep:99, loss:0.00001, loss_test:0.01219, lr:5.71e-02, fs:0.89216 (r=0.919,p=0.867),  time:34.891, tt:3489.061\n",
      "Ep:100, loss:0.00001, loss_test:0.01202, lr:5.71e-02, fs:0.88325 (r=0.879,p=0.888),  time:34.891, tt:3524.004\n",
      "Ep:101, loss:0.00001, loss_test:0.01228, lr:5.71e-02, fs:0.88325 (r=0.879,p=0.888),  time:34.890, tt:3558.752\n",
      "Ep:102, loss:0.00001, loss_test:0.01217, lr:5.71e-02, fs:0.89447 (r=0.899,p=0.890),  time:34.887, tt:3593.323\n",
      "Ep:103, loss:0.00001, loss_test:0.01238, lr:5.71e-02, fs:0.87047 (r=0.848,p=0.894),  time:34.902, tt:3629.798\n",
      "Ep:104, loss:0.00000, loss_test:0.01246, lr:5.65e-02, fs:0.86010 (r=0.838,p=0.883),  time:34.937, tt:3668.366\n",
      "Ep:105, loss:0.00000, loss_test:0.01253, lr:5.59e-02, fs:0.85864 (r=0.828,p=0.891),  time:34.950, tt:3704.689\n",
      "Ep:106, loss:0.00000, loss_test:0.01265, lr:5.54e-02, fs:0.85864 (r=0.828,p=0.891),  time:34.935, tt:3738.023\n",
      "Ep:107, loss:0.00000, loss_test:0.01265, lr:5.48e-02, fs:0.85263 (r=0.818,p=0.890),  time:34.939, tt:3773.441\n",
      "Ep:108, loss:0.00000, loss_test:0.01281, lr:5.43e-02, fs:0.85263 (r=0.818,p=0.890),  time:34.929, tt:3807.297\n",
      "Ep:109, loss:0.00000, loss_test:0.01286, lr:5.37e-02, fs:0.84656 (r=0.808,p=0.889),  time:34.927, tt:3842.008\n",
      "Ep:110, loss:0.00000, loss_test:0.01290, lr:5.32e-02, fs:0.85263 (r=0.818,p=0.890),  time:34.934, tt:3877.624\n",
      "Ep:111, loss:0.00000, loss_test:0.01301, lr:5.27e-02, fs:0.85263 (r=0.818,p=0.890),  time:34.932, tt:3912.347\n",
      "Ep:112, loss:0.00000, loss_test:0.01310, lr:5.21e-02, fs:0.84656 (r=0.808,p=0.889),  time:34.946, tt:3948.914\n",
      "Ep:113, loss:0.00000, loss_test:0.01326, lr:5.16e-02, fs:0.84656 (r=0.808,p=0.889),  time:34.949, tt:3984.132\n",
      "Ep:114, loss:0.00000, loss_test:0.01327, lr:5.11e-02, fs:0.84656 (r=0.808,p=0.889),  time:34.952, tt:4019.531\n",
      "Ep:115, loss:0.00000, loss_test:0.01333, lr:5.06e-02, fs:0.84656 (r=0.808,p=0.889),  time:34.955, tt:4054.762\n",
      "Ep:116, loss:0.00000, loss_test:0.01336, lr:5.01e-02, fs:0.84043 (r=0.798,p=0.888),  time:34.956, tt:4089.825\n",
      "Ep:117, loss:0.00000, loss_test:0.01350, lr:4.96e-02, fs:0.84043 (r=0.798,p=0.888),  time:34.950, tt:4124.143\n",
      "Ep:118, loss:0.00000, loss_test:0.01352, lr:4.91e-02, fs:0.82796 (r=0.778,p=0.885),  time:34.960, tt:4160.278\n",
      "Ep:119, loss:0.00000, loss_test:0.01368, lr:4.86e-02, fs:0.82796 (r=0.778,p=0.885),  time:34.958, tt:4194.905\n",
      "Ep:120, loss:0.00000, loss_test:0.01368, lr:4.81e-02, fs:0.83422 (r=0.788,p=0.886),  time:34.965, tt:4230.709\n",
      "Ep:121, loss:0.00000, loss_test:0.01379, lr:4.76e-02, fs:0.82796 (r=0.778,p=0.885),  time:34.950, tt:4263.931\n",
      "Ep:122, loss:0.00000, loss_test:0.01391, lr:4.71e-02, fs:0.83422 (r=0.788,p=0.886),  time:34.948, tt:4298.603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:123, loss:0.00000, loss_test:0.01388, lr:4.67e-02, fs:0.82796 (r=0.778,p=0.885),  time:34.938, tt:4332.251\n",
      "Ep:124, loss:0.00000, loss_test:0.01398, lr:4.62e-02, fs:0.81522 (r=0.758,p=0.882),  time:34.937, tt:4367.166\n",
      "Ep:125, loss:0.00000, loss_test:0.01407, lr:4.57e-02, fs:0.82162 (r=0.768,p=0.884),  time:34.937, tt:4402.098\n",
      "Ep:126, loss:0.00000, loss_test:0.01406, lr:4.53e-02, fs:0.82796 (r=0.778,p=0.885),  time:34.937, tt:4436.997\n",
      "Ep:127, loss:0.00000, loss_test:0.01425, lr:4.48e-02, fs:0.82162 (r=0.768,p=0.884),  time:34.937, tt:4471.903\n",
      "Ep:128, loss:0.00000, loss_test:0.01425, lr:4.44e-02, fs:0.82796 (r=0.778,p=0.885),  time:34.967, tt:4510.770\n",
      "Ep:129, loss:0.00000, loss_test:0.01438, lr:4.39e-02, fs:0.82162 (r=0.768,p=0.884),  time:34.956, tt:4544.292\n",
      "Ep:130, loss:0.00000, loss_test:0.01437, lr:4.35e-02, fs:0.81522 (r=0.758,p=0.882),  time:34.961, tt:4579.951\n",
      "Ep:131, loss:0.00000, loss_test:0.01450, lr:4.31e-02, fs:0.81522 (r=0.758,p=0.882),  time:34.968, tt:4615.810\n",
      "Ep:132, loss:0.00000, loss_test:0.01457, lr:4.26e-02, fs:0.81522 (r=0.758,p=0.882),  time:34.958, tt:4649.458\n",
      "Ep:133, loss:0.00000, loss_test:0.01463, lr:4.22e-02, fs:0.81522 (r=0.758,p=0.882),  time:34.952, tt:4683.501\n",
      "Ep:134, loss:0.00000, loss_test:0.01473, lr:4.18e-02, fs:0.81522 (r=0.758,p=0.882),  time:34.941, tt:4717.017\n",
      "Ep:135, loss:0.00000, loss_test:0.01474, lr:4.14e-02, fs:0.81522 (r=0.758,p=0.882),  time:34.949, tt:4753.059\n",
      "Ep:136, loss:0.00000, loss_test:0.01484, lr:4.10e-02, fs:0.81522 (r=0.758,p=0.882),  time:34.946, tt:4787.658\n",
      "Ep:137, loss:0.00000, loss_test:0.01488, lr:4.05e-02, fs:0.81522 (r=0.758,p=0.882),  time:34.958, tt:4824.266\n",
      "Ep:138, loss:0.00000, loss_test:0.01493, lr:4.01e-02, fs:0.80663 (r=0.737,p=0.890),  time:34.971, tt:4861.037\n",
      "Ep:139, loss:0.00000, loss_test:0.01497, lr:3.97e-02, fs:0.81967 (r=0.758,p=0.893),  time:34.973, tt:4896.273\n",
      "Ep:140, loss:0.00000, loss_test:0.01499, lr:3.93e-02, fs:0.80663 (r=0.737,p=0.890),  time:34.971, tt:4930.870\n",
      "Ep:141, loss:0.00000, loss_test:0.01512, lr:3.89e-02, fs:0.81319 (r=0.747,p=0.892),  time:34.977, tt:4966.794\n",
      "Ep:142, loss:0.00000, loss_test:0.01509, lr:3.86e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.994, tt:5004.087\n",
      "Ep:143, loss:0.00000, loss_test:0.01525, lr:3.82e-02, fs:0.81319 (r=0.747,p=0.892),  time:35.005, tt:5040.765\n",
      "Ep:144, loss:0.00000, loss_test:0.01520, lr:3.78e-02, fs:0.80663 (r=0.737,p=0.890),  time:35.018, tt:5077.632\n",
      "Ep:145, loss:0.00000, loss_test:0.01535, lr:3.74e-02, fs:0.82222 (r=0.747,p=0.914),  time:35.032, tt:5114.738\n",
      "Ep:146, loss:0.00000, loss_test:0.01535, lr:3.70e-02, fs:0.80000 (r=0.727,p=0.889),  time:35.040, tt:5150.938\n",
      "Ep:147, loss:0.00000, loss_test:0.01541, lr:3.67e-02, fs:0.80899 (r=0.727,p=0.911),  time:35.053, tt:5187.833\n",
      "Ep:148, loss:0.00000, loss_test:0.01543, lr:3.63e-02, fs:0.82222 (r=0.747,p=0.914),  time:35.056, tt:5223.363\n",
      "Ep:149, loss:0.00000, loss_test:0.01546, lr:3.59e-02, fs:0.80899 (r=0.727,p=0.911),  time:35.065, tt:5259.755\n",
      "Ep:150, loss:0.00000, loss_test:0.01557, lr:3.56e-02, fs:0.82222 (r=0.747,p=0.914),  time:35.074, tt:5296.102\n",
      "Ep:151, loss:0.00000, loss_test:0.01554, lr:3.52e-02, fs:0.79775 (r=0.717,p=0.899),  time:35.084, tt:5332.798\n",
      "Ep:152, loss:0.00000, loss_test:0.01565, lr:3.49e-02, fs:0.82222 (r=0.747,p=0.914),  time:35.094, tt:5369.394\n",
      "Ep:153, loss:0.00000, loss_test:0.01563, lr:3.45e-02, fs:0.80226 (r=0.717,p=0.910),  time:35.088, tt:5403.550\n",
      "Ep:154, loss:0.00000, loss_test:0.01577, lr:3.42e-02, fs:0.81564 (r=0.737,p=0.912),  time:35.087, tt:5438.510\n",
      "Ep:155, loss:0.00000, loss_test:0.01572, lr:3.38e-02, fs:0.80226 (r=0.717,p=0.910),  time:35.087, tt:5473.578\n",
      "Ep:156, loss:0.00000, loss_test:0.01580, lr:3.35e-02, fs:0.80682 (r=0.717,p=0.922),  time:35.091, tt:5509.263\n",
      "Ep:157, loss:0.00000, loss_test:0.01582, lr:3.32e-02, fs:0.80682 (r=0.717,p=0.922),  time:35.107, tt:5546.861\n",
      "Ep:158, loss:0.00000, loss_test:0.01587, lr:3.28e-02, fs:0.80682 (r=0.717,p=0.922),  time:35.110, tt:5582.415\n",
      "Ep:159, loss:0.00000, loss_test:0.01595, lr:3.25e-02, fs:0.79310 (r=0.697,p=0.920),  time:35.119, tt:5619.081\n",
      "Ep:160, loss:0.00000, loss_test:0.01588, lr:3.22e-02, fs:0.80682 (r=0.717,p=0.922),  time:35.121, tt:5654.411\n",
      "Ep:161, loss:0.00000, loss_test:0.01606, lr:3.19e-02, fs:0.80000 (r=0.707,p=0.921),  time:35.128, tt:5690.715\n",
      "Ep:162, loss:0.00000, loss_test:0.01596, lr:3.15e-02, fs:0.80682 (r=0.717,p=0.922),  time:35.128, tt:5725.941\n",
      "Ep:163, loss:0.00000, loss_test:0.01612, lr:3.12e-02, fs:0.79310 (r=0.697,p=0.920),  time:35.129, tt:5761.184\n",
      "Ep:164, loss:0.00000, loss_test:0.01610, lr:3.09e-02, fs:0.79310 (r=0.697,p=0.920),  time:35.128, tt:5796.146\n",
      "Ep:165, loss:0.00000, loss_test:0.01617, lr:3.06e-02, fs:0.79310 (r=0.697,p=0.920),  time:35.133, tt:5832.153\n",
      "Ep:166, loss:0.00000, loss_test:0.01616, lr:3.03e-02, fs:0.79310 (r=0.697,p=0.920),  time:35.142, tt:5868.643\n",
      "Ep:167, loss:0.00000, loss_test:0.01622, lr:3.00e-02, fs:0.79310 (r=0.697,p=0.920),  time:35.136, tt:5902.891\n",
      "Ep:168, loss:0.00000, loss_test:0.01625, lr:2.97e-02, fs:0.79310 (r=0.697,p=0.920),  time:35.142, tt:5939.019\n",
      "Ep:169, loss:0.00000, loss_test:0.01625, lr:2.94e-02, fs:0.79310 (r=0.697,p=0.920),  time:35.141, tt:5974.006\n",
      "Ep:170, loss:0.00000, loss_test:0.01635, lr:2.91e-02, fs:0.79310 (r=0.697,p=0.920),  time:35.137, tt:6008.374\n",
      "Ep:171, loss:0.00000, loss_test:0.01625, lr:2.88e-02, fs:0.79310 (r=0.697,p=0.920),  time:35.141, tt:6044.263\n",
      "Ep:172, loss:0.00000, loss_test:0.01647, lr:2.85e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.128, tt:6077.198\n",
      "Ep:173, loss:0.00000, loss_test:0.01636, lr:2.82e-02, fs:0.79310 (r=0.697,p=0.920),  time:35.131, tt:6112.721\n",
      "Ep:174, loss:0.00000, loss_test:0.01646, lr:2.80e-02, fs:0.79310 (r=0.697,p=0.920),  time:35.136, tt:6148.881\n",
      "Ep:175, loss:0.00000, loss_test:0.01646, lr:2.77e-02, fs:0.78613 (r=0.687,p=0.919),  time:35.130, tt:6182.888\n",
      "Ep:176, loss:0.00000, loss_test:0.01648, lr:2.74e-02, fs:0.78613 (r=0.687,p=0.919),  time:35.122, tt:6216.528\n",
      "Ep:177, loss:0.00000, loss_test:0.01653, lr:2.71e-02, fs:0.78613 (r=0.687,p=0.919),  time:35.128, tt:6252.779\n",
      "Ep:178, loss:0.00000, loss_test:0.01653, lr:2.69e-02, fs:0.78613 (r=0.687,p=0.919),  time:35.130, tt:6288.210\n",
      "Ep:179, loss:0.00000, loss_test:0.01660, lr:2.66e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.136, tt:6324.473\n",
      "Ep:180, loss:0.00000, loss_test:0.01658, lr:2.63e-02, fs:0.77907 (r=0.677,p=0.918),  time:35.138, tt:6359.921\n",
      "Ep:181, loss:0.00000, loss_test:0.01666, lr:2.61e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.143, tt:6396.076\n",
      "Ep:182, loss:0.00000, loss_test:0.01666, lr:2.58e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.145, tt:6431.470\n",
      "Ep:183, loss:0.00000, loss_test:0.01669, lr:2.55e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.145, tt:6466.633\n",
      "Ep:184, loss:0.00000, loss_test:0.01669, lr:2.53e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.147, tt:6502.125\n",
      "Ep:185, loss:0.00000, loss_test:0.01676, lr:2.50e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.156, tt:6539.063\n",
      "Ep:186, loss:0.00000, loss_test:0.01674, lr:2.48e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.161, tt:6575.031\n",
      "Ep:187, loss:0.00000, loss_test:0.01684, lr:2.45e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.166, tt:6611.114\n",
      "Ep:188, loss:0.00000, loss_test:0.01683, lr:2.43e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.176, tt:6648.284\n",
      "Ep:189, loss:0.00000, loss_test:0.01681, lr:2.40e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.185, tt:6685.178\n",
      "Ep:190, loss:0.00000, loss_test:0.01693, lr:2.38e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.201, tt:6723.305\n",
      "Ep:191, loss:0.00000, loss_test:0.01684, lr:2.36e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.211, tt:6760.491\n",
      "Ep:192, loss:0.00000, loss_test:0.01690, lr:2.33e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.215, tt:6796.489\n",
      "Ep:193, loss:0.00000, loss_test:0.01695, lr:2.31e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.227, tt:6834.029\n",
      "Ep:194, loss:0.00000, loss_test:0.01691, lr:2.29e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.227, tt:6869.348\n",
      "Ep:195, loss:0.00000, loss_test:0.01700, lr:2.26e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.233, tt:6905.733\n",
      "Ep:196, loss:0.00000, loss_test:0.01700, lr:2.24e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.230, tt:6940.401\n",
      "Ep:197, loss:0.00000, loss_test:0.01701, lr:2.22e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.231, tt:6975.645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:198, loss:0.00000, loss_test:0.01705, lr:2.20e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.233, tt:7011.406\n",
      "Ep:199, loss:0.00000, loss_test:0.01707, lr:2.17e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.229, tt:7045.722\n",
      "Ep:200, loss:0.00000, loss_test:0.01707, lr:2.15e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.215, tt:7078.121\n",
      "Ep:201, loss:0.00000, loss_test:0.01709, lr:2.13e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.208, tt:7112.108\n",
      "Ep:202, loss:0.00000, loss_test:0.01713, lr:2.11e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.190, tt:7143.576\n",
      "Ep:203, loss:0.00000, loss_test:0.01712, lr:2.09e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.190, tt:7178.739\n",
      "Ep:204, loss:0.00000, loss_test:0.01713, lr:2.07e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.181, tt:7212.063\n",
      "Ep:205, loss:0.00000, loss_test:0.01718, lr:2.05e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.172, tt:7245.507\n",
      "Ep:206, loss:0.00000, loss_test:0.01723, lr:2.03e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.157, tt:7277.598\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14288, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.948, tt:36.948\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14091, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.856, tt:71.712\n",
      "Ep:2, loss:0.00027, loss_test:0.13731, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:35.793, tt:107.380\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.13182, lr:1.00e-02, fs:0.67845 (r=0.970,p=0.522),  time:35.751, tt:143.005\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12542, lr:1.00e-02, fs:0.66917 (r=0.899,p=0.533),  time:35.997, tt:179.986\n",
      "Ep:5, loss:0.00025, loss_test:0.12082, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:36.252, tt:217.513\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.11708, lr:1.00e-02, fs:0.69106 (r=0.859,p=0.578),  time:36.088, tt:252.613\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.11416, lr:1.00e-02, fs:0.70161 (r=0.879,p=0.584),  time:36.297, tt:290.375\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11184, lr:1.00e-02, fs:0.70400 (r=0.889,p=0.583),  time:36.409, tt:327.685\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.10897, lr:1.00e-02, fs:0.71020 (r=0.879,p=0.596),  time:36.500, tt:365.001\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.10596, lr:1.00e-02, fs:0.70940 (r=0.838,p=0.615),  time:36.584, tt:402.424\n",
      "Ep:11, loss:0.00021, loss_test:0.10355, lr:1.00e-02, fs:0.72174 (r=0.838,p=0.634),  time:36.771, tt:441.252\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.10058, lr:1.00e-02, fs:0.74459 (r=0.869,p=0.652),  time:36.759, tt:477.871\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.09740, lr:1.00e-02, fs:0.75109 (r=0.869,p=0.662),  time:36.833, tt:515.656\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.09574, lr:1.00e-02, fs:0.74667 (r=0.848,p=0.667),  time:36.810, tt:552.146\n",
      "Ep:15, loss:0.00019, loss_test:0.09403, lr:1.00e-02, fs:0.76106 (r=0.869,p=0.677),  time:36.872, tt:589.953\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.09225, lr:1.00e-02, fs:0.76233 (r=0.859,p=0.685),  time:36.866, tt:626.717\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.09119, lr:1.00e-02, fs:0.78140 (r=0.848,p=0.724),  time:36.922, tt:664.604\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.09071, lr:1.00e-02, fs:0.78140 (r=0.848,p=0.724),  time:37.014, tt:703.265\n",
      "Ep:19, loss:0.00017, loss_test:0.08975, lr:1.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:37.047, tt:740.945\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.08870, lr:1.00e-02, fs:0.78505 (r=0.848,p=0.730),  time:37.023, tt:777.486\n",
      "Ep:21, loss:0.00016, loss_test:0.08794, lr:1.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:37.011, tt:814.246\n",
      "Ep:22, loss:0.00015, loss_test:0.08714, lr:1.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:36.975, tt:850.420\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.08632, lr:1.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:37.046, tt:889.098\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.08519, lr:1.00e-02, fs:0.80930 (r=0.879,p=0.750),  time:37.065, tt:926.629\n",
      "Ep:25, loss:0.00014, loss_test:0.08407, lr:1.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:37.009, tt:962.233\n",
      "Ep:26, loss:0.00014, loss_test:0.08360, lr:1.00e-02, fs:0.81690 (r=0.879,p=0.763),  time:37.033, tt:999.900\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.08225, lr:1.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:36.976, tt:1035.325\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.08116, lr:1.00e-02, fs:0.83412 (r=0.889,p=0.786),  time:36.992, tt:1072.776\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00012, loss_test:0.08051, lr:1.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:37.007, tt:1110.209\n",
      "Ep:30, loss:0.00012, loss_test:0.07954, lr:1.00e-02, fs:0.84112 (r=0.909,p=0.783),  time:37.056, tt:1148.746\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00011, loss_test:0.07880, lr:1.00e-02, fs:0.84112 (r=0.909,p=0.783),  time:37.078, tt:1186.484\n",
      "Ep:32, loss:0.00011, loss_test:0.07784, lr:1.00e-02, fs:0.84906 (r=0.909,p=0.796),  time:37.076, tt:1223.503\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00011, loss_test:0.07728, lr:1.00e-02, fs:0.85845 (r=0.949,p=0.783),  time:37.065, tt:1260.222\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.07668, lr:1.00e-02, fs:0.84360 (r=0.899,p=0.795),  time:37.050, tt:1296.755\n",
      "Ep:35, loss:0.00010, loss_test:0.07530, lr:1.00e-02, fs:0.85446 (r=0.919,p=0.798),  time:37.028, tt:1332.997\n",
      "Ep:36, loss:0.00010, loss_test:0.07489, lr:1.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:36.998, tt:1368.932\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00009, loss_test:0.07377, lr:1.00e-02, fs:0.87037 (r=0.949,p=0.803),  time:36.996, tt:1405.832\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.07261, lr:1.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:36.960, tt:1441.431\n",
      "Ep:39, loss:0.00009, loss_test:0.07174, lr:1.00e-02, fs:0.87850 (r=0.949,p=0.817),  time:36.970, tt:1478.789\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00009, loss_test:0.07340, lr:1.00e-02, fs:0.86758 (r=0.960,p=0.792),  time:36.969, tt:1515.714\n",
      "Ep:41, loss:0.00008, loss_test:0.07015, lr:1.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:36.980, tt:1553.177\n",
      "Ep:42, loss:0.00008, loss_test:0.06984, lr:1.00e-02, fs:0.87736 (r=0.939,p=0.823),  time:37.003, tt:1591.148\n",
      "Ep:43, loss:0.00008, loss_test:0.07097, lr:1.00e-02, fs:0.87671 (r=0.970,p=0.800),  time:37.020, tt:1628.884\n",
      "Ep:44, loss:0.00008, loss_test:0.06924, lr:1.00e-02, fs:0.88152 (r=0.939,p=0.830),  time:37.083, tt:1668.748\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00008, loss_test:0.06879, lr:1.00e-02, fs:0.88479 (r=0.970,p=0.814),  time:37.084, tt:1705.854\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00008, loss_test:0.06777, lr:1.00e-02, fs:0.88571 (r=0.939,p=0.838),  time:37.085, tt:1743.000\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00007, loss_test:0.06566, lr:1.00e-02, fs:0.89302 (r=0.970,p=0.828),  time:37.057, tt:1778.721\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00007, loss_test:0.06679, lr:1.00e-02, fs:0.90141 (r=0.970,p=0.842),  time:37.039, tt:1814.897\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00006, loss_test:0.06357, lr:1.00e-02, fs:0.91163 (r=0.990,p=0.845),  time:37.031, tt:1851.574\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:50, loss:0.00006, loss_test:0.06565, lr:1.00e-02, fs:0.90141 (r=0.970,p=0.842),  time:36.994, tt:1886.714\n",
      "Ep:51, loss:0.00006, loss_test:0.06226, lr:1.00e-02, fs:0.89524 (r=0.949,p=0.847),  time:36.968, tt:1922.325\n",
      "Ep:52, loss:0.00006, loss_test:0.06412, lr:1.00e-02, fs:0.90233 (r=0.980,p=0.836),  time:36.964, tt:1959.101\n",
      "Ep:53, loss:0.00006, loss_test:0.06185, lr:1.00e-02, fs:0.89100 (r=0.949,p=0.839),  time:36.963, tt:1996.004\n",
      "Ep:54, loss:0.00006, loss_test:0.06050, lr:1.00e-02, fs:0.91163 (r=0.990,p=0.845),  time:36.970, tt:2033.332\n",
      "Ep:55, loss:0.00005, loss_test:0.06199, lr:1.00e-02, fs:0.92019 (r=0.990,p=0.860),  time:36.936, tt:2068.411\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00005, loss_test:0.05920, lr:1.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:36.884, tt:2102.399\n",
      "Ep:57, loss:0.00005, loss_test:0.06059, lr:1.00e-02, fs:0.92891 (r=0.990,p=0.875),  time:36.884, tt:2139.282\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00005, loss_test:0.05848, lr:1.00e-02, fs:0.90654 (r=0.980,p=0.843),  time:36.848, tt:2174.017\n",
      "Ep:59, loss:0.00005, loss_test:0.05889, lr:1.00e-02, fs:0.91163 (r=0.990,p=0.845),  time:36.848, tt:2210.862\n",
      "Ep:60, loss:0.00005, loss_test:0.05991, lr:1.00e-02, fs:0.91429 (r=0.970,p=0.865),  time:36.875, tt:2249.401\n",
      "Ep:61, loss:0.00004, loss_test:0.05658, lr:1.00e-02, fs:0.91163 (r=0.990,p=0.845),  time:36.851, tt:2284.746\n",
      "Ep:62, loss:0.00004, loss_test:0.05925, lr:1.00e-02, fs:0.91429 (r=0.970,p=0.865),  time:36.841, tt:2321.014\n",
      "Ep:63, loss:0.00004, loss_test:0.05692, lr:1.00e-02, fs:0.90233 (r=0.980,p=0.836),  time:36.821, tt:2356.520\n",
      "Ep:64, loss:0.00004, loss_test:0.05747, lr:1.00e-02, fs:0.92453 (r=0.990,p=0.867),  time:36.817, tt:2393.133\n",
      "Ep:65, loss:0.00004, loss_test:0.05847, lr:1.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:36.808, tt:2429.352\n",
      "Ep:66, loss:0.00004, loss_test:0.05842, lr:1.00e-02, fs:0.93839 (r=1.000,p=0.884),  time:36.817, tt:2466.767\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00005, loss_test:0.06210, lr:1.00e-02, fs:0.91163 (r=0.990,p=0.845),  time:36.809, tt:2503.018\n",
      "Ep:68, loss:0.00005, loss_test:0.05703, lr:1.00e-02, fs:0.91943 (r=0.980,p=0.866),  time:36.807, tt:2539.706\n",
      "Ep:69, loss:0.00004, loss_test:0.05638, lr:1.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:36.814, tt:2576.993\n",
      "Ep:70, loss:0.00004, loss_test:0.06007, lr:1.00e-02, fs:0.90385 (r=0.949,p=0.862),  time:36.819, tt:2614.176\n",
      "Ep:71, loss:0.00004, loss_test:0.05544, lr:1.00e-02, fs:0.92093 (r=1.000,p=0.853),  time:36.814, tt:2650.603\n",
      "Ep:72, loss:0.00004, loss_test:0.05908, lr:1.00e-02, fs:0.91787 (r=0.960,p=0.880),  time:36.832, tt:2688.743\n",
      "Ep:73, loss:0.00004, loss_test:0.05523, lr:1.00e-02, fs:0.92523 (r=1.000,p=0.861),  time:36.808, tt:2723.790\n",
      "Ep:74, loss:0.00004, loss_test:0.05649, lr:1.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:36.783, tt:2758.733\n",
      "Ep:75, loss:0.00004, loss_test:0.05602, lr:1.00e-02, fs:0.93333 (r=0.990,p=0.883),  time:36.778, tt:2795.111\n",
      "Ep:76, loss:0.00004, loss_test:0.05459, lr:1.00e-02, fs:0.91509 (r=0.980,p=0.858),  time:36.745, tt:2829.330\n",
      "Ep:77, loss:0.00004, loss_test:0.05540, lr:1.00e-02, fs:0.92233 (r=0.960,p=0.888),  time:36.730, tt:2864.973\n",
      "Ep:78, loss:0.00003, loss_test:0.05273, lr:9.90e-03, fs:0.92093 (r=1.000,p=0.853),  time:36.701, tt:2899.408\n",
      "Ep:79, loss:0.00003, loss_test:0.05468, lr:9.80e-03, fs:0.90995 (r=0.970,p=0.857),  time:36.705, tt:2936.384\n",
      "Ep:80, loss:0.00003, loss_test:0.05327, lr:9.70e-03, fs:0.92381 (r=0.980,p=0.874),  time:36.687, tt:2971.627\n",
      "Ep:81, loss:0.00003, loss_test:0.05372, lr:9.61e-03, fs:0.92019 (r=0.990,p=0.860),  time:36.687, tt:3008.329\n",
      "Ep:82, loss:0.00003, loss_test:0.05462, lr:9.51e-03, fs:0.93204 (r=0.970,p=0.897),  time:36.658, tt:3042.649\n",
      "Ep:83, loss:0.00003, loss_test:0.05245, lr:9.41e-03, fs:0.91667 (r=1.000,p=0.846),  time:36.626, tt:3076.545\n",
      "Ep:84, loss:0.00003, loss_test:0.05299, lr:9.32e-03, fs:0.91346 (r=0.960,p=0.872),  time:36.609, tt:3111.764\n",
      "Ep:85, loss:0.00003, loss_test:0.05262, lr:9.23e-03, fs:0.93269 (r=0.980,p=0.890),  time:36.618, tt:3149.179\n",
      "Ep:86, loss:0.00003, loss_test:0.05194, lr:9.14e-03, fs:0.92093 (r=1.000,p=0.853),  time:36.618, tt:3185.787\n",
      "Ep:87, loss:0.00003, loss_test:0.05276, lr:9.04e-03, fs:0.91787 (r=0.960,p=0.880),  time:36.631, tt:3223.558\n",
      "Ep:88, loss:0.00003, loss_test:0.05059, lr:8.95e-03, fs:0.94737 (r=1.000,p=0.900),  time:36.631, tt:3260.116\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00002, loss_test:0.05197, lr:8.95e-03, fs:0.93269 (r=0.980,p=0.890),  time:36.675, tt:3300.726\n",
      "Ep:90, loss:0.00002, loss_test:0.05004, lr:8.95e-03, fs:0.95098 (r=0.980,p=0.924),  time:36.655, tt:3335.633\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00002, loss_test:0.05101, lr:8.95e-03, fs:0.94737 (r=1.000,p=0.900),  time:36.672, tt:3373.819\n",
      "Ep:92, loss:0.00002, loss_test:0.05004, lr:8.95e-03, fs:0.95098 (r=0.980,p=0.924),  time:36.679, tt:3411.179\n",
      "Ep:93, loss:0.00002, loss_test:0.05193, lr:8.95e-03, fs:0.94231 (r=0.990,p=0.899),  time:36.682, tt:3448.078\n",
      "Ep:94, loss:0.00002, loss_test:0.04974, lr:8.95e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.704, tt:3486.854\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00002, loss_test:0.04998, lr:8.95e-03, fs:0.96117 (r=1.000,p=0.925),  time:36.707, tt:3523.876\n",
      "Ep:96, loss:0.00002, loss_test:0.05184, lr:8.95e-03, fs:0.93333 (r=0.990,p=0.883),  time:36.711, tt:3560.997\n",
      "Ep:97, loss:0.00002, loss_test:0.04928, lr:8.95e-03, fs:0.96078 (r=0.990,p=0.933),  time:36.725, tt:3599.088\n",
      "Ep:98, loss:0.00002, loss_test:0.05070, lr:8.95e-03, fs:0.95146 (r=0.990,p=0.916),  time:36.733, tt:3636.579\n",
      "Ep:99, loss:0.00002, loss_test:0.04934, lr:8.95e-03, fs:0.96078 (r=0.990,p=0.933),  time:36.742, tt:3674.198\n",
      "Ep:100, loss:0.00002, loss_test:0.04951, lr:8.95e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.745, tt:3711.280\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00002, loss_test:0.04936, lr:8.95e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.760, tt:3749.570\n",
      "Ep:102, loss:0.00002, loss_test:0.04906, lr:8.95e-03, fs:0.96552 (r=0.990,p=0.942),  time:36.759, tt:3786.205\n",
      "Ep:103, loss:0.00002, loss_test:0.04911, lr:8.95e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.775, tt:3824.587\n",
      "Ep:104, loss:0.00002, loss_test:0.04972, lr:8.95e-03, fs:0.97537 (r=1.000,p=0.952),  time:36.783, tt:3862.189\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00002, loss_test:0.04859, lr:8.95e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.770, tt:3897.630\n",
      "Ep:106, loss:0.00002, loss_test:0.05034, lr:8.95e-03, fs:0.97537 (r=1.000,p=0.952),  time:36.762, tt:3933.497\n",
      "Ep:107, loss:0.00002, loss_test:0.04863, lr:8.95e-03, fs:0.96552 (r=0.990,p=0.942),  time:36.766, tt:3970.676\n",
      "Ep:108, loss:0.00002, loss_test:0.04838, lr:8.95e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.776, tt:4008.588\n",
      "Ep:109, loss:0.00002, loss_test:0.05017, lr:8.95e-03, fs:0.97537 (r=1.000,p=0.952),  time:36.771, tt:4044.792\n",
      "Ep:110, loss:0.00002, loss_test:0.04828, lr:8.95e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.765, tt:4080.871\n",
      "Ep:111, loss:0.00002, loss_test:0.05030, lr:8.95e-03, fs:0.97030 (r=0.990,p=0.951),  time:36.742, tt:4115.074\n",
      "Ep:112, loss:0.00002, loss_test:0.05066, lr:8.95e-03, fs:0.96552 (r=0.990,p=0.942),  time:36.726, tt:4150.063\n",
      "Ep:113, loss:0.00002, loss_test:0.04865, lr:8.95e-03, fs:0.96585 (r=1.000,p=0.934),  time:36.730, tt:4187.256\n",
      "Ep:114, loss:0.00002, loss_test:0.05023, lr:8.95e-03, fs:0.97537 (r=1.000,p=0.952),  time:36.728, tt:4223.687\n",
      "Ep:115, loss:0.00002, loss_test:0.04948, lr:8.95e-03, fs:0.98020 (r=1.000,p=0.961),  time:36.719, tt:4259.370\n",
      "##########Best model found so far##########\n",
      "Ep:116, loss:0.00002, loss_test:0.04864, lr:8.95e-03, fs:0.98020 (r=1.000,p=0.961),  time:36.723, tt:4296.569\n",
      "Ep:117, loss:0.00002, loss_test:0.04948, lr:8.95e-03, fs:0.94416 (r=0.939,p=0.949),  time:36.718, tt:4332.675\n",
      "Ep:118, loss:0.00002, loss_test:0.04981, lr:8.95e-03, fs:0.97537 (r=1.000,p=0.952),  time:36.711, tt:4368.551\n",
      "Ep:119, loss:0.00002, loss_test:0.05051, lr:8.95e-03, fs:0.94949 (r=0.949,p=0.949),  time:36.717, tt:4406.062\n",
      "Ep:120, loss:0.00002, loss_test:0.04858, lr:8.95e-03, fs:0.97537 (r=1.000,p=0.952),  time:36.737, tt:4445.121\n",
      "Ep:121, loss:0.00001, loss_test:0.04983, lr:8.95e-03, fs:0.94416 (r=0.939,p=0.949),  time:36.756, tt:4484.193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:122, loss:0.00001, loss_test:0.04890, lr:8.95e-03, fs:0.98020 (r=1.000,p=0.961),  time:36.741, tt:4519.181\n",
      "Ep:123, loss:0.00001, loss_test:0.04889, lr:8.95e-03, fs:0.98020 (r=1.000,p=0.961),  time:36.744, tt:4556.220\n",
      "Ep:124, loss:0.00001, loss_test:0.05084, lr:8.95e-03, fs:0.93878 (r=0.929,p=0.948),  time:36.752, tt:4594.056\n",
      "Ep:125, loss:0.00001, loss_test:0.04931, lr:8.95e-03, fs:0.97059 (r=1.000,p=0.943),  time:36.744, tt:4629.793\n",
      "Ep:126, loss:0.00001, loss_test:0.04961, lr:8.95e-03, fs:0.95522 (r=0.970,p=0.941),  time:36.734, tt:4665.176\n",
      "Ep:127, loss:0.00001, loss_test:0.04916, lr:8.86e-03, fs:0.98020 (r=1.000,p=0.961),  time:36.747, tt:4703.632\n",
      "Ep:128, loss:0.00001, loss_test:0.04783, lr:8.78e-03, fs:0.98020 (r=1.000,p=0.961),  time:36.750, tt:4740.755\n",
      "Ep:129, loss:0.00001, loss_test:0.04984, lr:8.69e-03, fs:0.94416 (r=0.939,p=0.949),  time:36.744, tt:4776.717\n",
      "Ep:130, loss:0.00001, loss_test:0.04943, lr:8.60e-03, fs:0.97537 (r=1.000,p=0.952),  time:36.741, tt:4813.068\n",
      "Ep:131, loss:0.00001, loss_test:0.05073, lr:8.51e-03, fs:0.93878 (r=0.929,p=0.948),  time:36.743, tt:4850.118\n",
      "Ep:132, loss:0.00001, loss_test:0.04976, lr:8.43e-03, fs:0.97537 (r=1.000,p=0.952),  time:36.735, tt:4885.768\n",
      "Ep:133, loss:0.00001, loss_test:0.05069, lr:8.35e-03, fs:0.93878 (r=0.929,p=0.948),  time:36.751, tt:4924.671\n",
      "Ep:134, loss:0.00001, loss_test:0.04907, lr:8.26e-03, fs:0.98020 (r=1.000,p=0.961),  time:36.754, tt:4961.759\n",
      "Ep:135, loss:0.00001, loss_test:0.04854, lr:8.18e-03, fs:0.98020 (r=1.000,p=0.961),  time:36.753, tt:4998.421\n",
      "Ep:136, loss:0.00001, loss_test:0.04920, lr:8.10e-03, fs:0.97000 (r=0.980,p=0.960),  time:36.753, tt:5035.101\n",
      "Ep:137, loss:0.00001, loss_test:0.04951, lr:8.02e-03, fs:0.98507 (r=1.000,p=0.971),  time:36.742, tt:5070.346\n",
      "##########Best model found so far##########\n",
      "Ep:138, loss:0.00001, loss_test:0.05006, lr:8.02e-03, fs:0.93878 (r=0.929,p=0.948),  time:36.741, tt:5107.050\n",
      "Ep:139, loss:0.00001, loss_test:0.04992, lr:8.02e-03, fs:0.98507 (r=1.000,p=0.971),  time:36.739, tt:5143.457\n",
      "Ep:140, loss:0.00001, loss_test:0.04913, lr:8.02e-03, fs:0.93878 (r=0.929,p=0.948),  time:36.744, tt:5180.836\n",
      "Ep:141, loss:0.00001, loss_test:0.04916, lr:8.02e-03, fs:0.98507 (r=1.000,p=0.971),  time:36.743, tt:5217.483\n",
      "Ep:142, loss:0.00001, loss_test:0.04955, lr:8.02e-03, fs:0.98507 (r=1.000,p=0.971),  time:36.752, tt:5255.515\n",
      "Ep:143, loss:0.00001, loss_test:0.04958, lr:8.02e-03, fs:0.93878 (r=0.929,p=0.948),  time:36.734, tt:5289.745\n",
      "Ep:144, loss:0.00001, loss_test:0.04991, lr:8.02e-03, fs:0.98020 (r=1.000,p=0.961),  time:36.734, tt:5326.363\n",
      "Ep:145, loss:0.00001, loss_test:0.04971, lr:8.02e-03, fs:0.94359 (r=0.929,p=0.958),  time:36.730, tt:5362.560\n",
      "Ep:146, loss:0.00001, loss_test:0.04974, lr:8.02e-03, fs:0.98507 (r=1.000,p=0.971),  time:36.719, tt:5397.728\n",
      "Ep:147, loss:0.00001, loss_test:0.05082, lr:8.02e-03, fs:0.93878 (r=0.929,p=0.948),  time:36.708, tt:5432.811\n",
      "Ep:148, loss:0.00001, loss_test:0.04934, lr:8.02e-03, fs:0.98507 (r=1.000,p=0.971),  time:36.711, tt:5469.910\n",
      "Ep:149, loss:0.00001, loss_test:0.05009, lr:7.94e-03, fs:0.93878 (r=0.929,p=0.948),  time:36.727, tt:5508.990\n",
      "Ep:150, loss:0.00001, loss_test:0.04961, lr:7.86e-03, fs:0.98507 (r=1.000,p=0.971),  time:36.723, tt:5545.246\n",
      "Ep:151, loss:0.00001, loss_test:0.04999, lr:7.78e-03, fs:0.94845 (r=0.929,p=0.968),  time:36.729, tt:5582.861\n",
      "Ep:152, loss:0.00001, loss_test:0.04971, lr:7.70e-03, fs:0.98507 (r=1.000,p=0.971),  time:36.727, tt:5619.256\n",
      "Ep:153, loss:0.00001, loss_test:0.04908, lr:7.62e-03, fs:0.97487 (r=0.980,p=0.970),  time:36.728, tt:5656.100\n",
      "Ep:154, loss:0.00001, loss_test:0.05026, lr:7.55e-03, fs:0.94359 (r=0.929,p=0.958),  time:36.727, tt:5692.636\n",
      "Ep:155, loss:0.00001, loss_test:0.04985, lr:7.47e-03, fs:0.98507 (r=1.000,p=0.971),  time:36.727, tt:5729.356\n",
      "Ep:156, loss:0.00001, loss_test:0.05017, lr:7.40e-03, fs:0.94359 (r=0.929,p=0.958),  time:36.731, tt:5766.772\n",
      "Ep:157, loss:0.00001, loss_test:0.05067, lr:7.32e-03, fs:0.98507 (r=1.000,p=0.971),  time:36.733, tt:5803.808\n",
      "Ep:158, loss:0.00001, loss_test:0.05008, lr:7.25e-03, fs:0.94359 (r=0.929,p=0.958),  time:36.723, tt:5838.910\n",
      "Ep:159, loss:0.00001, loss_test:0.04997, lr:7.18e-03, fs:0.97487 (r=0.980,p=0.970),  time:36.722, tt:5875.558\n",
      "Ep:160, loss:0.00001, loss_test:0.05075, lr:7.11e-03, fs:0.94359 (r=0.929,p=0.958),  time:36.714, tt:5910.889\n",
      "Ep:161, loss:0.00001, loss_test:0.05000, lr:7.03e-03, fs:0.94845 (r=0.929,p=0.968),  time:36.732, tt:5950.581\n",
      "Ep:162, loss:0.00001, loss_test:0.04954, lr:6.96e-03, fs:0.94359 (r=0.929,p=0.958),  time:36.735, tt:5987.876\n",
      "Ep:163, loss:0.00001, loss_test:0.05036, lr:6.89e-03, fs:0.94359 (r=0.929,p=0.958),  time:36.738, tt:6025.108\n",
      "Ep:164, loss:0.00001, loss_test:0.04981, lr:6.83e-03, fs:0.95918 (r=0.949,p=0.969),  time:36.744, tt:6062.715\n",
      "Ep:165, loss:0.00001, loss_test:0.04979, lr:6.76e-03, fs:0.94359 (r=0.929,p=0.958),  time:36.753, tt:6100.968\n",
      "Ep:166, loss:0.00001, loss_test:0.05027, lr:6.69e-03, fs:0.98507 (r=1.000,p=0.971),  time:36.755, tt:6138.123\n",
      "Ep:167, loss:0.00001, loss_test:0.05062, lr:6.62e-03, fs:0.94359 (r=0.929,p=0.958),  time:36.760, tt:6175.618\n",
      "Ep:168, loss:0.00001, loss_test:0.04993, lr:6.56e-03, fs:0.98507 (r=1.000,p=0.971),  time:36.764, tt:6213.082\n",
      "Ep:169, loss:0.00001, loss_test:0.05065, lr:6.49e-03, fs:0.94359 (r=0.929,p=0.958),  time:36.765, tt:6250.093\n",
      "Ep:170, loss:0.00001, loss_test:0.04976, lr:6.43e-03, fs:0.96447 (r=0.960,p=0.969),  time:36.765, tt:6286.883\n",
      "Ep:171, loss:0.00001, loss_test:0.04987, lr:6.36e-03, fs:0.94845 (r=0.929,p=0.968),  time:36.762, tt:6322.979\n",
      "Ep:172, loss:0.00001, loss_test:0.04967, lr:6.30e-03, fs:0.94845 (r=0.929,p=0.968),  time:36.768, tt:6360.814\n",
      "Ep:173, loss:0.00001, loss_test:0.04955, lr:6.24e-03, fs:0.94359 (r=0.929,p=0.958),  time:36.775, tt:6398.878\n",
      "Ep:174, loss:0.00001, loss_test:0.05061, lr:6.17e-03, fs:0.95918 (r=0.949,p=0.969),  time:36.772, tt:6435.181\n",
      "Ep:175, loss:0.00001, loss_test:0.04962, lr:6.11e-03, fs:0.94845 (r=0.929,p=0.968),  time:36.778, tt:6472.898\n",
      "Ep:176, loss:0.00001, loss_test:0.04961, lr:6.05e-03, fs:0.96970 (r=0.970,p=0.970),  time:36.787, tt:6511.290\n",
      "Ep:177, loss:0.00001, loss_test:0.05000, lr:5.99e-03, fs:0.94359 (r=0.929,p=0.958),  time:36.782, tt:6547.200\n",
      "Ep:178, loss:0.00001, loss_test:0.04968, lr:5.93e-03, fs:0.98507 (r=1.000,p=0.971),  time:36.781, tt:6583.760\n",
      "Ep:179, loss:0.00001, loss_test:0.04989, lr:5.87e-03, fs:0.94359 (r=0.929,p=0.958),  time:36.781, tt:6620.520\n",
      "Ep:180, loss:0.00001, loss_test:0.05021, lr:5.81e-03, fs:0.98507 (r=1.000,p=0.971),  time:36.786, tt:6658.324\n",
      "Ep:181, loss:0.00001, loss_test:0.05035, lr:5.75e-03, fs:0.94359 (r=0.929,p=0.958),  time:36.786, tt:6695.079\n",
      "Ep:182, loss:0.00001, loss_test:0.04974, lr:5.70e-03, fs:0.98507 (r=1.000,p=0.971),  time:36.792, tt:6733.026\n",
      "Ep:183, loss:0.00001, loss_test:0.05039, lr:5.64e-03, fs:0.94359 (r=0.929,p=0.958),  time:36.796, tt:6770.505\n",
      "Ep:184, loss:0.00001, loss_test:0.04966, lr:5.58e-03, fs:0.94845 (r=0.929,p=0.968),  time:36.803, tt:6808.488\n",
      "Ep:185, loss:0.00001, loss_test:0.05011, lr:5.53e-03, fs:0.94845 (r=0.929,p=0.968),  time:36.800, tt:6844.850\n",
      "Ep:186, loss:0.00001, loss_test:0.04986, lr:5.47e-03, fs:0.94845 (r=0.929,p=0.968),  time:36.794, tt:6880.465\n",
      "Ep:187, loss:0.00001, loss_test:0.04978, lr:5.42e-03, fs:0.97487 (r=0.980,p=0.970),  time:36.795, tt:6917.516\n",
      "Ep:188, loss:0.00001, loss_test:0.05034, lr:5.36e-03, fs:0.94359 (r=0.929,p=0.958),  time:36.806, tt:6956.331\n",
      "Ep:189, loss:0.00001, loss_test:0.04988, lr:5.31e-03, fs:0.97487 (r=0.980,p=0.970),  time:36.803, tt:6992.619\n",
      "Ep:190, loss:0.00001, loss_test:0.04986, lr:5.26e-03, fs:0.94845 (r=0.929,p=0.968),  time:36.805, tt:7029.676\n",
      "Ep:191, loss:0.00001, loss_test:0.04999, lr:5.20e-03, fs:0.94845 (r=0.929,p=0.968),  time:36.803, tt:7066.182\n",
      "Ep:192, loss:0.00001, loss_test:0.04987, lr:5.15e-03, fs:0.96447 (r=0.960,p=0.969),  time:36.809, tt:7104.062\n",
      "Ep:193, loss:0.00001, loss_test:0.04952, lr:5.10e-03, fs:0.94845 (r=0.929,p=0.968),  time:36.806, tt:7140.410\n",
      "Ep:194, loss:0.00001, loss_test:0.04979, lr:5.05e-03, fs:0.95918 (r=0.949,p=0.969),  time:36.819, tt:7179.728\n",
      "Ep:195, loss:0.00001, loss_test:0.04983, lr:5.00e-03, fs:0.94845 (r=0.929,p=0.968),  time:36.823, tt:7217.333\n",
      "Ep:196, loss:0.00001, loss_test:0.04943, lr:4.95e-03, fs:0.96447 (r=0.960,p=0.969),  time:36.820, tt:7253.456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:197, loss:0.00001, loss_test:0.04960, lr:4.90e-03, fs:0.95385 (r=0.939,p=0.969),  time:36.819, tt:7290.241\n",
      "Ep:198, loss:0.00001, loss_test:0.04961, lr:4.85e-03, fs:0.95385 (r=0.939,p=0.969),  time:36.820, tt:7327.088\n",
      "Ep:199, loss:0.00001, loss_test:0.04940, lr:4.80e-03, fs:0.95385 (r=0.939,p=0.969),  time:36.805, tt:7360.962\n",
      "Ep:200, loss:0.00001, loss_test:0.04936, lr:4.75e-03, fs:0.96447 (r=0.960,p=0.969),  time:36.794, tt:7395.645\n",
      "Ep:201, loss:0.00001, loss_test:0.04915, lr:4.71e-03, fs:0.94845 (r=0.929,p=0.968),  time:36.787, tt:7430.932\n",
      "Ep:202, loss:0.00001, loss_test:0.04964, lr:4.66e-03, fs:0.98507 (r=1.000,p=0.971),  time:36.758, tt:7461.953\n",
      "Ep:203, loss:0.00001, loss_test:0.04994, lr:4.61e-03, fs:0.94845 (r=0.929,p=0.968),  time:36.730, tt:7492.832\n",
      "Ep:204, loss:0.00001, loss_test:0.04990, lr:4.57e-03, fs:0.97487 (r=0.980,p=0.970),  time:36.694, tt:7522.366\n",
      "Ep:205, loss:0.00001, loss_test:0.04897, lr:4.52e-03, fs:0.94845 (r=0.929,p=0.968),  time:36.664, tt:7552.866\n",
      "Ep:206, loss:0.00001, loss_test:0.04938, lr:4.48e-03, fs:0.98000 (r=0.990,p=0.970),  time:36.655, tt:7587.629\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00009, loss_test:0.02187, lr:6.00e-02, fs:0.65370 (r=0.848,p=0.532),  time:34.984, tt:34.984\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02536, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.411, tt:66.822\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02740, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.899, tt:98.698\n",
      "Ep:3, loss:0.00005, loss_test:0.02742, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.382, tt:133.528\n",
      "Ep:4, loss:0.00005, loss_test:0.02641, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.572, tt:167.859\n",
      "Ep:5, loss:0.00005, loss_test:0.02498, lr:6.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:33.795, tt:202.771\n",
      "Ep:6, loss:0.00005, loss_test:0.02351, lr:6.00e-02, fs:0.63571 (r=0.899,p=0.492),  time:33.950, tt:237.650\n",
      "Ep:7, loss:0.00005, loss_test:0.02230, lr:6.00e-02, fs:0.64945 (r=0.889,p=0.512),  time:34.303, tt:274.421\n",
      "Ep:8, loss:0.00004, loss_test:0.02121, lr:6.00e-02, fs:0.66667 (r=0.889,p=0.533),  time:34.652, tt:311.870\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.02036, lr:6.00e-02, fs:0.64945 (r=0.889,p=0.512),  time:34.810, tt:348.100\n",
      "Ep:10, loss:0.00004, loss_test:0.01965, lr:6.00e-02, fs:0.66909 (r=0.929,p=0.523),  time:34.841, tt:383.248\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01887, lr:6.00e-02, fs:0.67897 (r=0.929,p=0.535),  time:34.826, tt:417.915\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01818, lr:6.00e-02, fs:0.69925 (r=0.939,p=0.557),  time:35.020, tt:455.265\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01779, lr:6.00e-02, fs:0.72656 (r=0.939,p=0.592),  time:35.052, tt:490.725\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01752, lr:6.00e-02, fs:0.72222 (r=0.919,p=0.595),  time:35.095, tt:526.427\n",
      "Ep:15, loss:0.00003, loss_test:0.01736, lr:6.00e-02, fs:0.72157 (r=0.929,p=0.590),  time:35.151, tt:562.422\n",
      "Ep:16, loss:0.00003, loss_test:0.01723, lr:6.00e-02, fs:0.72308 (r=0.949,p=0.584),  time:35.196, tt:598.337\n",
      "Ep:17, loss:0.00003, loss_test:0.01698, lr:6.00e-02, fs:0.72587 (r=0.949,p=0.588),  time:35.294, tt:635.295\n",
      "Ep:18, loss:0.00003, loss_test:0.01679, lr:6.00e-02, fs:0.72800 (r=0.919,p=0.603),  time:35.336, tt:671.379\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01659, lr:6.00e-02, fs:0.73770 (r=0.909,p=0.621),  time:35.326, tt:706.514\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01633, lr:6.00e-02, fs:0.74286 (r=0.919,p=0.623),  time:35.349, tt:742.319\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01607, lr:6.00e-02, fs:0.74494 (r=0.929,p=0.622),  time:35.322, tt:777.080\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01584, lr:6.00e-02, fs:0.76000 (r=0.960,p=0.629),  time:35.345, tt:812.941\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01564, lr:6.00e-02, fs:0.75918 (r=0.939,p=0.637),  time:35.372, tt:848.938\n",
      "Ep:24, loss:0.00003, loss_test:0.01542, lr:6.00e-02, fs:0.76033 (r=0.929,p=0.643),  time:35.343, tt:883.569\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01521, lr:6.00e-02, fs:0.76667 (r=0.929,p=0.652),  time:35.326, tt:918.486\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01500, lr:6.00e-02, fs:0.77311 (r=0.929,p=0.662),  time:35.335, tt:954.049\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01476, lr:6.00e-02, fs:0.77311 (r=0.929,p=0.662),  time:35.380, tt:990.630\n",
      "Ep:28, loss:0.00002, loss_test:0.01451, lr:6.00e-02, fs:0.78151 (r=0.939,p=0.669),  time:35.385, tt:1026.177\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01426, lr:6.00e-02, fs:0.78151 (r=0.939,p=0.669),  time:35.424, tt:1062.732\n",
      "Ep:30, loss:0.00002, loss_test:0.01403, lr:6.00e-02, fs:0.78814 (r=0.939,p=0.679),  time:35.465, tt:1099.423\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01386, lr:6.00e-02, fs:0.79325 (r=0.949,p=0.681),  time:35.427, tt:1133.679\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01374, lr:6.00e-02, fs:0.80000 (r=0.949,p=0.691),  time:35.408, tt:1168.475\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01364, lr:6.00e-02, fs:0.80000 (r=0.949,p=0.691),  time:35.384, tt:1203.059\n",
      "Ep:34, loss:0.00002, loss_test:0.01356, lr:6.00e-02, fs:0.81385 (r=0.949,p=0.712),  time:35.408, tt:1239.294\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01348, lr:6.00e-02, fs:0.81739 (r=0.949,p=0.718),  time:35.398, tt:1274.337\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01335, lr:6.00e-02, fs:0.81385 (r=0.949,p=0.712),  time:35.388, tt:1309.341\n",
      "Ep:37, loss:0.00002, loss_test:0.01328, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:35.391, tt:1344.849\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01323, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:35.387, tt:1380.076\n",
      "Ep:39, loss:0.00002, loss_test:0.01309, lr:6.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:35.378, tt:1415.124\n",
      "Ep:40, loss:0.00002, loss_test:0.01306, lr:6.00e-02, fs:0.81778 (r=0.929,p=0.730),  time:35.362, tt:1449.840\n",
      "Ep:41, loss:0.00002, loss_test:0.01294, lr:6.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:35.347, tt:1484.572\n",
      "Ep:42, loss:0.00002, loss_test:0.01289, lr:6.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:35.334, tt:1519.359\n",
      "Ep:43, loss:0.00002, loss_test:0.01277, lr:6.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:35.322, tt:1554.183\n",
      "Ep:44, loss:0.00002, loss_test:0.01257, lr:6.00e-02, fs:0.84685 (r=0.949,p=0.764),  time:35.346, tt:1590.589\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01253, lr:6.00e-02, fs:0.84685 (r=0.949,p=0.764),  time:35.349, tt:1626.076\n",
      "Ep:46, loss:0.00002, loss_test:0.01241, lr:6.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:35.378, tt:1662.771\n",
      "Ep:47, loss:0.00002, loss_test:0.01230, lr:6.00e-02, fs:0.85455 (r=0.949,p=0.777),  time:35.377, tt:1698.097\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.01229, lr:6.00e-02, fs:0.84404 (r=0.929,p=0.773),  time:35.364, tt:1732.820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:49, loss:0.00001, loss_test:0.01208, lr:6.00e-02, fs:0.84685 (r=0.949,p=0.764),  time:35.353, tt:1767.647\n",
      "Ep:50, loss:0.00001, loss_test:0.01203, lr:6.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:35.368, tt:1803.759\n",
      "Ep:51, loss:0.00001, loss_test:0.01188, lr:6.00e-02, fs:0.84932 (r=0.939,p=0.775),  time:35.374, tt:1839.450\n",
      "Ep:52, loss:0.00001, loss_test:0.01182, lr:6.00e-02, fs:0.85714 (r=0.939,p=0.788),  time:35.361, tt:1874.160\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.01168, lr:6.00e-02, fs:0.85714 (r=0.939,p=0.788),  time:35.365, tt:1909.687\n",
      "Ep:54, loss:0.00001, loss_test:0.01164, lr:6.00e-02, fs:0.85714 (r=0.939,p=0.788),  time:35.384, tt:1946.133\n",
      "Ep:55, loss:0.00001, loss_test:0.01155, lr:6.00e-02, fs:0.85714 (r=0.939,p=0.788),  time:35.387, tt:1981.696\n",
      "Ep:56, loss:0.00001, loss_test:0.01149, lr:6.00e-02, fs:0.85714 (r=0.939,p=0.788),  time:35.415, tt:2018.632\n",
      "Ep:57, loss:0.00001, loss_test:0.01145, lr:6.00e-02, fs:0.85714 (r=0.939,p=0.788),  time:35.428, tt:2054.825\n",
      "Ep:58, loss:0.00001, loss_test:0.01128, lr:6.00e-02, fs:0.85714 (r=0.939,p=0.788),  time:35.437, tt:2090.784\n",
      "Ep:59, loss:0.00001, loss_test:0.01135, lr:6.00e-02, fs:0.86239 (r=0.949,p=0.790),  time:35.438, tt:2126.295\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01122, lr:6.00e-02, fs:0.85714 (r=0.939,p=0.788),  time:35.454, tt:2162.700\n",
      "Ep:61, loss:0.00001, loss_test:0.01129, lr:6.00e-02, fs:0.87442 (r=0.949,p=0.810),  time:35.454, tt:2198.163\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01114, lr:6.00e-02, fs:0.86512 (r=0.939,p=0.802),  time:35.448, tt:2233.213\n",
      "Ep:63, loss:0.00001, loss_test:0.01132, lr:6.00e-02, fs:0.88372 (r=0.960,p=0.819),  time:35.447, tt:2268.616\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01101, lr:6.00e-02, fs:0.87558 (r=0.960,p=0.805),  time:35.444, tt:2303.847\n",
      "Ep:65, loss:0.00001, loss_test:0.01117, lr:6.00e-02, fs:0.88372 (r=0.960,p=0.819),  time:35.457, tt:2340.155\n",
      "Ep:66, loss:0.00001, loss_test:0.01102, lr:6.00e-02, fs:0.87558 (r=0.960,p=0.805),  time:35.476, tt:2376.891\n",
      "Ep:67, loss:0.00001, loss_test:0.01097, lr:6.00e-02, fs:0.88889 (r=0.970,p=0.821),  time:35.486, tt:2413.071\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.01089, lr:6.00e-02, fs:0.87963 (r=0.960,p=0.812),  time:35.488, tt:2448.701\n",
      "Ep:69, loss:0.00001, loss_test:0.01093, lr:6.00e-02, fs:0.87442 (r=0.949,p=0.810),  time:35.491, tt:2484.396\n",
      "Ep:70, loss:0.00001, loss_test:0.01089, lr:6.00e-02, fs:0.87963 (r=0.960,p=0.812),  time:35.501, tt:2520.554\n",
      "Ep:71, loss:0.00001, loss_test:0.01085, lr:6.00e-02, fs:0.88479 (r=0.970,p=0.814),  time:35.487, tt:2555.098\n",
      "Ep:72, loss:0.00001, loss_test:0.01083, lr:6.00e-02, fs:0.88479 (r=0.970,p=0.814),  time:35.483, tt:2590.238\n",
      "Ep:73, loss:0.00001, loss_test:0.01083, lr:6.00e-02, fs:0.87850 (r=0.949,p=0.817),  time:35.501, tt:2627.085\n",
      "Ep:74, loss:0.00001, loss_test:0.01068, lr:6.00e-02, fs:0.88479 (r=0.970,p=0.814),  time:35.503, tt:2662.737\n",
      "Ep:75, loss:0.00001, loss_test:0.01112, lr:6.00e-02, fs:0.89524 (r=0.949,p=0.847),  time:35.512, tt:2698.900\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.01075, lr:6.00e-02, fs:0.87850 (r=0.949,p=0.817),  time:35.508, tt:2734.096\n",
      "Ep:77, loss:0.00001, loss_test:0.01065, lr:6.00e-02, fs:0.87850 (r=0.949,p=0.817),  time:35.514, tt:2770.127\n",
      "Ep:78, loss:0.00001, loss_test:0.01111, lr:6.00e-02, fs:0.89952 (r=0.949,p=0.855),  time:35.502, tt:2804.621\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00001, loss_test:0.01083, lr:6.00e-02, fs:0.87736 (r=0.939,p=0.823),  time:35.461, tt:2836.880\n",
      "Ep:80, loss:0.00001, loss_test:0.01147, lr:6.00e-02, fs:0.90732 (r=0.939,p=0.877),  time:35.430, tt:2869.846\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00001, loss_test:0.01065, lr:6.00e-02, fs:0.89100 (r=0.949,p=0.839),  time:35.444, tt:2906.386\n",
      "Ep:82, loss:0.00001, loss_test:0.01079, lr:6.00e-02, fs:0.89952 (r=0.949,p=0.855),  time:35.443, tt:2941.750\n",
      "Ep:83, loss:0.00001, loss_test:0.01087, lr:6.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:35.445, tt:2977.389\n",
      "Ep:84, loss:0.00001, loss_test:0.01074, lr:6.00e-02, fs:0.89952 (r=0.949,p=0.855),  time:35.448, tt:3013.057\n",
      "Ep:85, loss:0.00001, loss_test:0.01125, lr:6.00e-02, fs:0.90732 (r=0.939,p=0.877),  time:35.424, tt:3046.437\n",
      "Ep:86, loss:0.00001, loss_test:0.01081, lr:6.00e-02, fs:0.89423 (r=0.939,p=0.853),  time:35.410, tt:3080.711\n",
      "Ep:87, loss:0.00001, loss_test:0.01105, lr:6.00e-02, fs:0.90821 (r=0.949,p=0.870),  time:35.426, tt:3117.506\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00001, loss_test:0.01103, lr:6.00e-02, fs:0.91262 (r=0.949,p=0.879),  time:35.436, tt:3153.798\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00001, loss_test:0.01097, lr:6.00e-02, fs:0.91262 (r=0.949,p=0.879),  time:35.447, tt:3190.242\n",
      "Ep:90, loss:0.00001, loss_test:0.01137, lr:6.00e-02, fs:0.90196 (r=0.929,p=0.876),  time:35.432, tt:3224.335\n",
      "Ep:91, loss:0.00001, loss_test:0.01138, lr:6.00e-02, fs:0.90099 (r=0.919,p=0.883),  time:35.435, tt:3260.026\n",
      "Ep:92, loss:0.00001, loss_test:0.01107, lr:6.00e-02, fs:0.90291 (r=0.939,p=0.869),  time:35.444, tt:3296.246\n",
      "Ep:93, loss:0.00001, loss_test:0.01142, lr:6.00e-02, fs:0.90099 (r=0.919,p=0.883),  time:35.440, tt:3331.317\n",
      "Ep:94, loss:0.00001, loss_test:0.01123, lr:6.00e-02, fs:0.91089 (r=0.929,p=0.893),  time:35.443, tt:3367.093\n",
      "Ep:95, loss:0.00001, loss_test:0.01122, lr:6.00e-02, fs:0.89423 (r=0.939,p=0.853),  time:35.434, tt:3401.647\n",
      "Ep:96, loss:0.00001, loss_test:0.01270, lr:6.00e-02, fs:0.84375 (r=0.818,p=0.871),  time:35.427, tt:3436.435\n",
      "Ep:97, loss:0.00001, loss_test:0.01089, lr:6.00e-02, fs:0.89423 (r=0.939,p=0.853),  time:35.421, tt:3471.272\n",
      "Ep:98, loss:0.00001, loss_test:0.01127, lr:6.00e-02, fs:0.89109 (r=0.909,p=0.874),  time:35.419, tt:3506.464\n",
      "Ep:99, loss:0.00001, loss_test:0.01139, lr:6.00e-02, fs:0.89552 (r=0.909,p=0.882),  time:35.421, tt:3542.080\n",
      "Ep:100, loss:0.00001, loss_test:0.01120, lr:5.94e-02, fs:0.90547 (r=0.919,p=0.892),  time:35.435, tt:3578.959\n",
      "Ep:101, loss:0.00001, loss_test:0.01161, lr:5.88e-02, fs:0.89447 (r=0.899,p=0.890),  time:35.422, tt:3613.091\n",
      "Ep:102, loss:0.00001, loss_test:0.01171, lr:5.82e-02, fs:0.87755 (r=0.869,p=0.887),  time:35.419, tt:3648.107\n",
      "Ep:103, loss:0.00001, loss_test:0.01244, lr:5.76e-02, fs:0.83158 (r=0.798,p=0.868),  time:35.428, tt:3684.515\n",
      "Ep:104, loss:0.00001, loss_test:0.01155, lr:5.71e-02, fs:0.89000 (r=0.899,p=0.881),  time:35.428, tt:3719.938\n",
      "Ep:105, loss:0.00001, loss_test:0.01219, lr:5.65e-02, fs:0.86010 (r=0.838,p=0.883),  time:35.421, tt:3754.588\n",
      "Ep:106, loss:0.00001, loss_test:0.01212, lr:5.59e-02, fs:0.85417 (r=0.828,p=0.882),  time:35.433, tt:3791.368\n",
      "Ep:107, loss:0.00001, loss_test:0.01196, lr:5.54e-02, fs:0.85417 (r=0.828,p=0.882),  time:35.419, tt:3825.300\n",
      "Ep:108, loss:0.00001, loss_test:0.01233, lr:5.48e-02, fs:0.84817 (r=0.818,p=0.880),  time:35.424, tt:3861.187\n",
      "Ep:109, loss:0.00001, loss_test:0.01256, lr:5.43e-02, fs:0.84211 (r=0.808,p=0.879),  time:35.412, tt:3895.282\n",
      "Ep:110, loss:0.00000, loss_test:0.01253, lr:5.37e-02, fs:0.84211 (r=0.808,p=0.879),  time:35.406, tt:3930.062\n",
      "Ep:111, loss:0.00000, loss_test:0.01239, lr:5.32e-02, fs:0.83598 (r=0.798,p=0.878),  time:35.406, tt:3965.454\n",
      "Ep:112, loss:0.00000, loss_test:0.01274, lr:5.27e-02, fs:0.83598 (r=0.798,p=0.878),  time:35.407, tt:4001.033\n",
      "Ep:113, loss:0.00000, loss_test:0.01306, lr:5.21e-02, fs:0.81720 (r=0.768,p=0.874),  time:35.412, tt:4036.923\n",
      "Ep:114, loss:0.00000, loss_test:0.01246, lr:5.16e-02, fs:0.82540 (r=0.788,p=0.867),  time:35.415, tt:4072.709\n",
      "Ep:115, loss:0.00000, loss_test:0.01303, lr:5.11e-02, fs:0.82162 (r=0.768,p=0.884),  time:35.412, tt:4107.804\n",
      "Ep:116, loss:0.00000, loss_test:0.01296, lr:5.06e-02, fs:0.84043 (r=0.798,p=0.888),  time:35.420, tt:4144.084\n",
      "Ep:117, loss:0.00000, loss_test:0.01284, lr:5.01e-02, fs:0.82979 (r=0.788,p=0.876),  time:35.420, tt:4179.617\n",
      "Ep:118, loss:0.00000, loss_test:0.01332, lr:4.96e-02, fs:0.82162 (r=0.768,p=0.884),  time:35.435, tt:4216.707\n",
      "Ep:119, loss:0.00000, loss_test:0.01312, lr:4.91e-02, fs:0.82162 (r=0.768,p=0.884),  time:35.430, tt:4251.638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:120, loss:0.00000, loss_test:0.01333, lr:4.86e-02, fs:0.81522 (r=0.758,p=0.882),  time:35.419, tt:4285.705\n",
      "Ep:121, loss:0.00000, loss_test:0.01317, lr:4.81e-02, fs:0.82796 (r=0.778,p=0.885),  time:35.405, tt:4319.448\n",
      "Ep:122, loss:0.00000, loss_test:0.01350, lr:4.76e-02, fs:0.80220 (r=0.737,p=0.880),  time:35.391, tt:4353.096\n",
      "Ep:123, loss:0.00000, loss_test:0.01382, lr:4.71e-02, fs:0.80220 (r=0.737,p=0.880),  time:35.392, tt:4388.588\n",
      "Ep:124, loss:0.00000, loss_test:0.01327, lr:4.67e-02, fs:0.81522 (r=0.758,p=0.882),  time:35.397, tt:4424.573\n",
      "Ep:125, loss:0.00000, loss_test:0.01387, lr:4.62e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.395, tt:4459.737\n",
      "Ep:126, loss:0.00000, loss_test:0.01364, lr:4.57e-02, fs:0.78889 (r=0.717,p=0.877),  time:35.384, tt:4493.734\n",
      "Ep:127, loss:0.00000, loss_test:0.01340, lr:4.53e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.378, tt:4528.372\n",
      "Ep:128, loss:0.00000, loss_test:0.01472, lr:4.48e-02, fs:0.79121 (r=0.727,p=0.867),  time:35.367, tt:4562.293\n",
      "Ep:129, loss:0.00000, loss_test:0.01314, lr:4.44e-02, fs:0.79121 (r=0.727,p=0.867),  time:35.367, tt:4597.692\n",
      "Ep:130, loss:0.00000, loss_test:0.01454, lr:4.39e-02, fs:0.78212 (r=0.707,p=0.875),  time:35.363, tt:4632.519\n",
      "Ep:131, loss:0.00000, loss_test:0.01349, lr:4.35e-02, fs:0.78889 (r=0.717,p=0.877),  time:35.372, tt:4669.123\n",
      "Ep:132, loss:0.00000, loss_test:0.01419, lr:4.31e-02, fs:0.76571 (r=0.677,p=0.882),  time:35.374, tt:4704.781\n",
      "Ep:133, loss:0.00000, loss_test:0.01361, lr:4.26e-02, fs:0.76136 (r=0.677,p=0.870),  time:35.369, tt:4739.508\n",
      "Ep:134, loss:0.00000, loss_test:0.01385, lr:4.22e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.357, tt:4773.187\n",
      "Ep:135, loss:0.00000, loss_test:0.01435, lr:4.18e-02, fs:0.76571 (r=0.677,p=0.882),  time:35.352, tt:4807.853\n",
      "Ep:136, loss:0.00000, loss_test:0.01398, lr:4.14e-02, fs:0.78652 (r=0.707,p=0.886),  time:35.349, tt:4842.859\n",
      "Ep:137, loss:0.00000, loss_test:0.01439, lr:4.10e-02, fs:0.75429 (r=0.667,p=0.868),  time:35.353, tt:4878.690\n",
      "Ep:138, loss:0.00000, loss_test:0.01424, lr:4.05e-02, fs:0.75145 (r=0.657,p=0.878),  time:35.348, tt:4913.324\n",
      "Ep:139, loss:0.00000, loss_test:0.01445, lr:4.01e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.349, tt:4948.929\n",
      "Ep:140, loss:0.00000, loss_test:0.01462, lr:3.97e-02, fs:0.75145 (r=0.657,p=0.878),  time:35.331, tt:4981.700\n",
      "Ep:141, loss:0.00000, loss_test:0.01433, lr:3.93e-02, fs:0.75145 (r=0.657,p=0.878),  time:35.326, tt:5016.279\n",
      "Ep:142, loss:0.00000, loss_test:0.01478, lr:3.89e-02, fs:0.75145 (r=0.657,p=0.878),  time:35.333, tt:5052.598\n",
      "Ep:143, loss:0.00000, loss_test:0.01467, lr:3.86e-02, fs:0.74419 (r=0.646,p=0.877),  time:35.321, tt:5086.165\n",
      "Ep:144, loss:0.00000, loss_test:0.01503, lr:3.82e-02, fs:0.75145 (r=0.657,p=0.878),  time:35.309, tt:5119.764\n",
      "Ep:145, loss:0.00000, loss_test:0.01466, lr:3.78e-02, fs:0.74118 (r=0.636,p=0.887),  time:35.309, tt:5155.056\n",
      "Ep:146, loss:0.00000, loss_test:0.01505, lr:3.74e-02, fs:0.75145 (r=0.657,p=0.878),  time:35.313, tt:5191.071\n",
      "Ep:147, loss:0.00000, loss_test:0.01498, lr:3.70e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.313, tt:5226.294\n",
      "Ep:148, loss:0.00000, loss_test:0.01515, lr:3.67e-02, fs:0.72941 (r=0.626,p=0.873),  time:35.308, tt:5260.846\n",
      "Ep:149, loss:0.00000, loss_test:0.01499, lr:3.63e-02, fs:0.75581 (r=0.657,p=0.890),  time:35.316, tt:5297.428\n",
      "Ep:150, loss:0.00000, loss_test:0.01505, lr:3.59e-02, fs:0.73373 (r=0.626,p=0.886),  time:35.317, tt:5332.809\n",
      "Ep:151, loss:0.00000, loss_test:0.01540, lr:3.56e-02, fs:0.75145 (r=0.657,p=0.878),  time:35.316, tt:5367.963\n",
      "Ep:152, loss:0.00000, loss_test:0.01501, lr:3.52e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.321, tt:5404.166\n",
      "Ep:153, loss:0.00000, loss_test:0.01555, lr:3.49e-02, fs:0.74419 (r=0.646,p=0.877),  time:35.326, tt:5440.205\n",
      "Ep:154, loss:0.00000, loss_test:0.01505, lr:3.45e-02, fs:0.72941 (r=0.626,p=0.873),  time:35.328, tt:5475.860\n",
      "Ep:155, loss:0.00000, loss_test:0.01559, lr:3.42e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.316, tt:5509.327\n",
      "Ep:156, loss:0.00000, loss_test:0.01524, lr:3.38e-02, fs:0.73373 (r=0.626,p=0.886),  time:35.322, tt:5545.613\n",
      "Ep:157, loss:0.00000, loss_test:0.01552, lr:3.35e-02, fs:0.74118 (r=0.636,p=0.887),  time:35.319, tt:5580.425\n",
      "Ep:158, loss:0.00000, loss_test:0.01544, lr:3.32e-02, fs:0.75581 (r=0.657,p=0.890),  time:35.316, tt:5615.239\n",
      "Ep:159, loss:0.00000, loss_test:0.01547, lr:3.28e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.321, tt:5651.323\n",
      "Ep:160, loss:0.00000, loss_test:0.01588, lr:3.25e-02, fs:0.75581 (r=0.657,p=0.890),  time:35.338, tt:5689.374\n",
      "Ep:161, loss:0.00000, loss_test:0.01542, lr:3.22e-02, fs:0.72189 (r=0.616,p=0.871),  time:35.338, tt:5724.756\n",
      "Ep:162, loss:0.00000, loss_test:0.01593, lr:3.19e-02, fs:0.74118 (r=0.636,p=0.887),  time:35.339, tt:5760.300\n",
      "Ep:163, loss:0.00000, loss_test:0.01545, lr:3.15e-02, fs:0.72189 (r=0.616,p=0.871),  time:35.341, tt:5795.855\n",
      "Ep:164, loss:0.00000, loss_test:0.01622, lr:3.12e-02, fs:0.74118 (r=0.636,p=0.887),  time:35.345, tt:5831.881\n",
      "Ep:165, loss:0.00000, loss_test:0.01555, lr:3.09e-02, fs:0.72189 (r=0.616,p=0.871),  time:35.346, tt:5867.440\n",
      "Ep:166, loss:0.00000, loss_test:0.01610, lr:3.06e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.340, tt:5901.855\n",
      "Ep:167, loss:0.00000, loss_test:0.01579, lr:3.03e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.337, tt:5936.671\n",
      "Ep:168, loss:0.00000, loss_test:0.01606, lr:3.00e-02, fs:0.73373 (r=0.626,p=0.886),  time:35.327, tt:5970.249\n",
      "Ep:169, loss:0.00000, loss_test:0.01605, lr:2.97e-02, fs:0.71856 (r=0.606,p=0.882),  time:35.325, tt:6005.208\n",
      "Ep:170, loss:0.00000, loss_test:0.01596, lr:2.94e-02, fs:0.73373 (r=0.626,p=0.886),  time:35.323, tt:6040.262\n",
      "Ep:171, loss:0.00000, loss_test:0.01609, lr:2.91e-02, fs:0.71856 (r=0.606,p=0.882),  time:35.314, tt:6074.008\n",
      "Ep:172, loss:0.00000, loss_test:0.01619, lr:2.88e-02, fs:0.73373 (r=0.626,p=0.886),  time:35.315, tt:6109.471\n",
      "Ep:173, loss:0.00000, loss_test:0.01611, lr:2.85e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.313, tt:6144.466\n",
      "Ep:174, loss:0.00000, loss_test:0.01630, lr:2.82e-02, fs:0.73373 (r=0.626,p=0.886),  time:35.316, tt:6180.288\n",
      "Ep:175, loss:0.00000, loss_test:0.01622, lr:2.80e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.316, tt:6215.623\n",
      "Ep:176, loss:0.00000, loss_test:0.01637, lr:2.77e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.317, tt:6251.041\n",
      "Ep:177, loss:0.00000, loss_test:0.01625, lr:2.74e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.315, tt:6286.101\n",
      "Ep:178, loss:0.00000, loss_test:0.01635, lr:2.71e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.318, tt:6321.912\n",
      "Ep:179, loss:0.00000, loss_test:0.01640, lr:2.69e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.322, tt:6357.873\n",
      "Ep:180, loss:0.00000, loss_test:0.01651, lr:2.66e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.325, tt:6393.789\n",
      "Ep:181, loss:0.00000, loss_test:0.01640, lr:2.63e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.322, tt:6428.648\n",
      "Ep:182, loss:0.00000, loss_test:0.01635, lr:2.61e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.328, tt:6464.987\n",
      "Ep:183, loss:0.00000, loss_test:0.01669, lr:2.58e-02, fs:0.71084 (r=0.596,p=0.881),  time:35.319, tt:6498.786\n",
      "Ep:184, loss:0.00000, loss_test:0.01651, lr:2.55e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.314, tt:6533.023\n",
      "Ep:185, loss:0.00000, loss_test:0.01662, lr:2.53e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.303, tt:6566.386\n",
      "Ep:186, loss:0.00000, loss_test:0.01652, lr:2.50e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.301, tt:6601.374\n",
      "Ep:187, loss:0.00000, loss_test:0.01670, lr:2.48e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.302, tt:6636.766\n",
      "Ep:188, loss:0.00000, loss_test:0.01661, lr:2.45e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.297, tt:6671.177\n",
      "Ep:189, loss:0.00000, loss_test:0.01674, lr:2.43e-02, fs:0.73373 (r=0.626,p=0.886),  time:35.292, tt:6705.532\n",
      "Ep:190, loss:0.00000, loss_test:0.01668, lr:2.40e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.291, tt:6740.651\n",
      "Ep:191, loss:0.00000, loss_test:0.01687, lr:2.38e-02, fs:0.73373 (r=0.626,p=0.886),  time:35.292, tt:6775.991\n",
      "Ep:192, loss:0.00000, loss_test:0.01672, lr:2.36e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.287, tt:6810.430\n",
      "Ep:193, loss:0.00000, loss_test:0.01691, lr:2.33e-02, fs:0.73373 (r=0.626,p=0.886),  time:35.280, tt:6844.377\n",
      "Ep:194, loss:0.00000, loss_test:0.01670, lr:2.31e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.273, tt:6878.311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:195, loss:0.00000, loss_test:0.01692, lr:2.29e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.279, tt:6914.599\n",
      "Ep:196, loss:0.00000, loss_test:0.01689, lr:2.26e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.274, tt:6948.906\n",
      "Ep:197, loss:0.00000, loss_test:0.01696, lr:2.24e-02, fs:0.71856 (r=0.606,p=0.882),  time:35.268, tt:6983.107\n",
      "Ep:198, loss:0.00000, loss_test:0.01692, lr:2.22e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.266, tt:7017.947\n",
      "Ep:199, loss:0.00000, loss_test:0.01687, lr:2.20e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.261, tt:7052.107\n",
      "Ep:200, loss:0.00000, loss_test:0.01719, lr:2.17e-02, fs:0.71856 (r=0.606,p=0.882),  time:35.259, tt:7087.157\n",
      "Ep:201, loss:0.00000, loss_test:0.01693, lr:2.15e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.255, tt:7121.558\n",
      "Ep:202, loss:0.00000, loss_test:0.01714, lr:2.13e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.226, tt:7150.865\n",
      "Ep:203, loss:0.00000, loss_test:0.01698, lr:2.11e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.214, tt:7183.756\n",
      "Ep:204, loss:0.00000, loss_test:0.01727, lr:2.09e-02, fs:0.71084 (r=0.596,p=0.881),  time:35.208, tt:7217.595\n",
      "Ep:205, loss:0.00000, loss_test:0.01708, lr:2.07e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.196, tt:7250.353\n",
      "Ep:206, loss:0.00000, loss_test:0.01715, lr:2.05e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.180, tt:7282.216\n",
      "Ep:207, loss:0.00000, loss_test:0.01727, lr:2.03e-02, fs:0.71084 (r=0.596,p=0.881),  time:35.167, tt:7314.685\n",
      "Ep:208, loss:0.00000, loss_test:0.01704, lr:2.01e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.165, tt:7349.484\n",
      "Ep:209, loss:0.00000, loss_test:0.01732, lr:1.99e-02, fs:0.71856 (r=0.606,p=0.882),  time:35.153, tt:7382.228\n",
      "Ep:210, loss:0.00000, loss_test:0.01724, lr:1.97e-02, fs:0.71084 (r=0.596,p=0.881),  time:35.138, tt:7414.209\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14302, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:35.796, tt:35.796\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14075, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:34.547, tt:69.094\n",
      "Ep:2, loss:0.00027, loss_test:0.13680, lr:1.00e-02, fs:0.64539 (r=0.919,p=0.497),  time:35.314, tt:105.941\n",
      "Ep:3, loss:0.00026, loss_test:0.13152, lr:1.00e-02, fs:0.65918 (r=0.889,p=0.524),  time:34.940, tt:139.761\n",
      "Ep:4, loss:0.00026, loss_test:0.12630, lr:1.00e-02, fs:0.67188 (r=0.869,p=0.548),  time:34.907, tt:174.536\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.12297, lr:1.00e-02, fs:0.67200 (r=0.848,p=0.556),  time:35.303, tt:211.817\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.12136, lr:1.00e-02, fs:0.68800 (r=0.869,p=0.570),  time:35.373, tt:247.608\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.12013, lr:1.00e-02, fs:0.67984 (r=0.869,p=0.558),  time:35.613, tt:284.906\n",
      "Ep:8, loss:0.00024, loss_test:0.11804, lr:1.00e-02, fs:0.69355 (r=0.869,p=0.577),  time:35.536, tt:319.825\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.11498, lr:1.00e-02, fs:0.70204 (r=0.869,p=0.589),  time:35.538, tt:355.382\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00023, loss_test:0.11258, lr:1.00e-02, fs:0.71667 (r=0.869,p=0.610),  time:35.484, tt:390.327\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00022, loss_test:0.11021, lr:1.00e-02, fs:0.71667 (r=0.869,p=0.610),  time:35.595, tt:427.140\n",
      "Ep:12, loss:0.00022, loss_test:0.10836, lr:1.00e-02, fs:0.71369 (r=0.869,p=0.606),  time:35.641, tt:463.328\n",
      "Ep:13, loss:0.00021, loss_test:0.10513, lr:1.00e-02, fs:0.72034 (r=0.859,p=0.620),  time:35.751, tt:500.511\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00021, loss_test:0.10270, lr:1.00e-02, fs:0.73276 (r=0.859,p=0.639),  time:35.821, tt:537.312\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00020, loss_test:0.10173, lr:1.00e-02, fs:0.74359 (r=0.879,p=0.644),  time:35.895, tt:574.317\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00020, loss_test:0.09922, lr:1.00e-02, fs:0.75652 (r=0.879,p=0.664),  time:35.920, tt:610.637\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00019, loss_test:0.09744, lr:1.00e-02, fs:0.75652 (r=0.879,p=0.664),  time:35.886, tt:645.945\n",
      "Ep:18, loss:0.00019, loss_test:0.09640, lr:1.00e-02, fs:0.77253 (r=0.909,p=0.672),  time:35.943, tt:682.909\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00018, loss_test:0.09426, lr:1.00e-02, fs:0.76233 (r=0.859,p=0.685),  time:35.903, tt:718.068\n",
      "Ep:20, loss:0.00017, loss_test:0.09294, lr:1.00e-02, fs:0.77193 (r=0.889,p=0.682),  time:35.950, tt:754.948\n",
      "Ep:21, loss:0.00017, loss_test:0.09168, lr:1.00e-02, fs:0.78571 (r=0.889,p=0.704),  time:35.964, tt:791.207\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00016, loss_test:0.09075, lr:1.00e-02, fs:0.79825 (r=0.919,p=0.705),  time:35.918, tt:826.111\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00016, loss_test:0.08914, lr:1.00e-02, fs:0.79646 (r=0.909,p=0.709),  time:35.874, tt:860.975\n",
      "Ep:24, loss:0.00015, loss_test:0.08811, lr:1.00e-02, fs:0.80357 (r=0.909,p=0.720),  time:35.803, tt:895.079\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00015, loss_test:0.08674, lr:1.00e-02, fs:0.79111 (r=0.899,p=0.706),  time:35.827, tt:931.509\n",
      "Ep:26, loss:0.00014, loss_test:0.08624, lr:1.00e-02, fs:0.80000 (r=0.869,p=0.741),  time:35.759, tt:965.500\n",
      "Ep:27, loss:0.00014, loss_test:0.08498, lr:1.00e-02, fs:0.80000 (r=0.909,p=0.714),  time:35.737, tt:1000.635\n",
      "Ep:28, loss:0.00013, loss_test:0.08437, lr:1.00e-02, fs:0.81690 (r=0.879,p=0.763),  time:35.676, tt:1034.594\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.08210, lr:1.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:35.680, tt:1070.390\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00013, loss_test:0.08148, lr:1.00e-02, fs:0.82791 (r=0.899,p=0.767),  time:35.624, tt:1104.354\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.08009, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:35.646, tt:1140.659\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00012, loss_test:0.07938, lr:1.00e-02, fs:0.83105 (r=0.919,p=0.758),  time:35.627, tt:1175.686\n",
      "Ep:33, loss:0.00011, loss_test:0.07820, lr:1.00e-02, fs:0.83412 (r=0.889,p=0.786),  time:35.622, tt:1211.134\n",
      "Ep:34, loss:0.00011, loss_test:0.07727, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:35.619, tt:1246.669\n",
      "Ep:35, loss:0.00010, loss_test:0.07754, lr:1.00e-02, fs:0.85308 (r=0.909,p=0.804),  time:35.593, tt:1281.364\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00011, loss_test:0.07491, lr:1.00e-02, fs:0.84651 (r=0.919,p=0.784),  time:35.547, tt:1315.226\n",
      "Ep:37, loss:0.00010, loss_test:0.07788, lr:1.00e-02, fs:0.81279 (r=0.899,p=0.742),  time:35.548, tt:1350.838\n",
      "Ep:38, loss:0.00010, loss_test:0.07596, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:35.527, tt:1385.541\n",
      "Ep:39, loss:0.00010, loss_test:0.07204, lr:1.00e-02, fs:0.87037 (r=0.949,p=0.803),  time:35.490, tt:1419.608\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00009, loss_test:0.07433, lr:1.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:35.476, tt:1454.501\n",
      "Ep:41, loss:0.00009, loss_test:0.07478, lr:1.00e-02, fs:0.85973 (r=0.960,p=0.779),  time:35.447, tt:1488.760\n",
      "Ep:42, loss:0.00009, loss_test:0.07579, lr:1.00e-02, fs:0.80769 (r=0.848,p=0.771),  time:35.419, tt:1523.032\n",
      "Ep:43, loss:0.00009, loss_test:0.06999, lr:1.00e-02, fs:0.85446 (r=0.919,p=0.798),  time:35.396, tt:1557.424\n",
      "Ep:44, loss:0.00008, loss_test:0.07029, lr:1.00e-02, fs:0.83254 (r=0.879,p=0.791),  time:35.408, tt:1593.339\n",
      "Ep:45, loss:0.00008, loss_test:0.07026, lr:1.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:35.407, tt:1628.706\n",
      "Ep:46, loss:0.00008, loss_test:0.06824, lr:1.00e-02, fs:0.86385 (r=0.929,p=0.807),  time:35.399, tt:1663.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:47, loss:0.00007, loss_test:0.06871, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:35.380, tt:1698.249\n",
      "Ep:48, loss:0.00007, loss_test:0.06552, lr:1.00e-02, fs:0.86792 (r=0.929,p=0.814),  time:35.358, tt:1732.546\n",
      "Ep:49, loss:0.00007, loss_test:0.06725, lr:1.00e-02, fs:0.83000 (r=0.838,p=0.822),  time:35.365, tt:1768.272\n",
      "Ep:50, loss:0.00006, loss_test:0.06485, lr:1.00e-02, fs:0.86916 (r=0.939,p=0.809),  time:35.360, tt:1803.368\n",
      "Ep:51, loss:0.00006, loss_test:0.06736, lr:9.90e-03, fs:0.83000 (r=0.838,p=0.822),  time:35.352, tt:1838.282\n",
      "Ep:52, loss:0.00006, loss_test:0.06328, lr:9.80e-03, fs:0.85437 (r=0.889,p=0.822),  time:35.344, tt:1873.210\n",
      "Ep:53, loss:0.00006, loss_test:0.06550, lr:9.70e-03, fs:0.84422 (r=0.848,p=0.840),  time:35.321, tt:1907.353\n",
      "Ep:54, loss:0.00006, loss_test:0.06147, lr:9.61e-03, fs:0.84729 (r=0.869,p=0.827),  time:35.314, tt:1942.288\n",
      "Ep:55, loss:0.00006, loss_test:0.06362, lr:9.51e-03, fs:0.85572 (r=0.869,p=0.843),  time:35.294, tt:1976.478\n",
      "Ep:56, loss:0.00006, loss_test:0.06200, lr:9.41e-03, fs:0.85572 (r=0.869,p=0.843),  time:35.297, tt:2011.921\n",
      "Ep:57, loss:0.00005, loss_test:0.06238, lr:9.32e-03, fs:0.85149 (r=0.869,p=0.835),  time:35.281, tt:2046.292\n",
      "Ep:58, loss:0.00005, loss_test:0.06199, lr:9.23e-03, fs:0.85149 (r=0.869,p=0.835),  time:35.268, tt:2080.808\n",
      "Ep:59, loss:0.00005, loss_test:0.05970, lr:9.14e-03, fs:0.85149 (r=0.869,p=0.835),  time:35.240, tt:2114.410\n",
      "Ep:60, loss:0.00005, loss_test:0.06096, lr:9.04e-03, fs:0.85149 (r=0.869,p=0.835),  time:35.230, tt:2149.057\n",
      "Ep:61, loss:0.00005, loss_test:0.05860, lr:8.95e-03, fs:0.85714 (r=0.879,p=0.837),  time:35.228, tt:2184.116\n",
      "Ep:62, loss:0.00005, loss_test:0.05999, lr:8.86e-03, fs:0.85572 (r=0.869,p=0.843),  time:35.231, tt:2219.579\n",
      "Ep:63, loss:0.00005, loss_test:0.06060, lr:8.78e-03, fs:0.86000 (r=0.869,p=0.851),  time:35.235, tt:2255.050\n",
      "Ep:64, loss:0.00004, loss_test:0.05891, lr:8.69e-03, fs:0.85714 (r=0.879,p=0.837),  time:35.212, tt:2288.770\n",
      "Ep:65, loss:0.00005, loss_test:0.05983, lr:8.60e-03, fs:0.87000 (r=0.879,p=0.861),  time:35.229, tt:2325.089\n",
      "Ep:66, loss:0.00005, loss_test:0.05765, lr:8.51e-03, fs:0.85149 (r=0.869,p=0.835),  time:35.238, tt:2360.959\n",
      "Ep:67, loss:0.00004, loss_test:0.05950, lr:8.43e-03, fs:0.88205 (r=0.869,p=0.896),  time:35.238, tt:2396.199\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00004, loss_test:0.05779, lr:8.43e-03, fs:0.86000 (r=0.869,p=0.851),  time:35.239, tt:2431.469\n",
      "Ep:69, loss:0.00004, loss_test:0.05817, lr:8.43e-03, fs:0.85572 (r=0.869,p=0.843),  time:35.221, tt:2465.472\n",
      "Ep:70, loss:0.00004, loss_test:0.05790, lr:8.43e-03, fs:0.87179 (r=0.859,p=0.885),  time:35.231, tt:2501.408\n",
      "Ep:71, loss:0.00004, loss_test:0.05739, lr:8.43e-03, fs:0.88083 (r=0.859,p=0.904),  time:35.229, tt:2536.485\n",
      "Ep:72, loss:0.00004, loss_test:0.05985, lr:8.43e-03, fs:0.87310 (r=0.869,p=0.878),  time:35.200, tt:2569.576\n",
      "Ep:73, loss:0.00004, loss_test:0.05622, lr:8.43e-03, fs:0.86700 (r=0.889,p=0.846),  time:35.200, tt:2604.788\n",
      "Ep:74, loss:0.00004, loss_test:0.05863, lr:8.43e-03, fs:0.88083 (r=0.859,p=0.904),  time:35.188, tt:2639.108\n",
      "Ep:75, loss:0.00004, loss_test:0.05507, lr:8.43e-03, fs:0.85000 (r=0.859,p=0.842),  time:35.191, tt:2674.497\n",
      "Ep:76, loss:0.00004, loss_test:0.06007, lr:8.43e-03, fs:0.85859 (r=0.859,p=0.859),  time:35.192, tt:2709.816\n",
      "Ep:77, loss:0.00004, loss_test:0.05527, lr:8.43e-03, fs:0.88205 (r=0.869,p=0.896),  time:35.188, tt:2744.698\n",
      "Ep:78, loss:0.00004, loss_test:0.05548, lr:8.43e-03, fs:0.88660 (r=0.869,p=0.905),  time:35.192, tt:2780.153\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00004, loss_test:0.05767, lr:8.43e-03, fs:0.86432 (r=0.869,p=0.860),  time:35.190, tt:2815.228\n",
      "Ep:80, loss:0.00003, loss_test:0.05568, lr:8.43e-03, fs:0.87500 (r=0.848,p=0.903),  time:35.210, tt:2851.991\n",
      "Ep:81, loss:0.00004, loss_test:0.05663, lr:8.43e-03, fs:0.86911 (r=0.838,p=0.902),  time:35.195, tt:2886.002\n",
      "Ep:82, loss:0.00003, loss_test:0.05612, lr:8.43e-03, fs:0.86432 (r=0.869,p=0.860),  time:35.226, tt:2923.733\n",
      "Ep:83, loss:0.00003, loss_test:0.05593, lr:8.43e-03, fs:0.86911 (r=0.838,p=0.902),  time:35.236, tt:2959.832\n",
      "Ep:84, loss:0.00003, loss_test:0.05399, lr:8.43e-03, fs:0.87000 (r=0.879,p=0.861),  time:35.243, tt:2995.658\n",
      "Ep:85, loss:0.00003, loss_test:0.05794, lr:8.43e-03, fs:0.86432 (r=0.869,p=0.860),  time:35.248, tt:3031.324\n",
      "Ep:86, loss:0.00003, loss_test:0.05392, lr:8.43e-03, fs:0.86911 (r=0.838,p=0.902),  time:35.220, tt:3064.167\n",
      "Ep:87, loss:0.00003, loss_test:0.05236, lr:8.43e-03, fs:0.88442 (r=0.889,p=0.880),  time:35.219, tt:3099.279\n",
      "Ep:88, loss:0.00003, loss_test:0.05788, lr:8.43e-03, fs:0.87310 (r=0.869,p=0.878),  time:35.209, tt:3133.599\n",
      "Ep:89, loss:0.00003, loss_test:0.05247, lr:8.43e-03, fs:0.87368 (r=0.838,p=0.912),  time:35.231, tt:3170.822\n",
      "Ep:90, loss:0.00003, loss_test:0.05748, lr:8.35e-03, fs:0.86869 (r=0.869,p=0.869),  time:35.226, tt:3205.549\n",
      "Ep:91, loss:0.00003, loss_test:0.05616, lr:8.26e-03, fs:0.86911 (r=0.838,p=0.902),  time:35.237, tt:3241.761\n",
      "Ep:92, loss:0.00003, loss_test:0.05257, lr:8.18e-03, fs:0.88000 (r=0.889,p=0.871),  time:35.248, tt:3278.097\n",
      "Ep:93, loss:0.00003, loss_test:0.05574, lr:8.10e-03, fs:0.90155 (r=0.879,p=0.926),  time:35.245, tt:3313.022\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00003, loss_test:0.05237, lr:8.10e-03, fs:0.87831 (r=0.838,p=0.922),  time:35.245, tt:3348.286\n",
      "Ep:95, loss:0.00002, loss_test:0.05319, lr:8.10e-03, fs:0.89899 (r=0.899,p=0.899),  time:35.252, tt:3384.149\n",
      "Ep:96, loss:0.00002, loss_test:0.05505, lr:8.10e-03, fs:0.89005 (r=0.859,p=0.924),  time:35.264, tt:3420.573\n",
      "Ep:97, loss:0.00003, loss_test:0.05196, lr:8.10e-03, fs:0.87368 (r=0.838,p=0.912),  time:35.274, tt:3456.896\n",
      "Ep:98, loss:0.00002, loss_test:0.05784, lr:8.10e-03, fs:0.87755 (r=0.869,p=0.887),  time:35.278, tt:3492.527\n",
      "Ep:99, loss:0.00003, loss_test:0.05595, lr:8.10e-03, fs:0.86316 (r=0.828,p=0.901),  time:35.276, tt:3527.621\n",
      "Ep:100, loss:0.00003, loss_test:0.05177, lr:8.10e-03, fs:0.89005 (r=0.859,p=0.924),  time:35.272, tt:3562.436\n",
      "Ep:101, loss:0.00003, loss_test:0.05608, lr:8.10e-03, fs:0.89005 (r=0.859,p=0.924),  time:35.278, tt:3598.335\n",
      "Ep:102, loss:0.00002, loss_test:0.05474, lr:8.10e-03, fs:0.85864 (r=0.828,p=0.891),  time:35.272, tt:3633.034\n",
      "Ep:103, loss:0.00002, loss_test:0.05590, lr:8.10e-03, fs:0.88660 (r=0.869,p=0.905),  time:35.257, tt:3666.760\n",
      "Ep:104, loss:0.00002, loss_test:0.05628, lr:8.10e-03, fs:0.86458 (r=0.838,p=0.892),  time:35.261, tt:3702.431\n",
      "Ep:105, loss:0.00003, loss_test:0.05580, lr:8.02e-03, fs:0.90155 (r=0.879,p=0.926),  time:35.274, tt:3739.093\n",
      "Ep:106, loss:0.00002, loss_test:0.05358, lr:7.94e-03, fs:0.87368 (r=0.838,p=0.912),  time:35.272, tt:3774.120\n",
      "Ep:107, loss:0.00002, loss_test:0.05265, lr:7.86e-03, fs:0.90625 (r=0.879,p=0.935),  time:35.275, tt:3809.716\n",
      "##########Best model found so far##########\n",
      "Ep:108, loss:0.00002, loss_test:0.05433, lr:7.86e-03, fs:0.89474 (r=0.859,p=0.934),  time:35.283, tt:3845.830\n",
      "Ep:109, loss:0.00002, loss_test:0.05483, lr:7.86e-03, fs:0.86316 (r=0.828,p=0.901),  time:35.271, tt:3879.773\n",
      "Ep:110, loss:0.00002, loss_test:0.05421, lr:7.86e-03, fs:0.89362 (r=0.848,p=0.944),  time:35.280, tt:3916.052\n",
      "Ep:111, loss:0.00002, loss_test:0.05310, lr:7.86e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.281, tt:3951.523\n",
      "Ep:112, loss:0.00002, loss_test:0.05429, lr:7.86e-03, fs:0.90526 (r=0.869,p=0.945),  time:35.308, tt:3989.775\n",
      "Ep:113, loss:0.00002, loss_test:0.05374, lr:7.86e-03, fs:0.87234 (r=0.828,p=0.921),  time:35.303, tt:4024.545\n",
      "Ep:114, loss:0.00002, loss_test:0.05481, lr:7.86e-03, fs:0.88298 (r=0.838,p=0.933),  time:35.313, tt:4061.040\n",
      "Ep:115, loss:0.00002, loss_test:0.05403, lr:7.86e-03, fs:0.89362 (r=0.848,p=0.944),  time:35.312, tt:4096.215\n",
      "Ep:116, loss:0.00002, loss_test:0.05444, lr:7.86e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.305, tt:4130.694\n",
      "Ep:117, loss:0.00002, loss_test:0.05507, lr:7.86e-03, fs:0.87701 (r=0.828,p=0.932),  time:35.304, tt:4165.829\n",
      "Ep:118, loss:0.00002, loss_test:0.05577, lr:7.86e-03, fs:0.90526 (r=0.869,p=0.945),  time:35.302, tt:4200.956\n",
      "Ep:119, loss:0.00002, loss_test:0.05445, lr:7.78e-03, fs:0.87701 (r=0.828,p=0.932),  time:35.299, tt:4235.879\n",
      "Ep:120, loss:0.00002, loss_test:0.05427, lr:7.70e-03, fs:0.87368 (r=0.838,p=0.912),  time:35.287, tt:4269.717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:121, loss:0.00002, loss_test:0.05654, lr:7.62e-03, fs:0.88770 (r=0.838,p=0.943),  time:35.285, tt:4304.805\n",
      "Ep:122, loss:0.00001, loss_test:0.05486, lr:7.55e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.293, tt:4340.988\n",
      "Ep:123, loss:0.00001, loss_test:0.05477, lr:7.47e-03, fs:0.87234 (r=0.828,p=0.921),  time:35.293, tt:4376.344\n",
      "Ep:124, loss:0.00001, loss_test:0.05608, lr:7.40e-03, fs:0.90155 (r=0.879,p=0.926),  time:35.295, tt:4411.883\n",
      "Ep:125, loss:0.00001, loss_test:0.05498, lr:7.32e-03, fs:0.87234 (r=0.828,p=0.921),  time:35.300, tt:4447.806\n",
      "Ep:126, loss:0.00001, loss_test:0.05547, lr:7.25e-03, fs:0.88542 (r=0.859,p=0.914),  time:35.308, tt:4484.057\n",
      "Ep:127, loss:0.00001, loss_test:0.05635, lr:7.18e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.314, tt:4520.221\n",
      "Ep:128, loss:0.00001, loss_test:0.05558, lr:7.11e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.320, tt:4556.239\n",
      "Ep:129, loss:0.00001, loss_test:0.05703, lr:7.03e-03, fs:0.86486 (r=0.808,p=0.930),  time:35.324, tt:4592.074\n",
      "Ep:130, loss:0.00001, loss_test:0.05628, lr:6.96e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.319, tt:4626.847\n",
      "Ep:131, loss:0.00001, loss_test:0.05618, lr:6.89e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.354, tt:4666.718\n",
      "Ep:132, loss:0.00001, loss_test:0.05756, lr:6.83e-03, fs:0.90155 (r=0.879,p=0.926),  time:35.368, tt:4703.997\n",
      "Ep:133, loss:0.00001, loss_test:0.05702, lr:6.76e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.386, tt:4741.756\n",
      "Ep:134, loss:0.00001, loss_test:0.05602, lr:6.69e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.394, tt:4778.216\n",
      "Ep:135, loss:0.00001, loss_test:0.05738, lr:6.62e-03, fs:0.86486 (r=0.808,p=0.930),  time:35.396, tt:4813.824\n",
      "Ep:136, loss:0.00001, loss_test:0.05650, lr:6.56e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.392, tt:4848.638\n",
      "Ep:137, loss:0.00001, loss_test:0.05655, lr:6.49e-03, fs:0.87097 (r=0.818,p=0.931),  time:35.392, tt:4884.050\n",
      "Ep:138, loss:0.00001, loss_test:0.05628, lr:6.43e-03, fs:0.87234 (r=0.828,p=0.921),  time:35.396, tt:4919.975\n",
      "Ep:139, loss:0.00001, loss_test:0.05729, lr:6.36e-03, fs:0.87234 (r=0.828,p=0.921),  time:35.399, tt:4955.858\n",
      "Ep:140, loss:0.00001, loss_test:0.05619, lr:6.30e-03, fs:0.87234 (r=0.828,p=0.921),  time:35.398, tt:4991.086\n",
      "Ep:141, loss:0.00001, loss_test:0.05771, lr:6.24e-03, fs:0.86631 (r=0.818,p=0.920),  time:35.402, tt:5027.112\n",
      "Ep:142, loss:0.00001, loss_test:0.05665, lr:6.17e-03, fs:0.87701 (r=0.828,p=0.932),  time:35.405, tt:5062.855\n",
      "Ep:143, loss:0.00001, loss_test:0.05730, lr:6.11e-03, fs:0.87097 (r=0.818,p=0.931),  time:35.408, tt:5098.815\n",
      "Ep:144, loss:0.00001, loss_test:0.05678, lr:6.05e-03, fs:0.86316 (r=0.828,p=0.901),  time:35.408, tt:5134.154\n",
      "Ep:145, loss:0.00001, loss_test:0.05757, lr:5.99e-03, fs:0.87097 (r=0.818,p=0.931),  time:35.423, tt:5171.789\n",
      "Ep:146, loss:0.00001, loss_test:0.05753, lr:5.93e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.422, tt:5207.017\n",
      "Ep:147, loss:0.00001, loss_test:0.05672, lr:5.87e-03, fs:0.87234 (r=0.828,p=0.921),  time:35.420, tt:5242.179\n",
      "Ep:148, loss:0.00001, loss_test:0.05765, lr:5.81e-03, fs:0.87234 (r=0.828,p=0.921),  time:35.419, tt:5277.461\n",
      "Ep:149, loss:0.00001, loss_test:0.05685, lr:5.75e-03, fs:0.87234 (r=0.828,p=0.921),  time:35.440, tt:5316.052\n",
      "Ep:150, loss:0.00001, loss_test:0.05748, lr:5.70e-03, fs:0.87234 (r=0.828,p=0.921),  time:35.445, tt:5352.268\n",
      "Ep:151, loss:0.00001, loss_test:0.05751, lr:5.64e-03, fs:0.87234 (r=0.828,p=0.921),  time:35.449, tt:5388.307\n",
      "Ep:152, loss:0.00001, loss_test:0.05735, lr:5.58e-03, fs:0.87234 (r=0.828,p=0.921),  time:35.458, tt:5425.098\n",
      "Ep:153, loss:0.00001, loss_test:0.05711, lr:5.53e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.467, tt:5461.952\n",
      "Ep:154, loss:0.00001, loss_test:0.05757, lr:5.47e-03, fs:0.87701 (r=0.828,p=0.932),  time:35.471, tt:5497.955\n",
      "Ep:155, loss:0.00001, loss_test:0.05803, lr:5.42e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.476, tt:5534.266\n",
      "Ep:156, loss:0.00001, loss_test:0.05701, lr:5.36e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.477, tt:5569.842\n",
      "Ep:157, loss:0.00001, loss_test:0.05888, lr:5.31e-03, fs:0.86631 (r=0.818,p=0.920),  time:35.468, tt:5603.928\n",
      "Ep:158, loss:0.00001, loss_test:0.05780, lr:5.26e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.466, tt:5639.055\n",
      "Ep:159, loss:0.00001, loss_test:0.05711, lr:5.20e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.466, tt:5674.605\n",
      "Ep:160, loss:0.00001, loss_test:0.05779, lr:5.15e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.465, tt:5709.795\n",
      "Ep:161, loss:0.00001, loss_test:0.05748, lr:5.10e-03, fs:0.87234 (r=0.828,p=0.921),  time:35.465, tt:5745.253\n",
      "Ep:162, loss:0.00001, loss_test:0.05740, lr:5.05e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.458, tt:5779.640\n",
      "Ep:163, loss:0.00001, loss_test:0.05758, lr:5.00e-03, fs:0.87234 (r=0.828,p=0.921),  time:35.460, tt:5815.494\n",
      "Ep:164, loss:0.00001, loss_test:0.05795, lr:4.95e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.470, tt:5852.589\n",
      "Ep:165, loss:0.00001, loss_test:0.05782, lr:4.90e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.474, tt:5888.760\n",
      "Ep:166, loss:0.00001, loss_test:0.05682, lr:4.85e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.467, tt:5922.961\n",
      "Ep:167, loss:0.00001, loss_test:0.05883, lr:4.80e-03, fs:0.87097 (r=0.818,p=0.931),  time:35.483, tt:5961.113\n",
      "Ep:168, loss:0.00001, loss_test:0.05804, lr:4.75e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.490, tt:5997.800\n",
      "Ep:169, loss:0.00001, loss_test:0.05767, lr:4.71e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.490, tt:6033.303\n",
      "Ep:170, loss:0.00001, loss_test:0.05730, lr:4.66e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.487, tt:6068.274\n",
      "Ep:171, loss:0.00001, loss_test:0.05818, lr:4.61e-03, fs:0.86631 (r=0.818,p=0.920),  time:35.487, tt:6103.841\n",
      "Ep:172, loss:0.00001, loss_test:0.05762, lr:4.57e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.493, tt:6140.292\n",
      "Ep:173, loss:0.00001, loss_test:0.05741, lr:4.52e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.492, tt:6175.582\n",
      "Ep:174, loss:0.00001, loss_test:0.05829, lr:4.48e-03, fs:0.87234 (r=0.828,p=0.921),  time:35.502, tt:6212.850\n",
      "Ep:175, loss:0.00001, loss_test:0.05764, lr:4.43e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.495, tt:6247.120\n",
      "Ep:176, loss:0.00001, loss_test:0.05788, lr:4.39e-03, fs:0.86170 (r=0.818,p=0.910),  time:35.501, tt:6283.723\n",
      "Ep:177, loss:0.00001, loss_test:0.05794, lr:4.34e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.507, tt:6320.270\n",
      "Ep:178, loss:0.00001, loss_test:0.05794, lr:4.30e-03, fs:0.86170 (r=0.818,p=0.910),  time:35.506, tt:6355.531\n",
      "Ep:179, loss:0.00001, loss_test:0.05758, lr:4.26e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.520, tt:6393.563\n",
      "Ep:180, loss:0.00001, loss_test:0.05867, lr:4.21e-03, fs:0.86631 (r=0.818,p=0.920),  time:35.524, tt:6429.802\n",
      "Ep:181, loss:0.00001, loss_test:0.05816, lr:4.17e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.530, tt:6466.405\n",
      "Ep:182, loss:0.00001, loss_test:0.05799, lr:4.13e-03, fs:0.86170 (r=0.818,p=0.910),  time:35.534, tt:6502.632\n",
      "Ep:183, loss:0.00001, loss_test:0.05829, lr:4.09e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.540, tt:6539.351\n",
      "Ep:184, loss:0.00001, loss_test:0.05854, lr:4.05e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.551, tt:6576.944\n",
      "Ep:185, loss:0.00001, loss_test:0.05810, lr:4.01e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.553, tt:6612.851\n",
      "Ep:186, loss:0.00001, loss_test:0.05797, lr:3.97e-03, fs:0.86316 (r=0.828,p=0.901),  time:35.572, tt:6651.925\n",
      "Ep:187, loss:0.00001, loss_test:0.05779, lr:3.93e-03, fs:0.86170 (r=0.818,p=0.910),  time:35.579, tt:6688.807\n",
      "Ep:188, loss:0.00001, loss_test:0.05798, lr:3.89e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.579, tt:6724.359\n",
      "Ep:189, loss:0.00001, loss_test:0.05826, lr:3.85e-03, fs:0.86170 (r=0.818,p=0.910),  time:35.586, tt:6761.250\n",
      "Ep:190, loss:0.00001, loss_test:0.05834, lr:3.81e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.595, tt:6798.614\n",
      "Ep:191, loss:0.00001, loss_test:0.05767, lr:3.77e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.592, tt:6833.609\n",
      "Ep:192, loss:0.00001, loss_test:0.05774, lr:3.73e-03, fs:0.85405 (r=0.798,p=0.919),  time:35.593, tt:6869.462\n",
      "Ep:193, loss:0.00001, loss_test:0.05786, lr:3.70e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.598, tt:6906.004\n",
      "Ep:194, loss:0.00001, loss_test:0.05841, lr:3.66e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.604, tt:6942.735\n",
      "Ep:195, loss:0.00001, loss_test:0.05714, lr:3.62e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.607, tt:6978.966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:196, loss:0.00001, loss_test:0.05923, lr:3.59e-03, fs:0.87701 (r=0.828,p=0.932),  time:35.615, tt:7016.074\n",
      "Ep:197, loss:0.00001, loss_test:0.05879, lr:3.55e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.616, tt:7051.949\n",
      "Ep:198, loss:0.00001, loss_test:0.05889, lr:3.52e-03, fs:0.84783 (r=0.788,p=0.918),  time:35.616, tt:7087.632\n",
      "Ep:199, loss:0.00001, loss_test:0.05840, lr:3.48e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.618, tt:7123.642\n",
      "Ep:200, loss:0.00001, loss_test:0.05906, lr:3.45e-03, fs:0.85405 (r=0.798,p=0.919),  time:35.621, tt:7159.821\n",
      "Ep:201, loss:0.00001, loss_test:0.05810, lr:3.41e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.626, tt:7196.444\n",
      "Ep:202, loss:0.00001, loss_test:0.05843, lr:3.38e-03, fs:0.86170 (r=0.818,p=0.910),  time:35.628, tt:7232.507\n",
      "Ep:203, loss:0.00001, loss_test:0.05824, lr:3.34e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.615, tt:7265.421\n",
      "Ep:204, loss:0.00001, loss_test:0.05845, lr:3.31e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.606, tt:7299.169\n",
      "Ep:205, loss:0.00001, loss_test:0.05849, lr:3.28e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.592, tt:7331.864\n",
      "Ep:206, loss:0.00001, loss_test:0.05837, lr:3.24e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.575, tt:7363.948\n",
      "Ep:207, loss:0.00001, loss_test:0.05825, lr:3.21e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.549, tt:7394.254\n",
      "Ep:208, loss:0.00001, loss_test:0.05834, lr:3.18e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.526, tt:7424.829\n",
      "Ep:209, loss:0.00001, loss_test:0.05808, lr:3.15e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.514, tt:7457.941\n",
      "Ep:210, loss:0.00001, loss_test:0.05781, lr:3.12e-03, fs:0.86772 (r=0.828,p=0.911),  time:35.488, tt:7488.025\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00011, loss_test:0.02250, lr:6.00e-02, fs:0.63004 (r=0.869,p=0.494),  time:34.644, tt:34.644\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02727, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.327, tt:66.655\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02990, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.756, tt:98.268\n",
      "Ep:3, loss:0.00006, loss_test:0.03036, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.414, tt:129.656\n",
      "Ep:4, loss:0.00006, loss_test:0.02977, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.255, tt:161.274\n",
      "Ep:5, loss:0.00006, loss_test:0.02866, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.580, tt:195.478\n",
      "Ep:6, loss:0.00005, loss_test:0.02713, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:32.785, tt:229.496\n",
      "Ep:7, loss:0.00005, loss_test:0.02543, lr:6.00e-02, fs:0.66897 (r=0.980,p=0.508),  time:33.363, tt:266.903\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00005, loss_test:0.02390, lr:6.00e-02, fs:0.63799 (r=0.899,p=0.494),  time:33.579, tt:302.208\n",
      "Ep:9, loss:0.00005, loss_test:0.02275, lr:6.00e-02, fs:0.65660 (r=0.879,p=0.524),  time:33.594, tt:335.943\n",
      "Ep:10, loss:0.00005, loss_test:0.02191, lr:6.00e-02, fs:0.67176 (r=0.889,p=0.540),  time:33.799, tt:371.790\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.02135, lr:6.00e-02, fs:0.66421 (r=0.909,p=0.523),  time:33.890, tt:406.683\n",
      "Ep:12, loss:0.00004, loss_test:0.02089, lr:6.00e-02, fs:0.67626 (r=0.949,p=0.525),  time:33.923, tt:440.995\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.02059, lr:6.00e-02, fs:0.69343 (r=0.960,p=0.543),  time:34.096, tt:477.348\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.02010, lr:6.00e-02, fs:0.70111 (r=0.960,p=0.552),  time:34.259, tt:513.882\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.01964, lr:6.00e-02, fs:0.70455 (r=0.939,p=0.564),  time:34.412, tt:550.587\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.01937, lr:6.00e-02, fs:0.70992 (r=0.939,p=0.571),  time:34.481, tt:586.180\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.01909, lr:6.00e-02, fs:0.70943 (r=0.949,p=0.566),  time:34.513, tt:621.225\n",
      "Ep:18, loss:0.00004, loss_test:0.01891, lr:6.00e-02, fs:0.70111 (r=0.960,p=0.552),  time:34.557, tt:656.581\n",
      "Ep:19, loss:0.00004, loss_test:0.01869, lr:6.00e-02, fs:0.70370 (r=0.960,p=0.556),  time:34.650, tt:692.996\n",
      "Ep:20, loss:0.00004, loss_test:0.01835, lr:6.00e-02, fs:0.70896 (r=0.960,p=0.562),  time:34.663, tt:727.923\n",
      "Ep:21, loss:0.00004, loss_test:0.01796, lr:6.00e-02, fs:0.72243 (r=0.960,p=0.579),  time:34.739, tt:764.268\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01762, lr:6.00e-02, fs:0.73077 (r=0.960,p=0.590),  time:34.715, tt:798.453\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01736, lr:6.00e-02, fs:0.74131 (r=0.970,p=0.600),  time:34.785, tt:834.838\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01709, lr:6.00e-02, fs:0.72656 (r=0.939,p=0.592),  time:34.798, tt:869.950\n",
      "Ep:25, loss:0.00003, loss_test:0.01680, lr:6.00e-02, fs:0.74016 (r=0.949,p=0.606),  time:34.835, tt:905.721\n",
      "Ep:26, loss:0.00003, loss_test:0.01656, lr:6.00e-02, fs:0.73437 (r=0.949,p=0.599),  time:35.009, tt:945.240\n",
      "Ep:27, loss:0.00003, loss_test:0.01636, lr:6.00e-02, fs:0.73810 (r=0.939,p=0.608),  time:35.026, tt:980.724\n",
      "Ep:28, loss:0.00003, loss_test:0.01626, lr:6.00e-02, fs:0.74194 (r=0.929,p=0.617),  time:35.017, tt:1015.482\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01610, lr:6.00e-02, fs:0.75610 (r=0.939,p=0.633),  time:35.015, tt:1050.463\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01594, lr:6.00e-02, fs:0.75102 (r=0.929,p=0.630),  time:35.014, tt:1085.428\n",
      "Ep:31, loss:0.00003, loss_test:0.01581, lr:6.00e-02, fs:0.74590 (r=0.919,p=0.628),  time:34.976, tt:1119.219\n",
      "Ep:32, loss:0.00003, loss_test:0.01569, lr:6.00e-02, fs:0.75000 (r=0.909,p=0.638),  time:35.012, tt:1155.402\n",
      "Ep:33, loss:0.00003, loss_test:0.01558, lr:6.00e-02, fs:0.74477 (r=0.899,p=0.636),  time:35.020, tt:1190.690\n",
      "Ep:34, loss:0.00003, loss_test:0.01545, lr:6.00e-02, fs:0.75314 (r=0.909,p=0.643),  time:35.096, tt:1228.362\n",
      "Ep:35, loss:0.00003, loss_test:0.01537, lr:6.00e-02, fs:0.75630 (r=0.909,p=0.647),  time:35.098, tt:1263.538\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01528, lr:6.00e-02, fs:0.75949 (r=0.909,p=0.652),  time:35.085, tt:1298.161\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01520, lr:6.00e-02, fs:0.75949 (r=0.909,p=0.652),  time:35.091, tt:1333.443\n",
      "Ep:38, loss:0.00002, loss_test:0.01510, lr:6.00e-02, fs:0.76596 (r=0.909,p=0.662),  time:35.094, tt:1368.685\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01500, lr:6.00e-02, fs:0.77253 (r=0.909,p=0.672),  time:35.151, tt:1406.036\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01488, lr:6.00e-02, fs:0.77586 (r=0.909,p=0.677),  time:35.166, tt:1441.798\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01475, lr:6.00e-02, fs:0.77922 (r=0.909,p=0.682),  time:35.147, tt:1476.194\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01460, lr:6.00e-02, fs:0.78414 (r=0.899,p=0.695),  time:35.177, tt:1512.592\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01446, lr:6.00e-02, fs:0.78414 (r=0.899,p=0.695),  time:35.176, tt:1547.756\n",
      "Ep:44, loss:0.00002, loss_test:0.01429, lr:6.00e-02, fs:0.78070 (r=0.899,p=0.690),  time:35.190, tt:1583.532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:45, loss:0.00002, loss_test:0.01418, lr:6.00e-02, fs:0.78414 (r=0.899,p=0.695),  time:35.186, tt:1618.556\n",
      "Ep:46, loss:0.00002, loss_test:0.01410, lr:6.00e-02, fs:0.78924 (r=0.889,p=0.710),  time:35.201, tt:1654.447\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01394, lr:6.00e-02, fs:0.80357 (r=0.909,p=0.720),  time:35.225, tt:1690.820\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01378, lr:6.00e-02, fs:0.80357 (r=0.909,p=0.720),  time:35.205, tt:1725.025\n",
      "Ep:49, loss:0.00002, loss_test:0.01368, lr:6.00e-02, fs:0.79821 (r=0.899,p=0.718),  time:35.198, tt:1759.918\n",
      "Ep:50, loss:0.00002, loss_test:0.01355, lr:6.00e-02, fs:0.79821 (r=0.899,p=0.718),  time:35.208, tt:1795.593\n",
      "Ep:51, loss:0.00002, loss_test:0.01345, lr:6.00e-02, fs:0.79821 (r=0.899,p=0.718),  time:35.205, tt:1830.660\n",
      "Ep:52, loss:0.00002, loss_test:0.01327, lr:6.00e-02, fs:0.79821 (r=0.899,p=0.718),  time:35.199, tt:1865.571\n",
      "Ep:53, loss:0.00002, loss_test:0.01316, lr:6.00e-02, fs:0.80357 (r=0.909,p=0.720),  time:35.192, tt:1900.362\n",
      "Ep:54, loss:0.00002, loss_test:0.01303, lr:6.00e-02, fs:0.80889 (r=0.919,p=0.722),  time:35.201, tt:1936.066\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.01293, lr:6.00e-02, fs:0.80889 (r=0.919,p=0.722),  time:35.216, tt:1972.114\n",
      "Ep:56, loss:0.00002, loss_test:0.01294, lr:6.00e-02, fs:0.81250 (r=0.919,p=0.728),  time:35.239, tt:2008.641\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.01289, lr:6.00e-02, fs:0.81250 (r=0.919,p=0.728),  time:35.263, tt:2045.259\n",
      "Ep:58, loss:0.00001, loss_test:0.01279, lr:6.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:35.261, tt:2080.382\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01265, lr:6.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:35.286, tt:2117.146\n",
      "Ep:60, loss:0.00001, loss_test:0.01258, lr:6.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:35.317, tt:2154.366\n",
      "Ep:61, loss:0.00001, loss_test:0.01258, lr:6.00e-02, fs:0.82511 (r=0.929,p=0.742),  time:35.324, tt:2190.080\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01248, lr:6.00e-02, fs:0.82883 (r=0.929,p=0.748),  time:35.339, tt:2226.355\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.01244, lr:6.00e-02, fs:0.83258 (r=0.929,p=0.754),  time:35.344, tt:2262.024\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01232, lr:6.00e-02, fs:0.84163 (r=0.939,p=0.762),  time:35.346, tt:2297.475\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.01233, lr:6.00e-02, fs:0.84163 (r=0.939,p=0.762),  time:35.345, tt:2332.765\n",
      "Ep:66, loss:0.00001, loss_test:0.01228, lr:6.00e-02, fs:0.84932 (r=0.939,p=0.775),  time:35.341, tt:2367.815\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01215, lr:6.00e-02, fs:0.84932 (r=0.939,p=0.775),  time:35.347, tt:2403.572\n",
      "Ep:68, loss:0.00001, loss_test:0.01213, lr:6.00e-02, fs:0.84545 (r=0.939,p=0.769),  time:35.358, tt:2439.712\n",
      "Ep:69, loss:0.00001, loss_test:0.01201, lr:6.00e-02, fs:0.84404 (r=0.929,p=0.773),  time:35.370, tt:2475.905\n",
      "Ep:70, loss:0.00001, loss_test:0.01198, lr:6.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:35.369, tt:2511.165\n",
      "Ep:71, loss:0.00001, loss_test:0.01215, lr:6.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:35.368, tt:2546.531\n",
      "Ep:72, loss:0.00001, loss_test:0.01195, lr:6.00e-02, fs:0.84259 (r=0.919,p=0.778),  time:35.345, tt:2580.183\n",
      "Ep:73, loss:0.00001, loss_test:0.01203, lr:6.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:35.344, tt:2615.438\n",
      "Ep:74, loss:0.00001, loss_test:0.01213, lr:6.00e-02, fs:0.84259 (r=0.919,p=0.778),  time:35.324, tt:2649.325\n",
      "Ep:75, loss:0.00001, loss_test:0.01193, lr:6.00e-02, fs:0.83178 (r=0.899,p=0.774),  time:35.326, tt:2684.772\n",
      "Ep:76, loss:0.00001, loss_test:0.01202, lr:6.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:35.312, tt:2719.002\n",
      "Ep:77, loss:0.00001, loss_test:0.01187, lr:6.00e-02, fs:0.84259 (r=0.919,p=0.778),  time:35.297, tt:2753.161\n",
      "Ep:78, loss:0.00001, loss_test:0.01219, lr:5.94e-02, fs:0.82857 (r=0.879,p=0.784),  time:35.279, tt:2787.080\n",
      "Ep:79, loss:0.00001, loss_test:0.01207, lr:5.88e-02, fs:0.82297 (r=0.869,p=0.782),  time:35.282, tt:2822.552\n",
      "Ep:80, loss:0.00001, loss_test:0.01194, lr:5.82e-02, fs:0.82297 (r=0.869,p=0.782),  time:35.270, tt:2856.909\n",
      "Ep:81, loss:0.00001, loss_test:0.01216, lr:5.76e-02, fs:0.81553 (r=0.848,p=0.785),  time:35.276, tt:2892.644\n",
      "Ep:82, loss:0.00001, loss_test:0.01207, lr:5.71e-02, fs:0.82759 (r=0.848,p=0.808),  time:35.254, tt:2926.088\n",
      "Ep:83, loss:0.00001, loss_test:0.01211, lr:5.65e-02, fs:0.80976 (r=0.838,p=0.783),  time:35.242, tt:2960.314\n",
      "Ep:84, loss:0.00001, loss_test:0.01219, lr:5.59e-02, fs:0.80392 (r=0.828,p=0.781),  time:35.239, tt:2995.310\n",
      "Ep:85, loss:0.00001, loss_test:0.01219, lr:5.54e-02, fs:0.82178 (r=0.838,p=0.806),  time:35.248, tt:3031.289\n",
      "Ep:86, loss:0.00001, loss_test:0.01220, lr:5.48e-02, fs:0.82587 (r=0.838,p=0.814),  time:35.243, tt:3066.102\n",
      "Ep:87, loss:0.00001, loss_test:0.01232, lr:5.43e-02, fs:0.82587 (r=0.838,p=0.814),  time:35.235, tt:3100.637\n",
      "Ep:88, loss:0.00001, loss_test:0.01224, lr:5.37e-02, fs:0.83582 (r=0.848,p=0.824),  time:35.246, tt:3136.892\n",
      "Ep:89, loss:0.00001, loss_test:0.01222, lr:5.32e-02, fs:0.83417 (r=0.838,p=0.830),  time:35.268, tt:3174.115\n",
      "Ep:90, loss:0.00001, loss_test:0.01238, lr:5.27e-02, fs:0.83417 (r=0.838,p=0.830),  time:35.283, tt:3210.766\n",
      "Ep:91, loss:0.00001, loss_test:0.01244, lr:5.21e-02, fs:0.82412 (r=0.828,p=0.820),  time:35.281, tt:3245.877\n",
      "Ep:92, loss:0.00001, loss_test:0.01268, lr:5.16e-02, fs:0.79803 (r=0.818,p=0.779),  time:35.265, tt:3279.688\n",
      "Ep:93, loss:0.00001, loss_test:0.01235, lr:5.11e-02, fs:0.83417 (r=0.838,p=0.830),  time:35.268, tt:3315.178\n",
      "Ep:94, loss:0.00001, loss_test:0.01266, lr:5.06e-02, fs:0.83417 (r=0.838,p=0.830),  time:35.277, tt:3351.354\n",
      "Ep:95, loss:0.00001, loss_test:0.01286, lr:5.01e-02, fs:0.81633 (r=0.808,p=0.825),  time:35.287, tt:3387.589\n",
      "Ep:96, loss:0.00001, loss_test:0.01260, lr:4.96e-02, fs:0.83417 (r=0.838,p=0.830),  time:35.285, tt:3422.612\n",
      "Ep:97, loss:0.00001, loss_test:0.01275, lr:4.91e-02, fs:0.82828 (r=0.828,p=0.828),  time:35.301, tt:3459.526\n",
      "Ep:98, loss:0.00001, loss_test:0.01324, lr:4.86e-02, fs:0.81865 (r=0.798,p=0.840),  time:35.303, tt:3495.029\n",
      "Ep:99, loss:0.00001, loss_test:0.01288, lr:4.81e-02, fs:0.83077 (r=0.818,p=0.844),  time:35.310, tt:3531.006\n",
      "Ep:100, loss:0.00001, loss_test:0.01272, lr:4.76e-02, fs:0.83838 (r=0.838,p=0.838),  time:35.312, tt:3566.546\n",
      "Ep:101, loss:0.00001, loss_test:0.01336, lr:4.71e-02, fs:0.81865 (r=0.798,p=0.840),  time:35.322, tt:3602.832\n",
      "Ep:102, loss:0.00001, loss_test:0.01310, lr:4.67e-02, fs:0.83938 (r=0.818,p=0.862),  time:35.315, tt:3637.403\n",
      "Ep:103, loss:0.00001, loss_test:0.01317, lr:4.62e-02, fs:0.83505 (r=0.818,p=0.853),  time:35.325, tt:3673.802\n",
      "Ep:104, loss:0.00001, loss_test:0.01358, lr:4.57e-02, fs:0.81053 (r=0.778,p=0.846),  time:35.328, tt:3709.438\n",
      "Ep:105, loss:0.00001, loss_test:0.01312, lr:4.53e-02, fs:0.84536 (r=0.828,p=0.863),  time:35.333, tt:3745.305\n",
      "Ep:106, loss:0.00001, loss_test:0.01328, lr:4.48e-02, fs:0.84375 (r=0.818,p=0.871),  time:35.349, tt:3782.380\n",
      "Ep:107, loss:0.00001, loss_test:0.01390, lr:4.44e-02, fs:0.79793 (r=0.778,p=0.819),  time:35.335, tt:3816.227\n",
      "Ep:108, loss:0.00001, loss_test:0.01292, lr:4.39e-02, fs:0.85128 (r=0.838,p=0.865),  time:35.346, tt:3852.758\n",
      "##########Best model found so far##########\n",
      "Ep:109, loss:0.00001, loss_test:0.01426, lr:4.39e-02, fs:0.79381 (r=0.778,p=0.811),  time:35.338, tt:3887.227\n",
      "Ep:110, loss:0.00001, loss_test:0.01287, lr:4.39e-02, fs:0.84103 (r=0.828,p=0.854),  time:35.344, tt:3923.215\n",
      "Ep:111, loss:0.00001, loss_test:0.01355, lr:4.39e-02, fs:0.81053 (r=0.778,p=0.846),  time:35.342, tt:3958.286\n",
      "Ep:112, loss:0.00001, loss_test:0.01338, lr:4.39e-02, fs:0.84375 (r=0.818,p=0.871),  time:35.330, tt:3992.281\n",
      "Ep:113, loss:0.00001, loss_test:0.01351, lr:4.39e-02, fs:0.84211 (r=0.808,p=0.879),  time:35.339, tt:4028.672\n",
      "Ep:114, loss:0.00001, loss_test:0.01390, lr:4.39e-02, fs:0.80423 (r=0.768,p=0.844),  time:35.349, tt:4065.103\n",
      "Ep:115, loss:0.00001, loss_test:0.01364, lr:4.39e-02, fs:0.83598 (r=0.798,p=0.878),  time:35.358, tt:4101.494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:116, loss:0.00001, loss_test:0.01415, lr:4.39e-02, fs:0.81081 (r=0.758,p=0.872),  time:35.371, tt:4138.455\n",
      "Ep:117, loss:0.00001, loss_test:0.01421, lr:4.39e-02, fs:0.82353 (r=0.778,p=0.875),  time:35.362, tt:4172.687\n",
      "Ep:118, loss:0.00000, loss_test:0.01409, lr:4.39e-02, fs:0.82979 (r=0.788,p=0.876),  time:35.356, tt:4207.350\n",
      "Ep:119, loss:0.00000, loss_test:0.01430, lr:4.39e-02, fs:0.80435 (r=0.747,p=0.871),  time:35.362, tt:4243.429\n",
      "Ep:120, loss:0.00000, loss_test:0.01465, lr:4.35e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.358, tt:4278.331\n",
      "Ep:121, loss:0.00000, loss_test:0.01431, lr:4.31e-02, fs:0.80220 (r=0.737,p=0.880),  time:35.360, tt:4313.918\n",
      "Ep:122, loss:0.00000, loss_test:0.01422, lr:4.26e-02, fs:0.81720 (r=0.768,p=0.874),  time:35.357, tt:4348.906\n",
      "Ep:123, loss:0.00000, loss_test:0.01478, lr:4.22e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.353, tt:4383.761\n",
      "Ep:124, loss:0.00000, loss_test:0.01491, lr:4.18e-02, fs:0.78889 (r=0.717,p=0.877),  time:35.354, tt:4419.302\n",
      "Ep:125, loss:0.00000, loss_test:0.01408, lr:4.14e-02, fs:0.81915 (r=0.778,p=0.865),  time:35.347, tt:4453.761\n",
      "Ep:126, loss:0.00000, loss_test:0.01488, lr:4.10e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.352, tt:4489.746\n",
      "Ep:127, loss:0.00000, loss_test:0.01456, lr:4.05e-02, fs:0.78889 (r=0.717,p=0.877),  time:35.351, tt:4524.865\n",
      "Ep:128, loss:0.00000, loss_test:0.01443, lr:4.01e-02, fs:0.78889 (r=0.717,p=0.877),  time:35.345, tt:4559.511\n",
      "Ep:129, loss:0.00000, loss_test:0.01493, lr:3.97e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.340, tt:4594.255\n",
      "Ep:130, loss:0.00000, loss_test:0.01467, lr:3.93e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.337, tt:4629.095\n",
      "Ep:131, loss:0.00000, loss_test:0.01490, lr:3.89e-02, fs:0.78652 (r=0.707,p=0.886),  time:35.339, tt:4664.682\n",
      "Ep:132, loss:0.00000, loss_test:0.01503, lr:3.86e-02, fs:0.78652 (r=0.707,p=0.886),  time:35.336, tt:4699.634\n",
      "Ep:133, loss:0.00000, loss_test:0.01490, lr:3.82e-02, fs:0.78652 (r=0.707,p=0.886),  time:35.332, tt:4734.496\n",
      "Ep:134, loss:0.00000, loss_test:0.01525, lr:3.78e-02, fs:0.76571 (r=0.677,p=0.882),  time:35.322, tt:4768.408\n",
      "Ep:135, loss:0.00000, loss_test:0.01498, lr:3.74e-02, fs:0.77966 (r=0.697,p=0.885),  time:35.320, tt:4803.579\n",
      "Ep:136, loss:0.00000, loss_test:0.01523, lr:3.70e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.313, tt:4837.914\n",
      "Ep:137, loss:0.00000, loss_test:0.01540, lr:3.67e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.309, tt:4872.689\n",
      "Ep:138, loss:0.00000, loss_test:0.01538, lr:3.63e-02, fs:0.75145 (r=0.657,p=0.878),  time:35.303, tt:4907.165\n",
      "Ep:139, loss:0.00000, loss_test:0.01539, lr:3.59e-02, fs:0.75145 (r=0.657,p=0.878),  time:35.304, tt:4942.498\n",
      "Ep:140, loss:0.00000, loss_test:0.01534, lr:3.56e-02, fs:0.75145 (r=0.657,p=0.878),  time:35.297, tt:4976.846\n",
      "Ep:141, loss:0.00000, loss_test:0.01547, lr:3.52e-02, fs:0.75145 (r=0.657,p=0.878),  time:35.301, tt:5012.746\n",
      "Ep:142, loss:0.00000, loss_test:0.01566, lr:3.49e-02, fs:0.74419 (r=0.646,p=0.877),  time:35.302, tt:5048.118\n",
      "Ep:143, loss:0.00000, loss_test:0.01548, lr:3.45e-02, fs:0.75145 (r=0.657,p=0.878),  time:35.295, tt:5082.484\n",
      "Ep:144, loss:0.00000, loss_test:0.01553, lr:3.42e-02, fs:0.75145 (r=0.657,p=0.878),  time:35.299, tt:5118.330\n",
      "Ep:145, loss:0.00000, loss_test:0.01588, lr:3.38e-02, fs:0.75581 (r=0.657,p=0.890),  time:35.293, tt:5152.744\n",
      "Ep:146, loss:0.00000, loss_test:0.01564, lr:3.35e-02, fs:0.75145 (r=0.657,p=0.878),  time:35.281, tt:5186.295\n",
      "Ep:147, loss:0.00000, loss_test:0.01563, lr:3.32e-02, fs:0.75145 (r=0.657,p=0.878),  time:35.284, tt:5221.990\n",
      "Ep:148, loss:0.00000, loss_test:0.01564, lr:3.28e-02, fs:0.75145 (r=0.657,p=0.878),  time:35.280, tt:5256.739\n",
      "Ep:149, loss:0.00000, loss_test:0.01596, lr:3.25e-02, fs:0.75581 (r=0.657,p=0.890),  time:35.277, tt:5291.527\n",
      "Ep:150, loss:0.00000, loss_test:0.01586, lr:3.22e-02, fs:0.75581 (r=0.657,p=0.890),  time:35.283, tt:5327.686\n",
      "Ep:151, loss:0.00000, loss_test:0.01593, lr:3.19e-02, fs:0.75581 (r=0.657,p=0.890),  time:35.281, tt:5362.689\n",
      "Ep:152, loss:0.00000, loss_test:0.01621, lr:3.15e-02, fs:0.75581 (r=0.657,p=0.890),  time:35.272, tt:5396.672\n",
      "Ep:153, loss:0.00000, loss_test:0.01565, lr:3.12e-02, fs:0.76023 (r=0.657,p=0.903),  time:35.267, tt:5431.047\n",
      "Ep:154, loss:0.00000, loss_test:0.01619, lr:3.09e-02, fs:0.75581 (r=0.657,p=0.890),  time:35.261, tt:5465.403\n",
      "Ep:155, loss:0.00000, loss_test:0.01629, lr:3.06e-02, fs:0.75581 (r=0.657,p=0.890),  time:35.262, tt:5500.945\n",
      "Ep:156, loss:0.00000, loss_test:0.01590, lr:3.03e-02, fs:0.75581 (r=0.657,p=0.890),  time:35.253, tt:5534.796\n",
      "Ep:157, loss:0.00000, loss_test:0.01610, lr:3.00e-02, fs:0.75581 (r=0.657,p=0.890),  time:35.248, tt:5569.207\n",
      "Ep:158, loss:0.00000, loss_test:0.01630, lr:2.97e-02, fs:0.76023 (r=0.657,p=0.903),  time:35.247, tt:5604.273\n",
      "Ep:159, loss:0.00000, loss_test:0.01609, lr:2.94e-02, fs:0.75581 (r=0.657,p=0.890),  time:35.233, tt:5637.270\n",
      "Ep:160, loss:0.00000, loss_test:0.01630, lr:2.91e-02, fs:0.76023 (r=0.657,p=0.903),  time:35.238, tt:5673.318\n",
      "Ep:161, loss:0.00000, loss_test:0.01637, lr:2.88e-02, fs:0.76023 (r=0.657,p=0.903),  time:35.248, tt:5710.250\n",
      "Ep:162, loss:0.00000, loss_test:0.01627, lr:2.85e-02, fs:0.76023 (r=0.657,p=0.903),  time:35.255, tt:5746.569\n",
      "Ep:163, loss:0.00000, loss_test:0.01638, lr:2.82e-02, fs:0.76023 (r=0.657,p=0.903),  time:35.262, tt:5782.972\n",
      "Ep:164, loss:0.00000, loss_test:0.01662, lr:2.80e-02, fs:0.76023 (r=0.657,p=0.903),  time:35.265, tt:5818.764\n",
      "Ep:165, loss:0.00000, loss_test:0.01643, lr:2.77e-02, fs:0.76023 (r=0.657,p=0.903),  time:35.258, tt:5852.909\n",
      "Ep:166, loss:0.00000, loss_test:0.01652, lr:2.74e-02, fs:0.76023 (r=0.657,p=0.903),  time:35.253, tt:5887.307\n",
      "Ep:167, loss:0.00000, loss_test:0.01657, lr:2.71e-02, fs:0.76023 (r=0.657,p=0.903),  time:35.256, tt:5923.062\n",
      "Ep:168, loss:0.00000, loss_test:0.01649, lr:2.69e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.263, tt:5959.376\n",
      "Ep:169, loss:0.00000, loss_test:0.01683, lr:2.66e-02, fs:0.76023 (r=0.657,p=0.903),  time:35.257, tt:5993.724\n",
      "Ep:170, loss:0.00000, loss_test:0.01640, lr:2.63e-02, fs:0.76023 (r=0.657,p=0.903),  time:35.256, tt:6028.856\n",
      "Ep:171, loss:0.00000, loss_test:0.01698, lr:2.61e-02, fs:0.76023 (r=0.657,p=0.903),  time:35.260, tt:6064.656\n",
      "Ep:172, loss:0.00000, loss_test:0.01656, lr:2.58e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.257, tt:6099.384\n",
      "Ep:173, loss:0.00000, loss_test:0.01681, lr:2.55e-02, fs:0.76023 (r=0.657,p=0.903),  time:35.248, tt:6133.087\n",
      "Ep:174, loss:0.00000, loss_test:0.01686, lr:2.53e-02, fs:0.76023 (r=0.657,p=0.903),  time:35.244, tt:6167.638\n",
      "Ep:175, loss:0.00000, loss_test:0.01643, lr:2.50e-02, fs:0.76023 (r=0.657,p=0.903),  time:35.234, tt:6201.260\n",
      "Ep:176, loss:0.00000, loss_test:0.01719, lr:2.48e-02, fs:0.76023 (r=0.657,p=0.903),  time:35.247, tt:6238.707\n",
      "Ep:177, loss:0.00000, loss_test:0.01654, lr:2.45e-02, fs:0.76023 (r=0.657,p=0.903),  time:35.233, tt:6271.494\n",
      "Ep:178, loss:0.00000, loss_test:0.01704, lr:2.43e-02, fs:0.76023 (r=0.657,p=0.903),  time:35.241, tt:6308.062\n",
      "Ep:179, loss:0.00000, loss_test:0.01660, lr:2.40e-02, fs:0.76023 (r=0.657,p=0.903),  time:35.241, tt:6343.444\n",
      "Ep:180, loss:0.00000, loss_test:0.01708, lr:2.38e-02, fs:0.76023 (r=0.657,p=0.903),  time:35.237, tt:6377.924\n",
      "Ep:181, loss:0.00000, loss_test:0.01667, lr:2.36e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.233, tt:6412.410\n",
      "Ep:182, loss:0.00000, loss_test:0.01711, lr:2.33e-02, fs:0.76023 (r=0.657,p=0.903),  time:35.238, tt:6448.634\n",
      "Ep:183, loss:0.00000, loss_test:0.01675, lr:2.31e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.242, tt:6484.621\n",
      "Ep:184, loss:0.00000, loss_test:0.01702, lr:2.29e-02, fs:0.76023 (r=0.657,p=0.903),  time:35.244, tt:6520.151\n",
      "Ep:185, loss:0.00000, loss_test:0.01701, lr:2.26e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.245, tt:6555.601\n",
      "Ep:186, loss:0.00000, loss_test:0.01694, lr:2.24e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.243, tt:6590.379\n",
      "Ep:187, loss:0.00000, loss_test:0.01710, lr:2.22e-02, fs:0.76023 (r=0.657,p=0.903),  time:35.250, tt:6626.947\n",
      "Ep:188, loss:0.00000, loss_test:0.01691, lr:2.20e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.255, tt:6663.235\n",
      "Ep:189, loss:0.00000, loss_test:0.01714, lr:2.17e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.248, tt:6697.127\n",
      "Ep:190, loss:0.00000, loss_test:0.01712, lr:2.15e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.259, tt:6734.381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:191, loss:0.00000, loss_test:0.01715, lr:2.13e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.262, tt:6770.371\n",
      "Ep:192, loss:0.00000, loss_test:0.01711, lr:2.11e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.261, tt:6805.299\n",
      "Ep:193, loss:0.00000, loss_test:0.01719, lr:2.09e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.257, tt:6839.845\n",
      "Ep:194, loss:0.00000, loss_test:0.01718, lr:2.07e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.262, tt:6876.087\n",
      "Ep:195, loss:0.00000, loss_test:0.01728, lr:2.05e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.259, tt:6910.690\n",
      "Ep:196, loss:0.00000, loss_test:0.01713, lr:2.03e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.263, tt:6946.876\n",
      "Ep:197, loss:0.00000, loss_test:0.01736, lr:2.01e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.265, tt:6982.516\n",
      "Ep:198, loss:0.00000, loss_test:0.01725, lr:1.99e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.267, tt:7018.203\n",
      "Ep:199, loss:0.00000, loss_test:0.01738, lr:1.97e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.267, tt:7053.418\n",
      "Ep:200, loss:0.00000, loss_test:0.01717, lr:1.95e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.264, tt:7087.981\n",
      "Ep:201, loss:0.00000, loss_test:0.01750, lr:1.93e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.261, tt:7122.688\n",
      "Ep:202, loss:0.00000, loss_test:0.01730, lr:1.91e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.258, tt:7157.424\n",
      "Ep:203, loss:0.00000, loss_test:0.01748, lr:1.89e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.259, tt:7192.862\n",
      "Ep:204, loss:0.00000, loss_test:0.01733, lr:1.87e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.269, tt:7230.118\n",
      "Ep:205, loss:0.00000, loss_test:0.01750, lr:1.85e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.277, tt:7267.065\n",
      "Ep:206, loss:0.00000, loss_test:0.01733, lr:1.83e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.259, tt:7298.655\n",
      "Ep:207, loss:0.00000, loss_test:0.01769, lr:1.81e-02, fs:0.76023 (r=0.657,p=0.903),  time:35.251, tt:7332.122\n",
      "Ep:208, loss:0.00000, loss_test:0.01729, lr:1.80e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.237, tt:7364.497\n",
      "Ep:209, loss:0.00000, loss_test:0.01764, lr:1.78e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.229, tt:7398.164\n",
      "Ep:210, loss:0.00000, loss_test:0.01739, lr:1.76e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.213, tt:7429.893\n",
      "Ep:211, loss:0.00000, loss_test:0.01764, lr:1.74e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.196, tt:7461.604\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14326, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.683, tt:36.683\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14128, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:35.713, tt:71.425\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13752, lr:1.00e-02, fs:0.67354 (r=0.990,p=0.510),  time:36.021, tt:108.062\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.13243, lr:1.00e-02, fs:0.64234 (r=0.889,p=0.503),  time:35.561, tt:142.243\n",
      "Ep:4, loss:0.00025, loss_test:0.12740, lr:1.00e-02, fs:0.66154 (r=0.869,p=0.534),  time:35.302, tt:176.510\n",
      "Ep:5, loss:0.00025, loss_test:0.12339, lr:1.00e-02, fs:0.66932 (r=0.848,p=0.553),  time:35.097, tt:210.585\n",
      "Ep:6, loss:0.00024, loss_test:0.12049, lr:1.00e-02, fs:0.67460 (r=0.859,p=0.556),  time:35.147, tt:246.031\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.11794, lr:1.00e-02, fs:0.68526 (r=0.869,p=0.566),  time:35.168, tt:281.341\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11577, lr:1.00e-02, fs:0.68273 (r=0.859,p=0.567),  time:35.349, tt:318.138\n",
      "Ep:9, loss:0.00023, loss_test:0.11272, lr:1.00e-02, fs:0.69421 (r=0.848,p=0.587),  time:35.362, tt:353.616\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.10835, lr:1.00e-02, fs:0.70886 (r=0.848,p=0.609),  time:35.345, tt:388.798\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.10509, lr:1.00e-02, fs:0.72174 (r=0.838,p=0.634),  time:35.843, tt:430.113\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.10276, lr:1.00e-02, fs:0.73362 (r=0.848,p=0.646),  time:35.759, tt:464.870\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.10030, lr:1.00e-02, fs:0.73128 (r=0.838,p=0.648),  time:35.841, tt:501.777\n",
      "Ep:14, loss:0.00020, loss_test:0.09676, lr:1.00e-02, fs:0.73778 (r=0.838,p=0.659),  time:35.847, tt:537.712\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.09585, lr:1.00e-02, fs:0.75221 (r=0.859,p=0.669),  time:35.846, tt:573.534\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.09280, lr:1.00e-02, fs:0.73733 (r=0.808,p=0.678),  time:35.910, tt:610.478\n",
      "Ep:17, loss:0.00018, loss_test:0.09137, lr:1.00e-02, fs:0.75576 (r=0.828,p=0.695),  time:35.893, tt:646.068\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.09080, lr:1.00e-02, fs:0.75000 (r=0.818,p=0.692),  time:35.924, tt:682.549\n",
      "Ep:19, loss:0.00016, loss_test:0.08923, lr:1.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:35.998, tt:719.970\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.09000, lr:1.00e-02, fs:0.79821 (r=0.899,p=0.718),  time:36.004, tt:756.082\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.08715, lr:1.00e-02, fs:0.79439 (r=0.859,p=0.739),  time:35.989, tt:791.747\n",
      "Ep:22, loss:0.00015, loss_test:0.08828, lr:1.00e-02, fs:0.78761 (r=0.899,p=0.701),  time:36.018, tt:828.417\n",
      "Ep:23, loss:0.00014, loss_test:0.08485, lr:1.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:36.051, tt:865.222\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.08468, lr:1.00e-02, fs:0.79279 (r=0.889,p=0.715),  time:36.079, tt:901.978\n",
      "Ep:25, loss:0.00014, loss_test:0.08285, lr:1.00e-02, fs:0.82407 (r=0.899,p=0.761),  time:36.105, tt:938.737\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.08379, lr:1.00e-02, fs:0.80909 (r=0.899,p=0.736),  time:36.147, tt:975.958\n",
      "Ep:27, loss:0.00013, loss_test:0.08094, lr:1.00e-02, fs:0.82407 (r=0.899,p=0.761),  time:36.225, tt:1014.297\n",
      "Ep:28, loss:0.00012, loss_test:0.07980, lr:1.00e-02, fs:0.82407 (r=0.899,p=0.761),  time:36.253, tt:1051.344\n",
      "Ep:29, loss:0.00012, loss_test:0.07813, lr:1.00e-02, fs:0.84112 (r=0.909,p=0.783),  time:36.265, tt:1087.964\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00012, loss_test:0.07639, lr:1.00e-02, fs:0.84906 (r=0.909,p=0.796),  time:36.297, tt:1125.200\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00011, loss_test:0.07536, lr:1.00e-02, fs:0.84112 (r=0.909,p=0.783),  time:36.325, tt:1162.391\n",
      "Ep:32, loss:0.00011, loss_test:0.07538, lr:1.00e-02, fs:0.83721 (r=0.909,p=0.776),  time:36.304, tt:1198.043\n",
      "Ep:33, loss:0.00010, loss_test:0.07572, lr:1.00e-02, fs:0.85714 (r=0.939,p=0.788),  time:36.297, tt:1234.098\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.07163, lr:1.00e-02, fs:0.87379 (r=0.909,p=0.841),  time:36.274, tt:1269.586\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00010, loss_test:0.07516, lr:1.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:36.257, tt:1305.269\n",
      "Ep:36, loss:0.00010, loss_test:0.07033, lr:1.00e-02, fs:0.85990 (r=0.899,p=0.824),  time:36.207, tt:1339.645\n",
      "Ep:37, loss:0.00009, loss_test:0.06742, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:36.175, tt:1374.652\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.07455, lr:1.00e-02, fs:0.85455 (r=0.949,p=0.777),  time:36.124, tt:1408.850\n",
      "Ep:39, loss:0.00010, loss_test:0.06779, lr:1.00e-02, fs:0.88372 (r=0.960,p=0.819),  time:36.146, tt:1445.846\n",
      "Ep:40, loss:0.00009, loss_test:0.06910, lr:1.00e-02, fs:0.88571 (r=0.939,p=0.838),  time:36.173, tt:1483.109\n",
      "Ep:41, loss:0.00009, loss_test:0.07591, lr:1.00e-02, fs:0.85321 (r=0.939,p=0.782),  time:36.184, tt:1519.713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:42, loss:0.00009, loss_test:0.06601, lr:1.00e-02, fs:0.89655 (r=0.919,p=0.875),  time:36.207, tt:1556.920\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00008, loss_test:0.06493, lr:1.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:36.253, tt:1595.119\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00008, loss_test:0.06720, lr:1.00e-02, fs:0.86916 (r=0.939,p=0.809),  time:36.261, tt:1631.729\n",
      "Ep:45, loss:0.00007, loss_test:0.06150, lr:1.00e-02, fs:0.93137 (r=0.960,p=0.905),  time:36.277, tt:1668.756\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00007, loss_test:0.06411, lr:1.00e-02, fs:0.90099 (r=0.919,p=0.883),  time:36.309, tt:1706.525\n",
      "Ep:47, loss:0.00007, loss_test:0.06428, lr:1.00e-02, fs:0.89401 (r=0.980,p=0.822),  time:36.324, tt:1743.533\n",
      "Ep:48, loss:0.00007, loss_test:0.06278, lr:1.00e-02, fs:0.92308 (r=0.970,p=0.881),  time:36.340, tt:1780.661\n",
      "Ep:49, loss:0.00006, loss_test:0.05795, lr:1.00e-02, fs:0.94175 (r=0.980,p=0.907),  time:36.339, tt:1816.929\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00007, loss_test:0.05954, lr:1.00e-02, fs:0.91176 (r=0.939,p=0.886),  time:36.320, tt:1852.337\n",
      "Ep:51, loss:0.00006, loss_test:0.06939, lr:1.00e-02, fs:0.85167 (r=0.899,p=0.809),  time:36.304, tt:1887.824\n",
      "Ep:52, loss:0.00006, loss_test:0.05717, lr:1.00e-02, fs:0.92611 (r=0.949,p=0.904),  time:36.288, tt:1923.248\n",
      "Ep:53, loss:0.00007, loss_test:0.05715, lr:1.00e-02, fs:0.93137 (r=0.960,p=0.905),  time:36.288, tt:1959.534\n",
      "Ep:54, loss:0.00006, loss_test:0.06836, lr:1.00e-02, fs:0.85981 (r=0.929,p=0.800),  time:36.304, tt:1996.737\n",
      "Ep:55, loss:0.00006, loss_test:0.05591, lr:1.00e-02, fs:0.93659 (r=0.970,p=0.906),  time:36.314, tt:2033.584\n",
      "Ep:56, loss:0.00006, loss_test:0.05609, lr:1.00e-02, fs:0.93596 (r=0.960,p=0.913),  time:36.278, tt:2067.819\n",
      "Ep:57, loss:0.00005, loss_test:0.05685, lr:1.00e-02, fs:0.95098 (r=0.980,p=0.924),  time:36.287, tt:2104.627\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00005, loss_test:0.05633, lr:1.00e-02, fs:0.92537 (r=0.939,p=0.912),  time:36.271, tt:2139.968\n",
      "Ep:59, loss:0.00005, loss_test:0.05363, lr:1.00e-02, fs:0.94686 (r=0.990,p=0.907),  time:36.250, tt:2175.004\n",
      "Ep:60, loss:0.00005, loss_test:0.05740, lr:1.00e-02, fs:0.93000 (r=0.939,p=0.921),  time:36.241, tt:2210.731\n",
      "Ep:61, loss:0.00005, loss_test:0.06114, lr:1.00e-02, fs:0.93596 (r=0.960,p=0.913),  time:36.245, tt:2247.194\n",
      "Ep:62, loss:0.00005, loss_test:0.05699, lr:1.00e-02, fs:0.93000 (r=0.939,p=0.921),  time:36.261, tt:2284.465\n",
      "Ep:63, loss:0.00004, loss_test:0.05589, lr:1.00e-02, fs:0.94581 (r=0.970,p=0.923),  time:36.252, tt:2320.112\n",
      "Ep:64, loss:0.00004, loss_test:0.05766, lr:1.00e-02, fs:0.93596 (r=0.960,p=0.913),  time:36.263, tt:2357.093\n",
      "Ep:65, loss:0.00004, loss_test:0.06473, lr:1.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:36.277, tt:2394.268\n",
      "Ep:66, loss:0.00005, loss_test:0.05654, lr:1.00e-02, fs:0.93000 (r=0.939,p=0.921),  time:36.259, tt:2429.367\n",
      "Ep:67, loss:0.00004, loss_test:0.05453, lr:1.00e-02, fs:0.92462 (r=0.929,p=0.920),  time:36.246, tt:2464.715\n",
      "Ep:68, loss:0.00004, loss_test:0.06029, lr:1.00e-02, fs:0.93596 (r=0.960,p=0.913),  time:36.276, tt:2503.044\n",
      "Ep:69, loss:0.00005, loss_test:0.06721, lr:9.90e-03, fs:0.82927 (r=0.859,p=0.802),  time:36.278, tt:2539.427\n",
      "Ep:70, loss:0.00005, loss_test:0.05466, lr:9.80e-03, fs:0.91919 (r=0.919,p=0.919),  time:36.271, tt:2575.256\n",
      "Ep:71, loss:0.00004, loss_test:0.05472, lr:9.70e-03, fs:0.92611 (r=0.949,p=0.904),  time:36.282, tt:2612.332\n",
      "Ep:72, loss:0.00004, loss_test:0.06585, lr:9.61e-03, fs:0.84058 (r=0.879,p=0.806),  time:36.308, tt:2650.492\n",
      "Ep:73, loss:0.00004, loss_test:0.05423, lr:9.51e-03, fs:0.92537 (r=0.939,p=0.912),  time:36.311, tt:2687.042\n",
      "Ep:74, loss:0.00004, loss_test:0.05983, lr:9.41e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.312, tt:2723.369\n",
      "Ep:75, loss:0.00004, loss_test:0.05263, lr:9.32e-03, fs:0.94581 (r=0.970,p=0.923),  time:36.309, tt:2759.497\n",
      "Ep:76, loss:0.00003, loss_test:0.05385, lr:9.23e-03, fs:0.91919 (r=0.919,p=0.919),  time:36.325, tt:2797.032\n",
      "Ep:77, loss:0.00003, loss_test:0.05659, lr:9.14e-03, fs:0.93401 (r=0.929,p=0.939),  time:36.342, tt:2834.655\n",
      "Ep:78, loss:0.00003, loss_test:0.05435, lr:9.04e-03, fs:0.92611 (r=0.949,p=0.904),  time:36.345, tt:2871.234\n",
      "Ep:79, loss:0.00003, loss_test:0.06061, lr:8.95e-03, fs:0.90355 (r=0.899,p=0.908),  time:36.334, tt:2906.737\n",
      "Ep:80, loss:0.00003, loss_test:0.05372, lr:8.86e-03, fs:0.92857 (r=0.919,p=0.938),  time:36.382, tt:2946.945\n",
      "Ep:81, loss:0.00003, loss_test:0.05723, lr:8.78e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.380, tt:2983.148\n",
      "Ep:82, loss:0.00003, loss_test:0.05599, lr:8.69e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.392, tt:3020.539\n",
      "Ep:83, loss:0.00003, loss_test:0.05462, lr:8.60e-03, fs:0.92386 (r=0.919,p=0.929),  time:36.404, tt:3057.942\n",
      "Ep:84, loss:0.00003, loss_test:0.05614, lr:8.51e-03, fs:0.91282 (r=0.899,p=0.927),  time:36.425, tt:3096.094\n",
      "Ep:85, loss:0.00003, loss_test:0.05599, lr:8.43e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.406, tt:3130.917\n",
      "Ep:86, loss:0.00003, loss_test:0.05554, lr:8.35e-03, fs:0.91282 (r=0.899,p=0.927),  time:36.400, tt:3166.815\n",
      "Ep:87, loss:0.00002, loss_test:0.05770, lr:8.26e-03, fs:0.87234 (r=0.828,p=0.921),  time:36.383, tt:3201.727\n",
      "Ep:88, loss:0.00002, loss_test:0.05660, lr:8.18e-03, fs:0.89583 (r=0.869,p=0.925),  time:36.392, tt:3238.870\n",
      "Ep:89, loss:0.00002, loss_test:0.05890, lr:8.10e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.420, tt:3277.841\n",
      "Ep:90, loss:0.00002, loss_test:0.05852, lr:8.02e-03, fs:0.88889 (r=0.848,p=0.933),  time:36.425, tt:3314.636\n",
      "Ep:91, loss:0.00003, loss_test:0.05870, lr:7.94e-03, fs:0.87097 (r=0.818,p=0.931),  time:36.429, tt:3351.450\n",
      "Ep:92, loss:0.00002, loss_test:0.05886, lr:7.86e-03, fs:0.85405 (r=0.798,p=0.919),  time:36.435, tt:3388.433\n",
      "Ep:93, loss:0.00002, loss_test:0.06203, lr:7.78e-03, fs:0.85106 (r=0.808,p=0.899),  time:36.445, tt:3425.875\n",
      "Ep:94, loss:0.00002, loss_test:0.05790, lr:7.70e-03, fs:0.86631 (r=0.818,p=0.920),  time:36.451, tt:3462.874\n",
      "Ep:95, loss:0.00002, loss_test:0.05886, lr:7.62e-03, fs:0.86486 (r=0.808,p=0.930),  time:36.457, tt:3499.882\n",
      "Ep:96, loss:0.00002, loss_test:0.05694, lr:7.55e-03, fs:0.84783 (r=0.788,p=0.918),  time:36.449, tt:3535.526\n",
      "Ep:97, loss:0.00002, loss_test:0.05902, lr:7.47e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.445, tt:3571.609\n",
      "Ep:98, loss:0.00002, loss_test:0.05907, lr:7.40e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.451, tt:3608.655\n",
      "Ep:99, loss:0.00002, loss_test:0.05765, lr:7.32e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.448, tt:3644.838\n",
      "Ep:100, loss:0.00002, loss_test:0.06093, lr:7.25e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.448, tt:3681.238\n",
      "Ep:101, loss:0.00002, loss_test:0.05877, lr:7.18e-03, fs:0.82873 (r=0.758,p=0.915),  time:36.449, tt:3717.798\n",
      "Ep:102, loss:0.00002, loss_test:0.06011, lr:7.11e-03, fs:0.87097 (r=0.818,p=0.931),  time:36.443, tt:3753.641\n",
      "Ep:103, loss:0.00002, loss_test:0.06098, lr:7.03e-03, fs:0.78857 (r=0.697,p=0.908),  time:36.438, tt:3789.576\n",
      "Ep:104, loss:0.00002, loss_test:0.06118, lr:6.96e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.441, tt:3826.258\n",
      "Ep:105, loss:0.00002, loss_test:0.05898, lr:6.89e-03, fs:0.81564 (r=0.737,p=0.912),  time:36.443, tt:3862.950\n",
      "Ep:106, loss:0.00002, loss_test:0.06173, lr:6.83e-03, fs:0.80000 (r=0.707,p=0.921),  time:36.447, tt:3899.834\n",
      "Ep:107, loss:0.00002, loss_test:0.06035, lr:6.76e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.462, tt:3937.882\n",
      "Ep:108, loss:0.00002, loss_test:0.06059, lr:6.69e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.472, tt:3975.457\n",
      "Ep:109, loss:0.00002, loss_test:0.06333, lr:6.62e-03, fs:0.79070 (r=0.687,p=0.932),  time:36.474, tt:4012.165\n",
      "Ep:110, loss:0.00002, loss_test:0.06095, lr:6.56e-03, fs:0.77457 (r=0.677,p=0.905),  time:36.483, tt:4049.658\n",
      "Ep:111, loss:0.00002, loss_test:0.06020, lr:6.49e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.487, tt:4086.541\n",
      "Ep:112, loss:0.00002, loss_test:0.06303, lr:6.43e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.498, tt:4124.311\n",
      "Ep:113, loss:0.00002, loss_test:0.06304, lr:6.36e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.513, tt:4162.450\n",
      "Ep:114, loss:0.00002, loss_test:0.06239, lr:6.30e-03, fs:0.75000 (r=0.636,p=0.913),  time:36.517, tt:4199.493\n",
      "Ep:115, loss:0.00002, loss_test:0.06263, lr:6.24e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.517, tt:4235.968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:116, loss:0.00002, loss_test:0.06292, lr:6.17e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.523, tt:4273.220\n",
      "Ep:117, loss:0.00002, loss_test:0.06348, lr:6.11e-03, fs:0.75000 (r=0.636,p=0.913),  time:36.538, tt:4311.497\n",
      "Ep:118, loss:0.00002, loss_test:0.06152, lr:6.05e-03, fs:0.80000 (r=0.707,p=0.921),  time:36.547, tt:4349.056\n",
      "Ep:119, loss:0.00002, loss_test:0.06457, lr:5.99e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.549, tt:4385.915\n",
      "Ep:120, loss:0.00002, loss_test:0.06293, lr:5.93e-03, fs:0.75000 (r=0.636,p=0.913),  time:36.553, tt:4422.862\n",
      "Ep:121, loss:0.00001, loss_test:0.06370, lr:5.87e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.551, tt:4459.245\n",
      "Ep:122, loss:0.00001, loss_test:0.06427, lr:5.81e-03, fs:0.75000 (r=0.636,p=0.913),  time:36.566, tt:4497.617\n",
      "Ep:123, loss:0.00001, loss_test:0.06481, lr:5.75e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.571, tt:4534.856\n",
      "Ep:124, loss:0.00001, loss_test:0.06415, lr:5.70e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.566, tt:4570.751\n",
      "Ep:125, loss:0.00001, loss_test:0.06367, lr:5.64e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.564, tt:4607.051\n",
      "Ep:126, loss:0.00001, loss_test:0.06606, lr:5.58e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.567, tt:4644.027\n",
      "Ep:127, loss:0.00001, loss_test:0.06331, lr:5.53e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.567, tt:4680.518\n",
      "Ep:128, loss:0.00001, loss_test:0.06429, lr:5.47e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.561, tt:4716.372\n",
      "Ep:129, loss:0.00001, loss_test:0.06458, lr:5.42e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.560, tt:4752.819\n",
      "Ep:130, loss:0.00001, loss_test:0.06542, lr:5.36e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.564, tt:4789.890\n",
      "Ep:131, loss:0.00001, loss_test:0.06490, lr:5.31e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.566, tt:4826.712\n",
      "Ep:132, loss:0.00001, loss_test:0.06506, lr:5.26e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.572, tt:4864.035\n",
      "Ep:133, loss:0.00001, loss_test:0.06509, lr:5.20e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.574, tt:4900.922\n",
      "Ep:134, loss:0.00001, loss_test:0.06507, lr:5.15e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.584, tt:4938.797\n",
      "Ep:135, loss:0.00001, loss_test:0.06418, lr:5.10e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.594, tt:4976.741\n",
      "Ep:136, loss:0.00001, loss_test:0.06664, lr:5.05e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.585, tt:5012.208\n",
      "Ep:137, loss:0.00001, loss_test:0.06465, lr:5.00e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.586, tt:5048.851\n",
      "Ep:138, loss:0.00001, loss_test:0.06661, lr:4.95e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.575, tt:5083.988\n",
      "Ep:139, loss:0.00001, loss_test:0.06615, lr:4.90e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.574, tt:5120.330\n",
      "Ep:140, loss:0.00001, loss_test:0.06582, lr:4.85e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.584, tt:5158.370\n",
      "Ep:141, loss:0.00001, loss_test:0.06532, lr:4.80e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.584, tt:5194.970\n",
      "Ep:142, loss:0.00001, loss_test:0.06736, lr:4.75e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.588, tt:5232.149\n",
      "Ep:143, loss:0.00001, loss_test:0.06686, lr:4.71e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.597, tt:5269.964\n",
      "Ep:144, loss:0.00001, loss_test:0.06597, lr:4.66e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.607, tt:5308.044\n",
      "Ep:145, loss:0.00001, loss_test:0.06687, lr:4.61e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.635, tt:5348.664\n",
      "Ep:146, loss:0.00001, loss_test:0.06579, lr:4.57e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.638, tt:5385.848\n",
      "Ep:147, loss:0.00001, loss_test:0.06772, lr:4.52e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.653, tt:5424.595\n",
      "Ep:148, loss:0.00001, loss_test:0.06645, lr:4.48e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.655, tt:5461.598\n",
      "Ep:149, loss:0.00001, loss_test:0.06713, lr:4.43e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.656, tt:5498.462\n",
      "Ep:150, loss:0.00001, loss_test:0.06555, lr:4.39e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.657, tt:5535.216\n",
      "Ep:151, loss:0.00001, loss_test:0.06845, lr:4.34e-03, fs:0.72727 (r=0.606,p=0.909),  time:36.663, tt:5572.717\n",
      "Ep:152, loss:0.00001, loss_test:0.06685, lr:4.30e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.677, tt:5611.585\n",
      "Ep:153, loss:0.00001, loss_test:0.06685, lr:4.26e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.681, tt:5648.799\n",
      "Ep:154, loss:0.00001, loss_test:0.06841, lr:4.21e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.691, tt:5687.074\n",
      "Ep:155, loss:0.00001, loss_test:0.06716, lr:4.17e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.688, tt:5723.364\n",
      "Ep:156, loss:0.00001, loss_test:0.06724, lr:4.13e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.703, tt:5762.380\n",
      "Ep:157, loss:0.00001, loss_test:0.06815, lr:4.09e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.694, tt:5797.667\n",
      "Ep:158, loss:0.00001, loss_test:0.06712, lr:4.05e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.698, tt:5834.945\n",
      "Ep:159, loss:0.00001, loss_test:0.06766, lr:4.01e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.699, tt:5871.852\n",
      "Ep:160, loss:0.00001, loss_test:0.06699, lr:3.97e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.713, tt:5910.807\n",
      "Ep:161, loss:0.00001, loss_test:0.06799, lr:3.93e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.723, tt:5949.079\n",
      "Ep:162, loss:0.00001, loss_test:0.06726, lr:3.89e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.728, tt:5986.706\n",
      "Ep:163, loss:0.00001, loss_test:0.06702, lr:3.85e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.747, tt:6026.449\n",
      "Ep:164, loss:0.00001, loss_test:0.06835, lr:3.81e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.780, tt:6068.740\n",
      "Ep:165, loss:0.00001, loss_test:0.06602, lr:3.77e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.785, tt:6106.363\n",
      "Ep:166, loss:0.00001, loss_test:0.06837, lr:3.73e-03, fs:0.71605 (r=0.586,p=0.921),  time:36.782, tt:6142.547\n",
      "Ep:167, loss:0.00001, loss_test:0.06654, lr:3.70e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.785, tt:6179.926\n",
      "Ep:168, loss:0.00001, loss_test:0.06825, lr:3.66e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.778, tt:6215.534\n",
      "Ep:169, loss:0.00001, loss_test:0.06675, lr:3.62e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.786, tt:6253.542\n",
      "Ep:170, loss:0.00001, loss_test:0.06824, lr:3.59e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.787, tt:6290.636\n",
      "Ep:171, loss:0.00001, loss_test:0.06765, lr:3.55e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.789, tt:6327.663\n",
      "Ep:172, loss:0.00001, loss_test:0.06745, lr:3.52e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.799, tt:6366.207\n",
      "Ep:173, loss:0.00001, loss_test:0.06950, lr:3.48e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.803, tt:6403.650\n",
      "Ep:174, loss:0.00001, loss_test:0.06776, lr:3.45e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.812, tt:6442.052\n",
      "Ep:175, loss:0.00001, loss_test:0.06748, lr:3.41e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.812, tt:6478.905\n",
      "Ep:176, loss:0.00001, loss_test:0.06864, lr:3.38e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.812, tt:6515.713\n",
      "Ep:177, loss:0.00001, loss_test:0.06913, lr:3.34e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.811, tt:6552.344\n",
      "Ep:178, loss:0.00001, loss_test:0.06802, lr:3.31e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.818, tt:6590.362\n",
      "Ep:179, loss:0.00001, loss_test:0.06794, lr:3.28e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.825, tt:6628.421\n",
      "Ep:180, loss:0.00001, loss_test:0.06800, lr:3.24e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.828, tt:6665.815\n",
      "Ep:181, loss:0.00001, loss_test:0.06843, lr:3.21e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.834, tt:6703.846\n",
      "Ep:182, loss:0.00001, loss_test:0.06808, lr:3.18e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.847, tt:6742.973\n",
      "Ep:183, loss:0.00001, loss_test:0.06772, lr:3.15e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.845, tt:6779.479\n",
      "Ep:184, loss:0.00001, loss_test:0.06912, lr:3.12e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.845, tt:6816.242\n",
      "Ep:185, loss:0.00001, loss_test:0.06844, lr:3.09e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.843, tt:6852.741\n",
      "Ep:186, loss:0.00001, loss_test:0.06815, lr:3.05e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.840, tt:6889.125\n",
      "Ep:187, loss:0.00001, loss_test:0.06859, lr:3.02e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.841, tt:6926.084\n",
      "Ep:188, loss:0.00001, loss_test:0.06776, lr:2.99e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.833, tt:6961.514\n",
      "Ep:189, loss:0.00001, loss_test:0.06844, lr:2.96e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.832, tt:6998.153\n",
      "Ep:190, loss:0.00001, loss_test:0.06811, lr:2.93e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.834, tt:7035.324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:191, loss:0.00001, loss_test:0.06914, lr:2.90e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.840, tt:7073.251\n",
      "Ep:192, loss:0.00001, loss_test:0.06840, lr:2.88e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.830, tt:7108.118\n",
      "Ep:193, loss:0.00001, loss_test:0.06829, lr:2.85e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.833, tt:7145.688\n",
      "Ep:194, loss:0.00001, loss_test:0.06846, lr:2.82e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.825, tt:7180.777\n",
      "Ep:195, loss:0.00001, loss_test:0.06812, lr:2.79e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.829, tt:7218.580\n",
      "Ep:196, loss:0.00001, loss_test:0.06860, lr:2.76e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.839, tt:7257.191\n",
      "Ep:197, loss:0.00001, loss_test:0.06873, lr:2.73e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.837, tt:7293.786\n",
      "Ep:198, loss:0.00001, loss_test:0.06862, lr:2.71e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.830, tt:7329.155\n",
      "Ep:199, loss:0.00001, loss_test:0.06849, lr:2.68e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.827, tt:7365.422\n",
      "Ep:200, loss:0.00001, loss_test:0.06839, lr:2.65e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.818, tt:7400.370\n",
      "Ep:201, loss:0.00001, loss_test:0.06920, lr:2.63e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.816, tt:7436.901\n",
      "Ep:202, loss:0.00001, loss_test:0.06847, lr:2.60e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.823, tt:7475.159\n",
      "Ep:203, loss:0.00001, loss_test:0.06889, lr:2.57e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.822, tt:7511.787\n",
      "Ep:204, loss:0.00001, loss_test:0.06900, lr:2.55e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.820, tt:7548.180\n",
      "Ep:205, loss:0.00001, loss_test:0.06825, lr:2.52e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.817, tt:7584.372\n",
      "Ep:206, loss:0.00001, loss_test:0.06918, lr:2.50e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.812, tt:7620.111\n",
      "Ep:207, loss:0.00001, loss_test:0.06887, lr:2.47e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.790, tt:7652.243\n",
      "Ep:208, loss:0.00001, loss_test:0.06904, lr:2.45e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.776, tt:7686.214\n",
      "Ep:209, loss:0.00001, loss_test:0.06973, lr:2.42e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.758, tt:7719.081\n",
      "Ep:210, loss:0.00001, loss_test:0.06886, lr:2.40e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.735, tt:7751.080\n",
      "Ep:211, loss:0.00001, loss_test:0.06928, lr:2.38e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.705, tt:7781.402\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00011, loss_test:0.02203, lr:6.00e-02, fs:0.65863 (r=0.828,p=0.547),  time:36.233, tt:36.233\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02485, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.262, tt:72.524\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02822, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.786, tt:107.357\n",
      "Ep:3, loss:0.00005, loss_test:0.02907, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.308, tt:141.232\n",
      "Ep:4, loss:0.00005, loss_test:0.02896, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.395, tt:171.976\n",
      "Ep:5, loss:0.00005, loss_test:0.02813, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.735, tt:202.412\n",
      "Ep:6, loss:0.00005, loss_test:0.02671, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.762, tt:236.334\n",
      "Ep:7, loss:0.00005, loss_test:0.02511, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.825, tt:270.602\n",
      "Ep:8, loss:0.00005, loss_test:0.02357, lr:6.00e-02, fs:0.67128 (r=0.980,p=0.511),  time:33.959, tt:305.627\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.02241, lr:6.00e-02, fs:0.65441 (r=0.899,p=0.514),  time:34.003, tt:340.029\n",
      "Ep:10, loss:0.00004, loss_test:0.02177, lr:6.00e-02, fs:0.65649 (r=0.869,p=0.528),  time:34.200, tt:376.196\n",
      "Ep:11, loss:0.00004, loss_test:0.02121, lr:6.00e-02, fs:0.66148 (r=0.859,p=0.538),  time:34.398, tt:412.770\n",
      "Ep:12, loss:0.00004, loss_test:0.02045, lr:6.00e-02, fs:0.66926 (r=0.869,p=0.544),  time:34.411, tt:447.344\n",
      "Ep:13, loss:0.00004, loss_test:0.01990, lr:6.00e-02, fs:0.67433 (r=0.889,p=0.543),  time:34.510, tt:483.144\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01949, lr:6.00e-02, fs:0.67176 (r=0.889,p=0.540),  time:34.626, tt:519.393\n",
      "Ep:15, loss:0.00004, loss_test:0.01910, lr:6.00e-02, fs:0.68679 (r=0.919,p=0.548),  time:34.687, tt:554.997\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.01864, lr:6.00e-02, fs:0.68441 (r=0.909,p=0.549),  time:34.865, tt:592.697\n",
      "Ep:17, loss:0.00004, loss_test:0.01824, lr:6.00e-02, fs:0.68235 (r=0.879,p=0.558),  time:34.857, tt:627.424\n",
      "Ep:18, loss:0.00004, loss_test:0.01793, lr:6.00e-02, fs:0.68504 (r=0.879,p=0.561),  time:34.881, tt:662.742\n",
      "Ep:19, loss:0.00003, loss_test:0.01766, lr:6.00e-02, fs:0.69048 (r=0.879,p=0.569),  time:34.961, tt:699.214\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01739, lr:6.00e-02, fs:0.69841 (r=0.889,p=0.575),  time:35.001, tt:735.029\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01713, lr:6.00e-02, fs:0.70312 (r=0.909,p=0.573),  time:35.033, tt:770.718\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01688, lr:6.00e-02, fs:0.70312 (r=0.909,p=0.573),  time:35.085, tt:806.951\n",
      "Ep:23, loss:0.00003, loss_test:0.01667, lr:6.00e-02, fs:0.72656 (r=0.939,p=0.592),  time:35.122, tt:842.934\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01653, lr:6.00e-02, fs:0.72727 (r=0.929,p=0.597),  time:35.139, tt:878.484\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01645, lr:6.00e-02, fs:0.72289 (r=0.909,p=0.600),  time:35.128, tt:913.332\n",
      "Ep:26, loss:0.00003, loss_test:0.01637, lr:6.00e-02, fs:0.72800 (r=0.919,p=0.603),  time:35.109, tt:947.941\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01627, lr:6.00e-02, fs:0.73684 (r=0.919,p=0.615),  time:35.102, tt:982.869\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01616, lr:6.00e-02, fs:0.74797 (r=0.929,p=0.626),  time:35.182, tt:1020.270\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01606, lr:6.00e-02, fs:0.76230 (r=0.939,p=0.641),  time:35.215, tt:1056.459\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01598, lr:6.00e-02, fs:0.76230 (r=0.939,p=0.641),  time:35.209, tt:1091.472\n",
      "Ep:31, loss:0.00002, loss_test:0.01589, lr:6.00e-02, fs:0.77824 (r=0.939,p=0.664),  time:35.207, tt:1126.631\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01575, lr:6.00e-02, fs:0.78112 (r=0.919,p=0.679),  time:35.202, tt:1161.682\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01558, lr:6.00e-02, fs:0.78632 (r=0.929,p=0.681),  time:35.185, tt:1196.295\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01541, lr:6.00e-02, fs:0.79310 (r=0.929,p=0.692),  time:35.186, tt:1231.509\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01524, lr:6.00e-02, fs:0.79654 (r=0.929,p=0.697),  time:35.270, tt:1269.725\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01513, lr:6.00e-02, fs:0.79654 (r=0.929,p=0.697),  time:35.261, tt:1304.664\n",
      "Ep:37, loss:0.00002, loss_test:0.01502, lr:6.00e-02, fs:0.80176 (r=0.919,p=0.711),  time:35.294, tt:1341.184\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01495, lr:6.00e-02, fs:0.79646 (r=0.909,p=0.709),  time:35.256, tt:1375.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:39, loss:0.00002, loss_test:0.01488, lr:6.00e-02, fs:0.79295 (r=0.909,p=0.703),  time:35.230, tt:1409.202\n",
      "Ep:40, loss:0.00002, loss_test:0.01480, lr:6.00e-02, fs:0.80349 (r=0.929,p=0.708),  time:35.239, tt:1444.789\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01478, lr:6.00e-02, fs:0.80531 (r=0.919,p=0.717),  time:35.243, tt:1480.192\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01479, lr:6.00e-02, fs:0.80000 (r=0.909,p=0.714),  time:35.230, tt:1514.880\n",
      "Ep:43, loss:0.00001, loss_test:0.01477, lr:6.00e-02, fs:0.80357 (r=0.909,p=0.720),  time:35.262, tt:1551.513\n",
      "Ep:44, loss:0.00001, loss_test:0.01476, lr:6.00e-02, fs:0.81081 (r=0.909,p=0.732),  time:35.246, tt:1586.056\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.01480, lr:6.00e-02, fs:0.80365 (r=0.889,p=0.733),  time:35.259, tt:1621.898\n",
      "Ep:46, loss:0.00001, loss_test:0.01488, lr:6.00e-02, fs:0.79817 (r=0.879,p=0.731),  time:35.279, tt:1658.129\n",
      "Ep:47, loss:0.00001, loss_test:0.01492, lr:6.00e-02, fs:0.79812 (r=0.859,p=0.746),  time:35.287, tt:1693.785\n",
      "Ep:48, loss:0.00001, loss_test:0.01498, lr:6.00e-02, fs:0.78673 (r=0.838,p=0.741),  time:35.314, tt:1730.364\n",
      "Ep:49, loss:0.00001, loss_test:0.01502, lr:6.00e-02, fs:0.78095 (r=0.828,p=0.739),  time:35.359, tt:1767.932\n",
      "Ep:50, loss:0.00001, loss_test:0.01509, lr:6.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:35.364, tt:1803.571\n",
      "Ep:51, loss:0.00001, loss_test:0.01519, lr:6.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:35.345, tt:1837.951\n",
      "Ep:52, loss:0.00001, loss_test:0.01524, lr:6.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:35.299, tt:1870.871\n",
      "Ep:53, loss:0.00001, loss_test:0.01528, lr:6.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:35.316, tt:1907.074\n",
      "Ep:54, loss:0.00001, loss_test:0.01535, lr:6.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:35.303, tt:1941.656\n",
      "Ep:55, loss:0.00001, loss_test:0.01544, lr:6.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:35.314, tt:1977.574\n",
      "Ep:56, loss:0.00001, loss_test:0.01554, lr:5.94e-02, fs:0.78261 (r=0.818,p=0.750),  time:35.313, tt:2012.849\n",
      "Ep:57, loss:0.00001, loss_test:0.01564, lr:5.88e-02, fs:0.79612 (r=0.828,p=0.766),  time:35.312, tt:2048.087\n",
      "Ep:58, loss:0.00001, loss_test:0.01570, lr:5.82e-02, fs:0.79227 (r=0.828,p=0.759),  time:35.308, tt:2083.170\n",
      "Ep:59, loss:0.00001, loss_test:0.01576, lr:5.76e-02, fs:0.79412 (r=0.818,p=0.771),  time:35.311, tt:2118.657\n",
      "Ep:60, loss:0.00001, loss_test:0.01588, lr:5.71e-02, fs:0.79803 (r=0.818,p=0.779),  time:35.299, tt:2153.218\n",
      "Ep:61, loss:0.00001, loss_test:0.01599, lr:5.65e-02, fs:0.80198 (r=0.818,p=0.786),  time:35.296, tt:2188.371\n",
      "Ep:62, loss:0.00001, loss_test:0.01597, lr:5.59e-02, fs:0.80198 (r=0.818,p=0.786),  time:35.313, tt:2224.702\n",
      "Ep:63, loss:0.00001, loss_test:0.01608, lr:5.54e-02, fs:0.80198 (r=0.818,p=0.786),  time:35.313, tt:2260.046\n",
      "Ep:64, loss:0.00001, loss_test:0.01623, lr:5.48e-02, fs:0.80198 (r=0.818,p=0.786),  time:35.359, tt:2298.356\n",
      "Ep:65, loss:0.00001, loss_test:0.01626, lr:5.43e-02, fs:0.80198 (r=0.818,p=0.786),  time:35.372, tt:2334.523\n",
      "Ep:66, loss:0.00001, loss_test:0.01632, lr:5.37e-02, fs:0.80198 (r=0.818,p=0.786),  time:35.356, tt:2368.866\n",
      "Ep:67, loss:0.00001, loss_test:0.01642, lr:5.32e-02, fs:0.80597 (r=0.818,p=0.794),  time:35.343, tt:2403.297\n",
      "Ep:68, loss:0.00001, loss_test:0.01650, lr:5.27e-02, fs:0.80203 (r=0.798,p=0.806),  time:35.319, tt:2436.992\n",
      "Ep:69, loss:0.00001, loss_test:0.01656, lr:5.21e-02, fs:0.80808 (r=0.808,p=0.808),  time:35.295, tt:2470.622\n",
      "Ep:70, loss:0.00001, loss_test:0.01660, lr:5.16e-02, fs:0.80000 (r=0.788,p=0.812),  time:35.287, tt:2505.365\n",
      "Ep:71, loss:0.00001, loss_test:0.01672, lr:5.11e-02, fs:0.79381 (r=0.778,p=0.811),  time:35.312, tt:2542.468\n",
      "Ep:72, loss:0.00001, loss_test:0.01682, lr:5.06e-02, fs:0.78974 (r=0.778,p=0.802),  time:35.312, tt:2577.752\n",
      "Ep:73, loss:0.00001, loss_test:0.01684, lr:5.01e-02, fs:0.80412 (r=0.788,p=0.821),  time:35.329, tt:2614.333\n",
      "Ep:74, loss:0.00001, loss_test:0.01697, lr:4.96e-02, fs:0.79793 (r=0.778,p=0.819),  time:35.333, tt:2649.976\n",
      "Ep:75, loss:0.00001, loss_test:0.01707, lr:4.91e-02, fs:0.80000 (r=0.768,p=0.835),  time:35.321, tt:2684.387\n",
      "Ep:76, loss:0.00001, loss_test:0.01711, lr:4.86e-02, fs:0.80000 (r=0.768,p=0.835),  time:35.302, tt:2718.267\n",
      "Ep:77, loss:0.00001, loss_test:0.01723, lr:4.81e-02, fs:0.77419 (r=0.727,p=0.828),  time:35.296, tt:2753.107\n",
      "Ep:78, loss:0.00001, loss_test:0.01733, lr:4.76e-02, fs:0.76757 (r=0.717,p=0.826),  time:35.289, tt:2787.811\n",
      "Ep:79, loss:0.00001, loss_test:0.01743, lr:4.71e-02, fs:0.74725 (r=0.687,p=0.819),  time:35.288, tt:2823.000\n",
      "Ep:80, loss:0.00001, loss_test:0.01749, lr:4.67e-02, fs:0.72222 (r=0.657,p=0.802),  time:35.253, tt:2855.460\n",
      "Ep:81, loss:0.00001, loss_test:0.01758, lr:4.62e-02, fs:0.72222 (r=0.657,p=0.802),  time:35.207, tt:2886.957\n",
      "Ep:82, loss:0.00001, loss_test:0.01765, lr:4.57e-02, fs:0.71508 (r=0.646,p=0.800),  time:35.221, tt:2923.336\n",
      "Ep:83, loss:0.00001, loss_test:0.01775, lr:4.53e-02, fs:0.71508 (r=0.646,p=0.800),  time:35.233, tt:2959.539\n",
      "Ep:84, loss:0.00001, loss_test:0.01786, lr:4.48e-02, fs:0.71910 (r=0.646,p=0.810),  time:35.232, tt:2994.755\n",
      "Ep:85, loss:0.00001, loss_test:0.01793, lr:4.44e-02, fs:0.72316 (r=0.646,p=0.821),  time:35.221, tt:3029.020\n",
      "Ep:86, loss:0.00001, loss_test:0.01799, lr:4.39e-02, fs:0.71910 (r=0.646,p=0.810),  time:35.206, tt:3062.942\n",
      "Ep:87, loss:0.00001, loss_test:0.01811, lr:4.35e-02, fs:0.71186 (r=0.636,p=0.808),  time:35.184, tt:3096.177\n",
      "Ep:88, loss:0.00000, loss_test:0.01816, lr:4.31e-02, fs:0.71591 (r=0.636,p=0.818),  time:35.178, tt:3130.876\n",
      "Ep:89, loss:0.00000, loss_test:0.01826, lr:4.26e-02, fs:0.72000 (r=0.636,p=0.829),  time:35.170, tt:3165.260\n",
      "Ep:90, loss:0.00000, loss_test:0.01838, lr:4.22e-02, fs:0.71264 (r=0.626,p=0.827),  time:35.155, tt:3199.075\n",
      "Ep:91, loss:0.00000, loss_test:0.01842, lr:4.18e-02, fs:0.70520 (r=0.616,p=0.824),  time:35.140, tt:3232.915\n",
      "Ep:92, loss:0.00000, loss_test:0.01848, lr:4.14e-02, fs:0.69767 (r=0.606,p=0.822),  time:35.145, tt:3268.510\n",
      "Ep:93, loss:0.00000, loss_test:0.01859, lr:4.10e-02, fs:0.69767 (r=0.606,p=0.822),  time:35.147, tt:3303.800\n",
      "Ep:94, loss:0.00000, loss_test:0.01866, lr:4.05e-02, fs:0.69767 (r=0.606,p=0.822),  time:35.134, tt:3337.761\n",
      "Ep:95, loss:0.00000, loss_test:0.01872, lr:4.01e-02, fs:0.69767 (r=0.606,p=0.822),  time:35.114, tt:3370.936\n",
      "Ep:96, loss:0.00000, loss_test:0.01883, lr:3.97e-02, fs:0.69767 (r=0.606,p=0.822),  time:35.099, tt:3404.571\n",
      "Ep:97, loss:0.00000, loss_test:0.01889, lr:3.93e-02, fs:0.69767 (r=0.606,p=0.822),  time:35.078, tt:3437.654\n",
      "Ep:98, loss:0.00000, loss_test:0.01898, lr:3.89e-02, fs:0.69006 (r=0.596,p=0.819),  time:35.074, tt:3472.326\n",
      "Ep:99, loss:0.00000, loss_test:0.01905, lr:3.86e-02, fs:0.69006 (r=0.596,p=0.819),  time:35.055, tt:3505.516\n",
      "Ep:100, loss:0.00000, loss_test:0.01912, lr:3.82e-02, fs:0.69006 (r=0.596,p=0.819),  time:35.042, tt:3539.223\n",
      "Ep:101, loss:0.00000, loss_test:0.01921, lr:3.78e-02, fs:0.69006 (r=0.596,p=0.819),  time:35.028, tt:3572.844\n",
      "Ep:102, loss:0.00000, loss_test:0.01928, lr:3.74e-02, fs:0.69006 (r=0.596,p=0.819),  time:35.026, tt:3607.705\n",
      "Ep:103, loss:0.00000, loss_test:0.01938, lr:3.70e-02, fs:0.69006 (r=0.596,p=0.819),  time:35.021, tt:3642.184\n",
      "Ep:104, loss:0.00000, loss_test:0.01942, lr:3.67e-02, fs:0.69006 (r=0.596,p=0.819),  time:35.013, tt:3676.358\n",
      "Ep:105, loss:0.00000, loss_test:0.01948, lr:3.63e-02, fs:0.69412 (r=0.596,p=0.831),  time:35.021, tt:3712.206\n",
      "Ep:106, loss:0.00000, loss_test:0.01956, lr:3.59e-02, fs:0.69412 (r=0.596,p=0.831),  time:35.010, tt:3746.065\n",
      "Ep:107, loss:0.00000, loss_test:0.01963, lr:3.56e-02, fs:0.69822 (r=0.596,p=0.843),  time:35.018, tt:3781.958\n",
      "Ep:108, loss:0.00000, loss_test:0.01971, lr:3.52e-02, fs:0.69822 (r=0.596,p=0.843),  time:35.030, tt:3818.298\n",
      "Ep:109, loss:0.00000, loss_test:0.01975, lr:3.49e-02, fs:0.69822 (r=0.596,p=0.843),  time:35.031, tt:3853.381\n",
      "Ep:110, loss:0.00000, loss_test:0.01983, lr:3.45e-02, fs:0.69822 (r=0.596,p=0.843),  time:35.027, tt:3887.959\n",
      "Ep:111, loss:0.00000, loss_test:0.01991, lr:3.42e-02, fs:0.69822 (r=0.596,p=0.843),  time:35.037, tt:3924.118\n",
      "Ep:112, loss:0.00000, loss_test:0.01995, lr:3.38e-02, fs:0.69822 (r=0.596,p=0.843),  time:35.032, tt:3958.657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:113, loss:0.00000, loss_test:0.02002, lr:3.35e-02, fs:0.69822 (r=0.596,p=0.843),  time:35.050, tt:3995.690\n",
      "Ep:114, loss:0.00000, loss_test:0.02013, lr:3.32e-02, fs:0.69822 (r=0.596,p=0.843),  time:35.048, tt:4030.474\n",
      "Ep:115, loss:0.00000, loss_test:0.02020, lr:3.28e-02, fs:0.69822 (r=0.596,p=0.843),  time:35.059, tt:4066.870\n",
      "Ep:116, loss:0.00000, loss_test:0.02026, lr:3.25e-02, fs:0.69822 (r=0.596,p=0.843),  time:35.074, tt:4103.625\n",
      "Ep:117, loss:0.00000, loss_test:0.02031, lr:3.22e-02, fs:0.69822 (r=0.596,p=0.843),  time:35.088, tt:4140.420\n",
      "Ep:118, loss:0.00000, loss_test:0.02036, lr:3.19e-02, fs:0.69822 (r=0.596,p=0.843),  time:35.090, tt:4175.758\n",
      "Ep:119, loss:0.00000, loss_test:0.02043, lr:3.15e-02, fs:0.70238 (r=0.596,p=0.855),  time:35.091, tt:4210.978\n",
      "Ep:120, loss:0.00000, loss_test:0.02052, lr:3.12e-02, fs:0.70238 (r=0.596,p=0.855),  time:35.092, tt:4246.186\n",
      "Ep:121, loss:0.00000, loss_test:0.02059, lr:3.09e-02, fs:0.70238 (r=0.596,p=0.855),  time:35.092, tt:4281.226\n",
      "Ep:122, loss:0.00000, loss_test:0.02065, lr:3.06e-02, fs:0.70659 (r=0.596,p=0.868),  time:35.111, tt:4318.601\n",
      "Ep:123, loss:0.00000, loss_test:0.02070, lr:3.03e-02, fs:0.70659 (r=0.596,p=0.868),  time:35.123, tt:4355.194\n",
      "Ep:124, loss:0.00000, loss_test:0.02075, lr:3.00e-02, fs:0.70659 (r=0.596,p=0.868),  time:35.126, tt:4390.703\n",
      "Ep:125, loss:0.00000, loss_test:0.02082, lr:2.97e-02, fs:0.70659 (r=0.596,p=0.868),  time:35.135, tt:4427.071\n",
      "Ep:126, loss:0.00000, loss_test:0.02086, lr:2.94e-02, fs:0.70659 (r=0.596,p=0.868),  time:35.128, tt:4461.267\n",
      "Ep:127, loss:0.00000, loss_test:0.02091, lr:2.91e-02, fs:0.70659 (r=0.596,p=0.868),  time:35.133, tt:4496.997\n",
      "Ep:128, loss:0.00000, loss_test:0.02098, lr:2.88e-02, fs:0.70659 (r=0.596,p=0.868),  time:35.130, tt:4531.751\n",
      "Ep:129, loss:0.00000, loss_test:0.02105, lr:2.85e-02, fs:0.70659 (r=0.596,p=0.868),  time:35.130, tt:4566.925\n",
      "Ep:130, loss:0.00000, loss_test:0.02109, lr:2.82e-02, fs:0.70659 (r=0.596,p=0.868),  time:35.135, tt:4602.688\n",
      "Ep:131, loss:0.00000, loss_test:0.02112, lr:2.80e-02, fs:0.71084 (r=0.596,p=0.881),  time:35.142, tt:4638.763\n",
      "Ep:132, loss:0.00000, loss_test:0.02121, lr:2.77e-02, fs:0.71084 (r=0.596,p=0.881),  time:35.153, tt:4675.346\n",
      "Ep:133, loss:0.00000, loss_test:0.02129, lr:2.74e-02, fs:0.71084 (r=0.596,p=0.881),  time:35.155, tt:4710.781\n",
      "Ep:134, loss:0.00000, loss_test:0.02133, lr:2.71e-02, fs:0.71084 (r=0.596,p=0.881),  time:35.159, tt:4746.400\n",
      "Ep:135, loss:0.00000, loss_test:0.02137, lr:2.69e-02, fs:0.71084 (r=0.596,p=0.881),  time:35.163, tt:4782.107\n",
      "Ep:136, loss:0.00000, loss_test:0.02143, lr:2.66e-02, fs:0.71084 (r=0.596,p=0.881),  time:35.160, tt:4816.895\n",
      "Ep:137, loss:0.00000, loss_test:0.02152, lr:2.63e-02, fs:0.71084 (r=0.596,p=0.881),  time:35.167, tt:4853.072\n",
      "Ep:138, loss:0.00000, loss_test:0.02155, lr:2.61e-02, fs:0.71084 (r=0.596,p=0.881),  time:35.159, tt:4887.060\n",
      "Ep:139, loss:0.00000, loss_test:0.02160, lr:2.58e-02, fs:0.71084 (r=0.596,p=0.881),  time:35.165, tt:4923.156\n",
      "Ep:140, loss:0.00000, loss_test:0.02165, lr:2.55e-02, fs:0.71084 (r=0.596,p=0.881),  time:35.177, tt:4960.023\n",
      "Ep:141, loss:0.00000, loss_test:0.02169, lr:2.53e-02, fs:0.71084 (r=0.596,p=0.881),  time:35.178, tt:4995.295\n",
      "Ep:142, loss:0.00000, loss_test:0.02174, lr:2.50e-02, fs:0.71084 (r=0.596,p=0.881),  time:35.175, tt:5029.953\n",
      "Ep:143, loss:0.00000, loss_test:0.02180, lr:2.48e-02, fs:0.71084 (r=0.596,p=0.881),  time:35.184, tt:5066.544\n",
      "Ep:144, loss:0.00000, loss_test:0.02186, lr:2.45e-02, fs:0.71084 (r=0.596,p=0.881),  time:35.195, tt:5103.331\n",
      "Ep:145, loss:0.00000, loss_test:0.02189, lr:2.43e-02, fs:0.71084 (r=0.596,p=0.881),  time:35.196, tt:5138.633\n",
      "Ep:146, loss:0.00000, loss_test:0.02194, lr:2.40e-02, fs:0.71084 (r=0.596,p=0.881),  time:35.188, tt:5172.667\n",
      "Ep:147, loss:0.00000, loss_test:0.02199, lr:2.38e-02, fs:0.71084 (r=0.596,p=0.881),  time:35.181, tt:5206.742\n",
      "Ep:148, loss:0.00000, loss_test:0.02203, lr:2.36e-02, fs:0.71084 (r=0.596,p=0.881),  time:35.180, tt:5241.842\n",
      "Ep:149, loss:0.00000, loss_test:0.02207, lr:2.33e-02, fs:0.71084 (r=0.596,p=0.881),  time:35.183, tt:5277.393\n",
      "Ep:150, loss:0.00000, loss_test:0.02212, lr:2.31e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.182, tt:5312.557\n",
      "Ep:151, loss:0.00000, loss_test:0.02218, lr:2.29e-02, fs:0.71084 (r=0.596,p=0.881),  time:35.179, tt:5347.203\n",
      "Ep:152, loss:0.00000, loss_test:0.02221, lr:2.26e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.178, tt:5382.239\n",
      "Ep:153, loss:0.00000, loss_test:0.02223, lr:2.24e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.181, tt:5417.938\n",
      "Ep:154, loss:0.00000, loss_test:0.02228, lr:2.22e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.176, tt:5452.289\n",
      "Ep:155, loss:0.00000, loss_test:0.02232, lr:2.20e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.180, tt:5488.085\n",
      "Ep:156, loss:0.00000, loss_test:0.02234, lr:2.17e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.180, tt:5523.336\n",
      "Ep:157, loss:0.00000, loss_test:0.02238, lr:2.15e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.179, tt:5558.250\n",
      "Ep:158, loss:0.00000, loss_test:0.02243, lr:2.13e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.186, tt:5594.517\n",
      "Ep:159, loss:0.00000, loss_test:0.02247, lr:2.11e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.193, tt:5630.876\n",
      "Ep:160, loss:0.00000, loss_test:0.02249, lr:2.09e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.202, tt:5667.563\n",
      "Ep:161, loss:0.00000, loss_test:0.02254, lr:2.07e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.198, tt:5702.010\n",
      "Ep:162, loss:0.00000, loss_test:0.02258, lr:2.05e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.199, tt:5737.517\n",
      "Ep:163, loss:0.00000, loss_test:0.02261, lr:2.03e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.201, tt:5772.988\n",
      "Ep:164, loss:0.00000, loss_test:0.02264, lr:2.01e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.201, tt:5808.086\n",
      "Ep:165, loss:0.00000, loss_test:0.02267, lr:1.99e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.208, tt:5844.489\n",
      "Ep:166, loss:0.00000, loss_test:0.02271, lr:1.97e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.213, tt:5880.540\n",
      "Ep:167, loss:0.00000, loss_test:0.02275, lr:1.95e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.220, tt:5917.011\n",
      "Ep:168, loss:0.00000, loss_test:0.02279, lr:1.93e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.216, tt:5951.577\n",
      "Ep:169, loss:0.00000, loss_test:0.02283, lr:1.91e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.235, tt:5989.993\n",
      "Ep:170, loss:0.00000, loss_test:0.02286, lr:1.89e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.231, tt:6024.460\n",
      "Ep:171, loss:0.00000, loss_test:0.02288, lr:1.87e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.238, tt:6060.979\n",
      "Ep:172, loss:0.00000, loss_test:0.02291, lr:1.85e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.244, tt:6097.208\n",
      "Ep:173, loss:0.00000, loss_test:0.02294, lr:1.83e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.251, tt:6133.663\n",
      "Ep:174, loss:0.00000, loss_test:0.02298, lr:1.81e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.246, tt:6168.109\n",
      "Ep:175, loss:0.00000, loss_test:0.02300, lr:1.80e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.248, tt:6203.705\n",
      "Ep:176, loss:0.00000, loss_test:0.02304, lr:1.78e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.249, tt:6239.031\n",
      "Ep:177, loss:0.00000, loss_test:0.02308, lr:1.76e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.252, tt:6274.831\n",
      "Ep:178, loss:0.00000, loss_test:0.02310, lr:1.74e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.252, tt:6310.034\n",
      "Ep:179, loss:0.00000, loss_test:0.02313, lr:1.73e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.253, tt:6345.573\n",
      "Ep:180, loss:0.00000, loss_test:0.02315, lr:1.71e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.254, tt:6380.948\n",
      "Ep:181, loss:0.00000, loss_test:0.02319, lr:1.69e-02, fs:0.73054 (r=0.616,p=0.897),  time:35.266, tt:6418.364\n",
      "Ep:182, loss:0.00000, loss_test:0.02323, lr:1.67e-02, fs:0.73054 (r=0.616,p=0.897),  time:35.265, tt:6453.525\n",
      "Ep:183, loss:0.00000, loss_test:0.02326, lr:1.66e-02, fs:0.73054 (r=0.616,p=0.897),  time:35.269, tt:6489.428\n",
      "Ep:184, loss:0.00000, loss_test:0.02329, lr:1.64e-02, fs:0.73054 (r=0.616,p=0.897),  time:35.275, tt:6525.950\n",
      "Ep:185, loss:0.00000, loss_test:0.02331, lr:1.62e-02, fs:0.73054 (r=0.616,p=0.897),  time:35.275, tt:6561.181\n",
      "Ep:186, loss:0.00000, loss_test:0.02334, lr:1.61e-02, fs:0.73054 (r=0.616,p=0.897),  time:35.280, tt:6597.303\n",
      "Ep:187, loss:0.00000, loss_test:0.02336, lr:1.59e-02, fs:0.73054 (r=0.616,p=0.897),  time:35.278, tt:6632.229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:188, loss:0.00000, loss_test:0.02339, lr:1.58e-02, fs:0.73054 (r=0.616,p=0.897),  time:35.285, tt:6668.856\n",
      "Ep:189, loss:0.00000, loss_test:0.02341, lr:1.56e-02, fs:0.73054 (r=0.616,p=0.897),  time:35.285, tt:6704.186\n",
      "Ep:190, loss:0.00000, loss_test:0.02344, lr:1.54e-02, fs:0.73054 (r=0.616,p=0.897),  time:35.287, tt:6739.766\n",
      "Ep:191, loss:0.00000, loss_test:0.02346, lr:1.53e-02, fs:0.73054 (r=0.616,p=0.897),  time:35.288, tt:6775.323\n",
      "Ep:192, loss:0.00000, loss_test:0.02347, lr:1.51e-02, fs:0.73054 (r=0.616,p=0.897),  time:35.287, tt:6810.481\n",
      "Ep:193, loss:0.00000, loss_test:0.02350, lr:1.50e-02, fs:0.73054 (r=0.616,p=0.897),  time:35.289, tt:6846.061\n",
      "Ep:194, loss:0.00000, loss_test:0.02353, lr:1.48e-02, fs:0.73054 (r=0.616,p=0.897),  time:35.287, tt:6880.909\n",
      "Ep:195, loss:0.00000, loss_test:0.02355, lr:1.47e-02, fs:0.73054 (r=0.616,p=0.897),  time:35.286, tt:6916.008\n",
      "Ep:196, loss:0.00000, loss_test:0.02357, lr:1.45e-02, fs:0.73054 (r=0.616,p=0.897),  time:35.276, tt:6949.327\n",
      "Ep:197, loss:0.00000, loss_test:0.02361, lr:1.44e-02, fs:0.73054 (r=0.616,p=0.897),  time:35.277, tt:6984.761\n",
      "Ep:198, loss:0.00000, loss_test:0.02362, lr:1.43e-02, fs:0.73054 (r=0.616,p=0.897),  time:35.271, tt:7018.989\n",
      "Ep:199, loss:0.00000, loss_test:0.02365, lr:1.41e-02, fs:0.73054 (r=0.616,p=0.897),  time:35.264, tt:7052.878\n",
      "Ep:200, loss:0.00000, loss_test:0.02367, lr:1.40e-02, fs:0.73054 (r=0.616,p=0.897),  time:35.254, tt:7086.021\n",
      "Ep:201, loss:0.00000, loss_test:0.02369, lr:1.38e-02, fs:0.73054 (r=0.616,p=0.897),  time:35.235, tt:7117.541\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00026, loss_test:0.13393, lr:1.00e-02, fs:0.65693 (r=0.909,p=0.514),  time:35.884, tt:35.884\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.13199, lr:1.00e-02, fs:0.66171 (r=0.899,p=0.524),  time:36.473, tt:72.945\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.12954, lr:1.00e-02, fs:0.68462 (r=0.899,p=0.553),  time:37.174, tt:111.522\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00025, loss_test:0.12753, lr:1.00e-02, fs:0.68217 (r=0.889,p=0.553),  time:37.256, tt:149.023\n",
      "Ep:4, loss:0.00025, loss_test:0.12595, lr:1.00e-02, fs:0.68750 (r=0.889,p=0.561),  time:36.281, tt:181.404\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.12477, lr:1.00e-02, fs:0.68235 (r=0.879,p=0.558),  time:35.870, tt:215.220\n",
      "Ep:6, loss:0.00025, loss_test:0.12385, lr:1.00e-02, fs:0.68750 (r=0.889,p=0.561),  time:36.127, tt:252.888\n",
      "Ep:7, loss:0.00024, loss_test:0.12280, lr:1.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:36.452, tt:291.619\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00024, loss_test:0.12084, lr:1.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:36.713, tt:330.418\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.11800, lr:1.00e-02, fs:0.69323 (r=0.879,p=0.572),  time:37.099, tt:370.994\n",
      "Ep:10, loss:0.00023, loss_test:0.11526, lr:1.00e-02, fs:0.69600 (r=0.879,p=0.576),  time:37.182, tt:409.002\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00022, loss_test:0.11288, lr:1.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:37.357, tt:448.283\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00022, loss_test:0.11035, lr:1.00e-02, fs:0.69710 (r=0.848,p=0.592),  time:37.437, tt:486.680\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00021, loss_test:0.10748, lr:1.00e-02, fs:0.72103 (r=0.848,p=0.627),  time:37.470, tt:524.579\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00021, loss_test:0.10436, lr:1.00e-02, fs:0.71053 (r=0.818,p=0.628),  time:37.398, tt:560.964\n",
      "Ep:15, loss:0.00020, loss_test:0.10180, lr:1.00e-02, fs:0.71681 (r=0.818,p=0.638),  time:37.294, tt:596.711\n",
      "Ep:16, loss:0.00019, loss_test:0.09992, lr:1.00e-02, fs:0.73636 (r=0.818,p=0.669),  time:37.370, tt:635.298\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00019, loss_test:0.09847, lr:1.00e-02, fs:0.73973 (r=0.818,p=0.675),  time:37.352, tt:672.343\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.09674, lr:1.00e-02, fs:0.75229 (r=0.828,p=0.689),  time:37.565, tt:713.728\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.09555, lr:1.00e-02, fs:0.75349 (r=0.818,p=0.698),  time:37.588, tt:751.752\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.09480, lr:1.00e-02, fs:0.74528 (r=0.798,p=0.699),  time:37.692, tt:791.525\n",
      "Ep:21, loss:0.00016, loss_test:0.09356, lr:1.00e-02, fs:0.75362 (r=0.788,p=0.722),  time:37.791, tt:831.413\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.09186, lr:1.00e-02, fs:0.74510 (r=0.768,p=0.724),  time:37.849, tt:870.530\n",
      "Ep:23, loss:0.00014, loss_test:0.09020, lr:1.00e-02, fs:0.73367 (r=0.737,p=0.730),  time:37.881, tt:909.149\n",
      "Ep:24, loss:0.00014, loss_test:0.08876, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:37.946, tt:948.657\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00013, loss_test:0.08740, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:37.974, tt:987.317\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00012, loss_test:0.08564, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:38.026, tt:1026.698\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00012, loss_test:0.08454, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:38.046, tt:1065.278\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00011, loss_test:0.08307, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:38.128, tt:1105.711\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00011, loss_test:0.08178, lr:1.00e-02, fs:0.82902 (r=0.808,p=0.851),  time:38.118, tt:1143.532\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00010, loss_test:0.08057, lr:1.00e-02, fs:0.83422 (r=0.788,p=0.886),  time:38.053, tt:1179.628\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00009, loss_test:0.07927, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:38.076, tt:1218.429\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00009, loss_test:0.07834, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:38.024, tt:1254.781\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00009, loss_test:0.07728, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:37.962, tt:1290.693\n",
      "Ep:34, loss:0.00008, loss_test:0.07738, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:37.927, tt:1327.436\n",
      "Ep:35, loss:0.00008, loss_test:0.07627, lr:1.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:37.897, tt:1364.279\n",
      "Ep:36, loss:0.00007, loss_test:0.07581, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:37.886, tt:1401.798\n",
      "Ep:37, loss:0.00007, loss_test:0.07585, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:37.852, tt:1438.386\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00007, loss_test:0.07471, lr:1.00e-02, fs:0.83799 (r=0.758,p=0.938),  time:37.817, tt:1474.874\n",
      "Ep:39, loss:0.00007, loss_test:0.07386, lr:1.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:37.786, tt:1511.429\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00006, loss_test:0.07272, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:37.791, tt:1549.450\n",
      "Ep:41, loss:0.00006, loss_test:0.07357, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:37.748, tt:1585.432\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00006, loss_test:0.07279, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:37.666, tt:1619.659\n",
      "Ep:43, loss:0.00005, loss_test:0.07228, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:37.597, tt:1654.279\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00005, loss_test:0.07212, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:37.564, tt:1690.383\n",
      "Ep:45, loss:0.00005, loss_test:0.07194, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:37.514, tt:1725.658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:46, loss:0.00005, loss_test:0.07307, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:37.462, tt:1760.713\n",
      "Ep:47, loss:0.00005, loss_test:0.07221, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:37.426, tt:1796.444\n",
      "Ep:48, loss:0.00005, loss_test:0.07202, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:37.406, tt:1832.903\n",
      "Ep:49, loss:0.00004, loss_test:0.07282, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:37.381, tt:1869.026\n",
      "Ep:50, loss:0.00004, loss_test:0.07249, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:37.343, tt:1904.473\n",
      "Ep:51, loss:0.00004, loss_test:0.07252, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:37.282, tt:1938.644\n",
      "Ep:52, loss:0.00004, loss_test:0.07218, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:37.240, tt:1973.744\n",
      "Ep:53, loss:0.00004, loss_test:0.07291, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:37.195, tt:2008.547\n",
      "Ep:54, loss:0.00004, loss_test:0.07145, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:37.127, tt:2041.986\n",
      "Ep:55, loss:0.00003, loss_test:0.07190, lr:9.90e-03, fs:0.86957 (r=0.808,p=0.941),  time:37.097, tt:2077.425\n",
      "Ep:56, loss:0.00003, loss_test:0.07279, lr:9.80e-03, fs:0.85714 (r=0.788,p=0.940),  time:37.061, tt:2112.500\n",
      "Ep:57, loss:0.00003, loss_test:0.07169, lr:9.70e-03, fs:0.86339 (r=0.798,p=0.940),  time:37.006, tt:2146.359\n",
      "Ep:58, loss:0.00003, loss_test:0.07284, lr:9.61e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.965, tt:2180.910\n",
      "Ep:59, loss:0.00003, loss_test:0.07172, lr:9.51e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.911, tt:2214.654\n",
      "Ep:60, loss:0.00003, loss_test:0.07241, lr:9.41e-03, fs:0.86022 (r=0.808,p=0.920),  time:36.874, tt:2249.325\n",
      "Ep:61, loss:0.00003, loss_test:0.07115, lr:9.32e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.821, tt:2282.909\n",
      "Ep:62, loss:0.00003, loss_test:0.07216, lr:9.23e-03, fs:0.85405 (r=0.798,p=0.919),  time:36.798, tt:2318.305\n",
      "Ep:63, loss:0.00003, loss_test:0.07147, lr:9.14e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.783, tt:2354.089\n",
      "Ep:64, loss:0.00003, loss_test:0.07095, lr:9.04e-03, fs:0.85405 (r=0.798,p=0.919),  time:36.768, tt:2389.944\n",
      "Ep:65, loss:0.00003, loss_test:0.07359, lr:8.95e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.767, tt:2426.636\n",
      "Ep:66, loss:0.00003, loss_test:0.06995, lr:8.86e-03, fs:0.85405 (r=0.798,p=0.919),  time:36.749, tt:2462.152\n",
      "Ep:67, loss:0.00002, loss_test:0.07560, lr:8.78e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.709, tt:2496.182\n",
      "Ep:68, loss:0.00002, loss_test:0.07177, lr:8.69e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.682, tt:2531.034\n",
      "Ep:69, loss:0.00002, loss_test:0.07209, lr:8.60e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.678, tt:2567.456\n",
      "Ep:70, loss:0.00002, loss_test:0.07387, lr:8.51e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.691, tt:2605.049\n",
      "Ep:71, loss:0.00002, loss_test:0.07223, lr:8.43e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.671, tt:2640.288\n",
      "Ep:72, loss:0.00002, loss_test:0.07300, lr:8.35e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.658, tt:2676.051\n",
      "Ep:73, loss:0.00002, loss_test:0.07455, lr:8.26e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.647, tt:2711.905\n",
      "Ep:74, loss:0.00002, loss_test:0.07184, lr:8.18e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.625, tt:2746.898\n",
      "Ep:75, loss:0.00002, loss_test:0.07517, lr:8.10e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.610, tt:2782.333\n",
      "Ep:76, loss:0.00002, loss_test:0.07297, lr:8.02e-03, fs:0.84783 (r=0.788,p=0.918),  time:36.604, tt:2818.517\n",
      "Ep:77, loss:0.00002, loss_test:0.07419, lr:7.94e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.592, tt:2854.174\n",
      "Ep:78, loss:0.00002, loss_test:0.07349, lr:7.86e-03, fs:0.84783 (r=0.788,p=0.918),  time:36.566, tt:2888.738\n",
      "Ep:79, loss:0.00002, loss_test:0.07383, lr:7.78e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.537, tt:2922.973\n",
      "Ep:80, loss:0.00002, loss_test:0.07483, lr:7.70e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.514, tt:2957.628\n",
      "Ep:81, loss:0.00002, loss_test:0.07418, lr:7.62e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.502, tt:2993.193\n",
      "Ep:82, loss:0.00002, loss_test:0.07440, lr:7.55e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.501, tt:3029.560\n",
      "Ep:83, loss:0.00002, loss_test:0.07467, lr:7.47e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.477, tt:3064.067\n",
      "Ep:84, loss:0.00002, loss_test:0.07441, lr:7.40e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.474, tt:3100.270\n",
      "Ep:85, loss:0.00002, loss_test:0.07668, lr:7.32e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.458, tt:3135.418\n",
      "Ep:86, loss:0.00002, loss_test:0.07312, lr:7.25e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.475, tt:3173.369\n",
      "Ep:87, loss:0.00002, loss_test:0.07656, lr:7.18e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.469, tt:3209.307\n",
      "Ep:88, loss:0.00002, loss_test:0.07674, lr:7.11e-03, fs:0.84916 (r=0.768,p=0.950),  time:36.455, tt:3244.471\n",
      "Ep:89, loss:0.00002, loss_test:0.07392, lr:7.03e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.465, tt:3281.850\n",
      "Ep:90, loss:0.00002, loss_test:0.07639, lr:6.96e-03, fs:0.84916 (r=0.768,p=0.950),  time:36.477, tt:3319.426\n",
      "Ep:91, loss:0.00002, loss_test:0.07534, lr:6.89e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.461, tt:3354.392\n",
      "Ep:92, loss:0.00001, loss_test:0.07652, lr:6.83e-03, fs:0.84916 (r=0.768,p=0.950),  time:36.458, tt:3390.632\n",
      "Ep:93, loss:0.00001, loss_test:0.07552, lr:6.76e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.439, tt:3425.313\n",
      "Ep:94, loss:0.00001, loss_test:0.07570, lr:6.69e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.420, tt:3459.946\n",
      "Ep:95, loss:0.00001, loss_test:0.07700, lr:6.62e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.397, tt:3494.088\n",
      "Ep:96, loss:0.00001, loss_test:0.07514, lr:6.56e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.398, tt:3530.564\n",
      "Ep:97, loss:0.00001, loss_test:0.07646, lr:6.49e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.398, tt:3566.955\n",
      "Ep:98, loss:0.00001, loss_test:0.07622, lr:6.43e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.400, tt:3603.558\n",
      "Ep:99, loss:0.00001, loss_test:0.07591, lr:6.36e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.389, tt:3638.921\n",
      "Ep:100, loss:0.00001, loss_test:0.07641, lr:6.30e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.395, tt:3675.915\n",
      "Ep:101, loss:0.00001, loss_test:0.07590, lr:6.24e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.406, tt:3713.442\n",
      "Ep:102, loss:0.00001, loss_test:0.07627, lr:6.17e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.401, tt:3749.323\n",
      "Ep:103, loss:0.00001, loss_test:0.07573, lr:6.11e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.401, tt:3785.683\n",
      "Ep:104, loss:0.00001, loss_test:0.07712, lr:6.05e-03, fs:0.84916 (r=0.768,p=0.950),  time:36.403, tt:3822.282\n",
      "Ep:105, loss:0.00001, loss_test:0.07672, lr:5.99e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.407, tt:3859.170\n",
      "Ep:106, loss:0.00001, loss_test:0.07579, lr:5.93e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.398, tt:3894.574\n",
      "Ep:107, loss:0.00001, loss_test:0.07766, lr:5.87e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.404, tt:3931.653\n",
      "Ep:108, loss:0.00001, loss_test:0.07616, lr:5.81e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.389, tt:3966.351\n",
      "Ep:109, loss:0.00001, loss_test:0.07609, lr:5.75e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.398, tt:4003.727\n",
      "Ep:110, loss:0.00001, loss_test:0.07763, lr:5.70e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.405, tt:4040.954\n",
      "Ep:111, loss:0.00001, loss_test:0.07634, lr:5.64e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.407, tt:4077.557\n",
      "Ep:112, loss:0.00001, loss_test:0.07673, lr:5.58e-03, fs:0.86339 (r=0.798,p=0.940),  time:36.399, tt:4113.136\n",
      "Ep:113, loss:0.00001, loss_test:0.07747, lr:5.53e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.400, tt:4149.572\n",
      "Ep:114, loss:0.00001, loss_test:0.07648, lr:5.47e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.409, tt:4187.034\n",
      "Ep:115, loss:0.00001, loss_test:0.07715, lr:5.42e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.421, tt:4224.860\n",
      "Ep:116, loss:0.00001, loss_test:0.07660, lr:5.36e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.422, tt:4261.352\n",
      "Ep:117, loss:0.00001, loss_test:0.07594, lr:5.31e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.410, tt:4296.436\n",
      "Ep:118, loss:0.00001, loss_test:0.07692, lr:5.26e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.413, tt:4333.111\n",
      "Ep:119, loss:0.00001, loss_test:0.07638, lr:5.20e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.416, tt:4369.930\n",
      "Ep:120, loss:0.00001, loss_test:0.07668, lr:5.15e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.413, tt:4405.924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:121, loss:0.00001, loss_test:0.07714, lr:5.10e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.416, tt:4442.772\n",
      "Ep:122, loss:0.00001, loss_test:0.07622, lr:5.05e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.416, tt:4479.191\n",
      "Ep:123, loss:0.00001, loss_test:0.07637, lr:5.00e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.431, tt:4517.466\n",
      "Ep:124, loss:0.00001, loss_test:0.07706, lr:4.95e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.423, tt:4552.851\n",
      "Ep:125, loss:0.00001, loss_test:0.07662, lr:4.90e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.417, tt:4588.537\n",
      "Ep:126, loss:0.00001, loss_test:0.07661, lr:4.85e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.425, tt:4625.976\n",
      "Ep:127, loss:0.00001, loss_test:0.07733, lr:4.80e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.411, tt:4660.628\n",
      "Ep:128, loss:0.00001, loss_test:0.07613, lr:4.75e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.419, tt:4697.989\n",
      "Ep:129, loss:0.00001, loss_test:0.07719, lr:4.71e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.413, tt:4733.704\n",
      "Ep:130, loss:0.00001, loss_test:0.07830, lr:4.66e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.404, tt:4768.874\n",
      "Ep:131, loss:0.00001, loss_test:0.07691, lr:4.61e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.390, tt:4803.525\n",
      "Ep:132, loss:0.00001, loss_test:0.07629, lr:4.57e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.377, tt:4838.105\n",
      "Ep:133, loss:0.00001, loss_test:0.07740, lr:4.52e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.372, tt:4873.848\n",
      "Ep:134, loss:0.00001, loss_test:0.07788, lr:4.48e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.377, tt:4910.914\n",
      "Ep:135, loss:0.00001, loss_test:0.07645, lr:4.43e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.374, tt:4946.805\n",
      "Ep:136, loss:0.00001, loss_test:0.07695, lr:4.39e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.368, tt:4982.420\n",
      "Ep:137, loss:0.00001, loss_test:0.07680, lr:4.34e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.367, tt:5018.703\n",
      "Ep:138, loss:0.00001, loss_test:0.07729, lr:4.30e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.356, tt:5053.545\n",
      "Ep:139, loss:0.00001, loss_test:0.07817, lr:4.26e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.345, tt:5088.355\n",
      "Ep:140, loss:0.00001, loss_test:0.07730, lr:4.21e-03, fs:0.86339 (r=0.798,p=0.940),  time:36.334, tt:5123.098\n",
      "Ep:141, loss:0.00001, loss_test:0.07642, lr:4.17e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.332, tt:5159.145\n",
      "Ep:142, loss:0.00001, loss_test:0.07764, lr:4.13e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.337, tt:5196.164\n",
      "Ep:143, loss:0.00001, loss_test:0.07795, lr:4.09e-03, fs:0.86339 (r=0.798,p=0.940),  time:36.333, tt:5231.879\n",
      "Ep:144, loss:0.00001, loss_test:0.07720, lr:4.05e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.328, tt:5267.586\n",
      "Ep:145, loss:0.00001, loss_test:0.07748, lr:4.01e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.327, tt:5303.721\n",
      "Ep:146, loss:0.00001, loss_test:0.07762, lr:3.97e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.328, tt:5340.216\n",
      "Ep:147, loss:0.00001, loss_test:0.07742, lr:3.93e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.330, tt:5376.857\n",
      "Ep:148, loss:0.00001, loss_test:0.07782, lr:3.89e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.331, tt:5413.393\n",
      "Ep:149, loss:0.00001, loss_test:0.07812, lr:3.85e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.333, tt:5450.004\n",
      "Ep:150, loss:0.00001, loss_test:0.07715, lr:3.81e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.339, tt:5487.114\n",
      "Ep:151, loss:0.00001, loss_test:0.07683, lr:3.77e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.341, tt:5523.820\n",
      "Ep:152, loss:0.00001, loss_test:0.07792, lr:3.73e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.346, tt:5561.008\n",
      "Ep:153, loss:0.00001, loss_test:0.07755, lr:3.70e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.340, tt:5596.331\n",
      "Ep:154, loss:0.00001, loss_test:0.07667, lr:3.66e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.345, tt:5633.407\n",
      "Ep:155, loss:0.00001, loss_test:0.07721, lr:3.62e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.346, tt:5669.931\n",
      "Ep:156, loss:0.00001, loss_test:0.07772, lr:3.59e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.345, tt:5706.194\n",
      "Ep:157, loss:0.00001, loss_test:0.07730, lr:3.55e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.350, tt:5743.254\n",
      "Ep:158, loss:0.00001, loss_test:0.07723, lr:3.52e-03, fs:0.86339 (r=0.798,p=0.940),  time:36.352, tt:5780.036\n",
      "Ep:159, loss:0.00001, loss_test:0.07766, lr:3.48e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.349, tt:5815.781\n",
      "Ep:160, loss:0.00001, loss_test:0.07735, lr:3.45e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.342, tt:5851.096\n",
      "Ep:161, loss:0.00001, loss_test:0.07714, lr:3.41e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.333, tt:5885.975\n",
      "Ep:162, loss:0.00001, loss_test:0.07740, lr:3.38e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.330, tt:5921.822\n",
      "Ep:163, loss:0.00001, loss_test:0.07792, lr:3.34e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.332, tt:5958.441\n",
      "Ep:164, loss:0.00001, loss_test:0.07733, lr:3.31e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.324, tt:5993.508\n",
      "Ep:165, loss:0.00001, loss_test:0.07686, lr:3.28e-03, fs:0.86339 (r=0.798,p=0.940),  time:36.311, tt:6027.643\n",
      "Ep:166, loss:0.00001, loss_test:0.07741, lr:3.24e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.314, tt:6064.402\n",
      "Ep:167, loss:0.00001, loss_test:0.07793, lr:3.21e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.319, tt:6101.528\n",
      "Ep:168, loss:0.00001, loss_test:0.07769, lr:3.18e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.318, tt:6137.775\n",
      "Ep:169, loss:0.00001, loss_test:0.07717, lr:3.15e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.316, tt:6173.776\n",
      "Ep:170, loss:0.00001, loss_test:0.07717, lr:3.12e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.301, tt:6207.507\n",
      "Ep:171, loss:0.00001, loss_test:0.07716, lr:3.09e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.298, tt:6243.309\n",
      "Ep:172, loss:0.00001, loss_test:0.07743, lr:3.05e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.297, tt:6279.310\n",
      "Ep:173, loss:0.00001, loss_test:0.07735, lr:3.02e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.289, tt:6314.285\n",
      "Ep:174, loss:0.00001, loss_test:0.07718, lr:2.99e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.287, tt:6350.195\n",
      "Ep:175, loss:0.00001, loss_test:0.07733, lr:2.96e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.285, tt:6386.242\n",
      "Ep:176, loss:0.00001, loss_test:0.07747, lr:2.93e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.284, tt:6422.218\n",
      "Ep:177, loss:0.00001, loss_test:0.07763, lr:2.90e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.285, tt:6458.668\n",
      "Ep:178, loss:0.00001, loss_test:0.07700, lr:2.88e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.286, tt:6495.263\n",
      "Ep:179, loss:0.00001, loss_test:0.07717, lr:2.85e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.283, tt:6530.935\n",
      "Ep:180, loss:0.00001, loss_test:0.07759, lr:2.82e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.284, tt:6567.367\n",
      "Ep:181, loss:0.00001, loss_test:0.07737, lr:2.79e-03, fs:0.86339 (r=0.798,p=0.940),  time:36.285, tt:6603.810\n",
      "Ep:182, loss:0.00001, loss_test:0.07720, lr:2.76e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.280, tt:6639.292\n",
      "Ep:183, loss:0.00001, loss_test:0.07766, lr:2.73e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.273, tt:6674.212\n",
      "Ep:184, loss:0.00001, loss_test:0.07754, lr:2.71e-03, fs:0.86339 (r=0.798,p=0.940),  time:36.261, tt:6708.271\n",
      "Ep:185, loss:0.00001, loss_test:0.07735, lr:2.68e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.271, tt:6746.462\n",
      "Ep:186, loss:0.00001, loss_test:0.07720, lr:2.65e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.267, tt:6781.981\n",
      "Ep:187, loss:0.00001, loss_test:0.07723, lr:2.63e-03, fs:0.86339 (r=0.798,p=0.940),  time:36.270, tt:6818.769\n",
      "Ep:188, loss:0.00001, loss_test:0.07731, lr:2.60e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.268, tt:6854.599\n",
      "Ep:189, loss:0.00001, loss_test:0.07733, lr:2.57e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.299, tt:6896.780\n",
      "Ep:190, loss:0.00001, loss_test:0.07745, lr:2.55e-03, fs:0.86339 (r=0.798,p=0.940),  time:36.292, tt:6931.743\n",
      "Ep:191, loss:0.00001, loss_test:0.07692, lr:2.52e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.293, tt:6968.193\n",
      "Ep:192, loss:0.00001, loss_test:0.07729, lr:2.50e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.289, tt:7003.749\n",
      "Ep:193, loss:0.00001, loss_test:0.07781, lr:2.47e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.283, tt:7038.855\n",
      "Ep:194, loss:0.00001, loss_test:0.07748, lr:2.45e-03, fs:0.86339 (r=0.798,p=0.940),  time:36.279, tt:7074.350\n",
      "Ep:195, loss:0.00001, loss_test:0.07703, lr:2.42e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.277, tt:7110.281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:196, loss:0.00001, loss_test:0.07697, lr:2.40e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.275, tt:7146.144\n",
      "Ep:197, loss:0.00001, loss_test:0.07763, lr:2.38e-03, fs:0.86339 (r=0.798,p=0.940),  time:36.258, tt:7179.074\n",
      "Ep:198, loss:0.00001, loss_test:0.07773, lr:2.35e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.240, tt:7211.692\n",
      "Ep:199, loss:0.00001, loss_test:0.07726, lr:2.33e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.215, tt:7242.922\n",
      "Ep:200, loss:0.00001, loss_test:0.07703, lr:2.31e-03, fs:0.86339 (r=0.798,p=0.940),  time:36.187, tt:7273.676\n",
      "Ep:201, loss:0.00001, loss_test:0.07741, lr:2.28e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.159, tt:7304.083\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_300_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00013, loss_test:0.02222, lr:6.00e-02, fs:0.68595 (r=0.838,p=0.580),  time:30.768, tt:30.768\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02481, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:31.043, tt:62.086\n",
      "Ep:2, loss:0.00005, loss_test:0.02830, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.360, tt:94.081\n",
      "Ep:3, loss:0.00005, loss_test:0.02898, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.988, tt:123.951\n",
      "Ep:4, loss:0.00005, loss_test:0.02859, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.575, tt:152.874\n",
      "Ep:5, loss:0.00005, loss_test:0.02750, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.956, tt:179.734\n",
      "Ep:6, loss:0.00005, loss_test:0.02613, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:29.722, tt:208.054\n",
      "Ep:7, loss:0.00005, loss_test:0.02472, lr:6.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:29.390, tt:235.121\n",
      "Ep:8, loss:0.00005, loss_test:0.02354, lr:6.00e-02, fs:0.64727 (r=0.899,p=0.506),  time:29.410, tt:264.690\n",
      "Ep:9, loss:0.00005, loss_test:0.02270, lr:6.00e-02, fs:0.65918 (r=0.889,p=0.524),  time:29.363, tt:293.634\n",
      "Ep:10, loss:0.00005, loss_test:0.02196, lr:6.00e-02, fs:0.65909 (r=0.879,p=0.527),  time:29.435, tt:323.789\n",
      "Ep:11, loss:0.00004, loss_test:0.02122, lr:6.00e-02, fs:0.65385 (r=0.859,p=0.528),  time:29.460, tt:353.521\n",
      "Ep:12, loss:0.00004, loss_test:0.02066, lr:5.94e-02, fs:0.65900 (r=0.869,p=0.531),  time:29.541, tt:384.035\n",
      "Ep:13, loss:0.00004, loss_test:0.02024, lr:5.88e-02, fs:0.67704 (r=0.879,p=0.551),  time:29.602, tt:414.430\n",
      "Ep:14, loss:0.00004, loss_test:0.01998, lr:5.82e-02, fs:0.70229 (r=0.929,p=0.564),  time:29.626, tt:444.397\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.01972, lr:5.82e-02, fs:0.71042 (r=0.929,p=0.575),  time:29.720, tt:475.520\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.01948, lr:5.82e-02, fs:0.70817 (r=0.919,p=0.576),  time:29.773, tt:506.149\n",
      "Ep:17, loss:0.00004, loss_test:0.01928, lr:5.82e-02, fs:0.69565 (r=0.889,p=0.571),  time:29.845, tt:537.207\n",
      "Ep:18, loss:0.00004, loss_test:0.01910, lr:5.82e-02, fs:0.69600 (r=0.879,p=0.576),  time:29.846, tt:567.082\n",
      "Ep:19, loss:0.00004, loss_test:0.01899, lr:5.82e-02, fs:0.69076 (r=0.869,p=0.573),  time:29.932, tt:598.633\n",
      "Ep:20, loss:0.00004, loss_test:0.01881, lr:5.82e-02, fs:0.69076 (r=0.869,p=0.573),  time:29.961, tt:629.184\n",
      "Ep:21, loss:0.00004, loss_test:0.01862, lr:5.82e-02, fs:0.69076 (r=0.869,p=0.573),  time:29.947, tt:658.836\n",
      "Ep:22, loss:0.00004, loss_test:0.01845, lr:5.82e-02, fs:0.69355 (r=0.869,p=0.577),  time:29.946, tt:688.768\n",
      "Ep:23, loss:0.00004, loss_test:0.01828, lr:5.82e-02, fs:0.70916 (r=0.899,p=0.586),  time:30.040, tt:720.957\n",
      "Ep:24, loss:0.00003, loss_test:0.01808, lr:5.82e-02, fs:0.71713 (r=0.909,p=0.592),  time:30.054, tt:751.338\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01787, lr:5.82e-02, fs:0.71713 (r=0.909,p=0.592),  time:30.081, tt:782.098\n",
      "Ep:26, loss:0.00003, loss_test:0.01766, lr:5.82e-02, fs:0.71713 (r=0.909,p=0.592),  time:30.154, tt:814.167\n",
      "Ep:27, loss:0.00003, loss_test:0.01747, lr:5.82e-02, fs:0.72289 (r=0.909,p=0.600),  time:30.170, tt:844.774\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01728, lr:5.82e-02, fs:0.73600 (r=0.929,p=0.609),  time:30.154, tt:874.465\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01710, lr:5.82e-02, fs:0.74194 (r=0.929,p=0.617),  time:30.172, tt:905.156\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01693, lr:5.82e-02, fs:0.74699 (r=0.939,p=0.620),  time:30.208, tt:936.436\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01679, lr:5.82e-02, fs:0.74400 (r=0.939,p=0.616),  time:30.192, tt:966.144\n",
      "Ep:32, loss:0.00003, loss_test:0.01668, lr:5.82e-02, fs:0.75000 (r=0.939,p=0.624),  time:30.244, tt:998.053\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01660, lr:5.82e-02, fs:0.74590 (r=0.919,p=0.628),  time:30.243, tt:1028.259\n",
      "Ep:34, loss:0.00003, loss_test:0.01652, lr:5.82e-02, fs:0.75207 (r=0.919,p=0.636),  time:30.271, tt:1059.498\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.01644, lr:5.82e-02, fs:0.74689 (r=0.909,p=0.634),  time:30.263, tt:1089.461\n",
      "Ep:36, loss:0.00003, loss_test:0.01642, lr:5.82e-02, fs:0.74477 (r=0.899,p=0.636),  time:30.303, tt:1121.225\n",
      "Ep:37, loss:0.00002, loss_test:0.01638, lr:5.82e-02, fs:0.74477 (r=0.899,p=0.636),  time:30.318, tt:1152.092\n",
      "Ep:38, loss:0.00002, loss_test:0.01631, lr:5.82e-02, fs:0.75833 (r=0.919,p=0.645),  time:30.342, tt:1183.341\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01625, lr:5.82e-02, fs:0.76793 (r=0.919,p=0.659),  time:30.335, tt:1213.391\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01621, lr:5.82e-02, fs:0.77447 (r=0.919,p=0.669),  time:30.334, tt:1243.690\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01624, lr:5.82e-02, fs:0.75325 (r=0.879,p=0.659),  time:30.332, tt:1273.943\n",
      "Ep:42, loss:0.00002, loss_test:0.01625, lr:5.82e-02, fs:0.75325 (r=0.879,p=0.659),  time:30.315, tt:1303.535\n",
      "Ep:43, loss:0.00002, loss_test:0.01620, lr:5.82e-02, fs:0.75439 (r=0.869,p=0.667),  time:30.326, tt:1334.330\n",
      "Ep:44, loss:0.00002, loss_test:0.01609, lr:5.82e-02, fs:0.75439 (r=0.869,p=0.667),  time:30.357, tt:1366.082\n",
      "Ep:45, loss:0.00002, loss_test:0.01605, lr:5.82e-02, fs:0.74890 (r=0.859,p=0.664),  time:30.398, tt:1398.325\n",
      "Ep:46, loss:0.00002, loss_test:0.01615, lr:5.82e-02, fs:0.75336 (r=0.848,p=0.677),  time:30.395, tt:1428.579\n",
      "Ep:47, loss:0.00002, loss_test:0.01612, lr:5.82e-02, fs:0.75676 (r=0.848,p=0.683),  time:30.396, tt:1459.019\n",
      "Ep:48, loss:0.00002, loss_test:0.01606, lr:5.82e-02, fs:0.75676 (r=0.848,p=0.683),  time:30.380, tt:1488.602\n",
      "Ep:49, loss:0.00002, loss_test:0.01610, lr:5.82e-02, fs:0.75229 (r=0.828,p=0.689),  time:30.374, tt:1518.689\n",
      "Ep:50, loss:0.00002, loss_test:0.01619, lr:5.82e-02, fs:0.75349 (r=0.818,p=0.698),  time:30.380, tt:1549.367\n",
      "Ep:51, loss:0.00002, loss_test:0.01611, lr:5.82e-02, fs:0.74766 (r=0.808,p=0.696),  time:30.391, tt:1580.306\n",
      "Ep:52, loss:0.00002, loss_test:0.01610, lr:5.76e-02, fs:0.74419 (r=0.808,p=0.690),  time:30.374, tt:1609.817\n",
      "Ep:53, loss:0.00002, loss_test:0.01617, lr:5.71e-02, fs:0.73239 (r=0.788,p=0.684),  time:30.368, tt:1639.893\n",
      "Ep:54, loss:0.00002, loss_test:0.01621, lr:5.65e-02, fs:0.72727 (r=0.768,p=0.691),  time:30.378, tt:1670.787\n",
      "Ep:55, loss:0.00001, loss_test:0.01614, lr:5.59e-02, fs:0.72038 (r=0.768,p=0.679),  time:30.395, tt:1702.099\n",
      "Ep:56, loss:0.00001, loss_test:0.01619, lr:5.54e-02, fs:0.71770 (r=0.758,p=0.682),  time:30.394, tt:1732.454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:57, loss:0.00001, loss_test:0.01622, lr:5.48e-02, fs:0.72381 (r=0.768,p=0.685),  time:30.382, tt:1762.168\n",
      "Ep:58, loss:0.00001, loss_test:0.01617, lr:5.43e-02, fs:0.73585 (r=0.788,p=0.690),  time:30.386, tt:1792.775\n",
      "Ep:59, loss:0.00001, loss_test:0.01621, lr:5.37e-02, fs:0.73333 (r=0.778,p=0.694),  time:30.375, tt:1822.498\n",
      "Ep:60, loss:0.00001, loss_test:0.01621, lr:5.32e-02, fs:0.72038 (r=0.768,p=0.679),  time:30.367, tt:1852.373\n",
      "Ep:61, loss:0.00001, loss_test:0.01603, lr:5.27e-02, fs:0.74396 (r=0.778,p=0.713),  time:30.379, tt:1883.491\n",
      "Ep:62, loss:0.00001, loss_test:0.01614, lr:5.21e-02, fs:0.73077 (r=0.768,p=0.697),  time:30.395, tt:1914.913\n",
      "Ep:63, loss:0.00001, loss_test:0.01603, lr:5.16e-02, fs:0.75122 (r=0.778,p=0.726),  time:30.397, tt:1945.439\n",
      "Ep:64, loss:0.00001, loss_test:0.01608, lr:5.11e-02, fs:0.74757 (r=0.778,p=0.720),  time:30.388, tt:1975.238\n",
      "Ep:65, loss:0.00001, loss_test:0.01625, lr:5.06e-02, fs:0.74757 (r=0.778,p=0.720),  time:30.389, tt:2005.698\n",
      "Ep:66, loss:0.00001, loss_test:0.01598, lr:5.01e-02, fs:0.76238 (r=0.778,p=0.748),  time:30.398, tt:2036.661\n",
      "Ep:67, loss:0.00001, loss_test:0.01613, lr:4.96e-02, fs:0.75122 (r=0.778,p=0.726),  time:30.398, tt:2067.081\n",
      "Ep:68, loss:0.00001, loss_test:0.01621, lr:4.91e-02, fs:0.75490 (r=0.778,p=0.733),  time:30.420, tt:2098.960\n",
      "Ep:69, loss:0.00001, loss_test:0.01624, lr:4.86e-02, fs:0.75862 (r=0.778,p=0.740),  time:30.422, tt:2129.571\n",
      "Ep:70, loss:0.00001, loss_test:0.01615, lr:4.81e-02, fs:0.76617 (r=0.778,p=0.755),  time:30.428, tt:2160.406\n",
      "Ep:71, loss:0.00001, loss_test:0.01633, lr:4.76e-02, fs:0.76238 (r=0.778,p=0.748),  time:30.424, tt:2190.517\n",
      "Ep:72, loss:0.00001, loss_test:0.01626, lr:4.71e-02, fs:0.76617 (r=0.778,p=0.755),  time:30.409, tt:2219.868\n",
      "Ep:73, loss:0.00001, loss_test:0.01636, lr:4.67e-02, fs:0.77000 (r=0.778,p=0.762),  time:30.407, tt:2250.144\n",
      "Ep:74, loss:0.00001, loss_test:0.01631, lr:4.62e-02, fs:0.77387 (r=0.778,p=0.770),  time:30.389, tt:2279.195\n",
      "Ep:75, loss:0.00001, loss_test:0.01669, lr:4.57e-02, fs:0.76238 (r=0.778,p=0.748),  time:30.389, tt:2309.583\n",
      "Ep:76, loss:0.00001, loss_test:0.01648, lr:4.53e-02, fs:0.77387 (r=0.778,p=0.770),  time:30.384, tt:2339.600\n",
      "Ep:77, loss:0.00001, loss_test:0.01667, lr:4.48e-02, fs:0.78173 (r=0.778,p=0.786),  time:30.385, tt:2370.014\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.01691, lr:4.48e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.378, tt:2399.883\n",
      "Ep:79, loss:0.00001, loss_test:0.01673, lr:4.48e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.370, tt:2429.636\n",
      "Ep:80, loss:0.00001, loss_test:0.01706, lr:4.48e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.365, tt:2459.528\n",
      "Ep:81, loss:0.00001, loss_test:0.01692, lr:4.48e-02, fs:0.78173 (r=0.778,p=0.786),  time:30.378, tt:2491.036\n",
      "Ep:82, loss:0.00001, loss_test:0.01729, lr:4.48e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.391, tt:2522.431\n",
      "Ep:83, loss:0.00001, loss_test:0.01728, lr:4.48e-02, fs:0.77387 (r=0.778,p=0.770),  time:30.407, tt:2554.178\n",
      "Ep:84, loss:0.00001, loss_test:0.01730, lr:4.48e-02, fs:0.78173 (r=0.778,p=0.786),  time:30.415, tt:2585.309\n",
      "Ep:85, loss:0.00001, loss_test:0.01740, lr:4.48e-02, fs:0.78173 (r=0.778,p=0.786),  time:30.404, tt:2614.772\n",
      "Ep:86, loss:0.00001, loss_test:0.01763, lr:4.48e-02, fs:0.78173 (r=0.778,p=0.786),  time:30.402, tt:2644.979\n",
      "Ep:87, loss:0.00001, loss_test:0.01760, lr:4.48e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.395, tt:2674.734\n",
      "Ep:88, loss:0.00001, loss_test:0.01755, lr:4.48e-02, fs:0.78173 (r=0.778,p=0.786),  time:30.394, tt:2705.061\n",
      "Ep:89, loss:0.00001, loss_test:0.01825, lr:4.44e-02, fs:0.78173 (r=0.778,p=0.786),  time:30.398, tt:2735.797\n",
      "Ep:90, loss:0.00001, loss_test:0.01774, lr:4.39e-02, fs:0.78173 (r=0.778,p=0.786),  time:30.406, tt:2766.973\n",
      "Ep:91, loss:0.00001, loss_test:0.01826, lr:4.35e-02, fs:0.77387 (r=0.778,p=0.770),  time:30.400, tt:2796.789\n",
      "Ep:92, loss:0.00001, loss_test:0.01803, lr:4.31e-02, fs:0.79793 (r=0.778,p=0.819),  time:30.397, tt:2826.886\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00001, loss_test:0.01827, lr:4.31e-02, fs:0.78571 (r=0.778,p=0.794),  time:30.385, tt:2856.226\n",
      "Ep:94, loss:0.00001, loss_test:0.01888, lr:4.31e-02, fs:0.78173 (r=0.778,p=0.786),  time:30.396, tt:2887.625\n",
      "Ep:95, loss:0.00001, loss_test:0.01821, lr:4.31e-02, fs:0.78351 (r=0.768,p=0.800),  time:30.407, tt:2919.096\n",
      "Ep:96, loss:0.00001, loss_test:0.01938, lr:4.31e-02, fs:0.77320 (r=0.758,p=0.789),  time:30.420, tt:2950.764\n",
      "Ep:97, loss:0.00001, loss_test:0.01827, lr:4.31e-02, fs:0.79167 (r=0.768,p=0.817),  time:30.418, tt:2980.975\n",
      "Ep:98, loss:0.00001, loss_test:0.01959, lr:4.31e-02, fs:0.76042 (r=0.737,p=0.785),  time:30.413, tt:3010.871\n",
      "Ep:99, loss:0.00001, loss_test:0.01849, lr:4.31e-02, fs:0.78756 (r=0.768,p=0.809),  time:30.412, tt:3041.150\n",
      "Ep:100, loss:0.00001, loss_test:0.01966, lr:4.31e-02, fs:0.77720 (r=0.758,p=0.798),  time:30.410, tt:3071.429\n",
      "Ep:101, loss:0.00001, loss_test:0.01910, lr:4.31e-02, fs:0.79167 (r=0.768,p=0.817),  time:30.415, tt:3102.322\n",
      "Ep:102, loss:0.00001, loss_test:0.02013, lr:4.31e-02, fs:0.78756 (r=0.768,p=0.809),  time:30.406, tt:3131.781\n",
      "Ep:103, loss:0.00001, loss_test:0.01940, lr:4.31e-02, fs:0.79581 (r=0.768,p=0.826),  time:30.412, tt:3162.825\n",
      "Ep:104, loss:0.00001, loss_test:0.02020, lr:4.26e-02, fs:0.76842 (r=0.737,p=0.802),  time:30.404, tt:3192.447\n",
      "Ep:105, loss:0.00001, loss_test:0.01986, lr:4.22e-02, fs:0.79167 (r=0.768,p=0.817),  time:30.390, tt:3221.297\n",
      "Ep:106, loss:0.00001, loss_test:0.02038, lr:4.18e-02, fs:0.78534 (r=0.758,p=0.815),  time:30.377, tt:3250.302\n",
      "Ep:107, loss:0.00001, loss_test:0.02063, lr:4.14e-02, fs:0.76596 (r=0.727,p=0.809),  time:30.332, tt:3275.830\n",
      "Ep:108, loss:0.00001, loss_test:0.02092, lr:4.10e-02, fs:0.75269 (r=0.707,p=0.805),  time:30.288, tt:3301.433\n",
      "Ep:109, loss:0.00001, loss_test:0.02077, lr:4.05e-02, fs:0.76596 (r=0.727,p=0.809),  time:30.282, tt:3331.009\n",
      "Ep:110, loss:0.00001, loss_test:0.02103, lr:4.01e-02, fs:0.75936 (r=0.717,p=0.807),  time:30.282, tt:3361.342\n",
      "Ep:111, loss:0.00001, loss_test:0.02124, lr:3.97e-02, fs:0.74595 (r=0.697,p=0.802),  time:30.287, tt:3392.194\n",
      "Ep:112, loss:0.00001, loss_test:0.02094, lr:3.93e-02, fs:0.72527 (r=0.667,p=0.795),  time:30.299, tt:3423.741\n",
      "Ep:113, loss:0.00001, loss_test:0.02187, lr:3.89e-02, fs:0.68927 (r=0.616,p=0.782),  time:30.300, tt:3454.181\n",
      "Ep:114, loss:0.00001, loss_test:0.02093, lr:3.86e-02, fs:0.75936 (r=0.717,p=0.807),  time:30.296, tt:3483.985\n",
      "Ep:115, loss:0.00001, loss_test:0.02234, lr:3.82e-02, fs:0.68927 (r=0.616,p=0.782),  time:30.315, tt:3516.484\n",
      "Ep:116, loss:0.00000, loss_test:0.02101, lr:3.78e-02, fs:0.75676 (r=0.707,p=0.814),  time:30.310, tt:3546.239\n",
      "Ep:117, loss:0.00000, loss_test:0.02274, lr:3.74e-02, fs:0.68927 (r=0.616,p=0.782),  time:30.321, tt:3577.875\n",
      "Ep:118, loss:0.00000, loss_test:0.02115, lr:3.70e-02, fs:0.75676 (r=0.707,p=0.814),  time:30.309, tt:3606.774\n",
      "Ep:119, loss:0.00000, loss_test:0.02280, lr:3.67e-02, fs:0.68927 (r=0.616,p=0.782),  time:30.310, tt:3637.158\n",
      "Ep:120, loss:0.00000, loss_test:0.02163, lr:3.63e-02, fs:0.72222 (r=0.657,p=0.802),  time:30.296, tt:3665.853\n",
      "Ep:121, loss:0.00000, loss_test:0.02313, lr:3.59e-02, fs:0.68927 (r=0.616,p=0.782),  time:30.297, tt:3696.176\n",
      "Ep:122, loss:0.00000, loss_test:0.02198, lr:3.56e-02, fs:0.72222 (r=0.657,p=0.802),  time:30.293, tt:3726.040\n",
      "Ep:123, loss:0.00000, loss_test:0.02321, lr:3.52e-02, fs:0.68182 (r=0.606,p=0.779),  time:30.297, tt:3756.812\n",
      "Ep:124, loss:0.00000, loss_test:0.02221, lr:3.49e-02, fs:0.71508 (r=0.646,p=0.800),  time:30.289, tt:3786.148\n",
      "Ep:125, loss:0.00000, loss_test:0.02370, lr:3.45e-02, fs:0.68182 (r=0.606,p=0.779),  time:30.289, tt:3816.471\n",
      "Ep:126, loss:0.00000, loss_test:0.02275, lr:3.42e-02, fs:0.69318 (r=0.616,p=0.792),  time:30.285, tt:3846.242\n",
      "Ep:127, loss:0.00000, loss_test:0.02361, lr:3.38e-02, fs:0.67429 (r=0.596,p=0.776),  time:30.280, tt:3875.779\n",
      "Ep:128, loss:0.00000, loss_test:0.02278, lr:3.35e-02, fs:0.69318 (r=0.616,p=0.792),  time:30.267, tt:3904.424\n",
      "Ep:129, loss:0.00000, loss_test:0.02370, lr:3.32e-02, fs:0.67429 (r=0.596,p=0.776),  time:30.263, tt:3934.227\n",
      "Ep:130, loss:0.00000, loss_test:0.02342, lr:3.28e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.270, tt:3965.326\n",
      "Ep:131, loss:0.00000, loss_test:0.02399, lr:3.25e-02, fs:0.67429 (r=0.596,p=0.776),  time:30.259, tt:3994.194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00000, loss_test:0.02388, lr:3.22e-02, fs:0.67052 (r=0.586,p=0.784),  time:30.252, tt:4023.481\n",
      "Ep:133, loss:0.00000, loss_test:0.02412, lr:3.19e-02, fs:0.67816 (r=0.596,p=0.787),  time:30.241, tt:4052.300\n",
      "Ep:134, loss:0.00000, loss_test:0.02396, lr:3.15e-02, fs:0.67052 (r=0.586,p=0.784),  time:30.237, tt:4081.987\n",
      "Ep:135, loss:0.00000, loss_test:0.02442, lr:3.12e-02, fs:0.67052 (r=0.586,p=0.784),  time:30.241, tt:4112.791\n",
      "Ep:136, loss:0.00000, loss_test:0.02423, lr:3.09e-02, fs:0.67052 (r=0.586,p=0.784),  time:30.243, tt:4143.250\n",
      "Ep:137, loss:0.00000, loss_test:0.02486, lr:3.06e-02, fs:0.67052 (r=0.586,p=0.784),  time:30.236, tt:4172.586\n",
      "Ep:138, loss:0.00000, loss_test:0.02429, lr:3.03e-02, fs:0.67052 (r=0.586,p=0.784),  time:30.234, tt:4202.513\n",
      "Ep:139, loss:0.00000, loss_test:0.02493, lr:3.00e-02, fs:0.67052 (r=0.586,p=0.784),  time:30.227, tt:4231.748\n",
      "Ep:140, loss:0.00000, loss_test:0.02465, lr:2.97e-02, fs:0.67052 (r=0.586,p=0.784),  time:30.223, tt:4261.402\n",
      "Ep:141, loss:0.00000, loss_test:0.02518, lr:2.94e-02, fs:0.67052 (r=0.586,p=0.784),  time:30.224, tt:4291.763\n",
      "Ep:142, loss:0.00000, loss_test:0.02486, lr:2.91e-02, fs:0.67052 (r=0.586,p=0.784),  time:30.222, tt:4321.727\n",
      "Ep:143, loss:0.00000, loss_test:0.02501, lr:2.88e-02, fs:0.67052 (r=0.586,p=0.784),  time:30.226, tt:4352.510\n",
      "Ep:144, loss:0.00000, loss_test:0.02551, lr:2.85e-02, fs:0.67052 (r=0.586,p=0.784),  time:30.231, tt:4383.501\n",
      "Ep:145, loss:0.00000, loss_test:0.02527, lr:2.82e-02, fs:0.67052 (r=0.586,p=0.784),  time:30.236, tt:4414.469\n",
      "Ep:146, loss:0.00000, loss_test:0.02526, lr:2.80e-02, fs:0.67052 (r=0.586,p=0.784),  time:30.243, tt:4445.648\n",
      "Ep:147, loss:0.00000, loss_test:0.02557, lr:2.77e-02, fs:0.67052 (r=0.586,p=0.784),  time:30.250, tt:4476.979\n",
      "Ep:148, loss:0.00000, loss_test:0.02547, lr:2.74e-02, fs:0.67052 (r=0.586,p=0.784),  time:30.248, tt:4506.905\n",
      "Ep:149, loss:0.00000, loss_test:0.02586, lr:2.71e-02, fs:0.67052 (r=0.586,p=0.784),  time:30.244, tt:4536.572\n",
      "Ep:150, loss:0.00000, loss_test:0.02577, lr:2.69e-02, fs:0.67052 (r=0.586,p=0.784),  time:30.234, tt:4565.353\n",
      "Ep:151, loss:0.00000, loss_test:0.02628, lr:2.66e-02, fs:0.67052 (r=0.586,p=0.784),  time:30.239, tt:4596.276\n",
      "Ep:152, loss:0.00000, loss_test:0.02595, lr:2.63e-02, fs:0.67052 (r=0.586,p=0.784),  time:30.246, tt:4627.592\n",
      "Ep:153, loss:0.00000, loss_test:0.02624, lr:2.61e-02, fs:0.67052 (r=0.586,p=0.784),  time:30.248, tt:4658.249\n",
      "Ep:154, loss:0.00000, loss_test:0.02573, lr:2.58e-02, fs:0.67442 (r=0.586,p=0.795),  time:30.254, tt:4689.304\n",
      "Ep:155, loss:0.00000, loss_test:0.02680, lr:2.55e-02, fs:0.67052 (r=0.586,p=0.784),  time:30.256, tt:4719.901\n",
      "Ep:156, loss:0.00000, loss_test:0.02614, lr:2.53e-02, fs:0.67442 (r=0.586,p=0.795),  time:30.252, tt:4749.596\n",
      "Ep:157, loss:0.00000, loss_test:0.02673, lr:2.50e-02, fs:0.67052 (r=0.586,p=0.784),  time:30.249, tt:4779.271\n",
      "Ep:158, loss:0.00000, loss_test:0.02653, lr:2.48e-02, fs:0.67442 (r=0.586,p=0.795),  time:30.250, tt:4809.698\n",
      "Ep:159, loss:0.00000, loss_test:0.02658, lr:2.45e-02, fs:0.67442 (r=0.586,p=0.795),  time:30.249, tt:4839.841\n",
      "Ep:160, loss:0.00000, loss_test:0.02711, lr:2.43e-02, fs:0.67052 (r=0.586,p=0.784),  time:30.240, tt:4868.635\n",
      "Ep:161, loss:0.00000, loss_test:0.02667, lr:2.40e-02, fs:0.67836 (r=0.586,p=0.806),  time:30.237, tt:4898.341\n",
      "Ep:162, loss:0.00000, loss_test:0.02707, lr:2.38e-02, fs:0.67442 (r=0.586,p=0.795),  time:30.239, tt:4928.995\n",
      "Ep:163, loss:0.00000, loss_test:0.02695, lr:2.36e-02, fs:0.67836 (r=0.586,p=0.806),  time:30.238, tt:4959.074\n",
      "Ep:164, loss:0.00000, loss_test:0.02728, lr:2.33e-02, fs:0.67442 (r=0.586,p=0.795),  time:30.251, tt:4991.494\n",
      "Ep:165, loss:0.00000, loss_test:0.02713, lr:2.31e-02, fs:0.67836 (r=0.586,p=0.806),  time:30.250, tt:5021.557\n",
      "Ep:166, loss:0.00000, loss_test:0.02735, lr:2.29e-02, fs:0.67836 (r=0.586,p=0.806),  time:30.245, tt:5050.889\n",
      "Ep:167, loss:0.00000, loss_test:0.02737, lr:2.26e-02, fs:0.67836 (r=0.586,p=0.806),  time:30.242, tt:5080.709\n",
      "Ep:168, loss:0.00000, loss_test:0.02743, lr:2.24e-02, fs:0.67836 (r=0.586,p=0.806),  time:30.245, tt:5111.417\n",
      "Ep:169, loss:0.00000, loss_test:0.02757, lr:2.22e-02, fs:0.67836 (r=0.586,p=0.806),  time:30.245, tt:5141.712\n",
      "Ep:170, loss:0.00000, loss_test:0.02736, lr:2.20e-02, fs:0.67836 (r=0.586,p=0.806),  time:30.249, tt:5172.643\n",
      "Ep:171, loss:0.00000, loss_test:0.02798, lr:2.17e-02, fs:0.67836 (r=0.586,p=0.806),  time:30.249, tt:5202.910\n",
      "Ep:172, loss:0.00000, loss_test:0.02758, lr:2.15e-02, fs:0.67836 (r=0.586,p=0.806),  time:30.250, tt:5233.305\n",
      "Ep:173, loss:0.00000, loss_test:0.02800, lr:2.13e-02, fs:0.67836 (r=0.586,p=0.806),  time:30.247, tt:5262.909\n",
      "Ep:174, loss:0.00000, loss_test:0.02782, lr:2.11e-02, fs:0.67836 (r=0.586,p=0.806),  time:30.251, tt:5293.872\n",
      "Ep:175, loss:0.00000, loss_test:0.02796, lr:2.09e-02, fs:0.67836 (r=0.586,p=0.806),  time:30.250, tt:5324.019\n",
      "Ep:176, loss:0.00000, loss_test:0.02829, lr:2.07e-02, fs:0.67836 (r=0.586,p=0.806),  time:30.250, tt:5354.302\n",
      "Ep:177, loss:0.00000, loss_test:0.02801, lr:2.05e-02, fs:0.67836 (r=0.586,p=0.806),  time:30.251, tt:5384.728\n",
      "Ep:178, loss:0.00000, loss_test:0.02847, lr:2.03e-02, fs:0.67836 (r=0.586,p=0.806),  time:30.238, tt:5412.584\n",
      "Ep:179, loss:0.00000, loss_test:0.02806, lr:2.01e-02, fs:0.67836 (r=0.586,p=0.806),  time:30.237, tt:5442.634\n",
      "Ep:180, loss:0.00000, loss_test:0.02845, lr:1.99e-02, fs:0.67836 (r=0.586,p=0.806),  time:30.230, tt:5471.602\n",
      "Ep:181, loss:0.00000, loss_test:0.02854, lr:1.97e-02, fs:0.67836 (r=0.586,p=0.806),  time:30.222, tt:5500.461\n",
      "Ep:182, loss:0.00000, loss_test:0.02837, lr:1.95e-02, fs:0.67836 (r=0.586,p=0.806),  time:30.217, tt:5529.773\n",
      "Ep:183, loss:0.00000, loss_test:0.02873, lr:1.93e-02, fs:0.67836 (r=0.586,p=0.806),  time:30.221, tt:5560.644\n",
      "Ep:184, loss:0.00000, loss_test:0.02839, lr:1.91e-02, fs:0.67836 (r=0.586,p=0.806),  time:30.222, tt:5591.079\n",
      "Ep:185, loss:0.00000, loss_test:0.02887, lr:1.89e-02, fs:0.67836 (r=0.586,p=0.806),  time:30.226, tt:5622.039\n",
      "Ep:186, loss:0.00000, loss_test:0.02870, lr:1.87e-02, fs:0.67836 (r=0.586,p=0.806),  time:30.231, tt:5653.130\n",
      "Ep:187, loss:0.00000, loss_test:0.02868, lr:1.85e-02, fs:0.67836 (r=0.586,p=0.806),  time:30.252, tt:5687.455\n",
      "Ep:188, loss:0.00000, loss_test:0.02911, lr:1.83e-02, fs:0.67836 (r=0.586,p=0.806),  time:30.254, tt:5718.074\n",
      "Ep:189, loss:0.00000, loss_test:0.02877, lr:1.81e-02, fs:0.67836 (r=0.586,p=0.806),  time:30.257, tt:5748.854\n",
      "Ep:190, loss:0.00000, loss_test:0.02918, lr:1.80e-02, fs:0.68235 (r=0.586,p=0.817),  time:30.258, tt:5779.358\n",
      "Ep:191, loss:0.00000, loss_test:0.02899, lr:1.78e-02, fs:0.68235 (r=0.586,p=0.817),  time:30.265, tt:5810.974\n",
      "Ep:192, loss:0.00000, loss_test:0.02904, lr:1.76e-02, fs:0.68235 (r=0.586,p=0.817),  time:30.267, tt:5841.485\n",
      "Ep:193, loss:0.00000, loss_test:0.02931, lr:1.74e-02, fs:0.68235 (r=0.586,p=0.817),  time:30.259, tt:5870.299\n",
      "Ep:194, loss:0.00000, loss_test:0.02908, lr:1.73e-02, fs:0.68235 (r=0.586,p=0.817),  time:30.254, tt:5899.602\n",
      "Ep:195, loss:0.00000, loss_test:0.02956, lr:1.71e-02, fs:0.68235 (r=0.586,p=0.817),  time:30.251, tt:5929.276\n",
      "Ep:196, loss:0.00000, loss_test:0.02921, lr:1.69e-02, fs:0.68235 (r=0.586,p=0.817),  time:30.236, tt:5956.422\n",
      "Ep:197, loss:0.00000, loss_test:0.02940, lr:1.67e-02, fs:0.68235 (r=0.586,p=0.817),  time:30.211, tt:5981.831\n",
      "Ep:198, loss:0.00000, loss_test:0.02949, lr:1.66e-02, fs:0.68235 (r=0.586,p=0.817),  time:30.203, tt:6010.397\n",
      "Ep:199, loss:0.00000, loss_test:0.02949, lr:1.64e-02, fs:0.68235 (r=0.586,p=0.817),  time:30.188, tt:6037.597\n",
      "Ep:200, loss:0.00000, loss_test:0.02972, lr:1.62e-02, fs:0.68235 (r=0.586,p=0.817),  time:30.162, tt:6062.602\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_300_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13540, lr:1.00e-02, fs:0.66434 (r=0.960,p=0.508),  time:32.086, tt:32.086\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:1, loss:0.00026, loss_test:0.13133, lr:1.00e-02, fs:0.67399 (r=0.929,p=0.529),  time:32.530, tt:65.060\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.12656, lr:1.00e-02, fs:0.67176 (r=0.889,p=0.540),  time:32.547, tt:97.640\n",
      "Ep:3, loss:0.00025, loss_test:0.12278, lr:1.00e-02, fs:0.69388 (r=0.859,p=0.582),  time:32.008, tt:128.032\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00024, loss_test:0.12002, lr:1.00e-02, fs:0.70588 (r=0.848,p=0.604),  time:31.759, tt:158.796\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.11862, lr:1.00e-02, fs:0.69136 (r=0.848,p=0.583),  time:31.660, tt:189.958\n",
      "Ep:6, loss:0.00023, loss_test:0.11811, lr:1.00e-02, fs:0.68273 (r=0.859,p=0.567),  time:31.068, tt:217.478\n",
      "Ep:7, loss:0.00023, loss_test:0.11411, lr:1.00e-02, fs:0.70000 (r=0.848,p=0.596),  time:31.771, tt:254.170\n",
      "Ep:8, loss:0.00022, loss_test:0.11145, lr:1.00e-02, fs:0.70638 (r=0.838,p=0.610),  time:31.840, tt:286.557\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.11182, lr:1.00e-02, fs:0.70000 (r=0.848,p=0.596),  time:31.861, tt:318.607\n",
      "Ep:10, loss:0.00022, loss_test:0.11057, lr:1.00e-02, fs:0.70248 (r=0.859,p=0.594),  time:31.912, tt:351.030\n",
      "Ep:11, loss:0.00021, loss_test:0.10750, lr:1.00e-02, fs:0.70996 (r=0.828,p=0.621),  time:31.967, tt:383.599\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.10658, lr:1.00e-02, fs:0.70690 (r=0.828,p=0.617),  time:32.057, tt:416.744\n",
      "Ep:13, loss:0.00020, loss_test:0.10661, lr:1.00e-02, fs:0.71130 (r=0.859,p=0.607),  time:32.035, tt:448.492\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00020, loss_test:0.10435, lr:1.00e-02, fs:0.72961 (r=0.859,p=0.634),  time:32.118, tt:481.777\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00020, loss_test:0.10282, lr:1.00e-02, fs:0.73593 (r=0.859,p=0.644),  time:32.116, tt:513.862\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.10217, lr:1.00e-02, fs:0.72574 (r=0.869,p=0.623),  time:32.097, tt:545.654\n",
      "Ep:17, loss:0.00019, loss_test:0.10061, lr:1.00e-02, fs:0.75000 (r=0.909,p=0.638),  time:32.136, tt:578.445\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.09932, lr:1.00e-02, fs:0.75833 (r=0.919,p=0.645),  time:32.130, tt:610.461\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00018, loss_test:0.09811, lr:1.00e-02, fs:0.76596 (r=0.909,p=0.662),  time:32.103, tt:642.066\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00017, loss_test:0.09718, lr:1.00e-02, fs:0.76271 (r=0.909,p=0.657),  time:32.233, tt:676.888\n",
      "Ep:21, loss:0.00017, loss_test:0.09663, lr:1.00e-02, fs:0.76395 (r=0.899,p=0.664),  time:32.251, tt:709.531\n",
      "Ep:22, loss:0.00016, loss_test:0.09577, lr:1.00e-02, fs:0.76856 (r=0.889,p=0.677),  time:32.313, tt:743.207\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00016, loss_test:0.09429, lr:1.00e-02, fs:0.77533 (r=0.889,p=0.688),  time:32.287, tt:774.890\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.09378, lr:1.00e-02, fs:0.76652 (r=0.879,p=0.680),  time:32.205, tt:805.123\n",
      "Ep:25, loss:0.00015, loss_test:0.09285, lr:1.00e-02, fs:0.77130 (r=0.869,p=0.694),  time:32.126, tt:835.278\n",
      "Ep:26, loss:0.00014, loss_test:0.09283, lr:1.00e-02, fs:0.77477 (r=0.869,p=0.699),  time:32.083, tt:866.253\n",
      "Ep:27, loss:0.00014, loss_test:0.09180, lr:1.00e-02, fs:0.78733 (r=0.879,p=0.713),  time:32.027, tt:896.770\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.09072, lr:1.00e-02, fs:0.78341 (r=0.859,p=0.720),  time:31.970, tt:927.134\n",
      "Ep:29, loss:0.00013, loss_test:0.09068, lr:1.00e-02, fs:0.78341 (r=0.859,p=0.720),  time:31.912, tt:957.365\n",
      "Ep:30, loss:0.00012, loss_test:0.09034, lr:1.00e-02, fs:0.79452 (r=0.879,p=0.725),  time:31.829, tt:986.692\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.08708, lr:1.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:31.783, tt:1017.053\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00011, loss_test:0.08713, lr:1.00e-02, fs:0.80189 (r=0.859,p=0.752),  time:31.759, tt:1048.048\n",
      "Ep:33, loss:0.00011, loss_test:0.08689, lr:1.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:31.740, tt:1079.164\n",
      "Ep:34, loss:0.00010, loss_test:0.08360, lr:1.00e-02, fs:0.80214 (r=0.758,p=0.852),  time:31.720, tt:1110.199\n",
      "Ep:35, loss:0.00010, loss_test:0.09020, lr:1.00e-02, fs:0.79263 (r=0.869,p=0.729),  time:31.700, tt:1141.184\n",
      "Ep:36, loss:0.00010, loss_test:0.08528, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:31.672, tt:1171.875\n",
      "Ep:37, loss:0.00009, loss_test:0.08285, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:31.678, tt:1203.755\n",
      "Ep:38, loss:0.00009, loss_test:0.08671, lr:1.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:31.649, tt:1234.302\n",
      "Ep:39, loss:0.00008, loss_test:0.08183, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:31.671, tt:1266.858\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00008, loss_test:0.08362, lr:1.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:31.644, tt:1297.418\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00007, loss_test:0.08191, lr:1.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:31.607, tt:1327.512\n",
      "Ep:42, loss:0.00007, loss_test:0.08128, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:31.608, tt:1359.139\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00007, loss_test:0.07947, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:31.634, tt:1391.888\n",
      "Ep:44, loss:0.00007, loss_test:0.07933, lr:1.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:31.601, tt:1422.052\n",
      "Ep:45, loss:0.00006, loss_test:0.08040, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:31.597, tt:1453.459\n",
      "Ep:46, loss:0.00006, loss_test:0.07305, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:31.610, tt:1485.686\n",
      "Ep:47, loss:0.00007, loss_test:0.08385, lr:1.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:31.614, tt:1517.489\n",
      "Ep:48, loss:0.00006, loss_test:0.07432, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:31.641, tt:1550.389\n",
      "Ep:49, loss:0.00006, loss_test:0.07338, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:31.650, tt:1582.518\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00006, loss_test:0.08077, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:31.633, tt:1613.307\n",
      "Ep:51, loss:0.00005, loss_test:0.07220, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:31.639, tt:1645.219\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00005, loss_test:0.07688, lr:1.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:31.614, tt:1675.537\n",
      "Ep:53, loss:0.00005, loss_test:0.07431, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:31.606, tt:1706.749\n",
      "Ep:54, loss:0.00005, loss_test:0.07627, lr:1.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:31.592, tt:1737.581\n",
      "Ep:55, loss:0.00005, loss_test:0.07489, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:31.615, tt:1770.448\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00004, loss_test:0.07617, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:31.611, tt:1801.801\n",
      "Ep:57, loss:0.00004, loss_test:0.07416, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:31.591, tt:1832.304\n",
      "Ep:58, loss:0.00004, loss_test:0.07430, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:31.584, tt:1863.467\n",
      "Ep:59, loss:0.00004, loss_test:0.07200, lr:1.00e-02, fs:0.86294 (r=0.859,p=0.867),  time:31.563, tt:1893.770\n",
      "Ep:60, loss:0.00004, loss_test:0.07444, lr:1.00e-02, fs:0.87234 (r=0.828,p=0.921),  time:31.557, tt:1924.954\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00004, loss_test:0.07770, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:31.554, tt:1956.368\n",
      "Ep:62, loss:0.00004, loss_test:0.07178, lr:1.00e-02, fs:0.88660 (r=0.869,p=0.905),  time:31.564, tt:1988.559\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00003, loss_test:0.07305, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:31.544, tt:2018.837\n",
      "Ep:64, loss:0.00003, loss_test:0.07511, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:31.529, tt:2049.380\n",
      "Ep:65, loss:0.00003, loss_test:0.07044, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:31.517, tt:2080.132\n",
      "Ep:66, loss:0.00003, loss_test:0.07719, lr:1.00e-02, fs:0.84375 (r=0.818,p=0.871),  time:31.489, tt:2109.751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:67, loss:0.00003, loss_test:0.07196, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:31.486, tt:2141.015\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00003, loss_test:0.07613, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:31.460, tt:2170.733\n",
      "Ep:69, loss:0.00003, loss_test:0.07324, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:31.474, tt:2203.210\n",
      "Ep:70, loss:0.00003, loss_test:0.07546, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:31.458, tt:2233.546\n",
      "Ep:71, loss:0.00003, loss_test:0.07180, lr:1.00e-02, fs:0.89474 (r=0.859,p=0.934),  time:31.438, tt:2263.545\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00003, loss_test:0.07567, lr:1.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:31.440, tt:2295.092\n",
      "Ep:73, loss:0.00003, loss_test:0.07355, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:31.412, tt:2324.518\n",
      "Ep:74, loss:0.00003, loss_test:0.07483, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:31.415, tt:2356.152\n",
      "Ep:75, loss:0.00003, loss_test:0.07271, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:31.411, tt:2387.234\n",
      "Ep:76, loss:0.00002, loss_test:0.07527, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:31.409, tt:2418.509\n",
      "Ep:77, loss:0.00002, loss_test:0.07155, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:31.391, tt:2448.517\n",
      "Ep:78, loss:0.00002, loss_test:0.07994, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:31.395, tt:2480.188\n",
      "Ep:79, loss:0.00002, loss_test:0.07220, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:31.419, tt:2513.539\n",
      "Ep:80, loss:0.00002, loss_test:0.08198, lr:1.00e-02, fs:0.78689 (r=0.727,p=0.857),  time:31.434, tt:2546.118\n",
      "Ep:81, loss:0.00003, loss_test:0.07319, lr:1.00e-02, fs:0.83616 (r=0.747,p=0.949),  time:31.438, tt:2577.928\n",
      "Ep:82, loss:0.00003, loss_test:0.08287, lr:1.00e-02, fs:0.77348 (r=0.707,p=0.854),  time:31.452, tt:2610.540\n",
      "Ep:83, loss:0.00002, loss_test:0.07032, lr:9.90e-03, fs:0.85246 (r=0.788,p=0.929),  time:31.457, tt:2642.388\n",
      "Ep:84, loss:0.00002, loss_test:0.08410, lr:9.80e-03, fs:0.76404 (r=0.687,p=0.861),  time:31.449, tt:2673.167\n",
      "Ep:85, loss:0.00002, loss_test:0.07219, lr:9.70e-03, fs:0.85246 (r=0.788,p=0.929),  time:31.467, tt:2706.186\n",
      "Ep:86, loss:0.00002, loss_test:0.08087, lr:9.61e-03, fs:0.78409 (r=0.697,p=0.896),  time:31.489, tt:2739.533\n",
      "Ep:87, loss:0.00002, loss_test:0.08206, lr:9.51e-03, fs:0.76301 (r=0.667,p=0.892),  time:31.486, tt:2770.756\n",
      "Ep:88, loss:0.00002, loss_test:0.07650, lr:9.41e-03, fs:0.83799 (r=0.758,p=0.938),  time:31.494, tt:2802.995\n",
      "Ep:89, loss:0.00002, loss_test:0.08215, lr:9.32e-03, fs:0.75862 (r=0.667,p=0.880),  time:31.503, tt:2835.255\n",
      "Ep:90, loss:0.00002, loss_test:0.07599, lr:9.23e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.489, tt:2865.521\n",
      "Ep:91, loss:0.00002, loss_test:0.08293, lr:9.14e-03, fs:0.76744 (r=0.667,p=0.904),  time:31.493, tt:2897.389\n",
      "Ep:92, loss:0.00002, loss_test:0.08058, lr:9.04e-03, fs:0.78409 (r=0.697,p=0.896),  time:31.497, tt:2929.217\n",
      "Ep:93, loss:0.00002, loss_test:0.07881, lr:8.95e-03, fs:0.82022 (r=0.737,p=0.924),  time:31.500, tt:2961.020\n",
      "Ep:94, loss:0.00002, loss_test:0.08399, lr:8.86e-03, fs:0.72515 (r=0.626,p=0.861),  time:31.515, tt:2993.885\n",
      "Ep:95, loss:0.00002, loss_test:0.08184, lr:8.78e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.521, tt:3025.995\n",
      "Ep:96, loss:0.00002, loss_test:0.08093, lr:8.69e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.518, tt:3057.200\n",
      "Ep:97, loss:0.00002, loss_test:0.08204, lr:8.60e-03, fs:0.75294 (r=0.646,p=0.901),  time:31.508, tt:3087.744\n",
      "Ep:98, loss:0.00002, loss_test:0.07960, lr:8.51e-03, fs:0.80925 (r=0.707,p=0.946),  time:31.510, tt:3119.451\n",
      "Ep:99, loss:0.00002, loss_test:0.08605, lr:8.43e-03, fs:0.73684 (r=0.636,p=0.875),  time:31.511, tt:3151.130\n",
      "Ep:100, loss:0.00002, loss_test:0.08019, lr:8.35e-03, fs:0.80460 (r=0.707,p=0.933),  time:31.516, tt:3183.158\n",
      "Ep:101, loss:0.00001, loss_test:0.08329, lr:8.26e-03, fs:0.71515 (r=0.596,p=0.894),  time:31.509, tt:3213.961\n",
      "Ep:102, loss:0.00001, loss_test:0.08345, lr:8.18e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.522, tt:3246.812\n",
      "Ep:103, loss:0.00001, loss_test:0.08265, lr:8.10e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.528, tt:3278.899\n",
      "Ep:104, loss:0.00001, loss_test:0.08356, lr:8.02e-03, fs:0.73054 (r=0.616,p=0.897),  time:31.523, tt:3309.959\n",
      "Ep:105, loss:0.00001, loss_test:0.08264, lr:7.94e-03, fs:0.77647 (r=0.667,p=0.930),  time:31.527, tt:3341.821\n",
      "Ep:106, loss:0.00001, loss_test:0.08497, lr:7.86e-03, fs:0.71951 (r=0.596,p=0.908),  time:31.529, tt:3373.591\n",
      "Ep:107, loss:0.00001, loss_test:0.08204, lr:7.78e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.535, tt:3405.826\n",
      "Ep:108, loss:0.00001, loss_test:0.08572, lr:7.70e-03, fs:0.71166 (r=0.586,p=0.906),  time:31.539, tt:3437.786\n",
      "Ep:109, loss:0.00001, loss_test:0.08374, lr:7.62e-03, fs:0.75449 (r=0.636,p=0.926),  time:31.555, tt:3471.079\n",
      "Ep:110, loss:0.00001, loss_test:0.08304, lr:7.55e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.554, tt:3502.538\n",
      "Ep:111, loss:0.00001, loss_test:0.08606, lr:7.47e-03, fs:0.70732 (r=0.586,p=0.892),  time:31.564, tt:3535.224\n",
      "Ep:112, loss:0.00001, loss_test:0.08348, lr:7.40e-03, fs:0.73939 (r=0.616,p=0.924),  time:31.563, tt:3566.576\n",
      "Ep:113, loss:0.00001, loss_test:0.08368, lr:7.32e-03, fs:0.71515 (r=0.596,p=0.894),  time:31.568, tt:3598.751\n",
      "Ep:114, loss:0.00001, loss_test:0.08317, lr:7.25e-03, fs:0.73494 (r=0.616,p=0.910),  time:31.576, tt:3631.221\n",
      "Ep:115, loss:0.00001, loss_test:0.08519, lr:7.18e-03, fs:0.68750 (r=0.556,p=0.902),  time:31.613, tt:3667.092\n",
      "Ep:116, loss:0.00001, loss_test:0.08552, lr:7.11e-03, fs:0.71166 (r=0.586,p=0.906),  time:31.622, tt:3699.790\n",
      "Ep:117, loss:0.00001, loss_test:0.08279, lr:7.03e-03, fs:0.75000 (r=0.636,p=0.913),  time:31.625, tt:3731.719\n",
      "Ep:118, loss:0.00001, loss_test:0.08716, lr:6.96e-03, fs:0.71166 (r=0.586,p=0.906),  time:31.632, tt:3764.218\n",
      "Ep:119, loss:0.00001, loss_test:0.08348, lr:6.89e-03, fs:0.73939 (r=0.616,p=0.924),  time:31.633, tt:3795.998\n",
      "Ep:120, loss:0.00001, loss_test:0.08479, lr:6.83e-03, fs:0.71951 (r=0.596,p=0.908),  time:31.631, tt:3827.388\n",
      "Ep:121, loss:0.00001, loss_test:0.08484, lr:6.76e-03, fs:0.73171 (r=0.606,p=0.923),  time:31.642, tt:3860.264\n",
      "Ep:122, loss:0.00001, loss_test:0.08501, lr:6.69e-03, fs:0.71605 (r=0.586,p=0.921),  time:31.651, tt:3893.084\n",
      "Ep:123, loss:0.00001, loss_test:0.08476, lr:6.62e-03, fs:0.69565 (r=0.566,p=0.903),  time:31.669, tt:3926.899\n",
      "Ep:124, loss:0.00001, loss_test:0.08511, lr:6.56e-03, fs:0.71605 (r=0.586,p=0.921),  time:31.673, tt:3959.171\n",
      "Ep:125, loss:0.00001, loss_test:0.08497, lr:6.49e-03, fs:0.69182 (r=0.556,p=0.917),  time:31.667, tt:3990.042\n",
      "Ep:126, loss:0.00001, loss_test:0.08651, lr:6.43e-03, fs:0.71166 (r=0.586,p=0.906),  time:31.672, tt:4022.349\n",
      "Ep:127, loss:0.00001, loss_test:0.08420, lr:6.36e-03, fs:0.71166 (r=0.586,p=0.906),  time:31.664, tt:4052.968\n",
      "Ep:128, loss:0.00001, loss_test:0.08536, lr:6.30e-03, fs:0.71166 (r=0.586,p=0.906),  time:31.662, tt:4084.391\n",
      "Ep:129, loss:0.00001, loss_test:0.08519, lr:6.24e-03, fs:0.68750 (r=0.556,p=0.902),  time:31.662, tt:4116.079\n",
      "Ep:130, loss:0.00001, loss_test:0.08592, lr:6.17e-03, fs:0.71166 (r=0.586,p=0.906),  time:31.646, tt:4145.666\n",
      "Ep:131, loss:0.00001, loss_test:0.08514, lr:6.11e-03, fs:0.69565 (r=0.566,p=0.903),  time:31.637, tt:4176.060\n",
      "Ep:132, loss:0.00001, loss_test:0.08464, lr:6.05e-03, fs:0.71605 (r=0.586,p=0.921),  time:31.628, tt:4206.551\n",
      "Ep:133, loss:0.00001, loss_test:0.08721, lr:5.99e-03, fs:0.68750 (r=0.556,p=0.902),  time:31.612, tt:4235.972\n",
      "Ep:134, loss:0.00001, loss_test:0.08561, lr:5.93e-03, fs:0.70807 (r=0.576,p=0.919),  time:31.607, tt:4266.931\n",
      "Ep:135, loss:0.00001, loss_test:0.08496, lr:5.87e-03, fs:0.70370 (r=0.576,p=0.905),  time:31.603, tt:4297.954\n",
      "Ep:136, loss:0.00001, loss_test:0.08641, lr:5.81e-03, fs:0.68750 (r=0.556,p=0.902),  time:31.602, tt:4329.478\n",
      "Ep:137, loss:0.00001, loss_test:0.08551, lr:5.75e-03, fs:0.70807 (r=0.576,p=0.919),  time:31.598, tt:4360.557\n",
      "Ep:138, loss:0.00001, loss_test:0.08635, lr:5.70e-03, fs:0.69182 (r=0.556,p=0.917),  time:31.581, tt:4389.820\n",
      "Ep:139, loss:0.00001, loss_test:0.08473, lr:5.64e-03, fs:0.71605 (r=0.586,p=0.921),  time:31.564, tt:4418.915\n",
      "Ep:140, loss:0.00001, loss_test:0.08662, lr:5.58e-03, fs:0.70370 (r=0.576,p=0.905),  time:31.553, tt:4448.994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:141, loss:0.00001, loss_test:0.08625, lr:5.53e-03, fs:0.71250 (r=0.576,p=0.934),  time:31.547, tt:4479.694\n",
      "Ep:142, loss:0.00001, loss_test:0.08563, lr:5.47e-03, fs:0.69620 (r=0.556,p=0.932),  time:31.545, tt:4510.989\n",
      "Ep:143, loss:0.00001, loss_test:0.08704, lr:5.42e-03, fs:0.71166 (r=0.586,p=0.906),  time:31.542, tt:4542.111\n",
      "Ep:144, loss:0.00001, loss_test:0.08576, lr:5.36e-03, fs:0.69620 (r=0.556,p=0.932),  time:31.533, tt:4572.311\n",
      "Ep:145, loss:0.00001, loss_test:0.08714, lr:5.31e-03, fs:0.68750 (r=0.556,p=0.902),  time:31.531, tt:4603.550\n",
      "Ep:146, loss:0.00001, loss_test:0.08548, lr:5.26e-03, fs:0.71605 (r=0.586,p=0.921),  time:31.527, tt:4634.432\n",
      "Ep:147, loss:0.00001, loss_test:0.08621, lr:5.20e-03, fs:0.69620 (r=0.556,p=0.932),  time:31.523, tt:4665.339\n",
      "Ep:148, loss:0.00001, loss_test:0.08702, lr:5.15e-03, fs:0.68354 (r=0.545,p=0.915),  time:31.498, tt:4693.273\n",
      "Ep:149, loss:0.00001, loss_test:0.08637, lr:5.10e-03, fs:0.70807 (r=0.576,p=0.919),  time:31.484, tt:4722.626\n",
      "Ep:150, loss:0.00001, loss_test:0.08653, lr:5.05e-03, fs:0.69620 (r=0.556,p=0.932),  time:31.475, tt:4752.770\n",
      "Ep:151, loss:0.00001, loss_test:0.08633, lr:5.00e-03, fs:0.68790 (r=0.545,p=0.931),  time:31.470, tt:4783.420\n",
      "Ep:152, loss:0.00001, loss_test:0.08731, lr:4.95e-03, fs:0.71166 (r=0.586,p=0.906),  time:31.458, tt:4813.108\n",
      "Ep:153, loss:0.00001, loss_test:0.08663, lr:4.90e-03, fs:0.68790 (r=0.545,p=0.931),  time:31.450, tt:4843.357\n",
      "Ep:154, loss:0.00001, loss_test:0.08649, lr:4.85e-03, fs:0.69620 (r=0.556,p=0.932),  time:31.446, tt:4874.120\n",
      "Ep:155, loss:0.00001, loss_test:0.08710, lr:4.80e-03, fs:0.71605 (r=0.586,p=0.921),  time:31.432, tt:4903.408\n",
      "Ep:156, loss:0.00001, loss_test:0.08703, lr:4.75e-03, fs:0.69182 (r=0.556,p=0.917),  time:31.431, tt:4934.700\n",
      "Ep:157, loss:0.00001, loss_test:0.08725, lr:4.71e-03, fs:0.68790 (r=0.545,p=0.931),  time:31.421, tt:4964.544\n",
      "Ep:158, loss:0.00001, loss_test:0.08760, lr:4.66e-03, fs:0.70440 (r=0.566,p=0.933),  time:31.419, tt:4995.583\n",
      "Ep:159, loss:0.00001, loss_test:0.08643, lr:4.61e-03, fs:0.70440 (r=0.566,p=0.933),  time:31.420, tt:5027.166\n",
      "Ep:160, loss:0.00001, loss_test:0.08700, lr:4.57e-03, fs:0.68790 (r=0.545,p=0.931),  time:31.419, tt:5058.490\n",
      "Ep:161, loss:0.00001, loss_test:0.08754, lr:4.52e-03, fs:0.69620 (r=0.556,p=0.932),  time:31.416, tt:5089.370\n",
      "Ep:162, loss:0.00001, loss_test:0.08700, lr:4.48e-03, fs:0.69620 (r=0.556,p=0.932),  time:31.410, tt:5119.809\n",
      "Ep:163, loss:0.00001, loss_test:0.08807, lr:4.43e-03, fs:0.69620 (r=0.556,p=0.932),  time:31.406, tt:5150.631\n",
      "Ep:164, loss:0.00001, loss_test:0.08631, lr:4.39e-03, fs:0.68790 (r=0.545,p=0.931),  time:31.409, tt:5182.423\n",
      "Ep:165, loss:0.00001, loss_test:0.08795, lr:4.34e-03, fs:0.70000 (r=0.566,p=0.918),  time:31.400, tt:5212.414\n",
      "Ep:166, loss:0.00001, loss_test:0.08704, lr:4.30e-03, fs:0.68790 (r=0.545,p=0.931),  time:31.394, tt:5242.777\n",
      "Ep:167, loss:0.00001, loss_test:0.08622, lr:4.26e-03, fs:0.69620 (r=0.556,p=0.932),  time:31.393, tt:5274.000\n",
      "Ep:168, loss:0.00001, loss_test:0.08784, lr:4.21e-03, fs:0.69620 (r=0.556,p=0.932),  time:31.389, tt:5304.795\n",
      "Ep:169, loss:0.00001, loss_test:0.08831, lr:4.17e-03, fs:0.68790 (r=0.545,p=0.931),  time:31.393, tt:5336.878\n",
      "Ep:170, loss:0.00001, loss_test:0.08764, lr:4.13e-03, fs:0.69620 (r=0.556,p=0.932),  time:31.397, tt:5368.837\n",
      "Ep:171, loss:0.00001, loss_test:0.08681, lr:4.09e-03, fs:0.69620 (r=0.556,p=0.932),  time:31.400, tt:5400.785\n",
      "Ep:172, loss:0.00001, loss_test:0.08827, lr:4.05e-03, fs:0.69620 (r=0.556,p=0.932),  time:31.403, tt:5432.726\n",
      "Ep:173, loss:0.00001, loss_test:0.08707, lr:4.01e-03, fs:0.68790 (r=0.545,p=0.931),  time:31.404, tt:5464.248\n",
      "Ep:174, loss:0.00001, loss_test:0.08691, lr:3.97e-03, fs:0.69620 (r=0.556,p=0.932),  time:31.389, tt:5493.055\n",
      "Ep:175, loss:0.00001, loss_test:0.08821, lr:3.93e-03, fs:0.69182 (r=0.556,p=0.917),  time:31.383, tt:5523.416\n",
      "Ep:176, loss:0.00001, loss_test:0.08699, lr:3.89e-03, fs:0.68790 (r=0.545,p=0.931),  time:31.364, tt:5551.453\n",
      "Ep:177, loss:0.00001, loss_test:0.08746, lr:3.85e-03, fs:0.68790 (r=0.545,p=0.931),  time:31.363, tt:5582.643\n",
      "Ep:178, loss:0.00001, loss_test:0.08930, lr:3.81e-03, fs:0.69182 (r=0.556,p=0.917),  time:31.355, tt:5612.634\n",
      "Ep:179, loss:0.00001, loss_test:0.08771, lr:3.77e-03, fs:0.69620 (r=0.556,p=0.932),  time:31.358, tt:5644.498\n",
      "Ep:180, loss:0.00001, loss_test:0.08667, lr:3.73e-03, fs:0.68790 (r=0.545,p=0.931),  time:31.369, tt:5677.878\n",
      "Ep:181, loss:0.00001, loss_test:0.08839, lr:3.70e-03, fs:0.69620 (r=0.556,p=0.932),  time:31.369, tt:5709.108\n",
      "Ep:182, loss:0.00001, loss_test:0.08808, lr:3.66e-03, fs:0.69620 (r=0.556,p=0.932),  time:31.372, tt:5741.158\n",
      "Ep:183, loss:0.00001, loss_test:0.08711, lr:3.62e-03, fs:0.69620 (r=0.556,p=0.932),  time:31.374, tt:5772.739\n",
      "Ep:184, loss:0.00001, loss_test:0.08759, lr:3.59e-03, fs:0.69620 (r=0.556,p=0.932),  time:31.371, tt:5803.685\n",
      "Ep:185, loss:0.00001, loss_test:0.08762, lr:3.55e-03, fs:0.69620 (r=0.556,p=0.932),  time:31.363, tt:5833.430\n",
      "Ep:186, loss:0.00001, loss_test:0.08716, lr:3.52e-03, fs:0.68790 (r=0.545,p=0.931),  time:31.353, tt:5863.026\n",
      "Ep:187, loss:0.00001, loss_test:0.08810, lr:3.48e-03, fs:0.68790 (r=0.545,p=0.931),  time:31.353, tt:5894.368\n",
      "Ep:188, loss:0.00001, loss_test:0.08796, lr:3.45e-03, fs:0.69620 (r=0.556,p=0.932),  time:31.351, tt:5925.419\n",
      "Ep:189, loss:0.00001, loss_test:0.08698, lr:3.41e-03, fs:0.69620 (r=0.556,p=0.932),  time:31.351, tt:5956.737\n",
      "Ep:190, loss:0.00001, loss_test:0.08772, lr:3.38e-03, fs:0.68790 (r=0.545,p=0.931),  time:31.345, tt:5986.881\n",
      "Ep:191, loss:0.00001, loss_test:0.08823, lr:3.34e-03, fs:0.68790 (r=0.545,p=0.931),  time:31.338, tt:6016.984\n",
      "Ep:192, loss:0.00001, loss_test:0.08766, lr:3.31e-03, fs:0.70064 (r=0.556,p=0.948),  time:31.325, tt:6045.691\n",
      "Ep:193, loss:0.00001, loss_test:0.08699, lr:3.28e-03, fs:0.68790 (r=0.545,p=0.931),  time:31.303, tt:6072.842\n",
      "Ep:194, loss:0.00001, loss_test:0.08808, lr:3.24e-03, fs:0.68790 (r=0.545,p=0.931),  time:31.283, tt:6100.107\n",
      "Ep:195, loss:0.00001, loss_test:0.08790, lr:3.21e-03, fs:0.69231 (r=0.545,p=0.947),  time:31.261, tt:6127.216\n",
      "Ep:196, loss:0.00001, loss_test:0.08824, lr:3.18e-03, fs:0.69231 (r=0.545,p=0.947),  time:31.248, tt:6155.779\n",
      "Ep:197, loss:0.00001, loss_test:0.08813, lr:3.15e-03, fs:0.69620 (r=0.556,p=0.932),  time:31.210, tt:6179.523\n",
      "Ep:198, loss:0.00001, loss_test:0.08690, lr:3.12e-03, fs:0.69231 (r=0.545,p=0.947),  time:31.164, tt:6201.626\n",
      "Ep:199, loss:0.00001, loss_test:0.08883, lr:3.09e-03, fs:0.68790 (r=0.545,p=0.931),  time:31.115, tt:6222.994\n",
      "Ep:200, loss:0.00001, loss_test:0.08917, lr:3.05e-03, fs:0.69620 (r=0.556,p=0.932),  time:31.096, tt:6250.346\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02002, lr:6.00e-02, fs:0.66909 (r=0.929,p=0.523),  time:25.983, tt:25.983\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02308, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.927, tt:57.853\n",
      "Ep:2, loss:0.00005, loss_test:0.02543, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.738, tt:98.214\n",
      "Ep:3, loss:0.00005, loss_test:0.02594, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.362, tt:137.449\n",
      "Ep:4, loss:0.00005, loss_test:0.02540, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.578, tt:177.890\n",
      "Ep:5, loss:0.00005, loss_test:0.02408, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.362, tt:218.170\n",
      "Ep:6, loss:0.00004, loss_test:0.02222, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.056, tt:259.393\n",
      "Ep:7, loss:0.00004, loss_test:0.02034, lr:6.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:37.728, tt:301.825\n",
      "Ep:8, loss:0.00004, loss_test:0.01909, lr:6.00e-02, fs:0.67399 (r=0.929,p=0.529),  time:37.969, tt:341.720\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01905, lr:6.00e-02, fs:0.68880 (r=0.838,p=0.585),  time:38.343, tt:383.425\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01939, lr:6.00e-02, fs:0.68996 (r=0.798,p=0.608),  time:38.566, tt:424.227\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01888, lr:6.00e-02, fs:0.69528 (r=0.818,p=0.604),  time:38.863, tt:466.355\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01808, lr:6.00e-02, fs:0.68548 (r=0.859,p=0.570),  time:39.039, tt:507.504\n",
      "Ep:13, loss:0.00003, loss_test:0.01770, lr:6.00e-02, fs:0.68441 (r=0.909,p=0.549),  time:39.054, tt:546.754\n",
      "Ep:14, loss:0.00003, loss_test:0.01751, lr:6.00e-02, fs:0.70149 (r=0.949,p=0.556),  time:39.124, tt:586.865\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01727, lr:6.00e-02, fs:0.69663 (r=0.939,p=0.554),  time:39.365, tt:629.833\n",
      "Ep:16, loss:0.00003, loss_test:0.01708, lr:6.00e-02, fs:0.72441 (r=0.929,p=0.594),  time:39.336, tt:668.705\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01710, lr:6.00e-02, fs:0.75630 (r=0.909,p=0.647),  time:39.336, tt:708.050\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01718, lr:6.00e-02, fs:0.75983 (r=0.879,p=0.669),  time:39.352, tt:747.685\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01709, lr:6.00e-02, fs:0.76316 (r=0.879,p=0.674),  time:39.401, tt:788.018\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01685, lr:6.00e-02, fs:0.76724 (r=0.899,p=0.669),  time:39.517, tt:829.866\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01659, lr:6.00e-02, fs:0.76068 (r=0.899,p=0.659),  time:39.532, tt:869.699\n",
      "Ep:22, loss:0.00002, loss_test:0.01642, lr:6.00e-02, fs:0.75424 (r=0.899,p=0.650),  time:39.558, tt:909.825\n",
      "Ep:23, loss:0.00002, loss_test:0.01632, lr:6.00e-02, fs:0.75424 (r=0.899,p=0.650),  time:39.661, tt:951.868\n",
      "Ep:24, loss:0.00002, loss_test:0.01629, lr:6.00e-02, fs:0.76068 (r=0.899,p=0.659),  time:39.686, tt:992.152\n",
      "Ep:25, loss:0.00002, loss_test:0.01630, lr:6.00e-02, fs:0.76190 (r=0.889,p=0.667),  time:39.706, tt:1032.350\n",
      "Ep:26, loss:0.00002, loss_test:0.01628, lr:6.00e-02, fs:0.76856 (r=0.889,p=0.677),  time:39.742, tt:1073.046\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01619, lr:6.00e-02, fs:0.77193 (r=0.889,p=0.682),  time:39.808, tt:1114.620\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01605, lr:6.00e-02, fs:0.76106 (r=0.869,p=0.677),  time:39.798, tt:1154.139\n",
      "Ep:29, loss:0.00002, loss_test:0.01590, lr:6.00e-02, fs:0.75556 (r=0.859,p=0.675),  time:39.857, tt:1195.697\n",
      "Ep:30, loss:0.00002, loss_test:0.01578, lr:6.00e-02, fs:0.76106 (r=0.869,p=0.677),  time:39.884, tt:1236.396\n",
      "Ep:31, loss:0.00002, loss_test:0.01571, lr:6.00e-02, fs:0.76444 (r=0.869,p=0.683),  time:39.924, tt:1277.558\n",
      "Ep:32, loss:0.00002, loss_test:0.01569, lr:6.00e-02, fs:0.77130 (r=0.869,p=0.694),  time:39.930, tt:1317.693\n",
      "Ep:33, loss:0.00002, loss_test:0.01565, lr:6.00e-02, fs:0.77130 (r=0.869,p=0.694),  time:39.941, tt:1358.000\n",
      "Ep:34, loss:0.00002, loss_test:0.01559, lr:6.00e-02, fs:0.77828 (r=0.869,p=0.705),  time:39.917, tt:1397.107\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01551, lr:6.00e-02, fs:0.78182 (r=0.869,p=0.711),  time:39.979, tt:1439.259\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01543, lr:6.00e-02, fs:0.76498 (r=0.838,p=0.703),  time:40.051, tt:1481.874\n",
      "Ep:37, loss:0.00002, loss_test:0.01536, lr:6.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:40.040, tt:1521.532\n",
      "Ep:38, loss:0.00002, loss_test:0.01531, lr:6.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:40.061, tt:1562.373\n",
      "Ep:39, loss:0.00002, loss_test:0.01527, lr:6.00e-02, fs:0.77209 (r=0.838,p=0.716),  time:40.080, tt:1603.212\n",
      "Ep:40, loss:0.00001, loss_test:0.01519, lr:6.00e-02, fs:0.77570 (r=0.838,p=0.722),  time:40.190, tt:1647.798\n",
      "Ep:41, loss:0.00001, loss_test:0.01516, lr:6.00e-02, fs:0.77570 (r=0.838,p=0.722),  time:40.207, tt:1688.706\n",
      "Ep:42, loss:0.00001, loss_test:0.01516, lr:6.00e-02, fs:0.77358 (r=0.828,p=0.726),  time:40.234, tt:1730.041\n",
      "Ep:43, loss:0.00001, loss_test:0.01513, lr:6.00e-02, fs:0.77358 (r=0.828,p=0.726),  time:40.242, tt:1770.631\n",
      "Ep:44, loss:0.00001, loss_test:0.01513, lr:6.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:40.258, tt:1811.594\n",
      "Ep:45, loss:0.00001, loss_test:0.01509, lr:6.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:40.244, tt:1851.220\n",
      "Ep:46, loss:0.00001, loss_test:0.01504, lr:6.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:40.256, tt:1892.028\n",
      "Ep:47, loss:0.00001, loss_test:0.01496, lr:5.94e-02, fs:0.77512 (r=0.818,p=0.736),  time:40.245, tt:1931.755\n",
      "Ep:48, loss:0.00001, loss_test:0.01494, lr:5.88e-02, fs:0.77512 (r=0.818,p=0.736),  time:40.261, tt:1972.781\n",
      "Ep:49, loss:0.00001, loss_test:0.01491, lr:5.82e-02, fs:0.77295 (r=0.808,p=0.741),  time:40.231, tt:2011.557\n",
      "Ep:50, loss:0.00001, loss_test:0.01488, lr:5.76e-02, fs:0.77885 (r=0.818,p=0.743),  time:40.226, tt:2051.524\n",
      "Ep:51, loss:0.00001, loss_test:0.01486, lr:5.71e-02, fs:0.77670 (r=0.808,p=0.748),  time:40.248, tt:2092.875\n",
      "Ep:52, loss:0.00001, loss_test:0.01482, lr:5.65e-02, fs:0.77670 (r=0.808,p=0.748),  time:40.239, tt:2132.643\n",
      "Ep:53, loss:0.00001, loss_test:0.01479, lr:5.59e-02, fs:0.77670 (r=0.808,p=0.748),  time:40.354, tt:2179.134\n",
      "Ep:54, loss:0.00001, loss_test:0.01480, lr:5.54e-02, fs:0.77451 (r=0.798,p=0.752),  time:40.347, tt:2219.088\n",
      "Ep:55, loss:0.00001, loss_test:0.01479, lr:5.48e-02, fs:0.77451 (r=0.798,p=0.752),  time:40.327, tt:2258.320\n",
      "Ep:56, loss:0.00001, loss_test:0.01477, lr:5.43e-02, fs:0.76238 (r=0.778,p=0.748),  time:40.339, tt:2299.346\n",
      "Ep:57, loss:0.00001, loss_test:0.01473, lr:5.37e-02, fs:0.76847 (r=0.788,p=0.750),  time:40.332, tt:2339.242\n",
      "Ep:58, loss:0.00001, loss_test:0.01473, lr:5.32e-02, fs:0.76847 (r=0.788,p=0.750),  time:40.353, tt:2380.845\n",
      "Ep:59, loss:0.00001, loss_test:0.01472, lr:5.27e-02, fs:0.77833 (r=0.798,p=0.760),  time:40.366, tt:2421.959\n",
      "Ep:60, loss:0.00001, loss_test:0.01470, lr:5.21e-02, fs:0.78218 (r=0.798,p=0.767),  time:40.362, tt:2462.099\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.01470, lr:5.21e-02, fs:0.78218 (r=0.798,p=0.767),  time:40.344, tt:2501.331\n",
      "Ep:62, loss:0.00001, loss_test:0.01472, lr:5.21e-02, fs:0.79000 (r=0.798,p=0.782),  time:40.344, tt:2541.698\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00001, loss_test:0.01472, lr:5.21e-02, fs:0.78392 (r=0.788,p=0.780),  time:40.346, tt:2582.176\n",
      "Ep:64, loss:0.00001, loss_test:0.01469, lr:5.21e-02, fs:0.78788 (r=0.788,p=0.788),  time:40.352, tt:2622.888\n",
      "Ep:65, loss:0.00001, loss_test:0.01467, lr:5.21e-02, fs:0.78788 (r=0.788,p=0.788),  time:40.343, tt:2662.667\n",
      "Ep:66, loss:0.00001, loss_test:0.01469, lr:5.21e-02, fs:0.76923 (r=0.758,p=0.781),  time:40.324, tt:2701.726\n",
      "Ep:67, loss:0.00001, loss_test:0.01469, lr:5.21e-02, fs:0.77320 (r=0.758,p=0.789),  time:40.316, tt:2741.516\n",
      "Ep:68, loss:0.00001, loss_test:0.01469, lr:5.21e-02, fs:0.76684 (r=0.747,p=0.787),  time:40.297, tt:2780.472\n",
      "Ep:69, loss:0.00001, loss_test:0.01471, lr:5.21e-02, fs:0.76684 (r=0.747,p=0.787),  time:40.282, tt:2819.742\n",
      "Ep:70, loss:0.00001, loss_test:0.01473, lr:5.21e-02, fs:0.76684 (r=0.747,p=0.787),  time:40.296, tt:2861.043\n",
      "Ep:71, loss:0.00001, loss_test:0.01473, lr:5.21e-02, fs:0.77083 (r=0.747,p=0.796),  time:40.288, tt:2900.708\n",
      "Ep:72, loss:0.00001, loss_test:0.01476, lr:5.21e-02, fs:0.77487 (r=0.747,p=0.804),  time:40.277, tt:2940.195\n",
      "Ep:73, loss:0.00001, loss_test:0.01476, lr:5.21e-02, fs:0.77487 (r=0.747,p=0.804),  time:40.256, tt:2978.967\n",
      "Ep:74, loss:0.00001, loss_test:0.01475, lr:5.16e-02, fs:0.76190 (r=0.727,p=0.800),  time:40.250, tt:3018.761\n",
      "Ep:75, loss:0.00001, loss_test:0.01476, lr:5.11e-02, fs:0.75532 (r=0.717,p=0.798),  time:40.262, tt:3059.882\n",
      "Ep:76, loss:0.00001, loss_test:0.01475, lr:5.06e-02, fs:0.75532 (r=0.717,p=0.798),  time:40.259, tt:3099.946\n",
      "Ep:77, loss:0.00001, loss_test:0.01476, lr:5.01e-02, fs:0.75936 (r=0.717,p=0.807),  time:40.258, tt:3140.092\n",
      "Ep:78, loss:0.00001, loss_test:0.01480, lr:4.96e-02, fs:0.76344 (r=0.717,p=0.816),  time:40.261, tt:3180.619\n",
      "Ep:79, loss:0.00001, loss_test:0.01484, lr:4.91e-02, fs:0.76344 (r=0.717,p=0.816),  time:40.248, tt:3219.821\n",
      "Ep:80, loss:0.00001, loss_test:0.01484, lr:4.86e-02, fs:0.75676 (r=0.707,p=0.814),  time:40.247, tt:3259.996\n",
      "Ep:81, loss:0.00001, loss_test:0.01486, lr:4.81e-02, fs:0.75676 (r=0.707,p=0.814),  time:40.225, tt:3298.411\n",
      "Ep:82, loss:0.00001, loss_test:0.01486, lr:4.76e-02, fs:0.75410 (r=0.697,p=0.821),  time:40.178, tt:3334.759\n",
      "Ep:83, loss:0.00001, loss_test:0.01489, lr:4.71e-02, fs:0.74725 (r=0.687,p=0.819),  time:40.172, tt:3374.474\n",
      "Ep:84, loss:0.00001, loss_test:0.01491, lr:4.67e-02, fs:0.74725 (r=0.687,p=0.819),  time:40.175, tt:3414.843\n",
      "Ep:85, loss:0.00001, loss_test:0.01493, lr:4.62e-02, fs:0.74444 (r=0.677,p=0.827),  time:40.133, tt:3451.413\n",
      "Ep:86, loss:0.00001, loss_test:0.01494, lr:4.57e-02, fs:0.74444 (r=0.677,p=0.827),  time:40.155, tt:3493.469\n",
      "Ep:87, loss:0.00001, loss_test:0.01495, lr:4.53e-02, fs:0.74444 (r=0.677,p=0.827),  time:40.139, tt:3532.195\n",
      "Ep:88, loss:0.00001, loss_test:0.01498, lr:4.48e-02, fs:0.74444 (r=0.677,p=0.827),  time:40.114, tt:3570.154\n",
      "Ep:89, loss:0.00001, loss_test:0.01502, lr:4.44e-02, fs:0.74444 (r=0.677,p=0.827),  time:40.132, tt:3611.869\n",
      "Ep:90, loss:0.00001, loss_test:0.01505, lr:4.39e-02, fs:0.74157 (r=0.667,p=0.835),  time:40.139, tt:3652.660\n",
      "Ep:91, loss:0.00001, loss_test:0.01508, lr:4.35e-02, fs:0.74157 (r=0.667,p=0.835),  time:40.127, tt:3691.715\n",
      "Ep:92, loss:0.00001, loss_test:0.01510, lr:4.31e-02, fs:0.74576 (r=0.667,p=0.846),  time:40.111, tt:3730.288\n",
      "Ep:93, loss:0.00001, loss_test:0.01511, lr:4.26e-02, fs:0.75000 (r=0.667,p=0.857),  time:40.112, tt:3770.546\n",
      "Ep:94, loss:0.00001, loss_test:0.01513, lr:4.22e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.110, tt:3810.481\n",
      "Ep:95, loss:0.00001, loss_test:0.01516, lr:4.18e-02, fs:0.74713 (r=0.657,p=0.867),  time:40.140, tt:3853.414\n",
      "Ep:96, loss:0.00001, loss_test:0.01517, lr:4.14e-02, fs:0.74713 (r=0.657,p=0.867),  time:40.142, tt:3893.756\n",
      "Ep:97, loss:0.00001, loss_test:0.01519, lr:4.10e-02, fs:0.74713 (r=0.657,p=0.867),  time:40.141, tt:3933.847\n",
      "Ep:98, loss:0.00001, loss_test:0.01520, lr:4.05e-02, fs:0.75145 (r=0.657,p=0.878),  time:40.152, tt:3975.011\n",
      "Ep:99, loss:0.00001, loss_test:0.01522, lr:4.01e-02, fs:0.75145 (r=0.657,p=0.878),  time:40.131, tt:4013.138\n",
      "Ep:100, loss:0.00000, loss_test:0.01525, lr:3.97e-02, fs:0.75145 (r=0.657,p=0.878),  time:40.124, tt:4052.509\n",
      "Ep:101, loss:0.00000, loss_test:0.01526, lr:3.93e-02, fs:0.75145 (r=0.657,p=0.878),  time:40.132, tt:4093.495\n",
      "Ep:102, loss:0.00000, loss_test:0.01527, lr:3.89e-02, fs:0.75145 (r=0.657,p=0.878),  time:40.134, tt:4133.805\n",
      "Ep:103, loss:0.00000, loss_test:0.01530, lr:3.86e-02, fs:0.75145 (r=0.657,p=0.878),  time:40.116, tt:4172.059\n",
      "Ep:104, loss:0.00000, loss_test:0.01532, lr:3.82e-02, fs:0.75145 (r=0.657,p=0.878),  time:40.107, tt:4211.206\n",
      "Ep:105, loss:0.00000, loss_test:0.01534, lr:3.78e-02, fs:0.75145 (r=0.657,p=0.878),  time:40.108, tt:4251.400\n",
      "Ep:106, loss:0.00000, loss_test:0.01537, lr:3.74e-02, fs:0.75145 (r=0.657,p=0.878),  time:40.105, tt:4291.199\n",
      "Ep:107, loss:0.00000, loss_test:0.01541, lr:3.70e-02, fs:0.75145 (r=0.657,p=0.878),  time:40.116, tt:4332.522\n",
      "Ep:108, loss:0.00000, loss_test:0.01542, lr:3.67e-02, fs:0.75145 (r=0.657,p=0.878),  time:40.117, tt:4372.705\n",
      "Ep:109, loss:0.00000, loss_test:0.01544, lr:3.63e-02, fs:0.75145 (r=0.657,p=0.878),  time:40.112, tt:4412.317\n",
      "Ep:110, loss:0.00000, loss_test:0.01546, lr:3.59e-02, fs:0.75145 (r=0.657,p=0.878),  time:40.114, tt:4452.650\n",
      "Ep:111, loss:0.00000, loss_test:0.01548, lr:3.56e-02, fs:0.75145 (r=0.657,p=0.878),  time:40.114, tt:4492.748\n",
      "Ep:112, loss:0.00000, loss_test:0.01551, lr:3.52e-02, fs:0.75145 (r=0.657,p=0.878),  time:40.108, tt:4532.215\n",
      "Ep:113, loss:0.00000, loss_test:0.01555, lr:3.49e-02, fs:0.75581 (r=0.657,p=0.890),  time:40.100, tt:4571.359\n",
      "Ep:114, loss:0.00000, loss_test:0.01558, lr:3.45e-02, fs:0.75581 (r=0.657,p=0.890),  time:40.095, tt:4610.907\n",
      "Ep:115, loss:0.00000, loss_test:0.01558, lr:3.42e-02, fs:0.75581 (r=0.657,p=0.890),  time:40.102, tt:4651.890\n",
      "Ep:116, loss:0.00000, loss_test:0.01560, lr:3.38e-02, fs:0.75581 (r=0.657,p=0.890),  time:40.124, tt:4694.459\n",
      "Ep:117, loss:0.00000, loss_test:0.01562, lr:3.35e-02, fs:0.75581 (r=0.657,p=0.890),  time:40.138, tt:4736.268\n",
      "Ep:118, loss:0.00000, loss_test:0.01565, lr:3.32e-02, fs:0.75581 (r=0.657,p=0.890),  time:40.133, tt:4775.879\n",
      "Ep:119, loss:0.00000, loss_test:0.01567, lr:3.28e-02, fs:0.75581 (r=0.657,p=0.890),  time:40.151, tt:4818.118\n",
      "Ep:120, loss:0.00000, loss_test:0.01569, lr:3.25e-02, fs:0.75581 (r=0.657,p=0.890),  time:40.158, tt:4859.076\n",
      "Ep:121, loss:0.00000, loss_test:0.01571, lr:3.22e-02, fs:0.75581 (r=0.657,p=0.890),  time:40.183, tt:4902.386\n",
      "Ep:122, loss:0.00000, loss_test:0.01574, lr:3.19e-02, fs:0.75581 (r=0.657,p=0.890),  time:40.186, tt:4942.830\n",
      "Ep:123, loss:0.00000, loss_test:0.01575, lr:3.15e-02, fs:0.75581 (r=0.657,p=0.890),  time:40.186, tt:4983.109\n",
      "Ep:124, loss:0.00000, loss_test:0.01575, lr:3.12e-02, fs:0.75581 (r=0.657,p=0.890),  time:40.197, tt:5024.635\n",
      "Ep:125, loss:0.00000, loss_test:0.01577, lr:3.09e-02, fs:0.75581 (r=0.657,p=0.890),  time:40.188, tt:5063.638\n",
      "Ep:126, loss:0.00000, loss_test:0.01578, lr:3.06e-02, fs:0.75581 (r=0.657,p=0.890),  time:40.176, tt:5102.386\n",
      "Ep:127, loss:0.00000, loss_test:0.01581, lr:3.03e-02, fs:0.75581 (r=0.657,p=0.890),  time:40.174, tt:5142.312\n",
      "Ep:128, loss:0.00000, loss_test:0.01581, lr:3.00e-02, fs:0.75581 (r=0.657,p=0.890),  time:40.196, tt:5185.279\n",
      "Ep:129, loss:0.00000, loss_test:0.01582, lr:2.97e-02, fs:0.75581 (r=0.657,p=0.890),  time:40.180, tt:5223.372\n",
      "Ep:130, loss:0.00000, loss_test:0.01584, lr:2.94e-02, fs:0.75581 (r=0.657,p=0.890),  time:40.184, tt:5264.094\n",
      "Ep:131, loss:0.00000, loss_test:0.01587, lr:2.91e-02, fs:0.75581 (r=0.657,p=0.890),  time:40.178, tt:5303.482\n",
      "Ep:132, loss:0.00000, loss_test:0.01589, lr:2.88e-02, fs:0.75581 (r=0.657,p=0.890),  time:40.184, tt:5344.449\n",
      "Ep:133, loss:0.00000, loss_test:0.01590, lr:2.85e-02, fs:0.76023 (r=0.657,p=0.903),  time:40.182, tt:5384.451\n",
      "Ep:134, loss:0.00000, loss_test:0.01593, lr:2.82e-02, fs:0.76023 (r=0.657,p=0.903),  time:40.183, tt:5424.640\n",
      "Ep:135, loss:0.00000, loss_test:0.01595, lr:2.80e-02, fs:0.76023 (r=0.657,p=0.903),  time:40.184, tt:5464.967\n",
      "Ep:136, loss:0.00000, loss_test:0.01598, lr:2.77e-02, fs:0.76023 (r=0.657,p=0.903),  time:40.174, tt:5503.798\n",
      "Ep:137, loss:0.00000, loss_test:0.01600, lr:2.74e-02, fs:0.75294 (r=0.646,p=0.901),  time:40.172, tt:5543.764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:138, loss:0.00000, loss_test:0.01603, lr:2.71e-02, fs:0.74556 (r=0.636,p=0.900),  time:40.160, tt:5582.191\n",
      "Ep:139, loss:0.00000, loss_test:0.01604, lr:2.69e-02, fs:0.74556 (r=0.636,p=0.900),  time:40.150, tt:5620.986\n",
      "Ep:140, loss:0.00000, loss_test:0.01605, lr:2.66e-02, fs:0.74556 (r=0.636,p=0.900),  time:40.166, tt:5663.424\n",
      "Ep:141, loss:0.00000, loss_test:0.01607, lr:2.63e-02, fs:0.73810 (r=0.626,p=0.899),  time:40.154, tt:5701.917\n",
      "Ep:142, loss:0.00000, loss_test:0.01609, lr:2.61e-02, fs:0.73810 (r=0.626,p=0.899),  time:40.165, tt:5743.551\n",
      "Ep:143, loss:0.00000, loss_test:0.01611, lr:2.58e-02, fs:0.73810 (r=0.626,p=0.899),  time:40.156, tt:5782.437\n",
      "Ep:144, loss:0.00000, loss_test:0.01611, lr:2.55e-02, fs:0.73810 (r=0.626,p=0.899),  time:40.155, tt:5822.487\n",
      "Ep:145, loss:0.00000, loss_test:0.01613, lr:2.53e-02, fs:0.74251 (r=0.626,p=0.912),  time:40.153, tt:5862.399\n",
      "Ep:146, loss:0.00000, loss_test:0.01615, lr:2.50e-02, fs:0.74251 (r=0.626,p=0.912),  time:40.148, tt:5901.765\n",
      "Ep:147, loss:0.00000, loss_test:0.01616, lr:2.48e-02, fs:0.74251 (r=0.626,p=0.912),  time:40.150, tt:5942.247\n",
      "Ep:148, loss:0.00000, loss_test:0.01617, lr:2.45e-02, fs:0.73494 (r=0.616,p=0.910),  time:40.144, tt:5981.509\n",
      "Ep:149, loss:0.00000, loss_test:0.01619, lr:2.43e-02, fs:0.73494 (r=0.616,p=0.910),  time:40.149, tt:6022.344\n",
      "Ep:150, loss:0.00000, loss_test:0.01622, lr:2.40e-02, fs:0.73494 (r=0.616,p=0.910),  time:40.148, tt:6062.407\n",
      "Ep:151, loss:0.00000, loss_test:0.01624, lr:2.38e-02, fs:0.73494 (r=0.616,p=0.910),  time:40.129, tt:6099.635\n",
      "Ep:152, loss:0.00000, loss_test:0.01625, lr:2.36e-02, fs:0.72727 (r=0.606,p=0.909),  time:40.127, tt:6139.442\n",
      "Ep:153, loss:0.00000, loss_test:0.01626, lr:2.33e-02, fs:0.72727 (r=0.606,p=0.909),  time:40.124, tt:6179.032\n",
      "Ep:154, loss:0.00000, loss_test:0.01628, lr:2.31e-02, fs:0.72727 (r=0.606,p=0.909),  time:40.118, tt:6218.280\n",
      "Ep:155, loss:0.00000, loss_test:0.01631, lr:2.29e-02, fs:0.72727 (r=0.606,p=0.909),  time:40.116, tt:6258.149\n",
      "Ep:156, loss:0.00000, loss_test:0.01632, lr:2.26e-02, fs:0.71951 (r=0.596,p=0.908),  time:40.117, tt:6298.448\n",
      "Ep:157, loss:0.00000, loss_test:0.01633, lr:2.24e-02, fs:0.71951 (r=0.596,p=0.908),  time:40.132, tt:6340.848\n",
      "Ep:158, loss:0.00000, loss_test:0.01635, lr:2.22e-02, fs:0.71166 (r=0.586,p=0.906),  time:40.142, tt:6382.598\n",
      "Ep:159, loss:0.00000, loss_test:0.01638, lr:2.20e-02, fs:0.71166 (r=0.586,p=0.906),  time:40.148, tt:6423.617\n",
      "Ep:160, loss:0.00000, loss_test:0.01639, lr:2.17e-02, fs:0.70370 (r=0.576,p=0.905),  time:40.139, tt:6462.388\n",
      "Ep:161, loss:0.00000, loss_test:0.01640, lr:2.15e-02, fs:0.70370 (r=0.576,p=0.905),  time:40.144, tt:6503.302\n",
      "Ep:162, loss:0.00000, loss_test:0.01641, lr:2.13e-02, fs:0.69565 (r=0.566,p=0.903),  time:40.141, tt:6542.981\n",
      "Ep:163, loss:0.00000, loss_test:0.01642, lr:2.11e-02, fs:0.69565 (r=0.566,p=0.903),  time:40.142, tt:6583.239\n",
      "Ep:164, loss:0.00000, loss_test:0.01643, lr:2.09e-02, fs:0.68750 (r=0.556,p=0.902),  time:40.139, tt:6622.946\n",
      "Ep:165, loss:0.00000, loss_test:0.01645, lr:2.07e-02, fs:0.68750 (r=0.556,p=0.902),  time:40.136, tt:6662.573\n",
      "Ep:166, loss:0.00000, loss_test:0.01646, lr:2.05e-02, fs:0.68750 (r=0.556,p=0.902),  time:40.130, tt:6701.712\n",
      "Ep:167, loss:0.00000, loss_test:0.01648, lr:2.03e-02, fs:0.68750 (r=0.556,p=0.902),  time:40.128, tt:6741.582\n",
      "Ep:168, loss:0.00000, loss_test:0.01650, lr:2.01e-02, fs:0.68750 (r=0.556,p=0.902),  time:40.125, tt:6781.061\n",
      "Ep:169, loss:0.00000, loss_test:0.01651, lr:1.99e-02, fs:0.69620 (r=0.556,p=0.932),  time:40.126, tt:6821.492\n",
      "Ep:170, loss:0.00000, loss_test:0.01652, lr:1.97e-02, fs:0.69620 (r=0.556,p=0.932),  time:40.115, tt:6859.735\n",
      "Ep:171, loss:0.00000, loss_test:0.01654, lr:1.95e-02, fs:0.68790 (r=0.545,p=0.931),  time:40.113, tt:6899.493\n",
      "Ep:172, loss:0.00000, loss_test:0.01655, lr:1.93e-02, fs:0.68790 (r=0.545,p=0.931),  time:40.126, tt:6941.834\n",
      "Ep:173, loss:0.00000, loss_test:0.01656, lr:1.91e-02, fs:0.68790 (r=0.545,p=0.931),  time:40.143, tt:6984.839\n",
      "Ep:174, loss:0.00000, loss_test:0.01658, lr:1.89e-02, fs:0.68790 (r=0.545,p=0.931),  time:40.153, tt:7026.717\n",
      "Ep:175, loss:0.00000, loss_test:0.01659, lr:1.87e-02, fs:0.68790 (r=0.545,p=0.931),  time:40.156, tt:7067.444\n",
      "Ep:176, loss:0.00000, loss_test:0.01661, lr:1.85e-02, fs:0.68790 (r=0.545,p=0.931),  time:40.159, tt:7108.229\n",
      "Ep:177, loss:0.00000, loss_test:0.01663, lr:1.83e-02, fs:0.68790 (r=0.545,p=0.931),  time:40.168, tt:7149.869\n",
      "Ep:178, loss:0.00000, loss_test:0.01664, lr:1.81e-02, fs:0.68790 (r=0.545,p=0.931),  time:40.193, tt:7194.562\n",
      "Ep:179, loss:0.00000, loss_test:0.01665, lr:1.80e-02, fs:0.68790 (r=0.545,p=0.931),  time:40.186, tt:7233.406\n",
      "Ep:180, loss:0.00000, loss_test:0.01667, lr:1.78e-02, fs:0.68790 (r=0.545,p=0.931),  time:40.181, tt:7272.851\n",
      "Ep:181, loss:0.00000, loss_test:0.01668, lr:1.76e-02, fs:0.68790 (r=0.545,p=0.931),  time:40.187, tt:7314.110\n",
      "Ep:182, loss:0.00000, loss_test:0.01669, lr:1.74e-02, fs:0.68790 (r=0.545,p=0.931),  time:40.194, tt:7355.527\n",
      "Ep:183, loss:0.00000, loss_test:0.01670, lr:1.73e-02, fs:0.68790 (r=0.545,p=0.931),  time:40.202, tt:7397.189\n",
      "Ep:184, loss:0.00000, loss_test:0.01672, lr:1.71e-02, fs:0.68790 (r=0.545,p=0.931),  time:40.197, tt:7436.494\n",
      "Ep:185, loss:0.00000, loss_test:0.01673, lr:1.69e-02, fs:0.68790 (r=0.545,p=0.931),  time:40.200, tt:7477.261\n",
      "Ep:186, loss:0.00000, loss_test:0.01674, lr:1.67e-02, fs:0.68790 (r=0.545,p=0.931),  time:40.207, tt:7518.790\n",
      "Ep:187, loss:0.00000, loss_test:0.01675, lr:1.66e-02, fs:0.68790 (r=0.545,p=0.931),  time:40.208, tt:7559.022\n",
      "Ep:188, loss:0.00000, loss_test:0.01676, lr:1.64e-02, fs:0.68790 (r=0.545,p=0.931),  time:40.211, tt:7599.855\n",
      "Ep:189, loss:0.00000, loss_test:0.01677, lr:1.62e-02, fs:0.68790 (r=0.545,p=0.931),  time:40.215, tt:7640.945\n",
      "Ep:190, loss:0.00000, loss_test:0.01679, lr:1.61e-02, fs:0.68790 (r=0.545,p=0.931),  time:40.222, tt:7682.393\n",
      "Ep:191, loss:0.00000, loss_test:0.01680, lr:1.59e-02, fs:0.68790 (r=0.545,p=0.931),  time:40.215, tt:7721.347\n",
      "Ep:192, loss:0.00000, loss_test:0.01681, lr:1.58e-02, fs:0.68790 (r=0.545,p=0.931),  time:40.215, tt:7761.473\n",
      "Ep:193, loss:0.00000, loss_test:0.01682, lr:1.56e-02, fs:0.67949 (r=0.535,p=0.930),  time:40.225, tt:7803.728\n",
      "Ep:194, loss:0.00000, loss_test:0.01683, lr:1.54e-02, fs:0.67949 (r=0.535,p=0.930),  time:40.224, tt:7843.708\n",
      "Ep:195, loss:0.00000, loss_test:0.01684, lr:1.53e-02, fs:0.67949 (r=0.535,p=0.930),  time:40.224, tt:7883.976\n",
      "Ep:196, loss:0.00000, loss_test:0.01685, lr:1.51e-02, fs:0.67949 (r=0.535,p=0.930),  time:40.218, tt:7922.971\n",
      "Ep:197, loss:0.00000, loss_test:0.01687, lr:1.50e-02, fs:0.67949 (r=0.535,p=0.930),  time:40.211, tt:7961.794\n",
      "Ep:198, loss:0.00000, loss_test:0.01688, lr:1.48e-02, fs:0.67949 (r=0.535,p=0.930),  time:40.205, tt:8000.776\n",
      "Ep:199, loss:0.00000, loss_test:0.01689, lr:1.47e-02, fs:0.67949 (r=0.535,p=0.930),  time:40.227, tt:8045.323\n",
      "Ep:200, loss:0.00000, loss_test:0.01690, lr:1.45e-02, fs:0.67949 (r=0.535,p=0.930),  time:40.224, tt:8085.056\n",
      "Ep:201, loss:0.00000, loss_test:0.01691, lr:1.44e-02, fs:0.67949 (r=0.535,p=0.930),  time:40.217, tt:8123.777\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13640, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:33.048, tt:33.048\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13311, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:31.822, tt:63.644\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.12687, lr:1.00e-02, fs:0.67606 (r=0.970,p=0.519),  time:34.513, tt:103.538\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00025, loss_test:0.11818, lr:1.00e-02, fs:0.70732 (r=0.879,p=0.592),  time:36.251, tt:145.005\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00024, loss_test:0.11314, lr:1.00e-02, fs:0.70370 (r=0.768,p=0.650),  time:37.677, tt:188.384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:5, loss:0.00023, loss_test:0.11116, lr:1.00e-02, fs:0.71921 (r=0.737,p=0.702),  time:38.649, tt:231.892\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00022, loss_test:0.10822, lr:1.00e-02, fs:0.73077 (r=0.768,p=0.697),  time:38.893, tt:272.250\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00021, loss_test:0.10751, lr:1.00e-02, fs:0.77828 (r=0.869,p=0.705),  time:39.381, tt:315.049\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00021, loss_test:0.10339, lr:1.00e-02, fs:0.78899 (r=0.869,p=0.723),  time:39.532, tt:355.783\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00020, loss_test:0.09967, lr:1.00e-02, fs:0.75248 (r=0.768,p=0.738),  time:39.932, tt:399.316\n",
      "Ep:10, loss:0.00019, loss_test:0.09822, lr:1.00e-02, fs:0.76768 (r=0.768,p=0.768),  time:40.055, tt:440.609\n",
      "Ep:11, loss:0.00018, loss_test:0.09696, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:40.228, tt:482.740\n",
      "Ep:12, loss:0.00017, loss_test:0.09592, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:40.386, tt:525.016\n",
      "Ep:13, loss:0.00016, loss_test:0.09478, lr:1.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:40.555, tt:567.775\n",
      "Ep:14, loss:0.00016, loss_test:0.09366, lr:1.00e-02, fs:0.76190 (r=0.727,p=0.800),  time:40.640, tt:609.601\n",
      "Ep:15, loss:0.00015, loss_test:0.09291, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:40.676, tt:650.824\n",
      "Ep:16, loss:0.00014, loss_test:0.09268, lr:1.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:40.871, tt:694.807\n",
      "Ep:17, loss:0.00013, loss_test:0.09144, lr:1.00e-02, fs:0.80645 (r=0.758,p=0.862),  time:41.104, tt:739.873\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00013, loss_test:0.08916, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:41.091, tt:780.738\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00012, loss_test:0.08805, lr:1.00e-02, fs:0.81967 (r=0.758,p=0.893),  time:41.119, tt:822.377\n",
      "Ep:20, loss:0.00012, loss_test:0.08704, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:41.079, tt:862.667\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00011, loss_test:0.08613, lr:1.00e-02, fs:0.81967 (r=0.758,p=0.893),  time:41.060, tt:903.315\n",
      "Ep:22, loss:0.00010, loss_test:0.08484, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:41.044, tt:944.023\n",
      "Ep:23, loss:0.00010, loss_test:0.08416, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:41.077, tt:985.854\n",
      "Ep:24, loss:0.00009, loss_test:0.08384, lr:1.00e-02, fs:0.79310 (r=0.697,p=0.920),  time:41.124, tt:1028.109\n",
      "Ep:25, loss:0.00009, loss_test:0.08231, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:41.143, tt:1069.722\n",
      "Ep:26, loss:0.00009, loss_test:0.08237, lr:1.00e-02, fs:0.77011 (r=0.677,p=0.893),  time:41.162, tt:1111.379\n",
      "Ep:27, loss:0.00008, loss_test:0.08090, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:41.148, tt:1152.134\n",
      "Ep:28, loss:0.00008, loss_test:0.08026, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:41.160, tt:1193.638\n",
      "Ep:29, loss:0.00007, loss_test:0.08071, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:41.170, tt:1235.114\n",
      "Ep:30, loss:0.00007, loss_test:0.07962, lr:1.00e-02, fs:0.80663 (r=0.737,p=0.890),  time:41.149, tt:1275.617\n",
      "Ep:31, loss:0.00007, loss_test:0.07942, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:41.094, tt:1314.993\n",
      "Ep:32, loss:0.00006, loss_test:0.07977, lr:9.90e-03, fs:0.76301 (r=0.667,p=0.892),  time:41.105, tt:1356.452\n",
      "Ep:33, loss:0.00006, loss_test:0.07875, lr:9.80e-03, fs:0.77966 (r=0.697,p=0.885),  time:41.152, tt:1399.180\n",
      "Ep:34, loss:0.00006, loss_test:0.07884, lr:9.70e-03, fs:0.76301 (r=0.667,p=0.892),  time:41.196, tt:1441.868\n",
      "Ep:35, loss:0.00006, loss_test:0.07814, lr:9.61e-03, fs:0.77273 (r=0.687,p=0.883),  time:41.182, tt:1482.538\n",
      "Ep:36, loss:0.00006, loss_test:0.07795, lr:9.51e-03, fs:0.76301 (r=0.667,p=0.892),  time:41.187, tt:1523.936\n",
      "Ep:37, loss:0.00005, loss_test:0.07788, lr:9.41e-03, fs:0.72941 (r=0.626,p=0.873),  time:41.156, tt:1563.934\n",
      "Ep:38, loss:0.00005, loss_test:0.07815, lr:9.32e-03, fs:0.70659 (r=0.596,p=0.868),  time:41.183, tt:1606.127\n",
      "Ep:39, loss:0.00005, loss_test:0.07749, lr:9.23e-03, fs:0.71084 (r=0.596,p=0.881),  time:41.152, tt:1646.070\n",
      "Ep:40, loss:0.00005, loss_test:0.07761, lr:9.14e-03, fs:0.68712 (r=0.566,p=0.875),  time:41.121, tt:1685.974\n",
      "Ep:41, loss:0.00005, loss_test:0.07736, lr:9.04e-03, fs:0.68712 (r=0.566,p=0.875),  time:41.082, tt:1725.447\n",
      "Ep:42, loss:0.00004, loss_test:0.07734, lr:8.95e-03, fs:0.69512 (r=0.576,p=0.877),  time:41.081, tt:1766.490\n",
      "Ep:43, loss:0.00004, loss_test:0.07721, lr:8.86e-03, fs:0.68712 (r=0.566,p=0.875),  time:41.098, tt:1808.318\n",
      "Ep:44, loss:0.00004, loss_test:0.07717, lr:8.78e-03, fs:0.69512 (r=0.576,p=0.877),  time:41.054, tt:1847.413\n",
      "Ep:45, loss:0.00004, loss_test:0.07819, lr:8.69e-03, fs:0.68323 (r=0.556,p=0.887),  time:41.052, tt:1888.388\n",
      "Ep:46, loss:0.00004, loss_test:0.07883, lr:8.60e-03, fs:0.68750 (r=0.556,p=0.902),  time:41.029, tt:1928.356\n",
      "Ep:47, loss:0.00004, loss_test:0.07707, lr:8.51e-03, fs:0.70303 (r=0.586,p=0.879),  time:41.045, tt:1970.140\n",
      "Ep:48, loss:0.00004, loss_test:0.07927, lr:8.43e-03, fs:0.67925 (r=0.545,p=0.900),  time:41.050, tt:2011.467\n",
      "Ep:49, loss:0.00004, loss_test:0.07771, lr:8.35e-03, fs:0.69939 (r=0.576,p=0.891),  time:41.076, tt:2053.790\n",
      "Ep:50, loss:0.00004, loss_test:0.07749, lr:8.26e-03, fs:0.70732 (r=0.586,p=0.892),  time:41.132, tt:2097.708\n",
      "Ep:51, loss:0.00003, loss_test:0.07852, lr:8.18e-03, fs:0.68750 (r=0.556,p=0.902),  time:41.136, tt:2139.055\n",
      "Ep:52, loss:0.00003, loss_test:0.07807, lr:8.10e-03, fs:0.68323 (r=0.556,p=0.887),  time:41.126, tt:2179.690\n",
      "Ep:53, loss:0.00003, loss_test:0.07784, lr:8.02e-03, fs:0.68323 (r=0.556,p=0.887),  time:41.143, tt:2221.739\n",
      "Ep:54, loss:0.00003, loss_test:0.07873, lr:7.94e-03, fs:0.68354 (r=0.545,p=0.915),  time:41.154, tt:2263.450\n",
      "Ep:55, loss:0.00003, loss_test:0.07804, lr:7.86e-03, fs:0.68750 (r=0.556,p=0.902),  time:41.172, tt:2305.630\n",
      "Ep:56, loss:0.00003, loss_test:0.07796, lr:7.78e-03, fs:0.70000 (r=0.566,p=0.918),  time:41.190, tt:2347.822\n",
      "Ep:57, loss:0.00003, loss_test:0.07890, lr:7.70e-03, fs:0.68354 (r=0.545,p=0.915),  time:41.212, tt:2390.288\n",
      "Ep:58, loss:0.00003, loss_test:0.07850, lr:7.62e-03, fs:0.69182 (r=0.556,p=0.917),  time:41.222, tt:2432.094\n",
      "Ep:59, loss:0.00003, loss_test:0.07865, lr:7.55e-03, fs:0.68354 (r=0.545,p=0.915),  time:41.240, tt:2474.379\n",
      "Ep:60, loss:0.00003, loss_test:0.07853, lr:7.47e-03, fs:0.69182 (r=0.556,p=0.917),  time:41.245, tt:2515.942\n",
      "Ep:61, loss:0.00003, loss_test:0.07835, lr:7.40e-03, fs:0.70000 (r=0.566,p=0.918),  time:41.258, tt:2557.989\n",
      "Ep:62, loss:0.00002, loss_test:0.07958, lr:7.32e-03, fs:0.69182 (r=0.556,p=0.917),  time:41.260, tt:2599.383\n",
      "Ep:63, loss:0.00002, loss_test:0.07854, lr:7.25e-03, fs:0.69182 (r=0.556,p=0.917),  time:41.291, tt:2642.624\n",
      "Ep:64, loss:0.00002, loss_test:0.07827, lr:7.18e-03, fs:0.70000 (r=0.566,p=0.918),  time:41.316, tt:2685.556\n",
      "Ep:65, loss:0.00002, loss_test:0.07932, lr:7.11e-03, fs:0.69620 (r=0.556,p=0.932),  time:41.408, tt:2732.943\n",
      "Ep:66, loss:0.00002, loss_test:0.07828, lr:7.03e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.410, tt:2774.479\n",
      "Ep:67, loss:0.00002, loss_test:0.07885, lr:6.96e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.418, tt:2816.450\n",
      "Ep:68, loss:0.00002, loss_test:0.07898, lr:6.89e-03, fs:0.69620 (r=0.556,p=0.932),  time:41.419, tt:2857.936\n",
      "Ep:69, loss:0.00002, loss_test:0.07847, lr:6.83e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.426, tt:2899.815\n",
      "Ep:70, loss:0.00002, loss_test:0.07865, lr:6.76e-03, fs:0.69620 (r=0.556,p=0.932),  time:41.449, tt:2942.890\n",
      "Ep:71, loss:0.00002, loss_test:0.07894, lr:6.69e-03, fs:0.69620 (r=0.556,p=0.932),  time:41.459, tt:2985.014\n",
      "Ep:72, loss:0.00002, loss_test:0.07874, lr:6.62e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.440, tt:3025.146\n",
      "Ep:73, loss:0.00002, loss_test:0.07951, lr:6.56e-03, fs:0.69620 (r=0.556,p=0.932),  time:41.451, tt:3067.378\n",
      "Ep:74, loss:0.00002, loss_test:0.07889, lr:6.49e-03, fs:0.69620 (r=0.556,p=0.932),  time:41.455, tt:3109.089\n",
      "Ep:75, loss:0.00002, loss_test:0.07999, lr:6.43e-03, fs:0.68790 (r=0.545,p=0.931),  time:41.482, tt:3152.640\n",
      "Ep:76, loss:0.00002, loss_test:0.08036, lr:6.36e-03, fs:0.68790 (r=0.545,p=0.931),  time:41.501, tt:3195.551\n",
      "Ep:77, loss:0.00002, loss_test:0.07862, lr:6.30e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.527, tt:3239.086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:78, loss:0.00002, loss_test:0.08029, lr:6.24e-03, fs:0.68790 (r=0.545,p=0.931),  time:41.547, tt:3282.205\n",
      "Ep:79, loss:0.00002, loss_test:0.08035, lr:6.17e-03, fs:0.68790 (r=0.545,p=0.931),  time:41.539, tt:3323.147\n",
      "Ep:80, loss:0.00002, loss_test:0.07891, lr:6.11e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.538, tt:3364.547\n",
      "Ep:81, loss:0.00002, loss_test:0.08020, lr:6.05e-03, fs:0.69620 (r=0.556,p=0.932),  time:41.538, tt:3406.099\n",
      "Ep:82, loss:0.00002, loss_test:0.08079, lr:5.99e-03, fs:0.68790 (r=0.545,p=0.931),  time:41.528, tt:3446.786\n",
      "Ep:83, loss:0.00002, loss_test:0.07957, lr:5.93e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.536, tt:3489.037\n",
      "Ep:84, loss:0.00002, loss_test:0.07997, lr:5.87e-03, fs:0.69620 (r=0.556,p=0.932),  time:41.532, tt:3530.225\n",
      "Ep:85, loss:0.00001, loss_test:0.08001, lr:5.81e-03, fs:0.68790 (r=0.545,p=0.931),  time:41.604, tt:3577.909\n",
      "Ep:86, loss:0.00001, loss_test:0.07946, lr:5.75e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.621, tt:3621.043\n",
      "Ep:87, loss:0.00001, loss_test:0.07981, lr:5.70e-03, fs:0.69620 (r=0.556,p=0.932),  time:41.643, tt:3664.582\n",
      "Ep:88, loss:0.00001, loss_test:0.07976, lr:5.64e-03, fs:0.69620 (r=0.556,p=0.932),  time:41.675, tt:3709.032\n",
      "Ep:89, loss:0.00001, loss_test:0.07945, lr:5.58e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.673, tt:3750.541\n",
      "Ep:90, loss:0.00001, loss_test:0.07964, lr:5.53e-03, fs:0.69620 (r=0.556,p=0.932),  time:41.650, tt:3790.144\n",
      "Ep:91, loss:0.00001, loss_test:0.07979, lr:5.47e-03, fs:0.69620 (r=0.556,p=0.932),  time:41.659, tt:3832.583\n",
      "Ep:92, loss:0.00001, loss_test:0.07974, lr:5.42e-03, fs:0.69620 (r=0.556,p=0.932),  time:41.649, tt:3873.347\n",
      "Ep:93, loss:0.00001, loss_test:0.07911, lr:5.36e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.661, tt:3916.177\n",
      "Ep:94, loss:0.00001, loss_test:0.08002, lr:5.31e-03, fs:0.68790 (r=0.545,p=0.931),  time:41.682, tt:3959.759\n",
      "Ep:95, loss:0.00001, loss_test:0.08002, lr:5.26e-03, fs:0.68790 (r=0.545,p=0.931),  time:41.724, tt:4005.498\n",
      "Ep:96, loss:0.00001, loss_test:0.07922, lr:5.20e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.731, tt:4047.954\n",
      "Ep:97, loss:0.00001, loss_test:0.07962, lr:5.15e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.722, tt:4088.762\n",
      "Ep:98, loss:0.00001, loss_test:0.07984, lr:5.10e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.723, tt:4130.605\n",
      "Ep:99, loss:0.00001, loss_test:0.07921, lr:5.05e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.731, tt:4173.123\n",
      "Ep:100, loss:0.00001, loss_test:0.07947, lr:5.00e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.721, tt:4213.808\n",
      "Ep:101, loss:0.00001, loss_test:0.07978, lr:4.95e-03, fs:0.69620 (r=0.556,p=0.932),  time:41.726, tt:4256.062\n",
      "Ep:102, loss:0.00001, loss_test:0.07916, lr:4.90e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.719, tt:4297.026\n",
      "Ep:103, loss:0.00001, loss_test:0.07947, lr:4.85e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.728, tt:4339.704\n",
      "Ep:104, loss:0.00001, loss_test:0.07953, lr:4.80e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.717, tt:4380.283\n",
      "Ep:105, loss:0.00001, loss_test:0.07893, lr:4.75e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.743, tt:4424.710\n",
      "Ep:106, loss:0.00001, loss_test:0.07950, lr:4.71e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.729, tt:4464.956\n",
      "Ep:107, loss:0.00001, loss_test:0.07965, lr:4.66e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.729, tt:4506.735\n",
      "Ep:108, loss:0.00001, loss_test:0.07909, lr:4.61e-03, fs:0.70886 (r=0.566,p=0.949),  time:41.753, tt:4551.052\n",
      "Ep:109, loss:0.00001, loss_test:0.07907, lr:4.57e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.785, tt:4596.379\n",
      "Ep:110, loss:0.00001, loss_test:0.07950, lr:4.52e-03, fs:0.70886 (r=0.566,p=0.949),  time:41.794, tt:4639.098\n",
      "Ep:111, loss:0.00001, loss_test:0.07928, lr:4.48e-03, fs:0.70886 (r=0.566,p=0.949),  time:41.814, tt:4683.209\n",
      "Ep:112, loss:0.00001, loss_test:0.07885, lr:4.43e-03, fs:0.70886 (r=0.566,p=0.949),  time:41.814, tt:4725.020\n",
      "Ep:113, loss:0.00001, loss_test:0.07948, lr:4.39e-03, fs:0.70886 (r=0.566,p=0.949),  time:41.805, tt:4765.715\n",
      "Ep:114, loss:0.00001, loss_test:0.07929, lr:4.34e-03, fs:0.70886 (r=0.566,p=0.949),  time:41.815, tt:4808.754\n",
      "Ep:115, loss:0.00001, loss_test:0.07928, lr:4.30e-03, fs:0.70886 (r=0.566,p=0.949),  time:41.824, tt:4851.592\n",
      "Ep:116, loss:0.00001, loss_test:0.07898, lr:4.26e-03, fs:0.70886 (r=0.566,p=0.949),  time:41.818, tt:4892.660\n",
      "Ep:117, loss:0.00001, loss_test:0.07927, lr:4.21e-03, fs:0.70886 (r=0.566,p=0.949),  time:41.825, tt:4935.347\n",
      "Ep:118, loss:0.00001, loss_test:0.07938, lr:4.17e-03, fs:0.70886 (r=0.566,p=0.949),  time:41.833, tt:4978.161\n",
      "Ep:119, loss:0.00001, loss_test:0.07926, lr:4.13e-03, fs:0.70886 (r=0.566,p=0.949),  time:41.847, tt:5021.692\n",
      "Ep:120, loss:0.00001, loss_test:0.07919, lr:4.09e-03, fs:0.70886 (r=0.566,p=0.949),  time:41.854, tt:5064.324\n",
      "Ep:121, loss:0.00001, loss_test:0.07946, lr:4.05e-03, fs:0.70886 (r=0.566,p=0.949),  time:41.874, tt:5108.580\n",
      "Ep:122, loss:0.00001, loss_test:0.07923, lr:4.01e-03, fs:0.70886 (r=0.566,p=0.949),  time:41.869, tt:5149.947\n",
      "Ep:123, loss:0.00001, loss_test:0.07934, lr:3.97e-03, fs:0.70886 (r=0.566,p=0.949),  time:41.877, tt:5192.713\n",
      "Ep:124, loss:0.00001, loss_test:0.07941, lr:3.93e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.911, tt:5238.889\n",
      "Ep:125, loss:0.00001, loss_test:0.07903, lr:3.89e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.937, tt:5284.056\n",
      "Ep:126, loss:0.00001, loss_test:0.07949, lr:3.85e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.940, tt:5326.369\n",
      "Ep:127, loss:0.00001, loss_test:0.07937, lr:3.81e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.950, tt:5369.605\n",
      "Ep:128, loss:0.00001, loss_test:0.07920, lr:3.77e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.971, tt:5414.296\n",
      "Ep:129, loss:0.00001, loss_test:0.07953, lr:3.73e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.990, tt:5458.679\n",
      "Ep:130, loss:0.00001, loss_test:0.07940, lr:3.70e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.983, tt:5499.799\n",
      "Ep:131, loss:0.00001, loss_test:0.07946, lr:3.66e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.967, tt:5539.586\n",
      "Ep:132, loss:0.00001, loss_test:0.07927, lr:3.62e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.973, tt:5582.377\n",
      "Ep:133, loss:0.00001, loss_test:0.07935, lr:3.59e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.968, tt:5623.701\n",
      "Ep:134, loss:0.00001, loss_test:0.07941, lr:3.55e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.982, tt:5667.633\n",
      "Ep:135, loss:0.00001, loss_test:0.07938, lr:3.52e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.982, tt:5709.497\n",
      "Ep:136, loss:0.00001, loss_test:0.07945, lr:3.48e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.961, tt:5748.599\n",
      "Ep:137, loss:0.00001, loss_test:0.07923, lr:3.45e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.948, tt:5788.878\n",
      "Ep:138, loss:0.00001, loss_test:0.07942, lr:3.41e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.933, tt:5828.653\n",
      "Ep:139, loss:0.00001, loss_test:0.07967, lr:3.38e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.921, tt:5868.925\n",
      "Ep:140, loss:0.00001, loss_test:0.07937, lr:3.34e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.963, tt:5916.797\n",
      "Ep:141, loss:0.00001, loss_test:0.07930, lr:3.31e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.965, tt:5958.963\n",
      "Ep:142, loss:0.00001, loss_test:0.07972, lr:3.28e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.969, tt:6001.599\n",
      "Ep:143, loss:0.00001, loss_test:0.07958, lr:3.24e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.960, tt:6042.182\n",
      "Ep:144, loss:0.00001, loss_test:0.07944, lr:3.21e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.959, tt:6084.121\n",
      "Ep:145, loss:0.00001, loss_test:0.07949, lr:3.18e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.954, tt:6125.273\n",
      "Ep:146, loss:0.00001, loss_test:0.07949, lr:3.15e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.945, tt:6165.919\n",
      "Ep:147, loss:0.00001, loss_test:0.07942, lr:3.12e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.942, tt:6207.437\n",
      "Ep:148, loss:0.00001, loss_test:0.07941, lr:3.09e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.934, tt:6248.172\n",
      "Ep:149, loss:0.00001, loss_test:0.07956, lr:3.05e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.922, tt:6288.326\n",
      "Ep:150, loss:0.00001, loss_test:0.07955, lr:3.02e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.912, tt:6328.641\n",
      "Ep:151, loss:0.00001, loss_test:0.07963, lr:2.99e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.900, tt:6368.748\n",
      "Ep:152, loss:0.00001, loss_test:0.07963, lr:2.96e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.897, tt:6410.242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:153, loss:0.00001, loss_test:0.07967, lr:2.93e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.901, tt:6452.729\n",
      "Ep:154, loss:0.00001, loss_test:0.07978, lr:2.90e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.893, tt:6493.360\n",
      "Ep:155, loss:0.00001, loss_test:0.07964, lr:2.88e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.893, tt:6535.263\n",
      "Ep:156, loss:0.00001, loss_test:0.07965, lr:2.85e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.887, tt:6576.213\n",
      "Ep:157, loss:0.00001, loss_test:0.07968, lr:2.82e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.881, tt:6617.162\n",
      "Ep:158, loss:0.00001, loss_test:0.07949, lr:2.79e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.879, tt:6658.690\n",
      "Ep:159, loss:0.00001, loss_test:0.07975, lr:2.76e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.873, tt:6699.605\n",
      "Ep:160, loss:0.00001, loss_test:0.07973, lr:2.73e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.882, tt:6743.028\n",
      "Ep:161, loss:0.00001, loss_test:0.07976, lr:2.71e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.877, tt:6784.034\n",
      "Ep:162, loss:0.00001, loss_test:0.07986, lr:2.68e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.872, tt:6825.193\n",
      "Ep:163, loss:0.00001, loss_test:0.07975, lr:2.65e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.861, tt:6865.214\n",
      "Ep:164, loss:0.00001, loss_test:0.07976, lr:2.63e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.855, tt:6906.138\n",
      "Ep:165, loss:0.00001, loss_test:0.07990, lr:2.60e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.861, tt:6948.901\n",
      "Ep:166, loss:0.00001, loss_test:0.07991, lr:2.57e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.841, tt:6987.426\n",
      "Ep:167, loss:0.00001, loss_test:0.07976, lr:2.55e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.827, tt:7026.917\n",
      "Ep:168, loss:0.00001, loss_test:0.07983, lr:2.52e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.823, tt:7068.092\n",
      "Ep:169, loss:0.00001, loss_test:0.07984, lr:2.50e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.814, tt:7108.367\n",
      "Ep:170, loss:0.00001, loss_test:0.07986, lr:2.47e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.812, tt:7149.789\n",
      "Ep:171, loss:0.00001, loss_test:0.07979, lr:2.45e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.814, tt:7192.057\n",
      "Ep:172, loss:0.00001, loss_test:0.07989, lr:2.42e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.799, tt:7231.309\n",
      "Ep:173, loss:0.00001, loss_test:0.07993, lr:2.40e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.791, tt:7271.675\n",
      "Ep:174, loss:0.00001, loss_test:0.07988, lr:2.38e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.791, tt:7313.378\n",
      "Ep:175, loss:0.00001, loss_test:0.07983, lr:2.35e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.789, tt:7354.847\n",
      "Ep:176, loss:0.00001, loss_test:0.08004, lr:2.33e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.792, tt:7397.151\n",
      "Ep:177, loss:0.00001, loss_test:0.08007, lr:2.31e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.801, tt:7440.570\n",
      "Ep:178, loss:0.00001, loss_test:0.07994, lr:2.28e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.807, tt:7483.519\n",
      "Ep:179, loss:0.00001, loss_test:0.07982, lr:2.26e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.817, tt:7526.999\n",
      "Ep:180, loss:0.00001, loss_test:0.07991, lr:2.24e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.815, tt:7568.454\n",
      "Ep:181, loss:0.00001, loss_test:0.07998, lr:2.21e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.820, tt:7611.245\n",
      "Ep:182, loss:0.00001, loss_test:0.08005, lr:2.19e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.822, tt:7653.344\n",
      "Ep:183, loss:0.00001, loss_test:0.08001, lr:2.17e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.832, tt:7697.116\n",
      "Ep:184, loss:0.00001, loss_test:0.08005, lr:2.15e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.848, tt:7741.826\n",
      "Ep:185, loss:0.00001, loss_test:0.08017, lr:2.13e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.854, tt:7784.852\n",
      "Ep:186, loss:0.00001, loss_test:0.08012, lr:2.11e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.877, tt:7830.972\n",
      "Ep:187, loss:0.00001, loss_test:0.08007, lr:2.08e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.878, tt:7873.023\n",
      "Ep:188, loss:0.00001, loss_test:0.08008, lr:2.06e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.878, tt:7914.977\n",
      "Ep:189, loss:0.00001, loss_test:0.08015, lr:2.04e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.890, tt:7959.093\n",
      "Ep:190, loss:0.00001, loss_test:0.08025, lr:2.02e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.897, tt:8002.408\n",
      "Ep:191, loss:0.00001, loss_test:0.08017, lr:2.00e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.907, tt:8046.166\n",
      "Ep:192, loss:0.00001, loss_test:0.08027, lr:1.98e-03, fs:0.71795 (r=0.566,p=0.982),  time:41.908, tt:8088.340\n",
      "Ep:193, loss:0.00001, loss_test:0.08022, lr:1.96e-03, fs:0.71795 (r=0.566,p=0.982),  time:41.916, tt:8131.672\n",
      "Ep:194, loss:0.00001, loss_test:0.08019, lr:1.94e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.916, tt:8173.678\n",
      "Ep:195, loss:0.00001, loss_test:0.08034, lr:1.92e-03, fs:0.71795 (r=0.566,p=0.982),  time:41.923, tt:8217.001\n",
      "Ep:196, loss:0.00001, loss_test:0.08028, lr:1.90e-03, fs:0.71795 (r=0.566,p=0.982),  time:41.931, tt:8260.472\n",
      "Ep:197, loss:0.00001, loss_test:0.08022, lr:1.89e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.946, tt:8305.373\n",
      "Ep:198, loss:0.00001, loss_test:0.08032, lr:1.87e-03, fs:0.71795 (r=0.566,p=0.982),  time:41.946, tt:8347.306\n",
      "Ep:199, loss:0.00001, loss_test:0.08034, lr:1.85e-03, fs:0.71795 (r=0.566,p=0.982),  time:41.942, tt:8388.465\n",
      "Ep:200, loss:0.00001, loss_test:0.08034, lr:1.83e-03, fs:0.71795 (r=0.566,p=0.982),  time:41.945, tt:8430.928\n",
      "Ep:201, loss:0.00001, loss_test:0.08031, lr:1.81e-03, fs:0.71795 (r=0.566,p=0.982),  time:41.909, tt:8465.558\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_600_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02095, lr:6.00e-02, fs:0.64769 (r=0.919,p=0.500),  time:20.532, tt:20.532\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02270, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.597, tt:51.195\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02305, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.639, tt:79.916\n",
      "Ep:3, loss:0.00004, loss_test:0.02219, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.628, tt:114.511\n",
      "Ep:4, loss:0.00004, loss_test:0.02074, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:29.893, tt:149.466\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.01945, lr:6.00e-02, fs:0.65683 (r=0.899,p=0.517),  time:30.900, tt:185.398\n",
      "Ep:6, loss:0.00004, loss_test:0.01903, lr:6.00e-02, fs:0.68293 (r=0.848,p=0.571),  time:31.265, tt:218.856\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01892, lr:6.00e-02, fs:0.67826 (r=0.788,p=0.595),  time:31.625, tt:252.999\n",
      "Ep:8, loss:0.00004, loss_test:0.01838, lr:6.00e-02, fs:0.70886 (r=0.848,p=0.609),  time:31.810, tt:286.286\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01800, lr:6.00e-02, fs:0.72797 (r=0.960,p=0.586),  time:32.040, tt:320.398\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01785, lr:6.00e-02, fs:0.70632 (r=0.960,p=0.559),  time:32.331, tt:355.639\n",
      "Ep:11, loss:0.00003, loss_test:0.01756, lr:6.00e-02, fs:0.71429 (r=0.960,p=0.569),  time:32.618, tt:391.418\n",
      "Ep:12, loss:0.00003, loss_test:0.01720, lr:6.00e-02, fs:0.72868 (r=0.949,p=0.591),  time:32.730, tt:425.485\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01698, lr:6.00e-02, fs:0.75410 (r=0.929,p=0.634),  time:32.810, tt:459.334\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01678, lr:6.00e-02, fs:0.76596 (r=0.909,p=0.662),  time:32.875, tt:493.127\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:15, loss:0.00003, loss_test:0.01651, lr:6.00e-02, fs:0.77686 (r=0.949,p=0.657),  time:32.946, tt:527.143\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01632, lr:6.00e-02, fs:0.77778 (r=0.990,p=0.641),  time:33.009, tt:561.161\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01610, lr:6.00e-02, fs:0.78400 (r=0.990,p=0.649),  time:33.055, tt:594.993\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01588, lr:6.00e-02, fs:0.80000 (r=0.990,p=0.671),  time:33.099, tt:628.886\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01574, lr:6.00e-02, fs:0.82353 (r=0.990,p=0.705),  time:33.127, tt:662.547\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.01561, lr:6.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:33.218, tt:697.575\n",
      "Ep:21, loss:0.00002, loss_test:0.01546, lr:6.00e-02, fs:0.82553 (r=0.980,p=0.713),  time:33.511, tt:737.249\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01526, lr:6.00e-02, fs:0.82553 (r=0.980,p=0.713),  time:33.536, tt:771.332\n",
      "Ep:23, loss:0.00002, loss_test:0.01517, lr:6.00e-02, fs:0.83117 (r=0.970,p=0.727),  time:33.527, tt:804.653\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01508, lr:6.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:33.550, tt:838.750\n",
      "Ep:25, loss:0.00002, loss_test:0.01494, lr:6.00e-02, fs:0.82301 (r=0.939,p=0.732),  time:33.598, tt:873.536\n",
      "Ep:26, loss:0.00002, loss_test:0.01477, lr:6.00e-02, fs:0.82301 (r=0.939,p=0.732),  time:33.642, tt:908.339\n",
      "Ep:27, loss:0.00002, loss_test:0.01462, lr:6.00e-02, fs:0.83036 (r=0.939,p=0.744),  time:33.647, tt:942.109\n",
      "Ep:28, loss:0.00002, loss_test:0.01443, lr:6.00e-02, fs:0.83408 (r=0.939,p=0.750),  time:33.662, tt:976.204\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01430, lr:6.00e-02, fs:0.83036 (r=0.939,p=0.744),  time:33.727, tt:1011.800\n",
      "Ep:30, loss:0.00002, loss_test:0.01421, lr:6.00e-02, fs:0.82883 (r=0.929,p=0.748),  time:33.767, tt:1046.791\n",
      "Ep:31, loss:0.00002, loss_test:0.01410, lr:6.00e-02, fs:0.84018 (r=0.929,p=0.767),  time:33.823, tt:1082.323\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01400, lr:6.00e-02, fs:0.84404 (r=0.929,p=0.773),  time:33.846, tt:1116.934\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01391, lr:6.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:33.906, tt:1152.801\n",
      "Ep:34, loss:0.00002, loss_test:0.01385, lr:6.00e-02, fs:0.84259 (r=0.919,p=0.778),  time:34.021, tt:1190.743\n",
      "Ep:35, loss:0.00002, loss_test:0.01376, lr:6.00e-02, fs:0.84259 (r=0.919,p=0.778),  time:34.027, tt:1224.978\n",
      "Ep:36, loss:0.00001, loss_test:0.01368, lr:6.00e-02, fs:0.84651 (r=0.919,p=0.784),  time:34.045, tt:1259.669\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00001, loss_test:0.01365, lr:6.00e-02, fs:0.84112 (r=0.909,p=0.783),  time:34.064, tt:1294.425\n",
      "Ep:38, loss:0.00001, loss_test:0.01360, lr:6.00e-02, fs:0.84507 (r=0.909,p=0.789),  time:34.089, tt:1329.457\n",
      "Ep:39, loss:0.00001, loss_test:0.01354, lr:6.00e-02, fs:0.84762 (r=0.899,p=0.802),  time:34.110, tt:1364.400\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00001, loss_test:0.01351, lr:6.00e-02, fs:0.84762 (r=0.899,p=0.802),  time:34.137, tt:1399.633\n",
      "Ep:41, loss:0.00001, loss_test:0.01346, lr:6.00e-02, fs:0.85167 (r=0.899,p=0.809),  time:34.177, tt:1435.430\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00001, loss_test:0.01341, lr:6.00e-02, fs:0.85167 (r=0.899,p=0.809),  time:34.215, tt:1471.265\n",
      "Ep:43, loss:0.00001, loss_test:0.01339, lr:6.00e-02, fs:0.85167 (r=0.899,p=0.809),  time:34.206, tt:1505.084\n",
      "Ep:44, loss:0.00001, loss_test:0.01340, lr:6.00e-02, fs:0.85577 (r=0.899,p=0.817),  time:34.260, tt:1541.688\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.01339, lr:6.00e-02, fs:0.85990 (r=0.899,p=0.824),  time:34.322, tt:1578.799\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01339, lr:6.00e-02, fs:0.86829 (r=0.899,p=0.840),  time:34.336, tt:1613.801\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01338, lr:6.00e-02, fs:0.86829 (r=0.899,p=0.840),  time:34.344, tt:1648.530\n",
      "Ep:48, loss:0.00001, loss_test:0.01338, lr:6.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:34.357, tt:1683.473\n",
      "Ep:49, loss:0.00001, loss_test:0.01341, lr:6.00e-02, fs:0.86700 (r=0.889,p=0.846),  time:34.364, tt:1718.200\n",
      "Ep:50, loss:0.00001, loss_test:0.01341, lr:6.00e-02, fs:0.87129 (r=0.889,p=0.854),  time:34.374, tt:1753.095\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01343, lr:6.00e-02, fs:0.87129 (r=0.889,p=0.854),  time:34.362, tt:1786.836\n",
      "Ep:52, loss:0.00001, loss_test:0.01344, lr:6.00e-02, fs:0.87129 (r=0.889,p=0.854),  time:34.339, tt:1819.982\n",
      "Ep:53, loss:0.00001, loss_test:0.01346, lr:6.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:34.355, tt:1855.149\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.01346, lr:6.00e-02, fs:0.88000 (r=0.889,p=0.871),  time:34.343, tt:1888.856\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01349, lr:6.00e-02, fs:0.88000 (r=0.889,p=0.871),  time:34.319, tt:1921.883\n",
      "Ep:56, loss:0.00001, loss_test:0.01352, lr:6.00e-02, fs:0.88000 (r=0.889,p=0.871),  time:34.318, tt:1956.131\n",
      "Ep:57, loss:0.00001, loss_test:0.01352, lr:6.00e-02, fs:0.88000 (r=0.889,p=0.871),  time:34.324, tt:1990.811\n",
      "Ep:58, loss:0.00001, loss_test:0.01347, lr:6.00e-02, fs:0.88000 (r=0.889,p=0.871),  time:34.306, tt:2024.051\n",
      "Ep:59, loss:0.00001, loss_test:0.01350, lr:6.00e-02, fs:0.88000 (r=0.889,p=0.871),  time:34.300, tt:2057.990\n",
      "Ep:60, loss:0.00001, loss_test:0.01359, lr:6.00e-02, fs:0.87879 (r=0.879,p=0.879),  time:34.298, tt:2092.181\n",
      "Ep:61, loss:0.00001, loss_test:0.01358, lr:6.00e-02, fs:0.88325 (r=0.879,p=0.888),  time:34.301, tt:2126.636\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01359, lr:6.00e-02, fs:0.88325 (r=0.879,p=0.888),  time:34.304, tt:2161.145\n",
      "Ep:63, loss:0.00001, loss_test:0.01358, lr:6.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:34.315, tt:2196.132\n",
      "Ep:64, loss:0.00001, loss_test:0.01362, lr:6.00e-02, fs:0.87629 (r=0.859,p=0.895),  time:34.325, tt:2231.148\n",
      "Ep:65, loss:0.00001, loss_test:0.01367, lr:6.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:34.351, tt:2267.180\n",
      "Ep:66, loss:0.00001, loss_test:0.01365, lr:6.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:34.352, tt:2301.607\n",
      "Ep:67, loss:0.00001, loss_test:0.01364, lr:6.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:34.351, tt:2335.878\n",
      "Ep:68, loss:0.00001, loss_test:0.01364, lr:6.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:34.349, tt:2370.103\n",
      "Ep:69, loss:0.00001, loss_test:0.01365, lr:6.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:34.365, tt:2405.575\n",
      "Ep:70, loss:0.00001, loss_test:0.01369, lr:6.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:34.372, tt:2440.446\n",
      "Ep:71, loss:0.00001, loss_test:0.01378, lr:6.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:34.373, tt:2474.832\n",
      "Ep:72, loss:0.00001, loss_test:0.01375, lr:6.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:34.359, tt:2508.190\n",
      "Ep:73, loss:0.00001, loss_test:0.01382, lr:5.94e-02, fs:0.85714 (r=0.818,p=0.900),  time:34.367, tt:2543.145\n",
      "Ep:74, loss:0.00001, loss_test:0.01389, lr:5.88e-02, fs:0.86170 (r=0.818,p=0.910),  time:34.376, tt:2578.180\n",
      "Ep:75, loss:0.00001, loss_test:0.01385, lr:5.82e-02, fs:0.86772 (r=0.828,p=0.911),  time:34.401, tt:2614.459\n",
      "Ep:76, loss:0.00001, loss_test:0.01389, lr:5.76e-02, fs:0.86772 (r=0.828,p=0.911),  time:34.414, tt:2649.882\n",
      "Ep:77, loss:0.00001, loss_test:0.01391, lr:5.71e-02, fs:0.86170 (r=0.818,p=0.910),  time:34.412, tt:2684.105\n",
      "Ep:78, loss:0.00001, loss_test:0.01394, lr:5.65e-02, fs:0.86772 (r=0.828,p=0.911),  time:34.409, tt:2718.288\n",
      "Ep:79, loss:0.00001, loss_test:0.01400, lr:5.59e-02, fs:0.86772 (r=0.828,p=0.911),  time:34.407, tt:2752.579\n",
      "Ep:80, loss:0.00001, loss_test:0.01398, lr:5.54e-02, fs:0.87234 (r=0.828,p=0.921),  time:34.394, tt:2785.933\n",
      "Ep:81, loss:0.00001, loss_test:0.01402, lr:5.48e-02, fs:0.87234 (r=0.828,p=0.921),  time:34.380, tt:2819.175\n",
      "Ep:82, loss:0.00001, loss_test:0.01406, lr:5.43e-02, fs:0.87234 (r=0.828,p=0.921),  time:34.368, tt:2852.506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:83, loss:0.00001, loss_test:0.01410, lr:5.37e-02, fs:0.87234 (r=0.828,p=0.921),  time:34.346, tt:2885.045\n",
      "Ep:84, loss:0.00001, loss_test:0.01413, lr:5.32e-02, fs:0.87234 (r=0.828,p=0.921),  time:34.353, tt:2920.000\n",
      "Ep:85, loss:0.00001, loss_test:0.01416, lr:5.27e-02, fs:0.87234 (r=0.828,p=0.921),  time:34.374, tt:2956.135\n",
      "Ep:86, loss:0.00000, loss_test:0.01416, lr:5.21e-02, fs:0.87234 (r=0.828,p=0.921),  time:34.352, tt:2988.622\n",
      "Ep:87, loss:0.00000, loss_test:0.01418, lr:5.16e-02, fs:0.87701 (r=0.828,p=0.932),  time:34.338, tt:3021.725\n",
      "Ep:88, loss:0.00000, loss_test:0.01424, lr:5.11e-02, fs:0.87701 (r=0.828,p=0.932),  time:34.318, tt:3054.327\n",
      "Ep:89, loss:0.00000, loss_test:0.01424, lr:5.06e-02, fs:0.87701 (r=0.828,p=0.932),  time:34.316, tt:3088.446\n",
      "Ep:90, loss:0.00000, loss_test:0.01425, lr:5.01e-02, fs:0.87701 (r=0.828,p=0.932),  time:34.313, tt:3122.494\n",
      "Ep:91, loss:0.00000, loss_test:0.01433, lr:4.96e-02, fs:0.87701 (r=0.828,p=0.932),  time:34.311, tt:3156.642\n",
      "Ep:92, loss:0.00000, loss_test:0.01434, lr:4.91e-02, fs:0.87701 (r=0.828,p=0.932),  time:34.298, tt:3189.760\n",
      "Ep:93, loss:0.00000, loss_test:0.01433, lr:4.86e-02, fs:0.87701 (r=0.828,p=0.932),  time:34.269, tt:3221.315\n",
      "Ep:94, loss:0.00000, loss_test:0.01441, lr:4.81e-02, fs:0.87701 (r=0.828,p=0.932),  time:34.261, tt:3254.764\n",
      "Ep:95, loss:0.00000, loss_test:0.01447, lr:4.76e-02, fs:0.87701 (r=0.828,p=0.932),  time:34.259, tt:3288.836\n",
      "Ep:96, loss:0.00000, loss_test:0.01444, lr:4.71e-02, fs:0.87701 (r=0.828,p=0.932),  time:34.269, tt:3324.091\n",
      "Ep:97, loss:0.00000, loss_test:0.01445, lr:4.67e-02, fs:0.87097 (r=0.818,p=0.931),  time:34.252, tt:3356.666\n",
      "Ep:98, loss:0.00000, loss_test:0.01454, lr:4.62e-02, fs:0.85870 (r=0.798,p=0.929),  time:34.248, tt:3390.541\n",
      "Ep:99, loss:0.00000, loss_test:0.01459, lr:4.57e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.257, tt:3425.688\n",
      "Ep:100, loss:0.00000, loss_test:0.01455, lr:4.53e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.272, tt:3461.435\n",
      "Ep:101, loss:0.00000, loss_test:0.01458, lr:4.48e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.272, tt:3495.762\n",
      "Ep:102, loss:0.00000, loss_test:0.01461, lr:4.44e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.268, tt:3529.653\n",
      "Ep:103, loss:0.00000, loss_test:0.01466, lr:4.39e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.262, tt:3563.216\n",
      "Ep:104, loss:0.00000, loss_test:0.01469, lr:4.35e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.246, tt:3595.860\n",
      "Ep:105, loss:0.00000, loss_test:0.01474, lr:4.31e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.241, tt:3629.542\n",
      "Ep:106, loss:0.00000, loss_test:0.01474, lr:4.26e-02, fs:0.85083 (r=0.778,p=0.939),  time:34.230, tt:3662.584\n",
      "Ep:107, loss:0.00000, loss_test:0.01473, lr:4.22e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.231, tt:3696.895\n",
      "Ep:108, loss:0.00000, loss_test:0.01482, lr:4.18e-02, fs:0.84444 (r=0.768,p=0.938),  time:34.224, tt:3730.423\n",
      "Ep:109, loss:0.00000, loss_test:0.01482, lr:4.14e-02, fs:0.83799 (r=0.758,p=0.938),  time:34.230, tt:3765.355\n",
      "Ep:110, loss:0.00000, loss_test:0.01483, lr:4.10e-02, fs:0.83146 (r=0.747,p=0.937),  time:34.223, tt:3798.726\n",
      "Ep:111, loss:0.00000, loss_test:0.01486, lr:4.05e-02, fs:0.83146 (r=0.747,p=0.937),  time:34.208, tt:3831.308\n",
      "Ep:112, loss:0.00000, loss_test:0.01488, lr:4.01e-02, fs:0.82486 (r=0.737,p=0.936),  time:34.185, tt:3862.895\n",
      "Ep:113, loss:0.00000, loss_test:0.01490, lr:3.97e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.161, tt:3894.384\n",
      "Ep:114, loss:0.00000, loss_test:0.01493, lr:3.93e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.154, tt:3927.736\n",
      "Ep:115, loss:0.00000, loss_test:0.01495, lr:3.89e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.136, tt:3959.779\n",
      "Ep:116, loss:0.00000, loss_test:0.01498, lr:3.86e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.135, tt:3993.790\n",
      "Ep:117, loss:0.00000, loss_test:0.01499, lr:3.82e-02, fs:0.80460 (r=0.707,p=0.933),  time:34.126, tt:4026.816\n",
      "Ep:118, loss:0.00000, loss_test:0.01502, lr:3.78e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.107, tt:4058.748\n",
      "Ep:119, loss:0.00000, loss_test:0.01504, lr:3.74e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.101, tt:4092.067\n",
      "Ep:120, loss:0.00000, loss_test:0.01507, lr:3.70e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.103, tt:4126.501\n",
      "Ep:121, loss:0.00000, loss_test:0.01510, lr:3.67e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.096, tt:4159.665\n",
      "Ep:122, loss:0.00000, loss_test:0.01512, lr:3.63e-02, fs:0.79070 (r=0.687,p=0.932),  time:34.097, tt:4193.992\n",
      "Ep:123, loss:0.00000, loss_test:0.01516, lr:3.59e-02, fs:0.79070 (r=0.687,p=0.932),  time:34.109, tt:4229.459\n",
      "Ep:124, loss:0.00000, loss_test:0.01515, lr:3.56e-02, fs:0.79070 (r=0.687,p=0.932),  time:34.101, tt:4262.659\n",
      "Ep:125, loss:0.00000, loss_test:0.01517, lr:3.52e-02, fs:0.79070 (r=0.687,p=0.932),  time:34.102, tt:4296.882\n",
      "Ep:126, loss:0.00000, loss_test:0.01520, lr:3.49e-02, fs:0.76923 (r=0.657,p=0.929),  time:34.097, tt:4330.368\n",
      "Ep:127, loss:0.00000, loss_test:0.01523, lr:3.45e-02, fs:0.76923 (r=0.657,p=0.929),  time:34.093, tt:4363.900\n",
      "Ep:128, loss:0.00000, loss_test:0.01524, lr:3.42e-02, fs:0.76923 (r=0.657,p=0.929),  time:34.100, tt:4398.910\n",
      "Ep:129, loss:0.00000, loss_test:0.01529, lr:3.38e-02, fs:0.76923 (r=0.657,p=0.929),  time:34.093, tt:4432.041\n",
      "Ep:130, loss:0.00000, loss_test:0.01529, lr:3.35e-02, fs:0.76923 (r=0.657,p=0.929),  time:34.083, tt:4464.853\n",
      "Ep:131, loss:0.00000, loss_test:0.01532, lr:3.32e-02, fs:0.76923 (r=0.657,p=0.929),  time:34.070, tt:4497.188\n",
      "Ep:132, loss:0.00000, loss_test:0.01535, lr:3.28e-02, fs:0.76923 (r=0.657,p=0.929),  time:34.067, tt:4530.916\n",
      "Ep:133, loss:0.00000, loss_test:0.01539, lr:3.25e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.057, tt:4563.613\n",
      "Ep:134, loss:0.00000, loss_test:0.01536, lr:3.22e-02, fs:0.76923 (r=0.657,p=0.929),  time:34.064, tt:4598.589\n",
      "Ep:135, loss:0.00000, loss_test:0.01539, lr:3.19e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.060, tt:4632.107\n",
      "Ep:136, loss:0.00000, loss_test:0.01542, lr:3.15e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.063, tt:4666.598\n",
      "Ep:137, loss:0.00000, loss_test:0.01545, lr:3.12e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.060, tt:4700.315\n",
      "Ep:138, loss:0.00000, loss_test:0.01549, lr:3.09e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.068, tt:4735.490\n",
      "Ep:139, loss:0.00000, loss_test:0.01549, lr:3.06e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.059, tt:4768.307\n",
      "Ep:140, loss:0.00000, loss_test:0.01549, lr:3.03e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.055, tt:4801.817\n",
      "Ep:141, loss:0.00000, loss_test:0.01553, lr:3.00e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.065, tt:4837.285\n",
      "Ep:142, loss:0.00000, loss_test:0.01554, lr:2.97e-02, fs:0.77844 (r=0.657,p=0.956),  time:34.073, tt:4872.396\n",
      "Ep:143, loss:0.00000, loss_test:0.01554, lr:2.94e-02, fs:0.77844 (r=0.657,p=0.956),  time:34.065, tt:4905.431\n",
      "Ep:144, loss:0.00000, loss_test:0.01555, lr:2.91e-02, fs:0.77844 (r=0.657,p=0.956),  time:34.075, tt:4940.918\n",
      "Ep:145, loss:0.00000, loss_test:0.01560, lr:2.88e-02, fs:0.78313 (r=0.657,p=0.970),  time:34.076, tt:4975.146\n",
      "Ep:146, loss:0.00000, loss_test:0.01563, lr:2.85e-02, fs:0.78313 (r=0.657,p=0.970),  time:34.077, tt:5009.246\n",
      "Ep:147, loss:0.00000, loss_test:0.01562, lr:2.82e-02, fs:0.78313 (r=0.657,p=0.970),  time:34.086, tt:5044.684\n",
      "Ep:148, loss:0.00000, loss_test:0.01565, lr:2.80e-02, fs:0.78313 (r=0.657,p=0.970),  time:34.090, tt:5079.466\n",
      "Ep:149, loss:0.00000, loss_test:0.01567, lr:2.77e-02, fs:0.78313 (r=0.657,p=0.970),  time:34.102, tt:5115.350\n",
      "Ep:150, loss:0.00000, loss_test:0.01569, lr:2.74e-02, fs:0.78313 (r=0.657,p=0.970),  time:34.114, tt:5151.230\n",
      "Ep:151, loss:0.00000, loss_test:0.01569, lr:2.71e-02, fs:0.78313 (r=0.657,p=0.970),  time:34.114, tt:5185.268\n",
      "Ep:152, loss:0.00000, loss_test:0.01574, lr:2.69e-02, fs:0.78313 (r=0.657,p=0.970),  time:34.114, tt:5219.420\n",
      "Ep:153, loss:0.00000, loss_test:0.01574, lr:2.66e-02, fs:0.78313 (r=0.657,p=0.970),  time:34.125, tt:5255.207\n",
      "Ep:154, loss:0.00000, loss_test:0.01574, lr:2.63e-02, fs:0.78313 (r=0.657,p=0.970),  time:34.130, tt:5290.074\n",
      "Ep:155, loss:0.00000, loss_test:0.01577, lr:2.61e-02, fs:0.78313 (r=0.657,p=0.970),  time:34.134, tt:5324.868\n",
      "Ep:156, loss:0.00000, loss_test:0.01577, lr:2.58e-02, fs:0.78313 (r=0.657,p=0.970),  time:34.127, tt:5357.932\n",
      "Ep:157, loss:0.00000, loss_test:0.01579, lr:2.55e-02, fs:0.78313 (r=0.657,p=0.970),  time:34.125, tt:5391.808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:158, loss:0.00000, loss_test:0.01580, lr:2.53e-02, fs:0.78313 (r=0.657,p=0.970),  time:34.128, tt:5426.355\n",
      "Ep:159, loss:0.00000, loss_test:0.01582, lr:2.50e-02, fs:0.78313 (r=0.657,p=0.970),  time:34.150, tt:5463.999\n",
      "Ep:160, loss:0.00000, loss_test:0.01584, lr:2.48e-02, fs:0.78313 (r=0.657,p=0.970),  time:34.146, tt:5497.523\n",
      "Ep:161, loss:0.00000, loss_test:0.01586, lr:2.45e-02, fs:0.78313 (r=0.657,p=0.970),  time:34.146, tt:5531.708\n",
      "Ep:162, loss:0.00000, loss_test:0.01586, lr:2.43e-02, fs:0.78313 (r=0.657,p=0.970),  time:34.147, tt:5565.986\n",
      "Ep:163, loss:0.00000, loss_test:0.01588, lr:2.40e-02, fs:0.78313 (r=0.657,p=0.970),  time:34.139, tt:5598.853\n",
      "Ep:164, loss:0.00000, loss_test:0.01588, lr:2.38e-02, fs:0.78313 (r=0.657,p=0.970),  time:34.143, tt:5633.536\n",
      "Ep:165, loss:0.00000, loss_test:0.01589, lr:2.36e-02, fs:0.78313 (r=0.657,p=0.970),  time:34.133, tt:5666.123\n",
      "Ep:166, loss:0.00000, loss_test:0.01592, lr:2.33e-02, fs:0.78313 (r=0.657,p=0.970),  time:34.133, tt:5700.193\n",
      "Ep:167, loss:0.00000, loss_test:0.01594, lr:2.31e-02, fs:0.78313 (r=0.657,p=0.970),  time:34.135, tt:5734.630\n",
      "Ep:168, loss:0.00000, loss_test:0.01594, lr:2.29e-02, fs:0.78313 (r=0.657,p=0.970),  time:34.135, tt:5768.885\n",
      "Ep:169, loss:0.00000, loss_test:0.01594, lr:2.26e-02, fs:0.78313 (r=0.657,p=0.970),  time:34.138, tt:5803.523\n",
      "Ep:170, loss:0.00000, loss_test:0.01597, lr:2.24e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.143, tt:5838.447\n",
      "Ep:171, loss:0.00000, loss_test:0.01599, lr:2.22e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.150, tt:5873.810\n",
      "Ep:172, loss:0.00000, loss_test:0.01601, lr:2.20e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.155, tt:5908.757\n",
      "Ep:173, loss:0.00000, loss_test:0.01602, lr:2.17e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.155, tt:5942.901\n",
      "Ep:174, loss:0.00000, loss_test:0.01603, lr:2.15e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.163, tt:5978.528\n",
      "Ep:175, loss:0.00000, loss_test:0.01603, lr:2.13e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.167, tt:6013.413\n",
      "Ep:176, loss:0.00000, loss_test:0.01604, lr:2.11e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.171, tt:6048.267\n",
      "Ep:177, loss:0.00000, loss_test:0.01608, lr:2.09e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.173, tt:6082.774\n",
      "Ep:178, loss:0.00000, loss_test:0.01608, lr:2.07e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.184, tt:6118.876\n",
      "Ep:179, loss:0.00000, loss_test:0.01609, lr:2.05e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.188, tt:6153.850\n",
      "Ep:180, loss:0.00000, loss_test:0.01611, lr:2.03e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.203, tt:6190.781\n",
      "Ep:181, loss:0.00000, loss_test:0.01612, lr:2.01e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.205, tt:6225.340\n",
      "Ep:182, loss:0.00000, loss_test:0.01613, lr:1.99e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.202, tt:6259.000\n",
      "Ep:183, loss:0.00000, loss_test:0.01613, lr:1.97e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.209, tt:6294.475\n",
      "Ep:184, loss:0.00000, loss_test:0.01614, lr:1.95e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.209, tt:6328.593\n",
      "Ep:185, loss:0.00000, loss_test:0.01615, lr:1.93e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.207, tt:6362.482\n",
      "Ep:186, loss:0.00000, loss_test:0.01617, lr:1.91e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.214, tt:6397.927\n",
      "Ep:187, loss:0.00000, loss_test:0.01617, lr:1.89e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.227, tt:6434.690\n",
      "Ep:188, loss:0.00000, loss_test:0.01619, lr:1.87e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.231, tt:6469.709\n",
      "Ep:189, loss:0.00000, loss_test:0.01622, lr:1.85e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.228, tt:6503.408\n",
      "Ep:190, loss:0.00000, loss_test:0.01623, lr:1.83e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.237, tt:6539.175\n",
      "Ep:191, loss:0.00000, loss_test:0.01624, lr:1.81e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.243, tt:6574.597\n",
      "Ep:192, loss:0.00000, loss_test:0.01626, lr:1.80e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.247, tt:6609.585\n",
      "Ep:193, loss:0.00000, loss_test:0.01626, lr:1.78e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.246, tt:6643.744\n",
      "Ep:194, loss:0.00000, loss_test:0.01627, lr:1.76e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.249, tt:6678.508\n",
      "Ep:195, loss:0.00000, loss_test:0.01628, lr:1.74e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.249, tt:6712.896\n",
      "Ep:196, loss:0.00000, loss_test:0.01630, lr:1.73e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.258, tt:6748.875\n",
      "Ep:197, loss:0.00000, loss_test:0.01629, lr:1.71e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.259, tt:6783.354\n",
      "Ep:198, loss:0.00000, loss_test:0.01630, lr:1.69e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.255, tt:6816.817\n",
      "Ep:199, loss:0.00000, loss_test:0.01632, lr:1.67e-02, fs:0.76829 (r=0.636,p=0.969),  time:34.243, tt:6848.688\n",
      "Ep:200, loss:0.00000, loss_test:0.01633, lr:1.66e-02, fs:0.76829 (r=0.636,p=0.969),  time:34.231, tt:6880.379\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_600_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14154, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.135, tt:29.135\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13969, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.256, tt:58.513\n",
      "Ep:2, loss:0.00027, loss_test:0.13634, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:30.256, tt:90.768\n",
      "Ep:3, loss:0.00026, loss_test:0.13038, lr:1.00e-02, fs:0.68551 (r=0.980,p=0.527),  time:31.802, tt:127.209\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.12141, lr:1.00e-02, fs:0.66935 (r=0.838,p=0.557),  time:32.528, tt:162.642\n",
      "Ep:5, loss:0.00024, loss_test:0.11803, lr:1.00e-02, fs:0.68161 (r=0.768,p=0.613),  time:33.169, tt:199.016\n",
      "Ep:6, loss:0.00024, loss_test:0.11684, lr:1.00e-02, fs:0.67907 (r=0.737,p=0.629),  time:33.644, tt:235.507\n",
      "Ep:7, loss:0.00023, loss_test:0.11491, lr:1.00e-02, fs:0.68067 (r=0.818,p=0.583),  time:33.900, tt:271.203\n",
      "Ep:8, loss:0.00022, loss_test:0.11416, lr:1.00e-02, fs:0.71255 (r=0.889,p=0.595),  time:34.085, tt:306.764\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.10964, lr:1.00e-02, fs:0.69565 (r=0.808,p=0.611),  time:34.245, tt:342.447\n",
      "Ep:10, loss:0.00021, loss_test:0.10702, lr:1.00e-02, fs:0.70476 (r=0.747,p=0.667),  time:34.310, tt:377.405\n",
      "Ep:11, loss:0.00020, loss_test:0.10660, lr:1.00e-02, fs:0.70813 (r=0.747,p=0.673),  time:34.828, tt:417.933\n",
      "Ep:12, loss:0.00020, loss_test:0.10705, lr:1.00e-02, fs:0.71749 (r=0.808,p=0.645),  time:34.987, tt:454.827\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.10463, lr:1.00e-02, fs:0.73303 (r=0.818,p=0.664),  time:35.050, tt:490.702\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.10226, lr:1.00e-02, fs:0.74766 (r=0.808,p=0.696),  time:35.173, tt:527.598\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.10270, lr:1.00e-02, fs:0.74312 (r=0.818,p=0.681),  time:35.244, tt:563.899\n",
      "Ep:16, loss:0.00018, loss_test:0.10227, lr:1.00e-02, fs:0.73148 (r=0.798,p=0.675),  time:35.321, tt:600.453\n",
      "Ep:17, loss:0.00017, loss_test:0.10016, lr:1.00e-02, fs:0.70707 (r=0.707,p=0.707),  time:35.448, tt:638.072\n",
      "Ep:18, loss:0.00016, loss_test:0.10089, lr:1.00e-02, fs:0.66321 (r=0.646,p=0.681),  time:35.562, tt:675.674\n",
      "Ep:19, loss:0.00016, loss_test:0.10053, lr:1.00e-02, fs:0.65625 (r=0.636,p=0.677),  time:35.556, tt:711.121\n",
      "Ep:20, loss:0.00015, loss_test:0.10095, lr:1.00e-02, fs:0.63102 (r=0.596,p=0.670),  time:35.592, tt:747.428\n",
      "Ep:21, loss:0.00014, loss_test:0.10069, lr:1.00e-02, fs:0.63043 (r=0.586,p=0.682),  time:35.644, tt:784.179\n",
      "Ep:22, loss:0.00014, loss_test:0.09795, lr:1.00e-02, fs:0.68394 (r=0.667,p=0.702),  time:35.684, tt:820.735\n",
      "Ep:23, loss:0.00013, loss_test:0.09862, lr:1.00e-02, fs:0.64407 (r=0.576,p=0.731),  time:35.788, tt:858.919\n",
      "Ep:24, loss:0.00012, loss_test:0.09600, lr:1.00e-02, fs:0.68508 (r=0.626,p=0.756),  time:35.871, tt:896.764\n",
      "Ep:25, loss:0.00012, loss_test:0.09550, lr:1.00e-02, fs:0.68235 (r=0.586,p=0.817),  time:35.933, tt:934.260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:26, loss:0.00011, loss_test:0.09530, lr:9.90e-03, fs:0.67442 (r=0.586,p=0.795),  time:35.980, tt:971.470\n",
      "Ep:27, loss:0.00010, loss_test:0.09405, lr:9.80e-03, fs:0.67059 (r=0.576,p=0.803),  time:36.032, tt:1008.902\n",
      "Ep:28, loss:0.00010, loss_test:0.09370, lr:9.70e-03, fs:0.67442 (r=0.586,p=0.795),  time:36.019, tt:1044.557\n",
      "Ep:29, loss:0.00010, loss_test:0.09291, lr:9.61e-03, fs:0.69006 (r=0.596,p=0.819),  time:36.085, tt:1082.544\n",
      "Ep:30, loss:0.00009, loss_test:0.09303, lr:9.51e-03, fs:0.67066 (r=0.566,p=0.824),  time:36.189, tt:1121.867\n",
      "Ep:31, loss:0.00009, loss_test:0.08936, lr:9.41e-03, fs:0.73563 (r=0.646,p=0.853),  time:36.223, tt:1159.134\n",
      "Ep:32, loss:0.00008, loss_test:0.09153, lr:9.32e-03, fs:0.66667 (r=0.556,p=0.833),  time:36.263, tt:1196.669\n",
      "Ep:33, loss:0.00008, loss_test:0.08869, lr:9.23e-03, fs:0.71856 (r=0.606,p=0.882),  time:36.299, tt:1234.179\n",
      "Ep:34, loss:0.00007, loss_test:0.08985, lr:9.14e-03, fs:0.66272 (r=0.566,p=0.800),  time:36.362, tt:1272.678\n",
      "Ep:35, loss:0.00007, loss_test:0.08586, lr:9.04e-03, fs:0.74556 (r=0.636,p=0.900),  time:36.398, tt:1310.337\n",
      "Ep:36, loss:0.00007, loss_test:0.08773, lr:8.95e-03, fs:0.71508 (r=0.646,p=0.800),  time:36.426, tt:1347.759\n",
      "Ep:37, loss:0.00006, loss_test:0.08552, lr:8.86e-03, fs:0.70000 (r=0.566,p=0.918),  time:36.419, tt:1383.914\n",
      "Ep:38, loss:0.00006, loss_test:0.08500, lr:8.78e-03, fs:0.76684 (r=0.747,p=0.787),  time:36.447, tt:1421.435\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00006, loss_test:0.08683, lr:8.78e-03, fs:0.68790 (r=0.545,p=0.931),  time:36.481, tt:1459.260\n",
      "Ep:40, loss:0.00006, loss_test:0.08319, lr:8.78e-03, fs:0.75978 (r=0.687,p=0.850),  time:36.519, tt:1497.275\n",
      "Ep:41, loss:0.00005, loss_test:0.08484, lr:8.78e-03, fs:0.72840 (r=0.596,p=0.937),  time:36.539, tt:1534.630\n",
      "Ep:42, loss:0.00005, loss_test:0.08077, lr:8.78e-03, fs:0.78075 (r=0.737,p=0.830),  time:36.585, tt:1573.141\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00005, loss_test:0.08407, lr:8.78e-03, fs:0.72050 (r=0.586,p=0.935),  time:36.657, tt:1612.921\n",
      "Ep:44, loss:0.00005, loss_test:0.08009, lr:8.78e-03, fs:0.76503 (r=0.707,p=0.833),  time:36.694, tt:1651.228\n",
      "Ep:45, loss:0.00005, loss_test:0.08660, lr:8.78e-03, fs:0.71338 (r=0.566,p=0.966),  time:36.709, tt:1688.631\n",
      "Ep:46, loss:0.00004, loss_test:0.08083, lr:8.78e-03, fs:0.77487 (r=0.747,p=0.804),  time:36.728, tt:1726.223\n",
      "Ep:47, loss:0.00004, loss_test:0.08574, lr:8.78e-03, fs:0.70968 (r=0.556,p=0.982),  time:36.747, tt:1763.866\n",
      "Ep:48, loss:0.00004, loss_test:0.07832, lr:8.78e-03, fs:0.76243 (r=0.697,p=0.841),  time:36.873, tt:1806.801\n",
      "Ep:49, loss:0.00004, loss_test:0.08102, lr:8.78e-03, fs:0.74534 (r=0.606,p=0.968),  time:36.951, tt:1847.543\n",
      "Ep:50, loss:0.00004, loss_test:0.07825, lr:8.78e-03, fs:0.75152 (r=0.626,p=0.939),  time:36.948, tt:1884.364\n",
      "Ep:51, loss:0.00004, loss_test:0.08138, lr:8.78e-03, fs:0.71765 (r=0.616,p=0.859),  time:36.932, tt:1920.474\n",
      "Ep:52, loss:0.00003, loss_test:0.07989, lr:8.78e-03, fs:0.73750 (r=0.596,p=0.967),  time:36.944, tt:1958.032\n",
      "Ep:53, loss:0.00003, loss_test:0.07885, lr:8.78e-03, fs:0.77011 (r=0.677,p=0.893),  time:36.916, tt:1993.470\n",
      "Ep:54, loss:0.00003, loss_test:0.07912, lr:8.69e-03, fs:0.74074 (r=0.606,p=0.952),  time:37.009, tt:2035.489\n",
      "Ep:55, loss:0.00003, loss_test:0.08022, lr:8.60e-03, fs:0.72393 (r=0.596,p=0.922),  time:36.981, tt:2070.939\n",
      "Ep:56, loss:0.00003, loss_test:0.07890, lr:8.51e-03, fs:0.71429 (r=0.606,p=0.870),  time:36.973, tt:2107.442\n",
      "Ep:57, loss:0.00003, loss_test:0.07902, lr:8.43e-03, fs:0.73750 (r=0.596,p=0.967),  time:36.942, tt:2142.663\n",
      "Ep:58, loss:0.00003, loss_test:0.08021, lr:8.35e-03, fs:0.71605 (r=0.586,p=0.921),  time:36.916, tt:2178.069\n",
      "Ep:59, loss:0.00003, loss_test:0.07973, lr:8.26e-03, fs:0.73171 (r=0.606,p=0.923),  time:36.906, tt:2214.344\n",
      "Ep:60, loss:0.00003, loss_test:0.07954, lr:8.18e-03, fs:0.72050 (r=0.586,p=0.935),  time:36.892, tt:2250.387\n",
      "Ep:61, loss:0.00002, loss_test:0.08090, lr:8.10e-03, fs:0.71605 (r=0.586,p=0.921),  time:36.867, tt:2285.723\n",
      "Ep:62, loss:0.00002, loss_test:0.07996, lr:8.02e-03, fs:0.72500 (r=0.586,p=0.951),  time:36.862, tt:2322.338\n",
      "Ep:63, loss:0.00002, loss_test:0.08327, lr:7.94e-03, fs:0.72500 (r=0.586,p=0.951),  time:36.861, tt:2359.091\n",
      "Ep:64, loss:0.00002, loss_test:0.08123, lr:7.86e-03, fs:0.71605 (r=0.586,p=0.921),  time:36.866, tt:2396.290\n",
      "Ep:65, loss:0.00002, loss_test:0.08094, lr:7.78e-03, fs:0.72500 (r=0.586,p=0.951),  time:36.840, tt:2431.457\n",
      "Ep:66, loss:0.00002, loss_test:0.08251, lr:7.70e-03, fs:0.71605 (r=0.586,p=0.921),  time:36.816, tt:2466.673\n",
      "Ep:67, loss:0.00002, loss_test:0.08195, lr:7.62e-03, fs:0.72500 (r=0.586,p=0.951),  time:36.803, tt:2502.621\n",
      "Ep:68, loss:0.00002, loss_test:0.08311, lr:7.55e-03, fs:0.72500 (r=0.586,p=0.951),  time:36.787, tt:2538.276\n",
      "Ep:69, loss:0.00002, loss_test:0.08512, lr:7.47e-03, fs:0.72956 (r=0.586,p=0.967),  time:36.771, tt:2573.951\n",
      "Ep:70, loss:0.00002, loss_test:0.08165, lr:7.40e-03, fs:0.72500 (r=0.586,p=0.951),  time:36.759, tt:2609.873\n",
      "Ep:71, loss:0.00002, loss_test:0.08424, lr:7.32e-03, fs:0.72500 (r=0.586,p=0.951),  time:36.751, tt:2646.048\n",
      "Ep:72, loss:0.00002, loss_test:0.08389, lr:7.25e-03, fs:0.72500 (r=0.586,p=0.951),  time:36.740, tt:2682.031\n",
      "Ep:73, loss:0.00002, loss_test:0.08374, lr:7.18e-03, fs:0.72500 (r=0.586,p=0.951),  time:36.731, tt:2718.118\n",
      "Ep:74, loss:0.00002, loss_test:0.08500, lr:7.11e-03, fs:0.72956 (r=0.586,p=0.967),  time:36.719, tt:2753.926\n",
      "Ep:75, loss:0.00002, loss_test:0.08353, lr:7.03e-03, fs:0.72500 (r=0.586,p=0.951),  time:36.716, tt:2790.385\n",
      "Ep:76, loss:0.00002, loss_test:0.08695, lr:6.96e-03, fs:0.72500 (r=0.586,p=0.951),  time:36.693, tt:2825.356\n",
      "Ep:77, loss:0.00001, loss_test:0.08386, lr:6.89e-03, fs:0.72500 (r=0.586,p=0.951),  time:36.662, tt:2859.603\n",
      "Ep:78, loss:0.00001, loss_test:0.08721, lr:6.83e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.632, tt:2893.910\n",
      "Ep:79, loss:0.00001, loss_test:0.08530, lr:6.76e-03, fs:0.72500 (r=0.586,p=0.951),  time:36.619, tt:2929.524\n",
      "Ep:80, loss:0.00001, loss_test:0.08461, lr:6.69e-03, fs:0.72956 (r=0.586,p=0.967),  time:36.596, tt:2964.299\n",
      "Ep:81, loss:0.00001, loss_test:0.08608, lr:6.62e-03, fs:0.72956 (r=0.586,p=0.967),  time:36.585, tt:2999.994\n",
      "Ep:82, loss:0.00001, loss_test:0.08655, lr:6.56e-03, fs:0.72956 (r=0.586,p=0.967),  time:36.553, tt:3033.910\n",
      "Ep:83, loss:0.00001, loss_test:0.08609, lr:6.49e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.536, tt:3069.021\n",
      "Ep:84, loss:0.00001, loss_test:0.08772, lr:6.43e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.536, tt:3105.540\n",
      "Ep:85, loss:0.00001, loss_test:0.08610, lr:6.36e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.517, tt:3140.431\n",
      "Ep:86, loss:0.00001, loss_test:0.08623, lr:6.30e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.506, tt:3176.062\n",
      "Ep:87, loss:0.00001, loss_test:0.08575, lr:6.24e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.493, tt:3211.344\n",
      "Ep:88, loss:0.00001, loss_test:0.08656, lr:6.17e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.472, tt:3246.011\n",
      "Ep:89, loss:0.00001, loss_test:0.08596, lr:6.11e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.444, tt:3279.938\n",
      "Ep:90, loss:0.00001, loss_test:0.08616, lr:6.05e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.434, tt:3315.529\n",
      "Ep:91, loss:0.00001, loss_test:0.08761, lr:5.99e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.404, tt:3349.213\n",
      "Ep:92, loss:0.00001, loss_test:0.08629, lr:5.93e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.394, tt:3384.648\n",
      "Ep:93, loss:0.00001, loss_test:0.08833, lr:5.87e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.386, tt:3420.260\n",
      "Ep:94, loss:0.00001, loss_test:0.08624, lr:5.81e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.383, tt:3456.339\n",
      "Ep:95, loss:0.00001, loss_test:0.08652, lr:5.75e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.386, tt:3493.062\n",
      "Ep:96, loss:0.00001, loss_test:0.08564, lr:5.70e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.377, tt:3528.569\n",
      "Ep:97, loss:0.00001, loss_test:0.08679, lr:5.64e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.375, tt:3564.728\n",
      "Ep:98, loss:0.00001, loss_test:0.08896, lr:5.58e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.372, tt:3600.842\n",
      "Ep:99, loss:0.00001, loss_test:0.08944, lr:5.53e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.366, tt:3636.644\n",
      "Ep:100, loss:0.00001, loss_test:0.08599, lr:5.47e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.370, tt:3673.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:101, loss:0.00001, loss_test:0.08928, lr:5.42e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.395, tt:3712.294\n",
      "Ep:102, loss:0.00001, loss_test:0.08583, lr:5.36e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.382, tt:3747.334\n",
      "Ep:103, loss:0.00001, loss_test:0.08663, lr:5.31e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.374, tt:3782.929\n",
      "Ep:104, loss:0.00001, loss_test:0.08652, lr:5.26e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.356, tt:3817.377\n",
      "Ep:105, loss:0.00001, loss_test:0.08695, lr:5.20e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.340, tt:3852.009\n",
      "Ep:106, loss:0.00001, loss_test:0.08673, lr:5.15e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.325, tt:3886.771\n",
      "Ep:107, loss:0.00001, loss_test:0.08868, lr:5.10e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.308, tt:3921.270\n",
      "Ep:108, loss:0.00001, loss_test:0.08750, lr:5.05e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.300, tt:3956.726\n",
      "Ep:109, loss:0.00001, loss_test:0.08712, lr:5.00e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.293, tt:3992.192\n",
      "Ep:110, loss:0.00001, loss_test:0.08936, lr:4.95e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.278, tt:4026.871\n",
      "Ep:111, loss:0.00001, loss_test:0.08653, lr:4.90e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.268, tt:4061.986\n",
      "Ep:112, loss:0.00001, loss_test:0.08748, lr:4.85e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.257, tt:4097.094\n",
      "Ep:113, loss:0.00001, loss_test:0.08920, lr:4.80e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.245, tt:4131.912\n",
      "Ep:114, loss:0.00001, loss_test:0.08644, lr:4.75e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.245, tt:4168.145\n",
      "Ep:115, loss:0.00001, loss_test:0.08877, lr:4.71e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.237, tt:4203.505\n",
      "Ep:116, loss:0.00001, loss_test:0.09275, lr:4.66e-03, fs:0.73885 (r=0.586,p=1.000),  time:36.221, tt:4237.868\n",
      "Ep:117, loss:0.00001, loss_test:0.08917, lr:4.61e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.183, tt:4269.563\n",
      "Ep:118, loss:0.00001, loss_test:0.08572, lr:4.57e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.143, tt:4301.014\n",
      "Ep:119, loss:0.00001, loss_test:0.09116, lr:4.52e-03, fs:0.73885 (r=0.586,p=1.000),  time:36.113, tt:4333.533\n",
      "Ep:120, loss:0.00001, loss_test:0.09158, lr:4.48e-03, fs:0.73885 (r=0.586,p=1.000),  time:36.087, tt:4366.572\n",
      "Ep:121, loss:0.00001, loss_test:0.08769, lr:4.43e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.034, tt:4396.183\n",
      "Ep:122, loss:0.00001, loss_test:0.08766, lr:4.39e-03, fs:0.73418 (r=0.586,p=0.983),  time:36.010, tt:4429.226\n",
      "Ep:123, loss:0.00001, loss_test:0.08838, lr:4.34e-03, fs:0.73418 (r=0.586,p=0.983),  time:35.991, tt:4462.926\n",
      "Ep:124, loss:0.00001, loss_test:0.08853, lr:4.30e-03, fs:0.73418 (r=0.586,p=0.983),  time:35.963, tt:4495.328\n",
      "Ep:125, loss:0.00001, loss_test:0.08811, lr:4.26e-03, fs:0.73885 (r=0.586,p=1.000),  time:35.923, tt:4526.267\n",
      "Ep:126, loss:0.00001, loss_test:0.08738, lr:4.21e-03, fs:0.73418 (r=0.586,p=0.983),  time:35.881, tt:4556.883\n",
      "Ep:127, loss:0.00001, loss_test:0.09043, lr:4.17e-03, fs:0.73885 (r=0.586,p=1.000),  time:35.856, tt:4589.602\n",
      "Ep:128, loss:0.00001, loss_test:0.08946, lr:4.13e-03, fs:0.73885 (r=0.586,p=1.000),  time:35.827, tt:4621.641\n",
      "Ep:129, loss:0.00001, loss_test:0.08731, lr:4.09e-03, fs:0.73418 (r=0.586,p=0.983),  time:35.797, tt:4653.576\n",
      "Ep:130, loss:0.00001, loss_test:0.08942, lr:4.05e-03, fs:0.73885 (r=0.586,p=1.000),  time:35.779, tt:4687.105\n",
      "Ep:131, loss:0.00001, loss_test:0.08974, lr:4.01e-03, fs:0.73885 (r=0.586,p=1.000),  time:35.753, tt:4719.452\n",
      "Ep:132, loss:0.00000, loss_test:0.08836, lr:3.97e-03, fs:0.73418 (r=0.586,p=0.983),  time:35.754, tt:4755.247\n",
      "Ep:133, loss:0.00000, loss_test:0.08867, lr:3.93e-03, fs:0.73418 (r=0.586,p=0.983),  time:35.735, tt:4788.464\n",
      "Ep:134, loss:0.00000, loss_test:0.08938, lr:3.89e-03, fs:0.73418 (r=0.586,p=0.983),  time:35.716, tt:4821.656\n",
      "Ep:135, loss:0.00000, loss_test:0.08809, lr:3.85e-03, fs:0.73418 (r=0.586,p=0.983),  time:35.684, tt:4853.054\n",
      "Ep:136, loss:0.00000, loss_test:0.08962, lr:3.81e-03, fs:0.73885 (r=0.586,p=1.000),  time:35.665, tt:4886.172\n",
      "Ep:137, loss:0.00000, loss_test:0.08848, lr:3.77e-03, fs:0.73418 (r=0.586,p=0.983),  time:35.653, tt:4920.051\n",
      "Ep:138, loss:0.00000, loss_test:0.08937, lr:3.73e-03, fs:0.73418 (r=0.586,p=0.983),  time:35.636, tt:4953.397\n",
      "Ep:139, loss:0.00000, loss_test:0.09043, lr:3.70e-03, fs:0.73885 (r=0.586,p=1.000),  time:35.616, tt:4986.189\n",
      "Ep:140, loss:0.00000, loss_test:0.08875, lr:3.66e-03, fs:0.73418 (r=0.586,p=0.983),  time:35.592, tt:5018.416\n",
      "Ep:141, loss:0.00000, loss_test:0.09011, lr:3.62e-03, fs:0.73885 (r=0.586,p=1.000),  time:35.578, tt:5052.007\n",
      "Ep:142, loss:0.00000, loss_test:0.09247, lr:3.59e-03, fs:0.73885 (r=0.586,p=1.000),  time:35.559, tt:5084.946\n",
      "Ep:143, loss:0.00000, loss_test:0.09006, lr:3.55e-03, fs:0.73418 (r=0.586,p=0.983),  time:35.538, tt:5117.401\n",
      "Ep:144, loss:0.00000, loss_test:0.08865, lr:3.52e-03, fs:0.73418 (r=0.586,p=0.983),  time:35.519, tt:5150.253\n",
      "Ep:145, loss:0.00000, loss_test:0.09108, lr:3.48e-03, fs:0.73885 (r=0.586,p=1.000),  time:35.507, tt:5183.951\n",
      "Ep:146, loss:0.00000, loss_test:0.09030, lr:3.45e-03, fs:0.73885 (r=0.586,p=1.000),  time:35.485, tt:5216.351\n",
      "Ep:147, loss:0.00000, loss_test:0.08883, lr:3.41e-03, fs:0.73418 (r=0.586,p=0.983),  time:35.451, tt:5246.808\n",
      "Ep:148, loss:0.00000, loss_test:0.08974, lr:3.38e-03, fs:0.73885 (r=0.586,p=1.000),  time:35.437, tt:5280.063\n",
      "Ep:149, loss:0.00000, loss_test:0.09023, lr:3.34e-03, fs:0.73885 (r=0.586,p=1.000),  time:35.414, tt:5312.131\n",
      "Ep:150, loss:0.00000, loss_test:0.08868, lr:3.31e-03, fs:0.73418 (r=0.586,p=0.983),  time:35.377, tt:5341.886\n",
      "Ep:151, loss:0.00000, loss_test:0.09056, lr:3.28e-03, fs:0.73885 (r=0.586,p=1.000),  time:35.349, tt:5373.094\n",
      "Ep:152, loss:0.00000, loss_test:0.09069, lr:3.24e-03, fs:0.73885 (r=0.586,p=1.000),  time:35.328, tt:5405.182\n",
      "Ep:153, loss:0.00000, loss_test:0.08911, lr:3.21e-03, fs:0.73418 (r=0.586,p=0.983),  time:35.306, tt:5437.094\n",
      "Ep:154, loss:0.00000, loss_test:0.08941, lr:3.18e-03, fs:0.73418 (r=0.586,p=0.983),  time:35.289, tt:5469.801\n",
      "Ep:155, loss:0.00000, loss_test:0.09015, lr:3.15e-03, fs:0.73885 (r=0.586,p=1.000),  time:35.260, tt:5500.575\n",
      "Ep:156, loss:0.00000, loss_test:0.08916, lr:3.12e-03, fs:0.73418 (r=0.586,p=0.983),  time:35.234, tt:5531.734\n",
      "Ep:157, loss:0.00000, loss_test:0.08968, lr:3.09e-03, fs:0.73885 (r=0.586,p=1.000),  time:35.217, tt:5564.233\n",
      "Ep:158, loss:0.00000, loss_test:0.09010, lr:3.05e-03, fs:0.73885 (r=0.586,p=1.000),  time:35.202, tt:5597.181\n",
      "Ep:159, loss:0.00000, loss_test:0.08947, lr:3.02e-03, fs:0.73418 (r=0.586,p=0.983),  time:35.186, tt:5629.774\n",
      "Ep:160, loss:0.00000, loss_test:0.09015, lr:2.99e-03, fs:0.73885 (r=0.586,p=1.000),  time:35.167, tt:5661.908\n",
      "Ep:161, loss:0.00000, loss_test:0.08969, lr:2.96e-03, fs:0.73418 (r=0.586,p=0.983),  time:35.136, tt:5692.108\n",
      "Ep:162, loss:0.00000, loss_test:0.08963, lr:2.93e-03, fs:0.73418 (r=0.586,p=0.983),  time:35.106, tt:5722.354\n",
      "Ep:163, loss:0.00000, loss_test:0.09001, lr:2.90e-03, fs:0.73885 (r=0.586,p=1.000),  time:35.085, tt:5753.881\n",
      "Ep:164, loss:0.00000, loss_test:0.08934, lr:2.88e-03, fs:0.73418 (r=0.586,p=0.983),  time:35.060, tt:5784.909\n",
      "Ep:165, loss:0.00000, loss_test:0.09025, lr:2.85e-03, fs:0.73885 (r=0.586,p=1.000),  time:35.044, tt:5817.285\n",
      "Ep:166, loss:0.00000, loss_test:0.09024, lr:2.82e-03, fs:0.73885 (r=0.586,p=1.000),  time:35.032, tt:5850.396\n",
      "Ep:167, loss:0.00000, loss_test:0.08937, lr:2.79e-03, fs:0.73885 (r=0.586,p=1.000),  time:35.021, tt:5883.527\n",
      "Ep:168, loss:0.00000, loss_test:0.09022, lr:2.76e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.999, tt:5914.910\n",
      "Ep:169, loss:0.00000, loss_test:0.09112, lr:2.73e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.983, tt:5947.153\n",
      "Ep:170, loss:0.00000, loss_test:0.09004, lr:2.71e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.963, tt:5978.593\n",
      "Ep:171, loss:0.00000, loss_test:0.09033, lr:2.68e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.941, tt:6009.844\n",
      "Ep:172, loss:0.00000, loss_test:0.09160, lr:2.65e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.930, tt:6042.836\n",
      "Ep:173, loss:0.00000, loss_test:0.09073, lr:2.63e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.909, tt:6074.176\n",
      "Ep:174, loss:0.00000, loss_test:0.08983, lr:2.60e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.902, tt:6107.795\n",
      "Ep:175, loss:0.00000, loss_test:0.09063, lr:2.57e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.886, tt:6139.986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:176, loss:0.00000, loss_test:0.09044, lr:2.55e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.866, tt:6171.257\n",
      "Ep:177, loss:0.00000, loss_test:0.08968, lr:2.52e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.849, tt:6203.127\n",
      "Ep:178, loss:0.00000, loss_test:0.09034, lr:2.50e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.818, tt:6232.508\n",
      "Ep:179, loss:0.00000, loss_test:0.09104, lr:2.47e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.798, tt:6263.564\n",
      "Ep:180, loss:0.00000, loss_test:0.09100, lr:2.45e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.776, tt:6294.522\n",
      "Ep:181, loss:0.00000, loss_test:0.09052, lr:2.42e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.754, tt:6325.165\n",
      "Ep:182, loss:0.00000, loss_test:0.09020, lr:2.40e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.740, tt:6357.452\n",
      "Ep:183, loss:0.00000, loss_test:0.09058, lr:2.38e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.716, tt:6387.827\n",
      "Ep:184, loss:0.00000, loss_test:0.09050, lr:2.35e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.697, tt:6419.009\n",
      "Ep:185, loss:0.00000, loss_test:0.09023, lr:2.33e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.667, tt:6448.024\n",
      "Ep:186, loss:0.00000, loss_test:0.09076, lr:2.31e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.650, tt:6479.498\n",
      "Ep:187, loss:0.00000, loss_test:0.09075, lr:2.28e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.623, tt:6509.104\n",
      "Ep:188, loss:0.00000, loss_test:0.09015, lr:2.26e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.608, tt:6540.840\n",
      "Ep:189, loss:0.00000, loss_test:0.09137, lr:2.24e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.588, tt:6571.661\n",
      "Ep:190, loss:0.00000, loss_test:0.09121, lr:2.21e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.553, tt:6599.612\n",
      "Ep:191, loss:0.00000, loss_test:0.09034, lr:2.19e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.530, tt:6629.828\n",
      "Ep:192, loss:0.00000, loss_test:0.09062, lr:2.17e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.517, tt:6661.878\n",
      "Ep:193, loss:0.00000, loss_test:0.09036, lr:2.15e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.505, tt:6693.949\n",
      "Ep:194, loss:0.00000, loss_test:0.09040, lr:2.13e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.493, tt:6726.180\n",
      "Ep:195, loss:0.00000, loss_test:0.09011, lr:2.11e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.480, tt:6758.096\n",
      "Ep:196, loss:0.00000, loss_test:0.09053, lr:2.08e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.460, tt:6788.639\n",
      "Ep:197, loss:0.00000, loss_test:0.09034, lr:2.06e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.431, tt:6817.272\n",
      "Ep:198, loss:0.00000, loss_test:0.09024, lr:2.04e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.395, tt:6844.523\n",
      "Ep:199, loss:0.00000, loss_test:0.09104, lr:2.02e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.346, tt:6869.292\n",
      "Ep:200, loss:0.00000, loss_test:0.09121, lr:2.00e-03, fs:0.73885 (r=0.586,p=1.000),  time:34.285, tt:6891.337\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_600_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_600_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.01991, lr:6.00e-02, fs:0.64135 (r=0.874,p=0.507),  time:27.415, tt:27.415\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02182, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.060, tt:60.120\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02282, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.398, tt:100.193\n",
      "Ep:3, loss:0.00004, loss_test:0.02233, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.764, tt:139.057\n",
      "Ep:4, loss:0.00004, loss_test:0.02111, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.969, tt:179.845\n",
      "Ep:5, loss:0.00004, loss_test:0.01955, lr:6.00e-02, fs:0.67442 (r=1.000,p=0.509),  time:36.802, tt:220.812\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01859, lr:6.00e-02, fs:0.69565 (r=0.920,p=0.559),  time:37.395, tt:261.767\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01878, lr:6.00e-02, fs:0.68657 (r=0.793,p=0.605),  time:38.090, tt:304.722\n",
      "Ep:8, loss:0.00004, loss_test:0.01905, lr:6.00e-02, fs:0.69744 (r=0.782,p=0.630),  time:38.272, tt:344.449\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01843, lr:6.00e-02, fs:0.71569 (r=0.839,p=0.624),  time:38.496, tt:384.960\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01777, lr:6.00e-02, fs:0.70698 (r=0.874,p=0.594),  time:38.750, tt:426.252\n",
      "Ep:11, loss:0.00003, loss_test:0.01736, lr:6.00e-02, fs:0.70588 (r=0.897,p=0.582),  time:39.084, tt:469.007\n",
      "Ep:12, loss:0.00003, loss_test:0.01703, lr:6.00e-02, fs:0.71628 (r=0.885,p=0.602),  time:39.311, tt:511.042\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01692, lr:6.00e-02, fs:0.73333 (r=0.885,p=0.626),  time:39.346, tt:550.846\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01701, lr:6.00e-02, fs:0.75248 (r=0.874,p=0.661),  time:39.395, tt:590.920\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01702, lr:6.00e-02, fs:0.75622 (r=0.874,p=0.667),  time:39.562, tt:632.997\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01687, lr:6.00e-02, fs:0.76382 (r=0.874,p=0.679),  time:39.604, tt:673.260\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01671, lr:6.00e-02, fs:0.76382 (r=0.874,p=0.679),  time:39.664, tt:713.944\n",
      "Ep:18, loss:0.00002, loss_test:0.01656, lr:6.00e-02, fs:0.74112 (r=0.839,p=0.664),  time:39.703, tt:754.358\n",
      "Ep:19, loss:0.00002, loss_test:0.01650, lr:6.00e-02, fs:0.73196 (r=0.816,p=0.664),  time:39.740, tt:794.792\n",
      "Ep:20, loss:0.00002, loss_test:0.01650, lr:6.00e-02, fs:0.74346 (r=0.816,p=0.683),  time:39.869, tt:837.255\n",
      "Ep:21, loss:0.00002, loss_test:0.01654, lr:6.00e-02, fs:0.74595 (r=0.793,p=0.704),  time:39.889, tt:877.567\n",
      "Ep:22, loss:0.00002, loss_test:0.01659, lr:6.00e-02, fs:0.76087 (r=0.805,p=0.722),  time:39.843, tt:916.395\n",
      "Ep:23, loss:0.00002, loss_test:0.01660, lr:6.00e-02, fs:0.75824 (r=0.793,p=0.726),  time:39.843, tt:956.238\n",
      "Ep:24, loss:0.00002, loss_test:0.01652, lr:6.00e-02, fs:0.75824 (r=0.793,p=0.726),  time:39.917, tt:997.928\n",
      "Ep:25, loss:0.00002, loss_test:0.01646, lr:6.00e-02, fs:0.75824 (r=0.793,p=0.726),  time:39.988, tt:1039.681\n",
      "Ep:26, loss:0.00002, loss_test:0.01647, lr:6.00e-02, fs:0.76667 (r=0.793,p=0.742),  time:40.100, tt:1082.689\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01649, lr:6.00e-02, fs:0.76667 (r=0.793,p=0.742),  time:40.049, tt:1121.382\n",
      "Ep:28, loss:0.00002, loss_test:0.01656, lr:6.00e-02, fs:0.75978 (r=0.782,p=0.739),  time:40.155, tt:1164.502\n",
      "Ep:29, loss:0.00002, loss_test:0.01661, lr:6.00e-02, fs:0.76836 (r=0.782,p=0.756),  time:40.184, tt:1205.506\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01669, lr:6.00e-02, fs:0.76836 (r=0.782,p=0.756),  time:40.198, tt:1246.148\n",
      "Ep:31, loss:0.00002, loss_test:0.01683, lr:6.00e-02, fs:0.77273 (r=0.782,p=0.764),  time:40.200, tt:1286.401\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01692, lr:6.00e-02, fs:0.77011 (r=0.770,p=0.770),  time:40.149, tt:1324.918\n",
      "Ep:33, loss:0.00002, loss_test:0.01696, lr:6.00e-02, fs:0.76571 (r=0.770,p=0.761),  time:40.206, tt:1367.021\n",
      "Ep:34, loss:0.00002, loss_test:0.01703, lr:6.00e-02, fs:0.77011 (r=0.770,p=0.770),  time:40.276, tt:1409.643\n",
      "Ep:35, loss:0.00002, loss_test:0.01707, lr:6.00e-02, fs:0.77011 (r=0.770,p=0.770),  time:40.242, tt:1448.698\n",
      "Ep:36, loss:0.00002, loss_test:0.01709, lr:6.00e-02, fs:0.77457 (r=0.770,p=0.779),  time:40.226, tt:1488.350\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01719, lr:6.00e-02, fs:0.77907 (r=0.770,p=0.788),  time:40.254, tt:1529.662\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00001, loss_test:0.01730, lr:6.00e-02, fs:0.78824 (r=0.770,p=0.807),  time:40.321, tt:1572.511\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00001, loss_test:0.01735, lr:6.00e-02, fs:0.78824 (r=0.770,p=0.807),  time:40.292, tt:1611.671\n",
      "Ep:40, loss:0.00001, loss_test:0.01740, lr:6.00e-02, fs:0.78824 (r=0.770,p=0.807),  time:40.326, tt:1653.374\n",
      "Ep:41, loss:0.00001, loss_test:0.01754, lr:6.00e-02, fs:0.78824 (r=0.770,p=0.807),  time:40.351, tt:1694.737\n",
      "Ep:42, loss:0.00001, loss_test:0.01762, lr:6.00e-02, fs:0.78824 (r=0.770,p=0.807),  time:40.305, tt:1733.116\n",
      "Ep:43, loss:0.00001, loss_test:0.01761, lr:6.00e-02, fs:0.78824 (r=0.770,p=0.807),  time:40.286, tt:1772.604\n",
      "Ep:44, loss:0.00001, loss_test:0.01759, lr:6.00e-02, fs:0.78824 (r=0.770,p=0.807),  time:40.268, tt:1812.058\n",
      "Ep:45, loss:0.00001, loss_test:0.01770, lr:6.00e-02, fs:0.78824 (r=0.770,p=0.807),  time:40.270, tt:1852.409\n",
      "Ep:46, loss:0.00001, loss_test:0.01788, lr:6.00e-02, fs:0.78824 (r=0.770,p=0.807),  time:40.261, tt:1892.272\n",
      "Ep:47, loss:0.00001, loss_test:0.01790, lr:6.00e-02, fs:0.78824 (r=0.770,p=0.807),  time:40.275, tt:1933.222\n",
      "Ep:48, loss:0.00001, loss_test:0.01801, lr:6.00e-02, fs:0.78824 (r=0.770,p=0.807),  time:40.379, tt:1978.557\n",
      "Ep:49, loss:0.00001, loss_test:0.01816, lr:6.00e-02, fs:0.78824 (r=0.770,p=0.807),  time:40.376, tt:2018.788\n",
      "Ep:50, loss:0.00001, loss_test:0.01817, lr:5.94e-02, fs:0.78824 (r=0.770,p=0.807),  time:40.364, tt:2058.566\n",
      "Ep:51, loss:0.00001, loss_test:0.01816, lr:5.88e-02, fs:0.78824 (r=0.770,p=0.807),  time:40.320, tt:2096.644\n",
      "Ep:52, loss:0.00001, loss_test:0.01834, lr:5.82e-02, fs:0.78824 (r=0.770,p=0.807),  time:40.349, tt:2138.513\n",
      "Ep:53, loss:0.00001, loss_test:0.01841, lr:5.76e-02, fs:0.78824 (r=0.770,p=0.807),  time:40.360, tt:2179.457\n",
      "Ep:54, loss:0.00001, loss_test:0.01842, lr:5.71e-02, fs:0.79290 (r=0.770,p=0.817),  time:40.343, tt:2218.872\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01850, lr:5.71e-02, fs:0.79290 (r=0.770,p=0.817),  time:40.288, tt:2256.104\n",
      "Ep:56, loss:0.00001, loss_test:0.01864, lr:5.71e-02, fs:0.79290 (r=0.770,p=0.817),  time:40.303, tt:2297.278\n",
      "Ep:57, loss:0.00001, loss_test:0.01870, lr:5.71e-02, fs:0.79290 (r=0.770,p=0.817),  time:40.311, tt:2338.066\n",
      "Ep:58, loss:0.00001, loss_test:0.01865, lr:5.71e-02, fs:0.79290 (r=0.770,p=0.817),  time:40.341, tt:2380.133\n",
      "Ep:59, loss:0.00001, loss_test:0.01885, lr:5.71e-02, fs:0.79290 (r=0.770,p=0.817),  time:40.352, tt:2421.108\n",
      "Ep:60, loss:0.00001, loss_test:0.01895, lr:5.71e-02, fs:0.79762 (r=0.770,p=0.827),  time:40.354, tt:2461.567\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.01895, lr:5.71e-02, fs:0.79762 (r=0.770,p=0.827),  time:40.351, tt:2501.751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00001, loss_test:0.01911, lr:5.71e-02, fs:0.80240 (r=0.770,p=0.838),  time:40.370, tt:2543.310\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.01917, lr:5.71e-02, fs:0.80723 (r=0.770,p=0.848),  time:40.428, tt:2587.377\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01908, lr:5.71e-02, fs:0.80723 (r=0.770,p=0.848),  time:40.463, tt:2630.102\n",
      "Ep:65, loss:0.00001, loss_test:0.01923, lr:5.71e-02, fs:0.80723 (r=0.770,p=0.848),  time:40.477, tt:2671.497\n",
      "Ep:66, loss:0.00001, loss_test:0.01927, lr:5.71e-02, fs:0.81212 (r=0.770,p=0.859),  time:40.488, tt:2712.707\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01929, lr:5.71e-02, fs:0.81212 (r=0.770,p=0.859),  time:40.491, tt:2753.408\n",
      "Ep:68, loss:0.00001, loss_test:0.01943, lr:5.71e-02, fs:0.81707 (r=0.770,p=0.870),  time:40.497, tt:2794.288\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01953, lr:5.71e-02, fs:0.81707 (r=0.770,p=0.870),  time:40.494, tt:2834.576\n",
      "Ep:70, loss:0.00001, loss_test:0.01950, lr:5.71e-02, fs:0.82716 (r=0.770,p=0.893),  time:40.472, tt:2873.546\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00001, loss_test:0.01959, lr:5.71e-02, fs:0.82209 (r=0.770,p=0.882),  time:40.467, tt:2913.630\n",
      "Ep:72, loss:0.00001, loss_test:0.01971, lr:5.71e-02, fs:0.82209 (r=0.770,p=0.882),  time:40.471, tt:2954.352\n",
      "Ep:73, loss:0.00001, loss_test:0.01977, lr:5.71e-02, fs:0.82209 (r=0.770,p=0.882),  time:40.505, tt:2997.343\n",
      "Ep:74, loss:0.00001, loss_test:0.01988, lr:5.71e-02, fs:0.82209 (r=0.770,p=0.882),  time:40.501, tt:3037.547\n",
      "Ep:75, loss:0.00001, loss_test:0.01999, lr:5.71e-02, fs:0.82209 (r=0.770,p=0.882),  time:40.478, tt:3076.342\n",
      "Ep:76, loss:0.00001, loss_test:0.01999, lr:5.71e-02, fs:0.82716 (r=0.770,p=0.893),  time:40.475, tt:3116.610\n",
      "Ep:77, loss:0.00001, loss_test:0.02007, lr:5.71e-02, fs:0.82716 (r=0.770,p=0.893),  time:40.467, tt:3156.394\n",
      "Ep:78, loss:0.00001, loss_test:0.02017, lr:5.71e-02, fs:0.82716 (r=0.770,p=0.893),  time:40.489, tt:3198.607\n",
      "Ep:79, loss:0.00001, loss_test:0.02020, lr:5.71e-02, fs:0.81988 (r=0.759,p=0.892),  time:40.521, tt:3241.675\n",
      "Ep:80, loss:0.00001, loss_test:0.02037, lr:5.71e-02, fs:0.81988 (r=0.759,p=0.892),  time:40.557, tt:3285.122\n",
      "Ep:81, loss:0.00001, loss_test:0.02031, lr:5.71e-02, fs:0.81988 (r=0.759,p=0.892),  time:40.575, tt:3327.149\n",
      "Ep:82, loss:0.00001, loss_test:0.02051, lr:5.65e-02, fs:0.81988 (r=0.759,p=0.892),  time:40.560, tt:3366.481\n",
      "Ep:83, loss:0.00001, loss_test:0.02059, lr:5.59e-02, fs:0.81988 (r=0.759,p=0.892),  time:40.583, tt:3408.989\n",
      "Ep:84, loss:0.00001, loss_test:0.02055, lr:5.54e-02, fs:0.81988 (r=0.759,p=0.892),  time:40.594, tt:3450.476\n",
      "Ep:85, loss:0.00001, loss_test:0.02072, lr:5.48e-02, fs:0.81988 (r=0.759,p=0.892),  time:40.659, tt:3496.705\n",
      "Ep:86, loss:0.00001, loss_test:0.02080, lr:5.43e-02, fs:0.81988 (r=0.759,p=0.892),  time:40.643, tt:3535.955\n",
      "Ep:87, loss:0.00001, loss_test:0.02083, lr:5.37e-02, fs:0.81988 (r=0.759,p=0.892),  time:40.620, tt:3574.596\n",
      "Ep:88, loss:0.00001, loss_test:0.02095, lr:5.32e-02, fs:0.81988 (r=0.759,p=0.892),  time:40.641, tt:3617.058\n",
      "Ep:89, loss:0.00001, loss_test:0.02107, lr:5.27e-02, fs:0.81988 (r=0.759,p=0.892),  time:40.648, tt:3658.330\n",
      "Ep:90, loss:0.00001, loss_test:0.02108, lr:5.21e-02, fs:0.81988 (r=0.759,p=0.892),  time:40.671, tt:3701.049\n",
      "Ep:91, loss:0.00001, loss_test:0.02120, lr:5.16e-02, fs:0.81988 (r=0.759,p=0.892),  time:40.686, tt:3743.075\n",
      "Ep:92, loss:0.00001, loss_test:0.02129, lr:5.11e-02, fs:0.81988 (r=0.759,p=0.892),  time:40.683, tt:3783.554\n",
      "Ep:93, loss:0.00001, loss_test:0.02136, lr:5.06e-02, fs:0.80503 (r=0.736,p=0.889),  time:40.690, tt:3824.832\n",
      "Ep:94, loss:0.00001, loss_test:0.02148, lr:5.01e-02, fs:0.79747 (r=0.724,p=0.887),  time:40.701, tt:3866.638\n",
      "Ep:95, loss:0.00001, loss_test:0.02147, lr:4.96e-02, fs:0.79747 (r=0.724,p=0.887),  time:40.718, tt:3908.960\n",
      "Ep:96, loss:0.00000, loss_test:0.02153, lr:4.91e-02, fs:0.79747 (r=0.724,p=0.887),  time:40.731, tt:3950.955\n",
      "Ep:97, loss:0.00000, loss_test:0.02164, lr:4.86e-02, fs:0.79747 (r=0.724,p=0.887),  time:40.742, tt:3992.748\n",
      "Ep:98, loss:0.00000, loss_test:0.02170, lr:4.81e-02, fs:0.78981 (r=0.713,p=0.886),  time:40.761, tt:4035.368\n",
      "Ep:99, loss:0.00000, loss_test:0.02178, lr:4.76e-02, fs:0.78981 (r=0.713,p=0.886),  time:40.760, tt:4075.993\n",
      "Ep:100, loss:0.00000, loss_test:0.02189, lr:4.71e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.758, tt:4116.559\n",
      "Ep:101, loss:0.00000, loss_test:0.02184, lr:4.67e-02, fs:0.75817 (r=0.667,p=0.879),  time:40.757, tt:4157.185\n",
      "Ep:102, loss:0.00000, loss_test:0.02197, lr:4.62e-02, fs:0.76623 (r=0.678,p=0.881),  time:40.775, tt:4199.817\n",
      "Ep:103, loss:0.00000, loss_test:0.02210, lr:4.57e-02, fs:0.75817 (r=0.667,p=0.879),  time:40.791, tt:4242.248\n",
      "Ep:104, loss:0.00000, loss_test:0.02200, lr:4.53e-02, fs:0.75817 (r=0.667,p=0.879),  time:40.802, tt:4284.183\n",
      "Ep:105, loss:0.00000, loss_test:0.02210, lr:4.48e-02, fs:0.76623 (r=0.678,p=0.881),  time:40.813, tt:4326.188\n",
      "Ep:106, loss:0.00000, loss_test:0.02224, lr:4.44e-02, fs:0.75000 (r=0.655,p=0.877),  time:40.860, tt:4371.985\n",
      "Ep:107, loss:0.00000, loss_test:0.02227, lr:4.39e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.869, tt:4413.894\n",
      "Ep:108, loss:0.00000, loss_test:0.02240, lr:4.35e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.885, tt:4456.512\n",
      "Ep:109, loss:0.00000, loss_test:0.02244, lr:4.31e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.888, tt:4497.689\n",
      "Ep:110, loss:0.00000, loss_test:0.02241, lr:4.26e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.903, tt:4540.208\n",
      "Ep:111, loss:0.00000, loss_test:0.02248, lr:4.22e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.902, tt:4581.071\n",
      "Ep:112, loss:0.00000, loss_test:0.02266, lr:4.18e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.914, tt:4623.302\n",
      "Ep:113, loss:0.00000, loss_test:0.02264, lr:4.14e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.909, tt:4663.677\n",
      "Ep:114, loss:0.00000, loss_test:0.02265, lr:4.10e-02, fs:0.74667 (r=0.644,p=0.889),  time:40.884, tt:4701.680\n",
      "Ep:115, loss:0.00000, loss_test:0.02284, lr:4.05e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.876, tt:4741.663\n",
      "Ep:116, loss:0.00000, loss_test:0.02281, lr:4.01e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.880, tt:4782.909\n",
      "Ep:117, loss:0.00000, loss_test:0.02283, lr:3.97e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.873, tt:4823.031\n",
      "Ep:118, loss:0.00000, loss_test:0.02305, lr:3.93e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.884, tt:4865.209\n",
      "Ep:119, loss:0.00000, loss_test:0.02298, lr:3.89e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.882, tt:4905.813\n",
      "Ep:120, loss:0.00000, loss_test:0.02293, lr:3.86e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.887, tt:4947.372\n",
      "Ep:121, loss:0.00000, loss_test:0.02315, lr:3.82e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.880, tt:4987.392\n",
      "Ep:122, loss:0.00000, loss_test:0.02323, lr:3.78e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.876, tt:5027.726\n",
      "Ep:123, loss:0.00000, loss_test:0.02318, lr:3.74e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.876, tt:5068.605\n",
      "Ep:124, loss:0.00000, loss_test:0.02326, lr:3.70e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.874, tt:5109.204\n",
      "Ep:125, loss:0.00000, loss_test:0.02333, lr:3.67e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.878, tt:5150.672\n",
      "Ep:126, loss:0.00000, loss_test:0.02328, lr:3.63e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.886, tt:5192.555\n",
      "Ep:127, loss:0.00000, loss_test:0.02340, lr:3.59e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.919, tt:5237.593\n",
      "Ep:128, loss:0.00000, loss_test:0.02353, lr:3.56e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.922, tt:5278.905\n",
      "Ep:129, loss:0.00000, loss_test:0.02343, lr:3.52e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.912, tt:5318.500\n",
      "Ep:130, loss:0.00000, loss_test:0.02349, lr:3.49e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.912, tt:5359.425\n",
      "Ep:131, loss:0.00000, loss_test:0.02360, lr:3.45e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.923, tt:5401.844\n",
      "Ep:132, loss:0.00000, loss_test:0.02364, lr:3.42e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.924, tt:5442.951\n",
      "Ep:133, loss:0.00000, loss_test:0.02364, lr:3.38e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.911, tt:5482.038\n",
      "Ep:134, loss:0.00000, loss_test:0.02377, lr:3.35e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.902, tt:5521.774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00000, loss_test:0.02373, lr:3.32e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.894, tt:5561.569\n",
      "Ep:136, loss:0.00000, loss_test:0.02380, lr:3.28e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.887, tt:5601.572\n",
      "Ep:137, loss:0.00000, loss_test:0.02386, lr:3.25e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.885, tt:5642.131\n",
      "Ep:138, loss:0.00000, loss_test:0.02383, lr:3.22e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.885, tt:5683.008\n",
      "Ep:139, loss:0.00000, loss_test:0.02391, lr:3.19e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.886, tt:5724.063\n",
      "Ep:140, loss:0.00000, loss_test:0.02397, lr:3.15e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.883, tt:5764.508\n",
      "Ep:141, loss:0.00000, loss_test:0.02402, lr:3.12e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.894, tt:5806.904\n",
      "Ep:142, loss:0.00000, loss_test:0.02407, lr:3.09e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.899, tt:5848.626\n",
      "Ep:143, loss:0.00000, loss_test:0.02406, lr:3.06e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.903, tt:5890.089\n",
      "Ep:144, loss:0.00000, loss_test:0.02407, lr:3.03e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.895, tt:5929.815\n",
      "Ep:145, loss:0.00000, loss_test:0.02415, lr:3.00e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.902, tt:5971.715\n",
      "Ep:146, loss:0.00000, loss_test:0.02420, lr:2.97e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.912, tt:6014.034\n",
      "Ep:147, loss:0.00000, loss_test:0.02421, lr:2.94e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.913, tt:6055.095\n",
      "Ep:148, loss:0.00000, loss_test:0.02430, lr:2.91e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.920, tt:6097.015\n",
      "Ep:149, loss:0.00000, loss_test:0.02431, lr:2.88e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.917, tt:6137.593\n",
      "Ep:150, loss:0.00000, loss_test:0.02434, lr:2.85e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.901, tt:6176.072\n",
      "Ep:151, loss:0.00000, loss_test:0.02440, lr:2.82e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.896, tt:6216.118\n",
      "Ep:152, loss:0.00000, loss_test:0.02439, lr:2.80e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.887, tt:6255.636\n",
      "Ep:153, loss:0.00000, loss_test:0.02445, lr:2.77e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.884, tt:6296.158\n",
      "Ep:154, loss:0.00000, loss_test:0.02450, lr:2.74e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.882, tt:6336.732\n",
      "Ep:155, loss:0.00000, loss_test:0.02453, lr:2.71e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.869, tt:6375.546\n",
      "Ep:156, loss:0.00000, loss_test:0.02452, lr:2.69e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.866, tt:6416.033\n",
      "Ep:157, loss:0.00000, loss_test:0.02459, lr:2.66e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.853, tt:6454.817\n",
      "Ep:158, loss:0.00000, loss_test:0.02461, lr:2.63e-02, fs:0.74324 (r=0.632,p=0.902),  time:40.843, tt:6494.084\n",
      "Ep:159, loss:0.00000, loss_test:0.02461, lr:2.61e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.828, tt:6532.431\n",
      "Ep:160, loss:0.00000, loss_test:0.02469, lr:2.58e-02, fs:0.75168 (r=0.644,p=0.903),  time:40.820, tt:6571.974\n",
      "Ep:161, loss:0.00000, loss_test:0.02470, lr:2.55e-02, fs:0.74324 (r=0.632,p=0.902),  time:40.808, tt:6610.965\n",
      "Ep:162, loss:0.00000, loss_test:0.02472, lr:2.53e-02, fs:0.74324 (r=0.632,p=0.902),  time:40.806, tt:6651.388\n",
      "Ep:163, loss:0.00000, loss_test:0.02478, lr:2.50e-02, fs:0.74324 (r=0.632,p=0.902),  time:40.798, tt:6690.854\n",
      "Ep:164, loss:0.00000, loss_test:0.02482, lr:2.48e-02, fs:0.74324 (r=0.632,p=0.902),  time:40.777, tt:6728.281\n",
      "Ep:165, loss:0.00000, loss_test:0.02485, lr:2.45e-02, fs:0.74324 (r=0.632,p=0.902),  time:40.773, tt:6768.388\n",
      "Ep:166, loss:0.00000, loss_test:0.02487, lr:2.43e-02, fs:0.74324 (r=0.632,p=0.902),  time:40.769, tt:6808.427\n",
      "Ep:167, loss:0.00000, loss_test:0.02486, lr:2.40e-02, fs:0.74324 (r=0.632,p=0.902),  time:40.772, tt:6849.645\n",
      "Ep:168, loss:0.00000, loss_test:0.02490, lr:2.38e-02, fs:0.74324 (r=0.632,p=0.902),  time:40.806, tt:6896.164\n",
      "Ep:169, loss:0.00000, loss_test:0.02495, lr:2.36e-02, fs:0.74324 (r=0.632,p=0.902),  time:40.793, tt:6934.743\n",
      "Ep:170, loss:0.00000, loss_test:0.02501, lr:2.33e-02, fs:0.74324 (r=0.632,p=0.902),  time:40.789, tt:6974.873\n",
      "Ep:171, loss:0.00000, loss_test:0.02502, lr:2.31e-02, fs:0.74324 (r=0.632,p=0.902),  time:40.776, tt:7013.421\n",
      "Ep:172, loss:0.00000, loss_test:0.02502, lr:2.29e-02, fs:0.74324 (r=0.632,p=0.902),  time:40.770, tt:7053.272\n",
      "Ep:173, loss:0.00000, loss_test:0.02506, lr:2.26e-02, fs:0.74324 (r=0.632,p=0.902),  time:40.751, tt:7090.705\n",
      "Ep:174, loss:0.00000, loss_test:0.02512, lr:2.24e-02, fs:0.74324 (r=0.632,p=0.902),  time:40.734, tt:7128.512\n",
      "Ep:175, loss:0.00000, loss_test:0.02512, lr:2.22e-02, fs:0.74324 (r=0.632,p=0.902),  time:40.731, tt:7168.594\n",
      "Ep:176, loss:0.00000, loss_test:0.02510, lr:2.20e-02, fs:0.74324 (r=0.632,p=0.902),  time:40.726, tt:7208.462\n",
      "Ep:177, loss:0.00000, loss_test:0.02515, lr:2.17e-02, fs:0.74324 (r=0.632,p=0.902),  time:40.727, tt:7249.432\n",
      "Ep:178, loss:0.00000, loss_test:0.02517, lr:2.15e-02, fs:0.74324 (r=0.632,p=0.902),  time:40.716, tt:7288.172\n",
      "Ep:179, loss:0.00000, loss_test:0.02519, lr:2.13e-02, fs:0.74324 (r=0.632,p=0.902),  time:40.715, tt:7328.672\n",
      "Ep:180, loss:0.00000, loss_test:0.02527, lr:2.11e-02, fs:0.74324 (r=0.632,p=0.902),  time:40.719, tt:7370.090\n",
      "Ep:181, loss:0.00000, loss_test:0.02528, lr:2.09e-02, fs:0.74324 (r=0.632,p=0.902),  time:40.710, tt:7409.296\n",
      "Ep:182, loss:0.00000, loss_test:0.02529, lr:2.07e-02, fs:0.74324 (r=0.632,p=0.902),  time:40.711, tt:7450.170\n",
      "Ep:183, loss:0.00000, loss_test:0.02533, lr:2.05e-02, fs:0.74324 (r=0.632,p=0.902),  time:40.700, tt:7488.857\n",
      "Ep:184, loss:0.00000, loss_test:0.02533, lr:2.03e-02, fs:0.74324 (r=0.632,p=0.902),  time:40.692, tt:7527.960\n",
      "Ep:185, loss:0.00000, loss_test:0.02537, lr:2.01e-02, fs:0.74324 (r=0.632,p=0.902),  time:40.689, tt:7568.114\n",
      "Ep:186, loss:0.00000, loss_test:0.02539, lr:1.99e-02, fs:0.74324 (r=0.632,p=0.902),  time:40.682, tt:7607.561\n",
      "Ep:187, loss:0.00000, loss_test:0.02544, lr:1.97e-02, fs:0.74324 (r=0.632,p=0.902),  time:40.680, tt:7647.861\n",
      "Ep:188, loss:0.00000, loss_test:0.02541, lr:1.95e-02, fs:0.74324 (r=0.632,p=0.902),  time:40.684, tt:7689.224\n",
      "Ep:189, loss:0.00000, loss_test:0.02543, lr:1.93e-02, fs:0.74830 (r=0.632,p=0.917),  time:40.701, tt:7733.193\n",
      "Ep:190, loss:0.00000, loss_test:0.02545, lr:1.91e-02, fs:0.75342 (r=0.632,p=0.932),  time:40.693, tt:7772.288\n",
      "Ep:191, loss:0.00000, loss_test:0.02552, lr:1.89e-02, fs:0.75342 (r=0.632,p=0.932),  time:40.693, tt:7813.099\n",
      "Ep:192, loss:0.00000, loss_test:0.02552, lr:1.87e-02, fs:0.75342 (r=0.632,p=0.932),  time:40.693, tt:7853.797\n",
      "Ep:193, loss:0.00000, loss_test:0.02552, lr:1.85e-02, fs:0.75342 (r=0.632,p=0.932),  time:40.690, tt:7893.927\n",
      "Ep:194, loss:0.00000, loss_test:0.02554, lr:1.83e-02, fs:0.75342 (r=0.632,p=0.932),  time:40.691, tt:7934.718\n",
      "Ep:195, loss:0.00000, loss_test:0.02557, lr:1.81e-02, fs:0.75342 (r=0.632,p=0.932),  time:40.697, tt:7976.568\n",
      "Ep:196, loss:0.00000, loss_test:0.02557, lr:1.80e-02, fs:0.75342 (r=0.632,p=0.932),  time:40.695, tt:8016.830\n",
      "Ep:197, loss:0.00000, loss_test:0.02556, lr:1.78e-02, fs:0.75342 (r=0.632,p=0.932),  time:40.687, tt:8056.072\n",
      "Ep:198, loss:0.00000, loss_test:0.02560, lr:1.76e-02, fs:0.75342 (r=0.632,p=0.932),  time:40.696, tt:8098.435\n",
      "Ep:199, loss:0.00000, loss_test:0.02565, lr:1.74e-02, fs:0.75342 (r=0.632,p=0.932),  time:40.695, tt:8138.974\n",
      "Ep:200, loss:0.00000, loss_test:0.02566, lr:1.73e-02, fs:0.75862 (r=0.632,p=0.948),  time:40.701, tt:8180.944\n",
      "Ep:201, loss:0.00000, loss_test:0.02568, lr:1.71e-02, fs:0.75862 (r=0.632,p=0.948),  time:40.711, tt:8223.603\n",
      "Ep:202, loss:0.00000, loss_test:0.02571, lr:1.69e-02, fs:0.75862 (r=0.632,p=0.948),  time:40.715, tt:8265.243\n",
      "Ep:203, loss:0.00000, loss_test:0.02571, lr:1.67e-02, fs:0.75342 (r=0.632,p=0.932),  time:40.718, tt:8306.461\n",
      "Ep:204, loss:0.00000, loss_test:0.02573, lr:1.66e-02, fs:0.75342 (r=0.632,p=0.932),  time:40.721, tt:8347.736\n",
      "Ep:205, loss:0.00000, loss_test:0.02576, lr:1.64e-02, fs:0.75862 (r=0.632,p=0.948),  time:40.724, tt:8389.191\n",
      "Ep:206, loss:0.00000, loss_test:0.02579, lr:1.62e-02, fs:0.75862 (r=0.632,p=0.948),  time:40.728, tt:8430.709\n",
      "Ep:207, loss:0.00000, loss_test:0.02580, lr:1.61e-02, fs:0.75862 (r=0.632,p=0.948),  time:40.734, tt:8472.750\n",
      "Ep:208, loss:0.00000, loss_test:0.02582, lr:1.59e-02, fs:0.75862 (r=0.632,p=0.948),  time:40.729, tt:8512.389\n",
      "Ep:209, loss:0.00000, loss_test:0.02584, lr:1.58e-02, fs:0.75862 (r=0.632,p=0.948),  time:40.746, tt:8556.720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:210, loss:0.00000, loss_test:0.02584, lr:1.56e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.737, tt:8595.576\n",
      "Ep:211, loss:0.00000, loss_test:0.02584, lr:1.54e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.713, tt:8631.103\n",
      "Ep:212, loss:0.00000, loss_test:0.02588, lr:1.53e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.695, tt:8668.049\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14231, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.844, tt:40.844\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14085, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.439, tt:82.879\n",
      "Ep:2, loss:0.00027, loss_test:0.13826, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.609, tt:124.827\n",
      "Ep:3, loss:0.00027, loss_test:0.13398, lr:1.00e-02, fs:0.66409 (r=0.989,p=0.500),  time:42.095, tt:168.381\n",
      "Ep:4, loss:0.00026, loss_test:0.12719, lr:1.00e-02, fs:0.66942 (r=0.931,p=0.523),  time:41.942, tt:209.712\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.11760, lr:1.00e-02, fs:0.67308 (r=0.805,p=0.579),  time:42.263, tt:253.579\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.11202, lr:1.00e-02, fs:0.67816 (r=0.678,p=0.678),  time:42.472, tt:297.302\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00022, loss_test:0.10967, lr:1.00e-02, fs:0.68605 (r=0.678,p=0.694),  time:42.728, tt:341.827\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00021, loss_test:0.10909, lr:1.00e-02, fs:0.70408 (r=0.793,p=0.633),  time:42.903, tt:386.125\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.10759, lr:1.00e-02, fs:0.71204 (r=0.782,p=0.654),  time:42.879, tt:428.786\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.10645, lr:1.00e-02, fs:0.69512 (r=0.655,p=0.740),  time:43.035, tt:473.382\n",
      "Ep:11, loss:0.00019, loss_test:0.10557, lr:1.00e-02, fs:0.71765 (r=0.701,p=0.735),  time:43.051, tt:516.612\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.10456, lr:1.00e-02, fs:0.72527 (r=0.759,p=0.695),  time:43.225, tt:561.925\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00017, loss_test:0.10094, lr:1.00e-02, fs:0.75152 (r=0.713,p=0.795),  time:43.282, tt:605.945\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.09797, lr:1.00e-02, fs:0.74390 (r=0.701,p=0.792),  time:43.290, tt:649.353\n",
      "Ep:15, loss:0.00016, loss_test:0.09612, lr:1.00e-02, fs:0.75862 (r=0.759,p=0.759),  time:43.402, tt:694.428\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.09335, lr:1.00e-02, fs:0.76364 (r=0.724,p=0.808),  time:43.542, tt:740.207\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.09212, lr:1.00e-02, fs:0.78824 (r=0.770,p=0.807),  time:43.495, tt:782.911\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.09101, lr:1.00e-02, fs:0.79769 (r=0.793,p=0.802),  time:43.499, tt:826.489\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.09019, lr:1.00e-02, fs:0.80702 (r=0.793,p=0.821),  time:43.493, tt:869.867\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.08904, lr:1.00e-02, fs:0.81143 (r=0.816,p=0.807),  time:43.485, tt:913.195\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.08823, lr:1.00e-02, fs:0.82558 (r=0.816,p=0.835),  time:43.518, tt:957.395\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00012, loss_test:0.08718, lr:1.00e-02, fs:0.84211 (r=0.828,p=0.857),  time:43.516, tt:1000.875\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.08720, lr:1.00e-02, fs:0.84706 (r=0.828,p=0.867),  time:43.535, tt:1044.833\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.08598, lr:1.00e-02, fs:0.83429 (r=0.839,p=0.830),  time:43.498, tt:1087.456\n",
      "Ep:25, loss:0.00011, loss_test:0.08667, lr:1.00e-02, fs:0.85207 (r=0.828,p=0.878),  time:43.432, tt:1129.238\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00010, loss_test:0.08533, lr:1.00e-02, fs:0.85207 (r=0.828,p=0.878),  time:43.469, tt:1173.668\n",
      "Ep:27, loss:0.00010, loss_test:0.08567, lr:1.00e-02, fs:0.85030 (r=0.816,p=0.887),  time:43.446, tt:1216.495\n",
      "Ep:28, loss:0.00010, loss_test:0.08551, lr:1.00e-02, fs:0.87059 (r=0.851,p=0.892),  time:43.481, tt:1260.963\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00009, loss_test:0.08651, lr:1.00e-02, fs:0.84146 (r=0.793,p=0.896),  time:43.466, tt:1303.986\n",
      "Ep:30, loss:0.00009, loss_test:0.08426, lr:1.00e-02, fs:0.87356 (r=0.874,p=0.874),  time:43.449, tt:1346.916\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00009, loss_test:0.08785, lr:1.00e-02, fs:0.79747 (r=0.724,p=0.887),  time:43.432, tt:1389.812\n",
      "Ep:32, loss:0.00008, loss_test:0.08350, lr:1.00e-02, fs:0.86705 (r=0.862,p=0.872),  time:43.463, tt:1434.290\n",
      "Ep:33, loss:0.00008, loss_test:0.08554, lr:1.00e-02, fs:0.84146 (r=0.793,p=0.896),  time:43.448, tt:1477.241\n",
      "Ep:34, loss:0.00007, loss_test:0.08430, lr:1.00e-02, fs:0.84848 (r=0.805,p=0.897),  time:43.445, tt:1520.567\n",
      "Ep:35, loss:0.00007, loss_test:0.08689, lr:1.00e-02, fs:0.83436 (r=0.782,p=0.895),  time:43.439, tt:1563.806\n",
      "Ep:36, loss:0.00007, loss_test:0.08270, lr:1.00e-02, fs:0.88372 (r=0.874,p=0.894),  time:43.431, tt:1606.953\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00007, loss_test:0.08723, lr:1.00e-02, fs:0.81988 (r=0.759,p=0.892),  time:43.396, tt:1649.048\n",
      "Ep:38, loss:0.00006, loss_test:0.08350, lr:1.00e-02, fs:0.86391 (r=0.839,p=0.890),  time:43.459, tt:1694.916\n",
      "Ep:39, loss:0.00006, loss_test:0.08723, lr:1.00e-02, fs:0.82278 (r=0.747,p=0.915),  time:43.468, tt:1738.723\n",
      "Ep:40, loss:0.00006, loss_test:0.08464, lr:1.00e-02, fs:0.85030 (r=0.816,p=0.887),  time:43.457, tt:1781.737\n",
      "Ep:41, loss:0.00006, loss_test:0.08603, lr:1.00e-02, fs:0.82051 (r=0.736,p=0.928),  time:43.427, tt:1823.929\n",
      "Ep:42, loss:0.00005, loss_test:0.08405, lr:1.00e-02, fs:0.82500 (r=0.759,p=0.904),  time:43.446, tt:1868.194\n",
      "Ep:43, loss:0.00005, loss_test:0.08646, lr:1.00e-02, fs:0.80519 (r=0.713,p=0.925),  time:43.448, tt:1911.717\n",
      "Ep:44, loss:0.00005, loss_test:0.08519, lr:1.00e-02, fs:0.80769 (r=0.724,p=0.913),  time:43.440, tt:1954.816\n",
      "Ep:45, loss:0.00005, loss_test:0.08568, lr:1.00e-02, fs:0.80000 (r=0.713,p=0.912),  time:43.444, tt:1998.428\n",
      "Ep:46, loss:0.00004, loss_test:0.08421, lr:1.00e-02, fs:0.77333 (r=0.667,p=0.921),  time:43.466, tt:2042.882\n",
      "Ep:47, loss:0.00004, loss_test:0.08601, lr:1.00e-02, fs:0.76821 (r=0.667,p=0.906),  time:43.425, tt:2084.381\n",
      "Ep:48, loss:0.00004, loss_test:0.08732, lr:9.90e-03, fs:0.76316 (r=0.667,p=0.892),  time:43.433, tt:2128.212\n",
      "Ep:49, loss:0.00004, loss_test:0.08670, lr:9.80e-03, fs:0.76000 (r=0.655,p=0.905),  time:43.447, tt:2172.350\n",
      "Ep:50, loss:0.00003, loss_test:0.08663, lr:9.70e-03, fs:0.75497 (r=0.655,p=0.891),  time:43.432, tt:2215.057\n",
      "Ep:51, loss:0.00003, loss_test:0.08871, lr:9.61e-03, fs:0.75497 (r=0.655,p=0.891),  time:43.446, tt:2259.182\n",
      "Ep:52, loss:0.00003, loss_test:0.09204, lr:9.51e-03, fs:0.76510 (r=0.655,p=0.919),  time:43.456, tt:2303.157\n",
      "Ep:53, loss:0.00003, loss_test:0.08709, lr:9.41e-03, fs:0.75497 (r=0.655,p=0.891),  time:43.472, tt:2347.508\n",
      "Ep:54, loss:0.00003, loss_test:0.09314, lr:9.32e-03, fs:0.75676 (r=0.644,p=0.918),  time:43.440, tt:2389.203\n",
      "Ep:55, loss:0.00003, loss_test:0.08792, lr:9.23e-03, fs:0.76000 (r=0.655,p=0.905),  time:43.454, tt:2433.422\n",
      "Ep:56, loss:0.00003, loss_test:0.09288, lr:9.14e-03, fs:0.77027 (r=0.655,p=0.934),  time:43.469, tt:2477.726\n",
      "Ep:57, loss:0.00003, loss_test:0.09249, lr:9.04e-03, fs:0.76510 (r=0.655,p=0.919),  time:43.445, tt:2519.812\n",
      "Ep:58, loss:0.00003, loss_test:0.09082, lr:8.95e-03, fs:0.76510 (r=0.655,p=0.919),  time:43.409, tt:2561.107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00003, loss_test:0.09602, lr:8.86e-03, fs:0.77551 (r=0.655,p=0.950),  time:43.394, tt:2603.633\n",
      "Ep:60, loss:0.00002, loss_test:0.08676, lr:8.78e-03, fs:0.75497 (r=0.655,p=0.891),  time:43.359, tt:2644.902\n",
      "Ep:61, loss:0.00002, loss_test:0.09638, lr:8.69e-03, fs:0.77551 (r=0.655,p=0.950),  time:43.344, tt:2687.359\n",
      "Ep:62, loss:0.00002, loss_test:0.09153, lr:8.60e-03, fs:0.76000 (r=0.655,p=0.905),  time:43.324, tt:2729.407\n",
      "Ep:63, loss:0.00002, loss_test:0.09421, lr:8.51e-03, fs:0.76510 (r=0.655,p=0.919),  time:43.315, tt:2772.175\n",
      "Ep:64, loss:0.00002, loss_test:0.09335, lr:8.43e-03, fs:0.77027 (r=0.655,p=0.934),  time:43.346, tt:2817.491\n",
      "Ep:65, loss:0.00002, loss_test:0.09172, lr:8.35e-03, fs:0.76000 (r=0.655,p=0.905),  time:43.333, tt:2860.006\n",
      "Ep:66, loss:0.00002, loss_test:0.09777, lr:8.26e-03, fs:0.77551 (r=0.655,p=0.950),  time:43.334, tt:2903.406\n",
      "Ep:67, loss:0.00002, loss_test:0.09118, lr:8.18e-03, fs:0.75497 (r=0.655,p=0.891),  time:43.329, tt:2946.365\n",
      "Ep:68, loss:0.00002, loss_test:0.09624, lr:8.10e-03, fs:0.77027 (r=0.655,p=0.934),  time:43.325, tt:2989.460\n",
      "Ep:69, loss:0.00002, loss_test:0.09334, lr:8.02e-03, fs:0.76000 (r=0.655,p=0.905),  time:43.328, tt:3032.955\n",
      "Ep:70, loss:0.00002, loss_test:0.09234, lr:7.94e-03, fs:0.75497 (r=0.655,p=0.891),  time:43.326, tt:3076.173\n",
      "Ep:71, loss:0.00002, loss_test:0.09575, lr:7.86e-03, fs:0.76510 (r=0.655,p=0.919),  time:43.339, tt:3120.375\n",
      "Ep:72, loss:0.00002, loss_test:0.09406, lr:7.78e-03, fs:0.75497 (r=0.655,p=0.891),  time:43.338, tt:3163.704\n",
      "Ep:73, loss:0.00002, loss_test:0.09506, lr:7.70e-03, fs:0.76000 (r=0.655,p=0.905),  time:43.363, tt:3208.859\n",
      "Ep:74, loss:0.00002, loss_test:0.09859, lr:7.62e-03, fs:0.77551 (r=0.655,p=0.950),  time:43.337, tt:3250.294\n",
      "Ep:75, loss:0.00002, loss_test:0.09391, lr:7.55e-03, fs:0.75497 (r=0.655,p=0.891),  time:43.406, tt:3298.841\n",
      "Ep:76, loss:0.00001, loss_test:0.09761, lr:7.47e-03, fs:0.77551 (r=0.655,p=0.950),  time:43.397, tt:3341.533\n",
      "Ep:77, loss:0.00001, loss_test:0.09491, lr:7.40e-03, fs:0.76000 (r=0.655,p=0.905),  time:43.416, tt:3386.468\n",
      "Ep:78, loss:0.00001, loss_test:0.09525, lr:7.32e-03, fs:0.77027 (r=0.655,p=0.934),  time:43.430, tt:3430.955\n",
      "Ep:79, loss:0.00001, loss_test:0.09682, lr:7.25e-03, fs:0.76000 (r=0.655,p=0.905),  time:43.428, tt:3474.212\n",
      "Ep:80, loss:0.00001, loss_test:0.09507, lr:7.18e-03, fs:0.76000 (r=0.655,p=0.905),  time:43.424, tt:3517.359\n",
      "Ep:81, loss:0.00001, loss_test:0.09606, lr:7.11e-03, fs:0.76000 (r=0.655,p=0.905),  time:43.442, tt:3562.238\n",
      "Ep:82, loss:0.00001, loss_test:0.09724, lr:7.03e-03, fs:0.77551 (r=0.655,p=0.950),  time:43.450, tt:3606.374\n",
      "Ep:83, loss:0.00001, loss_test:0.09550, lr:6.96e-03, fs:0.75497 (r=0.655,p=0.891),  time:43.473, tt:3651.700\n",
      "Ep:84, loss:0.00001, loss_test:0.09602, lr:6.89e-03, fs:0.76000 (r=0.655,p=0.905),  time:43.454, tt:3693.589\n",
      "Ep:85, loss:0.00001, loss_test:0.09762, lr:6.83e-03, fs:0.76510 (r=0.655,p=0.919),  time:43.467, tt:3738.202\n",
      "Ep:86, loss:0.00001, loss_test:0.09694, lr:6.76e-03, fs:0.75497 (r=0.655,p=0.891),  time:43.462, tt:3781.181\n",
      "Ep:87, loss:0.00001, loss_test:0.09687, lr:6.69e-03, fs:0.75497 (r=0.655,p=0.891),  time:43.467, tt:3825.101\n",
      "Ep:88, loss:0.00001, loss_test:0.09745, lr:6.62e-03, fs:0.76510 (r=0.655,p=0.919),  time:43.475, tt:3869.250\n",
      "Ep:89, loss:0.00001, loss_test:0.09839, lr:6.56e-03, fs:0.76510 (r=0.655,p=0.919),  time:43.492, tt:3914.294\n",
      "Ep:90, loss:0.00001, loss_test:0.09712, lr:6.49e-03, fs:0.75497 (r=0.655,p=0.891),  time:43.492, tt:3957.816\n",
      "Ep:91, loss:0.00001, loss_test:0.09948, lr:6.43e-03, fs:0.77027 (r=0.655,p=0.934),  time:43.486, tt:4000.689\n",
      "Ep:92, loss:0.00001, loss_test:0.09843, lr:6.36e-03, fs:0.77027 (r=0.655,p=0.934),  time:43.492, tt:4044.759\n",
      "Ep:93, loss:0.00001, loss_test:0.09753, lr:6.30e-03, fs:0.76000 (r=0.655,p=0.905),  time:43.504, tt:4089.363\n",
      "Ep:94, loss:0.00001, loss_test:0.09932, lr:6.24e-03, fs:0.77027 (r=0.655,p=0.934),  time:43.496, tt:4132.138\n",
      "Ep:95, loss:0.00001, loss_test:0.09839, lr:6.17e-03, fs:0.76510 (r=0.655,p=0.919),  time:43.555, tt:4181.277\n",
      "Ep:96, loss:0.00001, loss_test:0.09933, lr:6.11e-03, fs:0.77027 (r=0.655,p=0.934),  time:43.557, tt:4224.984\n",
      "Ep:97, loss:0.00001, loss_test:0.09881, lr:6.05e-03, fs:0.76510 (r=0.655,p=0.919),  time:43.549, tt:4267.775\n",
      "Ep:98, loss:0.00001, loss_test:0.09938, lr:5.99e-03, fs:0.75342 (r=0.632,p=0.932),  time:43.536, tt:4310.028\n",
      "Ep:99, loss:0.00001, loss_test:0.09975, lr:5.93e-03, fs:0.76510 (r=0.655,p=0.919),  time:43.515, tt:4351.475\n",
      "Ep:100, loss:0.00001, loss_test:0.09943, lr:5.87e-03, fs:0.76510 (r=0.655,p=0.919),  time:43.493, tt:4392.814\n",
      "Ep:101, loss:0.00001, loss_test:0.09982, lr:5.81e-03, fs:0.75342 (r=0.632,p=0.932),  time:43.481, tt:4435.103\n",
      "Ep:102, loss:0.00001, loss_test:0.09888, lr:5.75e-03, fs:0.76000 (r=0.655,p=0.905),  time:43.466, tt:4476.993\n",
      "Ep:103, loss:0.00001, loss_test:0.10117, lr:5.70e-03, fs:0.74483 (r=0.621,p=0.931),  time:43.460, tt:4519.795\n",
      "Ep:104, loss:0.00001, loss_test:0.10000, lr:5.64e-03, fs:0.75676 (r=0.644,p=0.918),  time:43.434, tt:4560.566\n",
      "Ep:105, loss:0.00001, loss_test:0.10089, lr:5.58e-03, fs:0.71831 (r=0.586,p=0.927),  time:43.416, tt:4602.056\n",
      "Ep:106, loss:0.00001, loss_test:0.10124, lr:5.53e-03, fs:0.71831 (r=0.586,p=0.927),  time:43.398, tt:4643.576\n",
      "Ep:107, loss:0.00001, loss_test:0.09946, lr:5.47e-03, fs:0.76510 (r=0.655,p=0.919),  time:43.385, tt:4685.544\n",
      "Ep:108, loss:0.00001, loss_test:0.10177, lr:5.42e-03, fs:0.70922 (r=0.575,p=0.926),  time:43.387, tt:4729.208\n",
      "Ep:109, loss:0.00001, loss_test:0.10111, lr:5.36e-03, fs:0.69504 (r=0.563,p=0.907),  time:43.374, tt:4771.112\n",
      "Ep:110, loss:0.00001, loss_test:0.10061, lr:5.31e-03, fs:0.75676 (r=0.644,p=0.918),  time:43.361, tt:4813.102\n",
      "Ep:111, loss:0.00001, loss_test:0.10127, lr:5.26e-03, fs:0.68571 (r=0.552,p=0.906),  time:43.351, tt:4855.356\n",
      "Ep:112, loss:0.00001, loss_test:0.10159, lr:5.20e-03, fs:0.67626 (r=0.540,p=0.904),  time:43.340, tt:4897.378\n",
      "Ep:113, loss:0.00001, loss_test:0.10075, lr:5.15e-03, fs:0.74830 (r=0.632,p=0.917),  time:43.317, tt:4938.121\n",
      "Ep:114, loss:0.00001, loss_test:0.10154, lr:5.10e-03, fs:0.68116 (r=0.540,p=0.922),  time:43.305, tt:4980.048\n",
      "Ep:115, loss:0.00001, loss_test:0.10169, lr:5.05e-03, fs:0.69504 (r=0.563,p=0.907),  time:43.347, tt:5028.243\n",
      "Ep:116, loss:0.00001, loss_test:0.10085, lr:5.00e-03, fs:0.71329 (r=0.586,p=0.911),  time:43.332, tt:5069.858\n",
      "Ep:117, loss:0.00001, loss_test:0.10212, lr:4.95e-03, fs:0.69065 (r=0.552,p=0.923),  time:43.321, tt:5111.851\n",
      "Ep:118, loss:0.00001, loss_test:0.10122, lr:4.90e-03, fs:0.69504 (r=0.563,p=0.907),  time:43.296, tt:5152.230\n",
      "Ep:119, loss:0.00001, loss_test:0.10194, lr:4.85e-03, fs:0.67626 (r=0.540,p=0.904),  time:43.284, tt:5194.101\n",
      "Ep:120, loss:0.00001, loss_test:0.10178, lr:4.80e-03, fs:0.67626 (r=0.540,p=0.904),  time:43.264, tt:5235.000\n",
      "Ep:121, loss:0.00001, loss_test:0.10176, lr:4.75e-03, fs:0.68571 (r=0.552,p=0.906),  time:43.246, tt:5276.062\n",
      "Ep:122, loss:0.00001, loss_test:0.10258, lr:4.71e-03, fs:0.67626 (r=0.540,p=0.904),  time:43.235, tt:5317.861\n",
      "Ep:123, loss:0.00001, loss_test:0.10182, lr:4.66e-03, fs:0.67626 (r=0.540,p=0.904),  time:43.221, tt:5359.447\n",
      "Ep:124, loss:0.00001, loss_test:0.10183, lr:4.61e-03, fs:0.67626 (r=0.540,p=0.904),  time:43.212, tt:5401.515\n",
      "Ep:125, loss:0.00001, loss_test:0.10263, lr:4.57e-03, fs:0.67626 (r=0.540,p=0.904),  time:43.195, tt:5442.594\n",
      "Ep:126, loss:0.00001, loss_test:0.10265, lr:4.52e-03, fs:0.67626 (r=0.540,p=0.904),  time:43.184, tt:5484.304\n",
      "Ep:127, loss:0.00001, loss_test:0.10226, lr:4.48e-03, fs:0.67626 (r=0.540,p=0.904),  time:43.175, tt:5526.387\n",
      "Ep:128, loss:0.00001, loss_test:0.10213, lr:4.43e-03, fs:0.67626 (r=0.540,p=0.904),  time:43.172, tt:5569.150\n",
      "Ep:129, loss:0.00001, loss_test:0.10324, lr:4.39e-03, fs:0.68116 (r=0.540,p=0.922),  time:43.167, tt:5611.721\n",
      "Ep:130, loss:0.00001, loss_test:0.10326, lr:4.34e-03, fs:0.68116 (r=0.540,p=0.922),  time:43.167, tt:5654.816\n",
      "Ep:131, loss:0.00001, loss_test:0.10159, lr:4.30e-03, fs:0.67626 (r=0.540,p=0.904),  time:43.162, tt:5697.371\n",
      "Ep:132, loss:0.00001, loss_test:0.10365, lr:4.26e-03, fs:0.68116 (r=0.540,p=0.922),  time:43.166, tt:5741.111\n",
      "Ep:133, loss:0.00001, loss_test:0.10403, lr:4.21e-03, fs:0.67626 (r=0.540,p=0.904),  time:43.139, tt:5780.571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00001, loss_test:0.10246, lr:4.17e-03, fs:0.67626 (r=0.540,p=0.904),  time:43.124, tt:5821.785\n",
      "Ep:135, loss:0.00001, loss_test:0.10328, lr:4.13e-03, fs:0.67626 (r=0.540,p=0.904),  time:43.119, tt:5864.196\n",
      "Ep:136, loss:0.00001, loss_test:0.10387, lr:4.09e-03, fs:0.68116 (r=0.540,p=0.922),  time:43.111, tt:5906.187\n",
      "Ep:137, loss:0.00001, loss_test:0.10349, lr:4.05e-03, fs:0.67626 (r=0.540,p=0.904),  time:43.109, tt:5949.058\n",
      "Ep:138, loss:0.00001, loss_test:0.10283, lr:4.01e-03, fs:0.67626 (r=0.540,p=0.904),  time:43.099, tt:5990.748\n",
      "Ep:139, loss:0.00001, loss_test:0.10347, lr:3.97e-03, fs:0.68116 (r=0.540,p=0.922),  time:43.097, tt:6033.620\n",
      "Ep:140, loss:0.00001, loss_test:0.10414, lr:3.93e-03, fs:0.68116 (r=0.540,p=0.922),  time:43.091, tt:6075.788\n",
      "Ep:141, loss:0.00000, loss_test:0.10378, lr:3.89e-03, fs:0.67626 (r=0.540,p=0.904),  time:43.070, tt:6115.945\n",
      "Ep:142, loss:0.00000, loss_test:0.10386, lr:3.85e-03, fs:0.67626 (r=0.540,p=0.904),  time:43.064, tt:6158.084\n",
      "Ep:143, loss:0.00000, loss_test:0.10415, lr:3.81e-03, fs:0.68116 (r=0.540,p=0.922),  time:43.045, tt:6198.523\n",
      "Ep:144, loss:0.00000, loss_test:0.10429, lr:3.77e-03, fs:0.68116 (r=0.540,p=0.922),  time:43.027, tt:6238.896\n",
      "Ep:145, loss:0.00000, loss_test:0.10369, lr:3.73e-03, fs:0.67626 (r=0.540,p=0.904),  time:43.012, tt:6279.707\n",
      "Ep:146, loss:0.00000, loss_test:0.10447, lr:3.70e-03, fs:0.68116 (r=0.540,p=0.922),  time:43.003, tt:6321.410\n",
      "Ep:147, loss:0.00000, loss_test:0.10428, lr:3.66e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.984, tt:6361.686\n",
      "Ep:148, loss:0.00000, loss_test:0.10429, lr:3.62e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.960, tt:6401.048\n",
      "Ep:149, loss:0.00000, loss_test:0.10428, lr:3.59e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.954, tt:6443.168\n",
      "Ep:150, loss:0.00000, loss_test:0.10450, lr:3.55e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.939, tt:6483.735\n",
      "Ep:151, loss:0.00000, loss_test:0.10433, lr:3.52e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.935, tt:6526.107\n",
      "Ep:152, loss:0.00000, loss_test:0.10468, lr:3.48e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.910, tt:6565.198\n",
      "Ep:153, loss:0.00000, loss_test:0.10459, lr:3.45e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.897, tt:6606.148\n",
      "Ep:154, loss:0.00000, loss_test:0.10468, lr:3.41e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.884, tt:6647.063\n",
      "Ep:155, loss:0.00000, loss_test:0.10479, lr:3.38e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.879, tt:6689.197\n",
      "Ep:156, loss:0.00000, loss_test:0.10490, lr:3.34e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.865, tt:6729.812\n",
      "Ep:157, loss:0.00000, loss_test:0.10520, lr:3.31e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.845, tt:6769.514\n",
      "Ep:158, loss:0.00000, loss_test:0.10500, lr:3.28e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.846, tt:6812.561\n",
      "Ep:159, loss:0.00000, loss_test:0.10569, lr:3.24e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.839, tt:6854.281\n",
      "Ep:160, loss:0.00000, loss_test:0.10552, lr:3.21e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.826, tt:6895.058\n",
      "Ep:161, loss:0.00000, loss_test:0.10505, lr:3.18e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.814, tt:6935.861\n",
      "Ep:162, loss:0.00000, loss_test:0.10521, lr:3.15e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.804, tt:6977.068\n",
      "Ep:163, loss:0.00000, loss_test:0.10590, lr:3.12e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.786, tt:7016.945\n",
      "Ep:164, loss:0.00000, loss_test:0.10605, lr:3.09e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.769, tt:7056.825\n",
      "Ep:165, loss:0.00000, loss_test:0.10557, lr:3.05e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.758, tt:7097.868\n",
      "Ep:166, loss:0.00000, loss_test:0.10589, lr:3.02e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.746, tt:7138.627\n",
      "Ep:167, loss:0.00000, loss_test:0.10599, lr:2.99e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.767, tt:7184.933\n",
      "Ep:168, loss:0.00000, loss_test:0.10615, lr:2.96e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.759, tt:7226.216\n",
      "Ep:169, loss:0.00000, loss_test:0.10629, lr:2.93e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.735, tt:7265.024\n",
      "Ep:170, loss:0.00000, loss_test:0.10621, lr:2.90e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.714, tt:7304.040\n",
      "Ep:171, loss:0.00000, loss_test:0.10648, lr:2.88e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.707, tt:7345.562\n",
      "Ep:172, loss:0.00000, loss_test:0.10643, lr:2.85e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.694, tt:7385.990\n",
      "Ep:173, loss:0.00000, loss_test:0.10648, lr:2.82e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.690, tt:7428.109\n",
      "Ep:174, loss:0.00000, loss_test:0.10672, lr:2.79e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.674, tt:7468.000\n",
      "Ep:175, loss:0.00000, loss_test:0.10679, lr:2.76e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.668, tt:7509.619\n",
      "Ep:176, loss:0.00000, loss_test:0.10682, lr:2.73e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.657, tt:7550.357\n",
      "Ep:177, loss:0.00000, loss_test:0.10697, lr:2.71e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.664, tt:7594.108\n",
      "Ep:178, loss:0.00000, loss_test:0.10687, lr:2.68e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.662, tt:7636.571\n",
      "Ep:179, loss:0.00000, loss_test:0.10677, lr:2.65e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.650, tt:7677.079\n",
      "Ep:180, loss:0.00000, loss_test:0.10704, lr:2.63e-03, fs:0.68613 (r=0.540,p=0.940),  time:42.643, tt:7718.463\n",
      "Ep:181, loss:0.00000, loss_test:0.10751, lr:2.60e-03, fs:0.68613 (r=0.540,p=0.940),  time:42.634, tt:7759.341\n",
      "Ep:182, loss:0.00000, loss_test:0.10706, lr:2.57e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.631, tt:7801.537\n",
      "Ep:183, loss:0.00000, loss_test:0.10692, lr:2.55e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.633, tt:7844.515\n",
      "Ep:184, loss:0.00000, loss_test:0.10702, lr:2.52e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.631, tt:7886.695\n",
      "Ep:185, loss:0.00000, loss_test:0.10766, lr:2.50e-03, fs:0.68613 (r=0.540,p=0.940),  time:42.629, tt:7929.015\n",
      "Ep:186, loss:0.00000, loss_test:0.10756, lr:2.47e-03, fs:0.68613 (r=0.540,p=0.940),  time:42.637, tt:7973.177\n",
      "Ep:187, loss:0.00000, loss_test:0.10712, lr:2.45e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.632, tt:8014.748\n",
      "Ep:188, loss:0.00000, loss_test:0.10698, lr:2.42e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.630, tt:8057.099\n",
      "Ep:189, loss:0.00000, loss_test:0.10756, lr:2.40e-03, fs:0.68613 (r=0.540,p=0.940),  time:42.624, tt:8098.471\n",
      "Ep:190, loss:0.00000, loss_test:0.10761, lr:2.38e-03, fs:0.68613 (r=0.540,p=0.940),  time:42.630, tt:8142.245\n",
      "Ep:191, loss:0.00000, loss_test:0.10758, lr:2.35e-03, fs:0.68613 (r=0.540,p=0.940),  time:42.628, tt:8184.492\n",
      "Ep:192, loss:0.00000, loss_test:0.10767, lr:2.33e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.625, tt:8226.543\n",
      "Ep:193, loss:0.00000, loss_test:0.10786, lr:2.31e-03, fs:0.68613 (r=0.540,p=0.940),  time:42.632, tt:8270.538\n",
      "Ep:194, loss:0.00000, loss_test:0.10802, lr:2.28e-03, fs:0.68613 (r=0.540,p=0.940),  time:42.634, tt:8313.621\n",
      "Ep:195, loss:0.00000, loss_test:0.10808, lr:2.26e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.627, tt:8354.987\n",
      "Ep:196, loss:0.00000, loss_test:0.10797, lr:2.24e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.628, tt:8397.762\n",
      "Ep:197, loss:0.00000, loss_test:0.10823, lr:2.21e-03, fs:0.68613 (r=0.540,p=0.940),  time:42.617, tt:8438.249\n",
      "Ep:198, loss:0.00000, loss_test:0.10820, lr:2.19e-03, fs:0.69118 (r=0.540,p=0.959),  time:42.621, tt:8481.489\n",
      "Ep:199, loss:0.00000, loss_test:0.10785, lr:2.17e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.616, tt:8523.171\n",
      "Ep:200, loss:0.00000, loss_test:0.10796, lr:2.15e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.621, tt:8566.882\n",
      "Ep:201, loss:0.00000, loss_test:0.10822, lr:2.13e-03, fs:0.68613 (r=0.540,p=0.940),  time:42.619, tt:8609.076\n",
      "Ep:202, loss:0.00000, loss_test:0.10811, lr:2.11e-03, fs:0.69118 (r=0.540,p=0.959),  time:42.611, tt:8649.978\n",
      "Ep:203, loss:0.00000, loss_test:0.10785, lr:2.08e-03, fs:0.68613 (r=0.540,p=0.940),  time:42.614, tt:8693.177\n",
      "Ep:204, loss:0.00000, loss_test:0.10777, lr:2.06e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.625, tt:8738.194\n",
      "Ep:205, loss:0.00000, loss_test:0.10811, lr:2.04e-03, fs:0.68613 (r=0.540,p=0.940),  time:42.633, tt:8782.376\n",
      "Ep:206, loss:0.00000, loss_test:0.10837, lr:2.02e-03, fs:0.68613 (r=0.540,p=0.940),  time:42.627, tt:8823.786\n",
      "Ep:207, loss:0.00000, loss_test:0.10847, lr:2.00e-03, fs:0.69118 (r=0.540,p=0.959),  time:42.633, tt:8867.600\n",
      "Ep:208, loss:0.00000, loss_test:0.10839, lr:1.98e-03, fs:0.69118 (r=0.540,p=0.959),  time:42.614, tt:8906.424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:209, loss:0.00000, loss_test:0.10819, lr:1.96e-03, fs:0.68613 (r=0.540,p=0.940),  time:42.601, tt:8946.195\n",
      "Ep:210, loss:0.00000, loss_test:0.10820, lr:1.94e-03, fs:0.68613 (r=0.540,p=0.940),  time:42.573, tt:8982.846\n",
      "Ep:211, loss:0.00000, loss_test:0.10843, lr:1.92e-03, fs:0.69118 (r=0.540,p=0.959),  time:42.509, tt:9011.961\n",
      "Ep:212, loss:0.00000, loss_test:0.10867, lr:1.90e-03, fs:0.69118 (r=0.540,p=0.959),  time:42.445, tt:9040.801\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02013, lr:6.00e-02, fs:0.64865 (r=0.828,p=0.533),  time:36.971, tt:36.971\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02165, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.294, tt:78.588\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02232, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.956, tt:119.869\n",
      "Ep:3, loss:0.00004, loss_test:0.02154, lr:6.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:40.811, tt:163.243\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.02021, lr:6.00e-02, fs:0.67188 (r=0.989,p=0.509),  time:40.495, tt:202.476\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.01940, lr:6.00e-02, fs:0.69198 (r=0.943,p=0.547),  time:40.688, tt:244.125\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01928, lr:6.00e-02, fs:0.67907 (r=0.839,p=0.570),  time:40.311, tt:282.175\n",
      "Ep:7, loss:0.00004, loss_test:0.01921, lr:6.00e-02, fs:0.68868 (r=0.839,p=0.584),  time:40.394, tt:323.155\n",
      "Ep:8, loss:0.00004, loss_test:0.01890, lr:6.00e-02, fs:0.68868 (r=0.839,p=0.584),  time:40.513, tt:364.614\n",
      "Ep:9, loss:0.00003, loss_test:0.01873, lr:6.00e-02, fs:0.70320 (r=0.885,p=0.583),  time:40.521, tt:405.209\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01860, lr:6.00e-02, fs:0.71233 (r=0.897,p=0.591),  time:40.427, tt:444.697\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01837, lr:6.00e-02, fs:0.72477 (r=0.908,p=0.603),  time:40.463, tt:485.554\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01807, lr:6.00e-02, fs:0.72222 (r=0.897,p=0.605),  time:40.527, tt:526.846\n",
      "Ep:13, loss:0.00003, loss_test:0.01778, lr:6.00e-02, fs:0.74757 (r=0.885,p=0.647),  time:40.577, tt:568.081\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01745, lr:6.00e-02, fs:0.74627 (r=0.862,p=0.658),  time:40.535, tt:608.028\n",
      "Ep:15, loss:0.00003, loss_test:0.01703, lr:6.00e-02, fs:0.76471 (r=0.897,p=0.667),  time:40.613, tt:649.810\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01662, lr:6.00e-02, fs:0.76699 (r=0.908,p=0.664),  time:40.552, tt:689.387\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01633, lr:6.00e-02, fs:0.77670 (r=0.920,p=0.672),  time:40.561, tt:730.097\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01615, lr:6.00e-02, fs:0.77670 (r=0.920,p=0.672),  time:40.644, tt:772.236\n",
      "Ep:19, loss:0.00003, loss_test:0.01602, lr:6.00e-02, fs:0.78818 (r=0.920,p=0.690),  time:40.653, tt:813.055\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01596, lr:6.00e-02, fs:0.80000 (r=0.920,p=0.708),  time:40.641, tt:853.464\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01589, lr:6.00e-02, fs:0.80000 (r=0.920,p=0.708),  time:40.699, tt:895.389\n",
      "Ep:22, loss:0.00002, loss_test:0.01575, lr:6.00e-02, fs:0.82587 (r=0.954,p=0.728),  time:40.812, tt:938.673\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01561, lr:6.00e-02, fs:0.83168 (r=0.966,p=0.730),  time:40.763, tt:978.314\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01551, lr:6.00e-02, fs:0.83168 (r=0.966,p=0.730),  time:40.676, tt:1016.891\n",
      "Ep:25, loss:0.00002, loss_test:0.01542, lr:6.00e-02, fs:0.83582 (r=0.966,p=0.737),  time:40.638, tt:1056.586\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01530, lr:6.00e-02, fs:0.83582 (r=0.966,p=0.737),  time:40.632, tt:1097.059\n",
      "Ep:27, loss:0.00002, loss_test:0.01522, lr:6.00e-02, fs:0.80612 (r=0.908,p=0.725),  time:40.596, tt:1136.683\n",
      "Ep:28, loss:0.00002, loss_test:0.01519, lr:6.00e-02, fs:0.78125 (r=0.862,p=0.714),  time:40.613, tt:1177.785\n",
      "Ep:29, loss:0.00002, loss_test:0.01520, lr:6.00e-02, fs:0.78947 (r=0.862,p=0.728),  time:40.659, tt:1219.757\n",
      "Ep:30, loss:0.00002, loss_test:0.01521, lr:6.00e-02, fs:0.79365 (r=0.862,p=0.735),  time:40.670, tt:1260.771\n",
      "Ep:31, loss:0.00002, loss_test:0.01519, lr:6.00e-02, fs:0.79365 (r=0.862,p=0.735),  time:40.615, tt:1299.683\n",
      "Ep:32, loss:0.00002, loss_test:0.01516, lr:6.00e-02, fs:0.80423 (r=0.874,p=0.745),  time:40.651, tt:1341.482\n",
      "Ep:33, loss:0.00002, loss_test:0.01512, lr:6.00e-02, fs:0.80423 (r=0.874,p=0.745),  time:40.635, tt:1381.606\n",
      "Ep:34, loss:0.00002, loss_test:0.01511, lr:6.00e-02, fs:0.81283 (r=0.874,p=0.760),  time:40.629, tt:1422.004\n",
      "Ep:35, loss:0.00002, loss_test:0.01513, lr:6.00e-02, fs:0.82162 (r=0.874,p=0.776),  time:40.641, tt:1463.071\n",
      "Ep:36, loss:0.00002, loss_test:0.01514, lr:6.00e-02, fs:0.83060 (r=0.874,p=0.792),  time:40.624, tt:1503.091\n",
      "Ep:37, loss:0.00002, loss_test:0.01512, lr:5.94e-02, fs:0.83516 (r=0.874,p=0.800),  time:40.587, tt:1542.306\n",
      "Ep:38, loss:0.00002, loss_test:0.01511, lr:5.88e-02, fs:0.83516 (r=0.874,p=0.800),  time:40.567, tt:1582.101\n",
      "Ep:39, loss:0.00002, loss_test:0.01515, lr:5.82e-02, fs:0.84444 (r=0.874,p=0.817),  time:40.554, tt:1622.144\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01511, lr:5.82e-02, fs:0.83978 (r=0.874,p=0.809),  time:40.564, tt:1663.108\n",
      "Ep:41, loss:0.00002, loss_test:0.01514, lr:5.82e-02, fs:0.83978 (r=0.874,p=0.809),  time:40.530, tt:1702.263\n",
      "Ep:42, loss:0.00002, loss_test:0.01520, lr:5.82e-02, fs:0.83516 (r=0.874,p=0.800),  time:40.512, tt:1742.005\n",
      "Ep:43, loss:0.00002, loss_test:0.01529, lr:5.82e-02, fs:0.83516 (r=0.874,p=0.800),  time:40.549, tt:1784.172\n",
      "Ep:44, loss:0.00002, loss_test:0.01537, lr:5.82e-02, fs:0.83516 (r=0.874,p=0.800),  time:40.572, tt:1825.743\n",
      "Ep:45, loss:0.00001, loss_test:0.01545, lr:5.82e-02, fs:0.83516 (r=0.874,p=0.800),  time:40.560, tt:1865.754\n",
      "Ep:46, loss:0.00001, loss_test:0.01553, lr:5.82e-02, fs:0.83060 (r=0.874,p=0.792),  time:40.545, tt:1905.597\n",
      "Ep:47, loss:0.00001, loss_test:0.01563, lr:5.82e-02, fs:0.83060 (r=0.874,p=0.792),  time:40.539, tt:1945.887\n",
      "Ep:48, loss:0.00001, loss_test:0.01571, lr:5.82e-02, fs:0.83060 (r=0.874,p=0.792),  time:40.559, tt:1987.380\n",
      "Ep:49, loss:0.00001, loss_test:0.01582, lr:5.82e-02, fs:0.83333 (r=0.862,p=0.806),  time:40.576, tt:2028.776\n",
      "Ep:50, loss:0.00001, loss_test:0.01588, lr:5.82e-02, fs:0.83333 (r=0.862,p=0.806),  time:40.573, tt:2069.209\n",
      "Ep:51, loss:0.00001, loss_test:0.01597, lr:5.76e-02, fs:0.82682 (r=0.851,p=0.804),  time:40.579, tt:2110.111\n",
      "Ep:52, loss:0.00001, loss_test:0.01609, lr:5.71e-02, fs:0.82486 (r=0.839,p=0.811),  time:40.584, tt:2150.966\n",
      "Ep:53, loss:0.00001, loss_test:0.01621, lr:5.65e-02, fs:0.81818 (r=0.828,p=0.809),  time:40.567, tt:2190.600\n",
      "Ep:54, loss:0.00001, loss_test:0.01636, lr:5.59e-02, fs:0.80000 (r=0.805,p=0.795),  time:40.566, tt:2231.137\n",
      "Ep:55, loss:0.00001, loss_test:0.01653, lr:5.54e-02, fs:0.80460 (r=0.805,p=0.805),  time:40.591, tt:2273.077\n",
      "Ep:56, loss:0.00001, loss_test:0.01664, lr:5.48e-02, fs:0.80460 (r=0.805,p=0.805),  time:40.582, tt:2313.193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:57, loss:0.00001, loss_test:0.01675, lr:5.43e-02, fs:0.80460 (r=0.805,p=0.805),  time:40.585, tt:2353.948\n",
      "Ep:58, loss:0.00001, loss_test:0.01681, lr:5.37e-02, fs:0.79769 (r=0.793,p=0.802),  time:40.584, tt:2394.439\n",
      "Ep:59, loss:0.00001, loss_test:0.01699, lr:5.32e-02, fs:0.79070 (r=0.782,p=0.800),  time:40.584, tt:2435.031\n",
      "Ep:60, loss:0.00001, loss_test:0.01712, lr:5.27e-02, fs:0.79070 (r=0.782,p=0.800),  time:40.563, tt:2474.314\n",
      "Ep:61, loss:0.00001, loss_test:0.01727, lr:5.21e-02, fs:0.78363 (r=0.770,p=0.798),  time:40.596, tt:2516.926\n",
      "Ep:62, loss:0.00001, loss_test:0.01740, lr:5.16e-02, fs:0.76923 (r=0.747,p=0.793),  time:40.595, tt:2557.468\n",
      "Ep:63, loss:0.00001, loss_test:0.01744, lr:5.11e-02, fs:0.76923 (r=0.747,p=0.793),  time:40.587, tt:2597.539\n",
      "Ep:64, loss:0.00001, loss_test:0.01761, lr:5.06e-02, fs:0.76923 (r=0.747,p=0.793),  time:40.577, tt:2637.487\n",
      "Ep:65, loss:0.00001, loss_test:0.01779, lr:5.01e-02, fs:0.76923 (r=0.747,p=0.793),  time:40.580, tt:2678.253\n",
      "Ep:66, loss:0.00001, loss_test:0.01788, lr:4.96e-02, fs:0.76923 (r=0.747,p=0.793),  time:40.580, tt:2718.831\n",
      "Ep:67, loss:0.00001, loss_test:0.01798, lr:4.91e-02, fs:0.76923 (r=0.747,p=0.793),  time:40.607, tt:2761.291\n",
      "Ep:68, loss:0.00001, loss_test:0.01810, lr:4.86e-02, fs:0.77381 (r=0.747,p=0.802),  time:40.614, tt:2802.348\n",
      "Ep:69, loss:0.00001, loss_test:0.01817, lr:4.81e-02, fs:0.77381 (r=0.747,p=0.802),  time:40.637, tt:2844.584\n",
      "Ep:70, loss:0.00001, loss_test:0.01832, lr:4.76e-02, fs:0.77381 (r=0.747,p=0.802),  time:40.647, tt:2885.906\n",
      "Ep:71, loss:0.00001, loss_test:0.01839, lr:4.71e-02, fs:0.77381 (r=0.747,p=0.802),  time:40.607, tt:2923.709\n",
      "Ep:72, loss:0.00001, loss_test:0.01854, lr:4.67e-02, fs:0.77381 (r=0.747,p=0.802),  time:40.615, tt:2964.900\n",
      "Ep:73, loss:0.00001, loss_test:0.01863, lr:4.62e-02, fs:0.77381 (r=0.747,p=0.802),  time:40.618, tt:3005.768\n",
      "Ep:74, loss:0.00001, loss_test:0.01875, lr:4.57e-02, fs:0.77381 (r=0.747,p=0.802),  time:40.594, tt:3044.587\n",
      "Ep:75, loss:0.00001, loss_test:0.01887, lr:4.53e-02, fs:0.77381 (r=0.747,p=0.802),  time:40.591, tt:3084.934\n",
      "Ep:76, loss:0.00001, loss_test:0.01906, lr:4.48e-02, fs:0.76647 (r=0.736,p=0.800),  time:40.600, tt:3126.188\n",
      "Ep:77, loss:0.00001, loss_test:0.01920, lr:4.44e-02, fs:0.76647 (r=0.736,p=0.800),  time:40.579, tt:3165.180\n",
      "Ep:78, loss:0.00001, loss_test:0.01929, lr:4.39e-02, fs:0.76647 (r=0.736,p=0.800),  time:40.581, tt:3205.904\n",
      "Ep:79, loss:0.00001, loss_test:0.01932, lr:4.35e-02, fs:0.76647 (r=0.736,p=0.800),  time:40.569, tt:3245.534\n",
      "Ep:80, loss:0.00001, loss_test:0.01939, lr:4.31e-02, fs:0.76647 (r=0.736,p=0.800),  time:40.558, tt:3285.170\n",
      "Ep:81, loss:0.00001, loss_test:0.01954, lr:4.26e-02, fs:0.76647 (r=0.736,p=0.800),  time:40.560, tt:3325.961\n",
      "Ep:82, loss:0.00001, loss_test:0.01967, lr:4.22e-02, fs:0.77108 (r=0.736,p=0.810),  time:40.552, tt:3365.778\n",
      "Ep:83, loss:0.00001, loss_test:0.01979, lr:4.18e-02, fs:0.77108 (r=0.736,p=0.810),  time:40.563, tt:3407.329\n",
      "Ep:84, loss:0.00001, loss_test:0.01983, lr:4.14e-02, fs:0.77108 (r=0.736,p=0.810),  time:40.586, tt:3449.852\n",
      "Ep:85, loss:0.00001, loss_test:0.01992, lr:4.10e-02, fs:0.77108 (r=0.736,p=0.810),  time:40.599, tt:3491.528\n",
      "Ep:86, loss:0.00001, loss_test:0.02012, lr:4.05e-02, fs:0.77108 (r=0.736,p=0.810),  time:40.634, tt:3535.167\n",
      "Ep:87, loss:0.00001, loss_test:0.02021, lr:4.01e-02, fs:0.77108 (r=0.736,p=0.810),  time:40.632, tt:3575.589\n",
      "Ep:88, loss:0.00001, loss_test:0.02030, lr:3.97e-02, fs:0.77108 (r=0.736,p=0.810),  time:40.640, tt:3616.993\n",
      "Ep:89, loss:0.00001, loss_test:0.02044, lr:3.93e-02, fs:0.77108 (r=0.736,p=0.810),  time:40.637, tt:3657.329\n",
      "Ep:90, loss:0.00001, loss_test:0.02053, lr:3.89e-02, fs:0.77108 (r=0.736,p=0.810),  time:40.634, tt:3697.672\n",
      "Ep:91, loss:0.00001, loss_test:0.02063, lr:3.86e-02, fs:0.77108 (r=0.736,p=0.810),  time:40.645, tt:3739.356\n",
      "Ep:92, loss:0.00001, loss_test:0.02081, lr:3.82e-02, fs:0.77108 (r=0.736,p=0.810),  time:40.671, tt:3782.440\n",
      "Ep:93, loss:0.00001, loss_test:0.02086, lr:3.78e-02, fs:0.77108 (r=0.736,p=0.810),  time:40.663, tt:3822.347\n",
      "Ep:94, loss:0.00001, loss_test:0.02094, lr:3.74e-02, fs:0.77108 (r=0.736,p=0.810),  time:40.674, tt:3864.019\n",
      "Ep:95, loss:0.00001, loss_test:0.02099, lr:3.70e-02, fs:0.77108 (r=0.736,p=0.810),  time:40.650, tt:3902.392\n",
      "Ep:96, loss:0.00001, loss_test:0.02114, lr:3.67e-02, fs:0.77108 (r=0.736,p=0.810),  time:40.661, tt:3944.107\n",
      "Ep:97, loss:0.00001, loss_test:0.02126, lr:3.63e-02, fs:0.77108 (r=0.736,p=0.810),  time:40.670, tt:3985.652\n",
      "Ep:98, loss:0.00001, loss_test:0.02136, lr:3.59e-02, fs:0.77108 (r=0.736,p=0.810),  time:40.684, tt:4027.755\n",
      "Ep:99, loss:0.00001, loss_test:0.02137, lr:3.56e-02, fs:0.77108 (r=0.736,p=0.810),  time:40.690, tt:4068.958\n",
      "Ep:100, loss:0.00001, loss_test:0.02150, lr:3.52e-02, fs:0.77576 (r=0.736,p=0.821),  time:40.691, tt:4109.748\n",
      "Ep:101, loss:0.00001, loss_test:0.02161, lr:3.49e-02, fs:0.77576 (r=0.736,p=0.821),  time:40.710, tt:4152.383\n",
      "Ep:102, loss:0.00001, loss_test:0.02164, lr:3.45e-02, fs:0.77576 (r=0.736,p=0.821),  time:40.727, tt:4194.893\n",
      "Ep:103, loss:0.00001, loss_test:0.02180, lr:3.42e-02, fs:0.77576 (r=0.736,p=0.821),  time:40.749, tt:4237.870\n",
      "Ep:104, loss:0.00001, loss_test:0.02196, lr:3.38e-02, fs:0.77576 (r=0.736,p=0.821),  time:40.762, tt:4279.970\n",
      "Ep:105, loss:0.00001, loss_test:0.02201, lr:3.35e-02, fs:0.77576 (r=0.736,p=0.821),  time:40.781, tt:4322.735\n",
      "Ep:106, loss:0.00001, loss_test:0.02198, lr:3.32e-02, fs:0.77576 (r=0.736,p=0.821),  time:40.801, tt:4365.707\n",
      "Ep:107, loss:0.00001, loss_test:0.02212, lr:3.28e-02, fs:0.77576 (r=0.736,p=0.821),  time:40.813, tt:4407.819\n",
      "Ep:108, loss:0.00001, loss_test:0.02226, lr:3.25e-02, fs:0.77576 (r=0.736,p=0.821),  time:40.818, tt:4449.165\n",
      "Ep:109, loss:0.00001, loss_test:0.02236, lr:3.22e-02, fs:0.77576 (r=0.736,p=0.821),  time:40.815, tt:4489.661\n",
      "Ep:110, loss:0.00001, loss_test:0.02239, lr:3.19e-02, fs:0.77576 (r=0.736,p=0.821),  time:40.825, tt:4531.616\n",
      "Ep:111, loss:0.00001, loss_test:0.02247, lr:3.15e-02, fs:0.77576 (r=0.736,p=0.821),  time:40.874, tt:4577.919\n",
      "Ep:112, loss:0.00001, loss_test:0.02256, lr:3.12e-02, fs:0.77576 (r=0.736,p=0.821),  time:40.861, tt:4617.271\n",
      "Ep:113, loss:0.00001, loss_test:0.02264, lr:3.09e-02, fs:0.77576 (r=0.736,p=0.821),  time:40.869, tt:4659.042\n",
      "Ep:114, loss:0.00001, loss_test:0.02273, lr:3.06e-02, fs:0.77576 (r=0.736,p=0.821),  time:40.864, tt:4699.394\n",
      "Ep:115, loss:0.00001, loss_test:0.02288, lr:3.03e-02, fs:0.77576 (r=0.736,p=0.821),  time:40.868, tt:4740.714\n",
      "Ep:116, loss:0.00001, loss_test:0.02290, lr:3.00e-02, fs:0.77576 (r=0.736,p=0.821),  time:40.868, tt:4781.580\n",
      "Ep:117, loss:0.00001, loss_test:0.02302, lr:2.97e-02, fs:0.77576 (r=0.736,p=0.821),  time:40.870, tt:4822.651\n",
      "Ep:118, loss:0.00001, loss_test:0.02310, lr:2.94e-02, fs:0.77576 (r=0.736,p=0.821),  time:40.864, tt:4862.849\n",
      "Ep:119, loss:0.00001, loss_test:0.02316, lr:2.91e-02, fs:0.77576 (r=0.736,p=0.821),  time:40.867, tt:4904.025\n",
      "Ep:120, loss:0.00001, loss_test:0.02329, lr:2.88e-02, fs:0.77576 (r=0.736,p=0.821),  time:40.862, tt:4944.328\n",
      "Ep:121, loss:0.00001, loss_test:0.02341, lr:2.85e-02, fs:0.77576 (r=0.736,p=0.821),  time:40.859, tt:4984.775\n",
      "Ep:122, loss:0.00001, loss_test:0.02345, lr:2.82e-02, fs:0.77576 (r=0.736,p=0.821),  time:40.842, tt:5023.541\n",
      "Ep:123, loss:0.00001, loss_test:0.02354, lr:2.80e-02, fs:0.77576 (r=0.736,p=0.821),  time:40.834, tt:5063.390\n",
      "Ep:124, loss:0.00001, loss_test:0.02361, lr:2.77e-02, fs:0.78049 (r=0.736,p=0.831),  time:40.827, tt:5103.344\n",
      "Ep:125, loss:0.00001, loss_test:0.02374, lr:2.74e-02, fs:0.78049 (r=0.736,p=0.831),  time:40.816, tt:5142.870\n",
      "Ep:126, loss:0.00001, loss_test:0.02378, lr:2.71e-02, fs:0.77576 (r=0.736,p=0.821),  time:40.818, tt:5183.842\n",
      "Ep:127, loss:0.00001, loss_test:0.02383, lr:2.69e-02, fs:0.78049 (r=0.736,p=0.831),  time:40.826, tt:5225.717\n",
      "Ep:128, loss:0.00001, loss_test:0.02397, lr:2.66e-02, fs:0.78528 (r=0.736,p=0.842),  time:40.863, tt:5271.311\n",
      "Ep:129, loss:0.00001, loss_test:0.02403, lr:2.63e-02, fs:0.78528 (r=0.736,p=0.842),  time:40.860, tt:5311.754\n",
      "Ep:130, loss:0.00001, loss_test:0.02411, lr:2.61e-02, fs:0.78528 (r=0.736,p=0.842),  time:40.865, tt:5353.290\n",
      "Ep:131, loss:0.00001, loss_test:0.02418, lr:2.58e-02, fs:0.77778 (r=0.724,p=0.840),  time:40.867, tt:5394.397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00001, loss_test:0.02419, lr:2.55e-02, fs:0.77778 (r=0.724,p=0.840),  time:40.861, tt:5434.547\n",
      "Ep:133, loss:0.00001, loss_test:0.02423, lr:2.53e-02, fs:0.78528 (r=0.736,p=0.842),  time:40.867, tt:5476.189\n",
      "Ep:134, loss:0.00000, loss_test:0.02436, lr:2.50e-02, fs:0.77778 (r=0.724,p=0.840),  time:40.869, tt:5517.324\n",
      "Ep:135, loss:0.00000, loss_test:0.02453, lr:2.48e-02, fs:0.77778 (r=0.724,p=0.840),  time:40.883, tt:5560.047\n",
      "Ep:136, loss:0.00000, loss_test:0.02452, lr:2.45e-02, fs:0.77778 (r=0.724,p=0.840),  time:40.896, tt:5602.768\n",
      "Ep:137, loss:0.00000, loss_test:0.02455, lr:2.43e-02, fs:0.77778 (r=0.724,p=0.840),  time:40.899, tt:5644.116\n",
      "Ep:138, loss:0.00000, loss_test:0.02468, lr:2.40e-02, fs:0.77778 (r=0.724,p=0.840),  time:40.907, tt:5686.090\n",
      "Ep:139, loss:0.00000, loss_test:0.02476, lr:2.38e-02, fs:0.77778 (r=0.724,p=0.840),  time:40.915, tt:5728.146\n",
      "Ep:140, loss:0.00000, loss_test:0.02484, lr:2.36e-02, fs:0.77778 (r=0.724,p=0.840),  time:40.928, tt:5770.880\n",
      "Ep:141, loss:0.00000, loss_test:0.02494, lr:2.33e-02, fs:0.77778 (r=0.724,p=0.840),  time:40.935, tt:5812.841\n",
      "Ep:142, loss:0.00000, loss_test:0.02502, lr:2.31e-02, fs:0.78261 (r=0.724,p=0.851),  time:40.938, tt:5854.081\n",
      "Ep:143, loss:0.00000, loss_test:0.02503, lr:2.29e-02, fs:0.78261 (r=0.724,p=0.851),  time:40.941, tt:5895.568\n",
      "Ep:144, loss:0.00000, loss_test:0.02508, lr:2.26e-02, fs:0.78261 (r=0.724,p=0.851),  time:40.945, tt:5937.043\n",
      "Ep:145, loss:0.00000, loss_test:0.02517, lr:2.24e-02, fs:0.78261 (r=0.724,p=0.851),  time:40.935, tt:5976.558\n",
      "Ep:146, loss:0.00000, loss_test:0.02524, lr:2.22e-02, fs:0.78261 (r=0.724,p=0.851),  time:40.919, tt:6015.140\n",
      "Ep:147, loss:0.00000, loss_test:0.02532, lr:2.20e-02, fs:0.78261 (r=0.724,p=0.851),  time:40.931, tt:6057.795\n",
      "Ep:148, loss:0.00000, loss_test:0.02532, lr:2.17e-02, fs:0.78261 (r=0.724,p=0.851),  time:40.930, tt:6098.609\n",
      "Ep:149, loss:0.00000, loss_test:0.02541, lr:2.15e-02, fs:0.78261 (r=0.724,p=0.851),  time:40.927, tt:6138.995\n",
      "Ep:150, loss:0.00000, loss_test:0.02546, lr:2.13e-02, fs:0.78261 (r=0.724,p=0.851),  time:40.921, tt:6179.064\n",
      "Ep:151, loss:0.00000, loss_test:0.02550, lr:2.11e-02, fs:0.78261 (r=0.724,p=0.851),  time:40.917, tt:6219.383\n",
      "Ep:152, loss:0.00000, loss_test:0.02557, lr:2.09e-02, fs:0.78261 (r=0.724,p=0.851),  time:40.911, tt:6259.431\n",
      "Ep:153, loss:0.00000, loss_test:0.02569, lr:2.07e-02, fs:0.78261 (r=0.724,p=0.851),  time:40.909, tt:6300.021\n",
      "Ep:154, loss:0.00000, loss_test:0.02576, lr:2.05e-02, fs:0.78261 (r=0.724,p=0.851),  time:40.913, tt:6341.504\n",
      "Ep:155, loss:0.00000, loss_test:0.02579, lr:2.03e-02, fs:0.78261 (r=0.724,p=0.851),  time:40.903, tt:6380.934\n",
      "Ep:156, loss:0.00000, loss_test:0.02584, lr:2.01e-02, fs:0.78261 (r=0.724,p=0.851),  time:40.907, tt:6422.348\n",
      "Ep:157, loss:0.00000, loss_test:0.02585, lr:1.99e-02, fs:0.77500 (r=0.713,p=0.849),  time:40.903, tt:6462.711\n",
      "Ep:158, loss:0.00000, loss_test:0.02590, lr:1.97e-02, fs:0.77500 (r=0.713,p=0.849),  time:40.910, tt:6504.743\n",
      "Ep:159, loss:0.00000, loss_test:0.02598, lr:1.95e-02, fs:0.77500 (r=0.713,p=0.849),  time:40.914, tt:6546.201\n",
      "Ep:160, loss:0.00000, loss_test:0.02607, lr:1.93e-02, fs:0.77500 (r=0.713,p=0.849),  time:40.899, tt:6584.788\n",
      "Ep:161, loss:0.00000, loss_test:0.02611, lr:1.91e-02, fs:0.77500 (r=0.713,p=0.849),  time:40.895, tt:6624.915\n",
      "Ep:162, loss:0.00000, loss_test:0.02614, lr:1.89e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.903, tt:6667.215\n",
      "Ep:163, loss:0.00000, loss_test:0.02618, lr:1.87e-02, fs:0.77500 (r=0.713,p=0.849),  time:40.894, tt:6706.550\n",
      "Ep:164, loss:0.00000, loss_test:0.02625, lr:1.85e-02, fs:0.77500 (r=0.713,p=0.849),  time:40.887, tt:6746.313\n",
      "Ep:165, loss:0.00000, loss_test:0.02633, lr:1.83e-02, fs:0.77500 (r=0.713,p=0.849),  time:40.897, tt:6788.969\n",
      "Ep:166, loss:0.00000, loss_test:0.02637, lr:1.81e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.881, tt:6827.137\n",
      "Ep:167, loss:0.00000, loss_test:0.02645, lr:1.80e-02, fs:0.77500 (r=0.713,p=0.849),  time:40.889, tt:6869.339\n",
      "Ep:168, loss:0.00000, loss_test:0.02652, lr:1.78e-02, fs:0.77500 (r=0.713,p=0.849),  time:40.891, tt:6910.609\n",
      "Ep:169, loss:0.00000, loss_test:0.02650, lr:1.76e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.890, tt:6951.311\n",
      "Ep:170, loss:0.00000, loss_test:0.02657, lr:1.74e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.891, tt:6992.437\n",
      "Ep:171, loss:0.00000, loss_test:0.02665, lr:1.73e-02, fs:0.77500 (r=0.713,p=0.849),  time:40.884, tt:7032.040\n",
      "Ep:172, loss:0.00000, loss_test:0.02670, lr:1.71e-02, fs:0.77500 (r=0.713,p=0.849),  time:40.882, tt:7072.576\n",
      "Ep:173, loss:0.00000, loss_test:0.02670, lr:1.69e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.881, tt:7113.312\n",
      "Ep:174, loss:0.00000, loss_test:0.02677, lr:1.67e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.888, tt:7155.380\n",
      "Ep:175, loss:0.00000, loss_test:0.02685, lr:1.66e-02, fs:0.77500 (r=0.713,p=0.849),  time:40.888, tt:7196.360\n",
      "Ep:176, loss:0.00000, loss_test:0.02682, lr:1.64e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.880, tt:7235.823\n",
      "Ep:177, loss:0.00000, loss_test:0.02686, lr:1.62e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.876, tt:7275.917\n",
      "Ep:178, loss:0.00000, loss_test:0.02692, lr:1.61e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.900, tt:7321.107\n",
      "Ep:179, loss:0.00000, loss_test:0.02700, lr:1.59e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.899, tt:7361.854\n",
      "Ep:180, loss:0.00000, loss_test:0.02702, lr:1.58e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.903, tt:7403.425\n",
      "Ep:181, loss:0.00000, loss_test:0.02705, lr:1.56e-02, fs:0.75949 (r=0.690,p=0.845),  time:40.913, tt:7446.164\n",
      "Ep:182, loss:0.00000, loss_test:0.02710, lr:1.54e-02, fs:0.75949 (r=0.690,p=0.845),  time:40.918, tt:7487.944\n",
      "Ep:183, loss:0.00000, loss_test:0.02713, lr:1.53e-02, fs:0.75949 (r=0.690,p=0.845),  time:40.919, tt:7529.151\n",
      "Ep:184, loss:0.00000, loss_test:0.02714, lr:1.51e-02, fs:0.75949 (r=0.690,p=0.845),  time:40.916, tt:7569.539\n",
      "Ep:185, loss:0.00000, loss_test:0.02720, lr:1.50e-02, fs:0.75949 (r=0.690,p=0.845),  time:40.924, tt:7611.837\n",
      "Ep:186, loss:0.00000, loss_test:0.02727, lr:1.48e-02, fs:0.75949 (r=0.690,p=0.845),  time:40.933, tt:7654.406\n",
      "Ep:187, loss:0.00000, loss_test:0.02733, lr:1.47e-02, fs:0.75949 (r=0.690,p=0.845),  time:40.930, tt:7694.761\n",
      "Ep:188, loss:0.00000, loss_test:0.02737, lr:1.45e-02, fs:0.75949 (r=0.690,p=0.845),  time:40.938, tt:7737.212\n",
      "Ep:189, loss:0.00000, loss_test:0.02738, lr:1.44e-02, fs:0.75949 (r=0.690,p=0.845),  time:40.937, tt:7778.011\n",
      "Ep:190, loss:0.00000, loss_test:0.02744, lr:1.43e-02, fs:0.75949 (r=0.690,p=0.845),  time:40.936, tt:7818.797\n",
      "Ep:191, loss:0.00000, loss_test:0.02749, lr:1.41e-02, fs:0.75949 (r=0.690,p=0.845),  time:40.937, tt:7859.941\n",
      "Ep:192, loss:0.00000, loss_test:0.02749, lr:1.40e-02, fs:0.75949 (r=0.690,p=0.845),  time:40.936, tt:7900.699\n",
      "Ep:193, loss:0.00000, loss_test:0.02753, lr:1.38e-02, fs:0.75949 (r=0.690,p=0.845),  time:40.951, tt:7944.423\n",
      "Ep:194, loss:0.00000, loss_test:0.02758, lr:1.37e-02, fs:0.75949 (r=0.690,p=0.845),  time:40.951, tt:7985.350\n",
      "Ep:195, loss:0.00000, loss_test:0.02765, lr:1.36e-02, fs:0.75641 (r=0.678,p=0.855),  time:40.950, tt:8026.122\n",
      "Ep:196, loss:0.00000, loss_test:0.02767, lr:1.34e-02, fs:0.75641 (r=0.678,p=0.855),  time:40.945, tt:8066.261\n",
      "Ep:197, loss:0.00000, loss_test:0.02767, lr:1.33e-02, fs:0.75641 (r=0.678,p=0.855),  time:40.946, tt:8107.224\n",
      "Ep:198, loss:0.00000, loss_test:0.02768, lr:1.32e-02, fs:0.75641 (r=0.678,p=0.855),  time:40.950, tt:8149.147\n",
      "Ep:199, loss:0.00000, loss_test:0.02769, lr:1.30e-02, fs:0.75325 (r=0.667,p=0.866),  time:40.951, tt:8190.198\n",
      "Ep:200, loss:0.00000, loss_test:0.02775, lr:1.29e-02, fs:0.75325 (r=0.667,p=0.866),  time:40.950, tt:8231.017\n",
      "Ep:201, loss:0.00000, loss_test:0.02782, lr:1.28e-02, fs:0.75325 (r=0.667,p=0.866),  time:40.951, tt:8272.177\n",
      "Ep:202, loss:0.00000, loss_test:0.02786, lr:1.26e-02, fs:0.74510 (r=0.655,p=0.864),  time:40.963, tt:8315.515\n",
      "Ep:203, loss:0.00000, loss_test:0.02787, lr:1.25e-02, fs:0.74510 (r=0.655,p=0.864),  time:40.960, tt:8355.872\n",
      "Ep:204, loss:0.00000, loss_test:0.02789, lr:1.24e-02, fs:0.74510 (r=0.655,p=0.864),  time:40.960, tt:8396.832\n",
      "Ep:205, loss:0.00000, loss_test:0.02795, lr:1.23e-02, fs:0.74510 (r=0.655,p=0.864),  time:40.961, tt:8437.887\n",
      "Ep:206, loss:0.00000, loss_test:0.02797, lr:1.21e-02, fs:0.74510 (r=0.655,p=0.864),  time:40.961, tt:8478.982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:207, loss:0.00000, loss_test:0.02801, lr:1.20e-02, fs:0.74510 (r=0.655,p=0.864),  time:40.984, tt:8524.597\n",
      "Ep:208, loss:0.00000, loss_test:0.02801, lr:1.19e-02, fs:0.74510 (r=0.655,p=0.864),  time:40.986, tt:8566.109\n",
      "Ep:209, loss:0.00000, loss_test:0.02804, lr:1.18e-02, fs:0.74510 (r=0.655,p=0.864),  time:40.989, tt:8607.663\n",
      "Ep:210, loss:0.00000, loss_test:0.02807, lr:1.17e-02, fs:0.74510 (r=0.655,p=0.864),  time:40.966, tt:8643.779\n",
      "Ep:211, loss:0.00000, loss_test:0.02810, lr:1.15e-02, fs:0.73684 (r=0.644,p=0.862),  time:40.954, tt:8682.270\n",
      "Ep:212, loss:0.00000, loss_test:0.02815, lr:1.14e-02, fs:0.73684 (r=0.644,p=0.862),  time:40.923, tt:8716.518\n",
      "Ep:213, loss:0.00000, loss_test:0.02821, lr:1.13e-02, fs:0.73684 (r=0.644,p=0.862),  time:40.888, tt:8750.022\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14332, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.907, tt:34.907\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14220, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.514, tt:75.028\n",
      "Ep:2, loss:0.00028, loss_test:0.14020, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.509, tt:118.528\n",
      "Ep:3, loss:0.00027, loss_test:0.13691, lr:1.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:39.933, tt:159.733\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.13159, lr:1.00e-02, fs:0.67717 (r=0.989,p=0.515),  time:40.252, tt:201.262\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.12386, lr:1.00e-02, fs:0.65789 (r=0.862,p=0.532),  time:40.576, tt:243.453\n",
      "Ep:6, loss:0.00024, loss_test:0.11710, lr:1.00e-02, fs:0.65979 (r=0.736,p=0.598),  time:40.688, tt:284.817\n",
      "Ep:7, loss:0.00023, loss_test:0.11637, lr:1.00e-02, fs:0.64045 (r=0.655,p=0.626),  time:40.901, tt:327.210\n",
      "Ep:8, loss:0.00022, loss_test:0.11471, lr:1.00e-02, fs:0.66298 (r=0.690,p=0.638),  time:41.085, tt:369.765\n",
      "Ep:9, loss:0.00022, loss_test:0.11287, lr:1.00e-02, fs:0.66667 (r=0.724,p=0.618),  time:41.039, tt:410.388\n",
      "Ep:10, loss:0.00021, loss_test:0.10976, lr:1.00e-02, fs:0.67033 (r=0.701,p=0.642),  time:41.089, tt:451.979\n",
      "Ep:11, loss:0.00020, loss_test:0.10894, lr:1.00e-02, fs:0.65868 (r=0.632,p=0.688),  time:41.130, tt:493.565\n",
      "Ep:12, loss:0.00020, loss_test:0.10627, lr:1.00e-02, fs:0.68966 (r=0.690,p=0.690),  time:41.185, tt:535.408\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.10399, lr:1.00e-02, fs:0.74317 (r=0.782,p=0.708),  time:41.343, tt:578.804\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.10278, lr:1.00e-02, fs:0.73864 (r=0.747,p=0.730),  time:41.309, tt:619.632\n",
      "Ep:15, loss:0.00018, loss_test:0.10278, lr:1.00e-02, fs:0.73256 (r=0.724,p=0.741),  time:41.322, tt:661.146\n",
      "Ep:16, loss:0.00018, loss_test:0.10001, lr:1.00e-02, fs:0.76136 (r=0.770,p=0.753),  time:41.351, tt:702.969\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.09913, lr:1.00e-02, fs:0.76190 (r=0.736,p=0.790),  time:41.449, tt:746.081\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00016, loss_test:0.09626, lr:1.00e-02, fs:0.76647 (r=0.736,p=0.800),  time:41.455, tt:787.638\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.09304, lr:1.00e-02, fs:0.80000 (r=0.805,p=0.795),  time:41.466, tt:829.321\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00015, loss_test:0.09206, lr:1.00e-02, fs:0.77108 (r=0.736,p=0.810),  time:41.515, tt:871.812\n",
      "Ep:21, loss:0.00015, loss_test:0.08877, lr:1.00e-02, fs:0.81143 (r=0.816,p=0.807),  time:41.416, tt:911.157\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00014, loss_test:0.08738, lr:1.00e-02, fs:0.82081 (r=0.816,p=0.826),  time:41.415, tt:952.545\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.08527, lr:1.00e-02, fs:0.81871 (r=0.805,p=0.833),  time:41.411, tt:993.868\n",
      "Ep:24, loss:0.00013, loss_test:0.08324, lr:1.00e-02, fs:0.85393 (r=0.874,p=0.835),  time:41.305, tt:1032.615\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00013, loss_test:0.08334, lr:1.00e-02, fs:0.86857 (r=0.874,p=0.864),  time:41.328, tt:1074.533\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00012, loss_test:0.08110, lr:1.00e-02, fs:0.86631 (r=0.931,p=0.810),  time:41.343, tt:1116.251\n",
      "Ep:27, loss:0.00012, loss_test:0.08203, lr:1.00e-02, fs:0.84337 (r=0.805,p=0.886),  time:41.263, tt:1155.358\n",
      "Ep:28, loss:0.00011, loss_test:0.07884, lr:1.00e-02, fs:0.90426 (r=0.977,p=0.842),  time:41.273, tt:1196.917\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00011, loss_test:0.07927, lr:1.00e-02, fs:0.85882 (r=0.839,p=0.880),  time:41.331, tt:1239.942\n",
      "Ep:30, loss:0.00010, loss_test:0.07757, lr:1.00e-02, fs:0.89247 (r=0.954,p=0.838),  time:41.268, tt:1279.302\n",
      "Ep:31, loss:0.00010, loss_test:0.07895, lr:1.00e-02, fs:0.88372 (r=0.874,p=0.894),  time:41.275, tt:1320.809\n",
      "Ep:32, loss:0.00010, loss_test:0.07691, lr:1.00e-02, fs:0.86517 (r=0.885,p=0.846),  time:41.279, tt:1362.200\n",
      "Ep:33, loss:0.00009, loss_test:0.07592, lr:1.00e-02, fs:0.89773 (r=0.908,p=0.888),  time:41.321, tt:1404.903\n",
      "Ep:34, loss:0.00009, loss_test:0.07568, lr:1.00e-02, fs:0.89017 (r=0.885,p=0.895),  time:41.306, tt:1445.713\n",
      "Ep:35, loss:0.00009, loss_test:0.07692, lr:1.00e-02, fs:0.89286 (r=0.862,p=0.926),  time:41.273, tt:1485.832\n",
      "Ep:36, loss:0.00008, loss_test:0.07449, lr:1.00e-02, fs:0.88889 (r=0.920,p=0.860),  time:41.296, tt:1527.942\n",
      "Ep:37, loss:0.00008, loss_test:0.07545, lr:1.00e-02, fs:0.91228 (r=0.897,p=0.929),  time:41.313, tt:1569.902\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00008, loss_test:0.07315, lr:1.00e-02, fs:0.87151 (r=0.897,p=0.848),  time:41.364, tt:1613.177\n",
      "Ep:39, loss:0.00007, loss_test:0.07487, lr:1.00e-02, fs:0.90698 (r=0.897,p=0.918),  time:41.367, tt:1654.669\n",
      "Ep:40, loss:0.00007, loss_test:0.07406, lr:1.00e-02, fs:0.89655 (r=0.897,p=0.897),  time:41.365, tt:1695.972\n",
      "Ep:41, loss:0.00007, loss_test:0.07287, lr:1.00e-02, fs:0.88136 (r=0.897,p=0.867),  time:41.331, tt:1735.901\n",
      "Ep:42, loss:0.00007, loss_test:0.07501, lr:1.00e-02, fs:0.89024 (r=0.839,p=0.948),  time:41.334, tt:1777.372\n",
      "Ep:43, loss:0.00006, loss_test:0.07472, lr:1.00e-02, fs:0.88136 (r=0.897,p=0.867),  time:41.424, tt:1822.672\n",
      "Ep:44, loss:0.00006, loss_test:0.07588, lr:1.00e-02, fs:0.91463 (r=0.862,p=0.974),  time:41.442, tt:1864.889\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00006, loss_test:0.07315, lr:1.00e-02, fs:0.88136 (r=0.897,p=0.867),  time:41.445, tt:1906.462\n",
      "Ep:46, loss:0.00006, loss_test:0.07965, lr:1.00e-02, fs:0.85350 (r=0.770,p=0.957),  time:41.424, tt:1946.940\n",
      "Ep:47, loss:0.00005, loss_test:0.07405, lr:1.00e-02, fs:0.89655 (r=0.897,p=0.897),  time:41.387, tt:1986.579\n",
      "Ep:48, loss:0.00005, loss_test:0.07863, lr:1.00e-02, fs:0.84810 (r=0.770,p=0.944),  time:41.375, tt:2027.385\n",
      "Ep:49, loss:0.00005, loss_test:0.07511, lr:1.00e-02, fs:0.83636 (r=0.793,p=0.885),  time:41.470, tt:2073.491\n",
      "Ep:50, loss:0.00005, loss_test:0.07531, lr:1.00e-02, fs:0.92308 (r=0.897,p=0.951),  time:41.446, tt:2113.742\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00005, loss_test:0.07781, lr:1.00e-02, fs:0.80745 (r=0.747,p=0.878),  time:41.401, tt:2152.853\n",
      "Ep:52, loss:0.00004, loss_test:0.07723, lr:1.00e-02, fs:0.84277 (r=0.770,p=0.931),  time:41.400, tt:2194.221\n",
      "Ep:53, loss:0.00004, loss_test:0.07531, lr:1.00e-02, fs:0.92308 (r=0.897,p=0.951),  time:41.388, tt:2234.976\n",
      "Ep:54, loss:0.00004, loss_test:0.08218, lr:1.00e-02, fs:0.84810 (r=0.770,p=0.944),  time:41.381, tt:2275.975\n",
      "Ep:55, loss:0.00004, loss_test:0.07631, lr:1.00e-02, fs:0.83230 (r=0.770,p=0.905),  time:41.360, tt:2316.143\n",
      "Ep:56, loss:0.00004, loss_test:0.07851, lr:1.00e-02, fs:0.88485 (r=0.839,p=0.936),  time:41.350, tt:2356.934\n",
      "Ep:57, loss:0.00004, loss_test:0.07422, lr:1.00e-02, fs:0.85030 (r=0.816,p=0.887),  time:41.365, tt:2399.195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00004, loss_test:0.07774, lr:1.00e-02, fs:0.83750 (r=0.770,p=0.918),  time:41.377, tt:2441.240\n",
      "Ep:59, loss:0.00004, loss_test:0.08104, lr:1.00e-02, fs:0.87500 (r=0.805,p=0.959),  time:41.403, tt:2484.182\n",
      "Ep:60, loss:0.00003, loss_test:0.07740, lr:1.00e-02, fs:0.81761 (r=0.747,p=0.903),  time:41.421, tt:2526.695\n",
      "Ep:61, loss:0.00003, loss_test:0.08067, lr:1.00e-02, fs:0.85350 (r=0.770,p=0.957),  time:41.408, tt:2567.304\n",
      "Ep:62, loss:0.00003, loss_test:0.07959, lr:9.90e-03, fs:0.81529 (r=0.736,p=0.914),  time:41.337, tt:2604.240\n",
      "Ep:63, loss:0.00003, loss_test:0.08023, lr:9.80e-03, fs:0.92857 (r=0.897,p=0.963),  time:41.328, tt:2644.967\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00003, loss_test:0.08160, lr:9.80e-03, fs:0.89157 (r=0.851,p=0.937),  time:41.322, tt:2685.952\n",
      "Ep:65, loss:0.00003, loss_test:0.08055, lr:9.80e-03, fs:0.83230 (r=0.770,p=0.905),  time:41.359, tt:2729.687\n",
      "Ep:66, loss:0.00003, loss_test:0.08436, lr:9.80e-03, fs:0.82051 (r=0.736,p=0.928),  time:41.346, tt:2770.157\n",
      "Ep:67, loss:0.00003, loss_test:0.08150, lr:9.80e-03, fs:0.88485 (r=0.839,p=0.936),  time:41.347, tt:2811.602\n",
      "Ep:68, loss:0.00003, loss_test:0.08109, lr:9.80e-03, fs:0.81529 (r=0.736,p=0.914),  time:41.332, tt:2851.879\n",
      "Ep:69, loss:0.00003, loss_test:0.08183, lr:9.80e-03, fs:0.90476 (r=0.874,p=0.938),  time:41.326, tt:2892.838\n",
      "Ep:70, loss:0.00003, loss_test:0.08053, lr:9.80e-03, fs:0.80503 (r=0.736,p=0.889),  time:41.305, tt:2932.646\n",
      "Ep:71, loss:0.00003, loss_test:0.08319, lr:9.80e-03, fs:0.83117 (r=0.736,p=0.955),  time:41.279, tt:2972.086\n",
      "Ep:72, loss:0.00002, loss_test:0.08140, lr:9.80e-03, fs:0.82803 (r=0.747,p=0.929),  time:41.265, tt:3012.370\n",
      "Ep:73, loss:0.00002, loss_test:0.08323, lr:9.80e-03, fs:0.79470 (r=0.690,p=0.938),  time:41.265, tt:3053.594\n",
      "Ep:74, loss:0.00002, loss_test:0.07665, lr:9.80e-03, fs:0.90476 (r=0.874,p=0.938),  time:41.238, tt:3092.840\n",
      "Ep:75, loss:0.00002, loss_test:0.08493, lr:9.70e-03, fs:0.79470 (r=0.690,p=0.938),  time:41.247, tt:3134.759\n",
      "Ep:76, loss:0.00002, loss_test:0.08033, lr:9.61e-03, fs:0.83117 (r=0.736,p=0.955),  time:41.270, tt:3177.771\n",
      "Ep:77, loss:0.00002, loss_test:0.08011, lr:9.51e-03, fs:0.87117 (r=0.816,p=0.934),  time:41.251, tt:3217.566\n",
      "Ep:78, loss:0.00002, loss_test:0.08327, lr:9.41e-03, fs:0.83117 (r=0.736,p=0.955),  time:41.251, tt:3258.791\n",
      "Ep:79, loss:0.00002, loss_test:0.07908, lr:9.32e-03, fs:0.89820 (r=0.862,p=0.938),  time:41.229, tt:3298.329\n",
      "Ep:80, loss:0.00002, loss_test:0.08477, lr:9.23e-03, fs:0.80795 (r=0.701,p=0.953),  time:41.243, tt:3340.677\n",
      "Ep:81, loss:0.00002, loss_test:0.08349, lr:9.14e-03, fs:0.82581 (r=0.736,p=0.941),  time:41.238, tt:3381.544\n",
      "Ep:82, loss:0.00002, loss_test:0.08231, lr:9.04e-03, fs:0.82581 (r=0.736,p=0.941),  time:41.225, tt:3421.650\n",
      "Ep:83, loss:0.00002, loss_test:0.08241, lr:8.95e-03, fs:0.80263 (r=0.701,p=0.938),  time:41.218, tt:3462.313\n",
      "Ep:84, loss:0.00001, loss_test:0.08260, lr:8.86e-03, fs:0.83117 (r=0.736,p=0.955),  time:41.206, tt:3502.552\n",
      "Ep:85, loss:0.00001, loss_test:0.08403, lr:8.78e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.219, tt:3544.795\n",
      "Ep:86, loss:0.00001, loss_test:0.08359, lr:8.69e-03, fs:0.82581 (r=0.736,p=0.941),  time:41.218, tt:3585.929\n",
      "Ep:87, loss:0.00001, loss_test:0.08563, lr:8.60e-03, fs:0.76712 (r=0.644,p=0.949),  time:41.215, tt:3626.927\n",
      "Ep:88, loss:0.00001, loss_test:0.08348, lr:8.51e-03, fs:0.82353 (r=0.724,p=0.955),  time:41.202, tt:3666.942\n",
      "Ep:89, loss:0.00001, loss_test:0.08414, lr:8.43e-03, fs:0.83117 (r=0.736,p=0.955),  time:41.228, tt:3710.544\n",
      "Ep:90, loss:0.00001, loss_test:0.08388, lr:8.35e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.216, tt:3750.635\n",
      "Ep:91, loss:0.00001, loss_test:0.08439, lr:8.26e-03, fs:0.83117 (r=0.736,p=0.955),  time:41.221, tt:3792.313\n",
      "Ep:92, loss:0.00001, loss_test:0.08699, lr:8.18e-03, fs:0.76712 (r=0.644,p=0.949),  time:41.243, tt:3835.620\n",
      "Ep:93, loss:0.00001, loss_test:0.08600, lr:8.10e-03, fs:0.82353 (r=0.724,p=0.955),  time:41.236, tt:3876.198\n",
      "Ep:94, loss:0.00001, loss_test:0.08555, lr:8.02e-03, fs:0.82581 (r=0.736,p=0.941),  time:41.242, tt:3918.036\n",
      "Ep:95, loss:0.00001, loss_test:0.08581, lr:7.94e-03, fs:0.81579 (r=0.713,p=0.954),  time:41.248, tt:3959.780\n",
      "Ep:96, loss:0.00001, loss_test:0.08388, lr:7.86e-03, fs:0.83117 (r=0.736,p=0.955),  time:41.267, tt:4002.855\n",
      "Ep:97, loss:0.00001, loss_test:0.08617, lr:7.78e-03, fs:0.79195 (r=0.678,p=0.952),  time:41.255, tt:4042.981\n",
      "Ep:98, loss:0.00001, loss_test:0.08497, lr:7.70e-03, fs:0.82051 (r=0.736,p=0.928),  time:41.269, tt:4085.677\n",
      "Ep:99, loss:0.00001, loss_test:0.08830, lr:7.62e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.269, tt:4126.884\n",
      "Ep:100, loss:0.00001, loss_test:0.08615, lr:7.55e-03, fs:0.83117 (r=0.736,p=0.955),  time:41.263, tt:4167.551\n",
      "Ep:101, loss:0.00001, loss_test:0.08635, lr:7.47e-03, fs:0.86076 (r=0.782,p=0.958),  time:41.294, tt:4211.955\n",
      "Ep:102, loss:0.00001, loss_test:0.08704, lr:7.40e-03, fs:0.75000 (r=0.621,p=0.947),  time:41.286, tt:4252.438\n",
      "Ep:103, loss:0.00001, loss_test:0.08417, lr:7.32e-03, fs:0.83117 (r=0.736,p=0.955),  time:41.274, tt:4292.498\n",
      "Ep:104, loss:0.00001, loss_test:0.08682, lr:7.25e-03, fs:0.71429 (r=0.575,p=0.943),  time:41.290, tt:4335.413\n",
      "Ep:105, loss:0.00001, loss_test:0.08441, lr:7.18e-03, fs:0.82353 (r=0.724,p=0.955),  time:41.294, tt:4377.164\n",
      "Ep:106, loss:0.00001, loss_test:0.08662, lr:7.11e-03, fs:0.71429 (r=0.575,p=0.943),  time:41.274, tt:4416.295\n",
      "Ep:107, loss:0.00001, loss_test:0.08720, lr:7.03e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.267, tt:4456.863\n",
      "Ep:108, loss:0.00001, loss_test:0.08521, lr:6.96e-03, fs:0.83117 (r=0.736,p=0.955),  time:41.266, tt:4498.045\n",
      "Ep:109, loss:0.00001, loss_test:0.08863, lr:6.89e-03, fs:0.70504 (r=0.563,p=0.942),  time:41.273, tt:4539.987\n",
      "Ep:110, loss:0.00001, loss_test:0.08570, lr:6.83e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.275, tt:4581.510\n",
      "Ep:111, loss:0.00001, loss_test:0.08712, lr:6.76e-03, fs:0.75342 (r=0.632,p=0.932),  time:41.282, tt:4623.605\n",
      "Ep:112, loss:0.00001, loss_test:0.08784, lr:6.69e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.276, tt:4664.181\n",
      "Ep:113, loss:0.00001, loss_test:0.08449, lr:6.62e-03, fs:0.77852 (r=0.667,p=0.935),  time:41.280, tt:4705.964\n",
      "Ep:114, loss:0.00001, loss_test:0.08801, lr:6.56e-03, fs:0.71429 (r=0.575,p=0.943),  time:41.279, tt:4747.087\n",
      "Ep:115, loss:0.00001, loss_test:0.08753, lr:6.49e-03, fs:0.75342 (r=0.632,p=0.932),  time:41.293, tt:4789.982\n",
      "Ep:116, loss:0.00001, loss_test:0.08515, lr:6.43e-03, fs:0.82051 (r=0.736,p=0.928),  time:41.310, tt:4833.216\n",
      "Ep:117, loss:0.00001, loss_test:0.08957, lr:6.36e-03, fs:0.70504 (r=0.563,p=0.942),  time:41.305, tt:4873.940\n",
      "Ep:118, loss:0.00001, loss_test:0.08751, lr:6.30e-03, fs:0.77027 (r=0.655,p=0.934),  time:41.310, tt:4915.921\n",
      "Ep:119, loss:0.00001, loss_test:0.08670, lr:6.24e-03, fs:0.70504 (r=0.563,p=0.942),  time:41.321, tt:4958.482\n",
      "Ep:120, loss:0.00001, loss_test:0.08845, lr:6.17e-03, fs:0.70504 (r=0.563,p=0.942),  time:41.323, tt:5000.031\n",
      "Ep:121, loss:0.00001, loss_test:0.08535, lr:6.11e-03, fs:0.79470 (r=0.690,p=0.938),  time:41.327, tt:5041.870\n",
      "Ep:122, loss:0.00001, loss_test:0.08650, lr:6.05e-03, fs:0.75342 (r=0.632,p=0.932),  time:41.308, tt:5080.824\n",
      "Ep:123, loss:0.00000, loss_test:0.08968, lr:5.99e-03, fs:0.70504 (r=0.563,p=0.942),  time:41.323, tt:5124.098\n",
      "Ep:124, loss:0.00000, loss_test:0.08659, lr:5.93e-03, fs:0.77333 (r=0.667,p=0.921),  time:41.319, tt:5164.830\n",
      "Ep:125, loss:0.00000, loss_test:0.08586, lr:5.87e-03, fs:0.75862 (r=0.632,p=0.948),  time:41.314, tt:5205.585\n",
      "Ep:126, loss:0.00000, loss_test:0.08646, lr:5.81e-03, fs:0.75862 (r=0.632,p=0.948),  time:41.325, tt:5248.267\n",
      "Ep:127, loss:0.00000, loss_test:0.08661, lr:5.75e-03, fs:0.77027 (r=0.655,p=0.934),  time:41.322, tt:5289.215\n",
      "Ep:128, loss:0.00000, loss_test:0.08703, lr:5.70e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.322, tt:5330.562\n",
      "Ep:129, loss:0.00000, loss_test:0.08654, lr:5.64e-03, fs:0.75342 (r=0.632,p=0.932),  time:41.334, tt:5373.390\n",
      "Ep:130, loss:0.00000, loss_test:0.08664, lr:5.58e-03, fs:0.70504 (r=0.563,p=0.942),  time:41.342, tt:5415.741\n",
      "Ep:131, loss:0.00000, loss_test:0.08618, lr:5.53e-03, fs:0.75676 (r=0.644,p=0.918),  time:41.351, tt:5458.269\n",
      "Ep:132, loss:0.00000, loss_test:0.08587, lr:5.47e-03, fs:0.75862 (r=0.632,p=0.948),  time:41.365, tt:5501.571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00000, loss_test:0.08718, lr:5.42e-03, fs:0.70922 (r=0.575,p=0.926),  time:41.373, tt:5543.953\n",
      "Ep:134, loss:0.00000, loss_test:0.08593, lr:5.36e-03, fs:0.77027 (r=0.655,p=0.934),  time:41.384, tt:5586.792\n",
      "Ep:135, loss:0.00000, loss_test:0.08569, lr:5.31e-03, fs:0.72727 (r=0.598,p=0.929),  time:41.401, tt:5630.555\n",
      "Ep:136, loss:0.00000, loss_test:0.08621, lr:5.26e-03, fs:0.75676 (r=0.644,p=0.918),  time:41.404, tt:5672.298\n",
      "Ep:137, loss:0.00000, loss_test:0.08747, lr:5.20e-03, fs:0.70504 (r=0.563,p=0.942),  time:41.423, tt:5716.369\n",
      "Ep:138, loss:0.00000, loss_test:0.08756, lr:5.15e-03, fs:0.70504 (r=0.563,p=0.942),  time:41.443, tt:5760.624\n",
      "Ep:139, loss:0.00000, loss_test:0.08645, lr:5.10e-03, fs:0.76510 (r=0.655,p=0.919),  time:41.451, tt:5803.149\n",
      "Ep:140, loss:0.00000, loss_test:0.08685, lr:5.05e-03, fs:0.70922 (r=0.575,p=0.926),  time:41.451, tt:5844.608\n",
      "Ep:141, loss:0.00000, loss_test:0.08635, lr:5.00e-03, fs:0.73973 (r=0.621,p=0.915),  time:41.458, tt:5887.008\n",
      "Ep:142, loss:0.00000, loss_test:0.08636, lr:4.95e-03, fs:0.73973 (r=0.621,p=0.915),  time:41.471, tt:5930.409\n",
      "Ep:143, loss:0.00000, loss_test:0.08680, lr:4.90e-03, fs:0.70423 (r=0.575,p=0.909),  time:41.467, tt:5971.242\n",
      "Ep:144, loss:0.00000, loss_test:0.08711, lr:4.85e-03, fs:0.73973 (r=0.621,p=0.915),  time:41.473, tt:6013.528\n",
      "Ep:145, loss:0.00000, loss_test:0.08717, lr:4.80e-03, fs:0.71329 (r=0.586,p=0.911),  time:41.473, tt:6055.077\n",
      "Ep:146, loss:0.00000, loss_test:0.08762, lr:4.75e-03, fs:0.73611 (r=0.609,p=0.930),  time:41.499, tt:6100.388\n",
      "Ep:147, loss:0.00000, loss_test:0.08791, lr:4.71e-03, fs:0.70922 (r=0.575,p=0.926),  time:41.493, tt:6140.999\n",
      "Ep:148, loss:0.00000, loss_test:0.08705, lr:4.66e-03, fs:0.76510 (r=0.655,p=0.919),  time:41.486, tt:6181.350\n",
      "Ep:149, loss:0.00000, loss_test:0.08699, lr:4.61e-03, fs:0.70922 (r=0.575,p=0.926),  time:41.502, tt:6225.269\n",
      "Ep:150, loss:0.00000, loss_test:0.08764, lr:4.57e-03, fs:0.70000 (r=0.563,p=0.925),  time:41.508, tt:6267.662\n",
      "Ep:151, loss:0.00000, loss_test:0.08683, lr:4.52e-03, fs:0.76510 (r=0.655,p=0.919),  time:41.509, tt:6309.321\n",
      "Ep:152, loss:0.00000, loss_test:0.08730, lr:4.48e-03, fs:0.70922 (r=0.575,p=0.926),  time:41.510, tt:6350.975\n",
      "Ep:153, loss:0.00000, loss_test:0.08812, lr:4.43e-03, fs:0.70000 (r=0.563,p=0.925),  time:41.502, tt:6391.262\n",
      "Ep:154, loss:0.00000, loss_test:0.08711, lr:4.39e-03, fs:0.76510 (r=0.655,p=0.919),  time:41.493, tt:6431.443\n",
      "Ep:155, loss:0.00000, loss_test:0.08671, lr:4.34e-03, fs:0.74830 (r=0.632,p=0.917),  time:41.495, tt:6473.182\n",
      "Ep:156, loss:0.00000, loss_test:0.08801, lr:4.30e-03, fs:0.70000 (r=0.563,p=0.925),  time:41.501, tt:6515.701\n",
      "Ep:157, loss:0.00000, loss_test:0.08815, lr:4.26e-03, fs:0.71831 (r=0.586,p=0.927),  time:41.503, tt:6557.427\n",
      "Ep:158, loss:0.00000, loss_test:0.08749, lr:4.21e-03, fs:0.76510 (r=0.655,p=0.919),  time:41.492, tt:6597.230\n",
      "Ep:159, loss:0.00000, loss_test:0.08759, lr:4.17e-03, fs:0.70000 (r=0.563,p=0.925),  time:41.488, tt:6638.060\n",
      "Ep:160, loss:0.00000, loss_test:0.08738, lr:4.13e-03, fs:0.73103 (r=0.609,p=0.914),  time:41.485, tt:6679.016\n",
      "Ep:161, loss:0.00000, loss_test:0.08703, lr:4.09e-03, fs:0.76510 (r=0.655,p=0.919),  time:41.493, tt:6721.855\n",
      "Ep:162, loss:0.00000, loss_test:0.08774, lr:4.05e-03, fs:0.71429 (r=0.575,p=0.943),  time:41.480, tt:6761.321\n",
      "Ep:163, loss:0.00000, loss_test:0.08901, lr:4.01e-03, fs:0.70922 (r=0.575,p=0.926),  time:41.491, tt:6804.476\n",
      "Ep:164, loss:0.00000, loss_test:0.08890, lr:3.97e-03, fs:0.73973 (r=0.621,p=0.915),  time:41.498, tt:6847.107\n",
      "Ep:165, loss:0.00000, loss_test:0.08775, lr:3.93e-03, fs:0.75676 (r=0.644,p=0.918),  time:41.507, tt:6890.173\n",
      "Ep:166, loss:0.00000, loss_test:0.08700, lr:3.89e-03, fs:0.74830 (r=0.632,p=0.917),  time:41.540, tt:6937.252\n",
      "Ep:167, loss:0.00000, loss_test:0.08656, lr:3.85e-03, fs:0.75676 (r=0.644,p=0.918),  time:41.539, tt:6978.530\n",
      "Ep:168, loss:0.00000, loss_test:0.08717, lr:3.81e-03, fs:0.75676 (r=0.644,p=0.918),  time:41.544, tt:7020.981\n",
      "Ep:169, loss:0.00000, loss_test:0.08807, lr:3.77e-03, fs:0.73103 (r=0.609,p=0.914),  time:41.553, tt:7063.936\n",
      "Ep:170, loss:0.00000, loss_test:0.08822, lr:3.73e-03, fs:0.73973 (r=0.621,p=0.915),  time:41.563, tt:7107.310\n",
      "Ep:171, loss:0.00000, loss_test:0.08810, lr:3.70e-03, fs:0.71329 (r=0.586,p=0.911),  time:41.570, tt:7150.070\n",
      "Ep:172, loss:0.00000, loss_test:0.08784, lr:3.66e-03, fs:0.71329 (r=0.586,p=0.911),  time:41.568, tt:7191.258\n",
      "Ep:173, loss:0.00000, loss_test:0.08747, lr:3.62e-03, fs:0.76510 (r=0.655,p=0.919),  time:41.570, tt:7233.184\n",
      "Ep:174, loss:0.00000, loss_test:0.08767, lr:3.59e-03, fs:0.75676 (r=0.644,p=0.918),  time:41.568, tt:7274.372\n",
      "Ep:175, loss:0.00000, loss_test:0.08828, lr:3.55e-03, fs:0.72222 (r=0.598,p=0.912),  time:41.563, tt:7315.048\n",
      "Ep:176, loss:0.00000, loss_test:0.08809, lr:3.52e-03, fs:0.76510 (r=0.655,p=0.919),  time:41.568, tt:7357.449\n",
      "Ep:177, loss:0.00000, loss_test:0.08782, lr:3.48e-03, fs:0.76510 (r=0.655,p=0.919),  time:41.570, tt:7399.433\n",
      "Ep:178, loss:0.00000, loss_test:0.08820, lr:3.45e-03, fs:0.75000 (r=0.621,p=0.947),  time:41.572, tt:7441.423\n",
      "Ep:179, loss:0.00000, loss_test:0.08790, lr:3.41e-03, fs:0.76190 (r=0.644,p=0.933),  time:41.570, tt:7482.533\n",
      "Ep:180, loss:0.00000, loss_test:0.08771, lr:3.38e-03, fs:0.76510 (r=0.655,p=0.919),  time:41.563, tt:7522.956\n",
      "Ep:181, loss:0.00000, loss_test:0.08795, lr:3.34e-03, fs:0.75676 (r=0.644,p=0.918),  time:41.572, tt:7566.103\n",
      "Ep:182, loss:0.00000, loss_test:0.08840, lr:3.31e-03, fs:0.73103 (r=0.609,p=0.914),  time:41.577, tt:7608.624\n",
      "Ep:183, loss:0.00000, loss_test:0.08809, lr:3.28e-03, fs:0.75676 (r=0.644,p=0.918),  time:41.579, tt:7650.625\n",
      "Ep:184, loss:0.00000, loss_test:0.08754, lr:3.24e-03, fs:0.76510 (r=0.655,p=0.919),  time:41.582, tt:7692.665\n",
      "Ep:185, loss:0.00000, loss_test:0.08802, lr:3.21e-03, fs:0.73973 (r=0.621,p=0.915),  time:41.584, tt:7734.596\n",
      "Ep:186, loss:0.00000, loss_test:0.08791, lr:3.18e-03, fs:0.75676 (r=0.644,p=0.918),  time:41.589, tt:7777.083\n",
      "Ep:187, loss:0.00000, loss_test:0.08756, lr:3.15e-03, fs:0.76510 (r=0.655,p=0.919),  time:41.588, tt:7818.626\n",
      "Ep:188, loss:0.00000, loss_test:0.08824, lr:3.12e-03, fs:0.73973 (r=0.621,p=0.915),  time:41.590, tt:7860.601\n",
      "Ep:189, loss:0.00000, loss_test:0.08857, lr:3.09e-03, fs:0.72222 (r=0.598,p=0.912),  time:41.583, tt:7900.705\n",
      "Ep:190, loss:0.00000, loss_test:0.08842, lr:3.05e-03, fs:0.76510 (r=0.655,p=0.919),  time:41.574, tt:7940.581\n",
      "Ep:191, loss:0.00000, loss_test:0.08873, lr:3.02e-03, fs:0.75676 (r=0.644,p=0.918),  time:41.582, tt:7983.735\n",
      "Ep:192, loss:0.00000, loss_test:0.08856, lr:2.99e-03, fs:0.73973 (r=0.621,p=0.915),  time:41.590, tt:8026.814\n",
      "Ep:193, loss:0.00000, loss_test:0.08810, lr:2.96e-03, fs:0.76510 (r=0.655,p=0.919),  time:41.592, tt:8068.766\n",
      "Ep:194, loss:0.00000, loss_test:0.08824, lr:2.93e-03, fs:0.75676 (r=0.644,p=0.918),  time:41.585, tt:8109.110\n",
      "Ep:195, loss:0.00000, loss_test:0.08826, lr:2.90e-03, fs:0.75676 (r=0.644,p=0.918),  time:41.587, tt:8150.983\n",
      "Ep:196, loss:0.00000, loss_test:0.08831, lr:2.88e-03, fs:0.75676 (r=0.644,p=0.918),  time:41.583, tt:8191.763\n",
      "Ep:197, loss:0.00000, loss_test:0.08835, lr:2.85e-03, fs:0.75676 (r=0.644,p=0.918),  time:41.587, tt:8234.157\n",
      "Ep:198, loss:0.00000, loss_test:0.08821, lr:2.82e-03, fs:0.75676 (r=0.644,p=0.918),  time:41.590, tt:8276.437\n",
      "Ep:199, loss:0.00000, loss_test:0.08826, lr:2.79e-03, fs:0.75676 (r=0.644,p=0.918),  time:41.602, tt:8320.309\n",
      "Ep:200, loss:0.00000, loss_test:0.08840, lr:2.76e-03, fs:0.76510 (r=0.655,p=0.919),  time:41.590, tt:8359.671\n",
      "Ep:201, loss:0.00000, loss_test:0.08837, lr:2.73e-03, fs:0.76510 (r=0.655,p=0.919),  time:41.589, tt:8400.998\n",
      "Ep:202, loss:0.00000, loss_test:0.08833, lr:2.71e-03, fs:0.75676 (r=0.644,p=0.918),  time:41.589, tt:8442.643\n",
      "Ep:203, loss:0.00000, loss_test:0.08860, lr:2.68e-03, fs:0.75676 (r=0.644,p=0.918),  time:41.591, tt:8484.602\n",
      "Ep:204, loss:0.00000, loss_test:0.08905, lr:2.65e-03, fs:0.73973 (r=0.621,p=0.915),  time:41.591, tt:8526.243\n",
      "Ep:205, loss:0.00000, loss_test:0.08881, lr:2.63e-03, fs:0.73103 (r=0.609,p=0.914),  time:41.601, tt:8569.823\n",
      "Ep:206, loss:0.00000, loss_test:0.08832, lr:2.60e-03, fs:0.76510 (r=0.655,p=0.919),  time:41.606, tt:8612.377\n",
      "Ep:207, loss:0.00000, loss_test:0.08826, lr:2.57e-03, fs:0.76510 (r=0.655,p=0.919),  time:41.618, tt:8656.463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:208, loss:0.00000, loss_test:0.08856, lr:2.55e-03, fs:0.75676 (r=0.644,p=0.918),  time:41.625, tt:8699.702\n",
      "Ep:209, loss:0.00000, loss_test:0.08864, lr:2.52e-03, fs:0.75676 (r=0.644,p=0.918),  time:41.630, tt:8742.287\n",
      "Ep:210, loss:0.00000, loss_test:0.08880, lr:2.50e-03, fs:0.75676 (r=0.644,p=0.918),  time:41.631, tt:8784.145\n",
      "Ep:211, loss:0.00000, loss_test:0.08870, lr:2.47e-03, fs:0.73973 (r=0.621,p=0.915),  time:41.590, tt:8817.016\n",
      "Ep:212, loss:0.00000, loss_test:0.08811, lr:2.45e-03, fs:0.75676 (r=0.644,p=0.918),  time:41.543, tt:8848.744\n",
      "Ep:213, loss:0.00000, loss_test:0.08798, lr:2.42e-03, fs:0.76510 (r=0.655,p=0.919),  time:41.490, tt:8878.959\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02017, lr:6.00e-02, fs:0.62810 (r=0.874,p=0.490),  time:35.015, tt:35.015\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02298, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.058, tt:72.116\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02358, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.671, tt:113.012\n",
      "Ep:3, loss:0.00005, loss_test:0.02228, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.530, tt:154.118\n",
      "Ep:4, loss:0.00004, loss_test:0.02047, lr:6.00e-02, fs:0.66409 (r=0.989,p=0.500),  time:38.936, tt:194.681\n",
      "Ep:5, loss:0.00004, loss_test:0.01917, lr:6.00e-02, fs:0.69959 (r=0.977,p=0.545),  time:39.076, tt:234.454\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01889, lr:6.00e-02, fs:0.66667 (r=0.828,p=0.558),  time:39.425, tt:275.974\n",
      "Ep:7, loss:0.00004, loss_test:0.01886, lr:6.00e-02, fs:0.69608 (r=0.816,p=0.607),  time:39.638, tt:317.104\n",
      "Ep:8, loss:0.00004, loss_test:0.01852, lr:6.00e-02, fs:0.69194 (r=0.839,p=0.589),  time:39.701, tt:357.312\n",
      "Ep:9, loss:0.00003, loss_test:0.01830, lr:6.00e-02, fs:0.71171 (r=0.908,p=0.585),  time:39.928, tt:399.284\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01814, lr:6.00e-02, fs:0.70175 (r=0.920,p=0.567),  time:40.111, tt:441.219\n",
      "Ep:11, loss:0.00003, loss_test:0.01787, lr:6.00e-02, fs:0.70485 (r=0.920,p=0.571),  time:40.528, tt:486.342\n",
      "Ep:12, loss:0.00003, loss_test:0.01760, lr:6.00e-02, fs:0.71233 (r=0.897,p=0.591),  time:41.159, tt:535.064\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01741, lr:6.00e-02, fs:0.73077 (r=0.874,p=0.628),  time:41.156, tt:576.188\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01718, lr:6.00e-02, fs:0.73077 (r=0.874,p=0.628),  time:41.053, tt:615.800\n",
      "Ep:15, loss:0.00003, loss_test:0.01686, lr:6.00e-02, fs:0.73333 (r=0.885,p=0.626),  time:41.090, tt:657.444\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01657, lr:6.00e-02, fs:0.74766 (r=0.920,p=0.630),  time:41.021, tt:697.355\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01637, lr:6.00e-02, fs:0.74766 (r=0.920,p=0.630),  time:41.091, tt:739.642\n",
      "Ep:18, loss:0.00003, loss_test:0.01627, lr:6.00e-02, fs:0.76555 (r=0.920,p=0.656),  time:41.212, tt:783.034\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01622, lr:6.00e-02, fs:0.77670 (r=0.920,p=0.672),  time:41.233, tt:824.668\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01614, lr:6.00e-02, fs:0.75897 (r=0.851,p=0.685),  time:41.322, tt:867.761\n",
      "Ep:21, loss:0.00003, loss_test:0.01600, lr:6.00e-02, fs:0.76531 (r=0.862,p=0.688),  time:41.349, tt:909.686\n",
      "Ep:22, loss:0.00002, loss_test:0.01587, lr:6.00e-02, fs:0.76142 (r=0.862,p=0.682),  time:41.401, tt:952.213\n",
      "Ep:23, loss:0.00002, loss_test:0.01576, lr:6.00e-02, fs:0.76531 (r=0.862,p=0.688),  time:41.344, tt:992.265\n",
      "Ep:24, loss:0.00002, loss_test:0.01571, lr:6.00e-02, fs:0.77949 (r=0.874,p=0.704),  time:41.355, tt:1033.872\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01573, lr:6.00e-02, fs:0.78173 (r=0.885,p=0.700),  time:41.376, tt:1075.766\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01576, lr:6.00e-02, fs:0.78173 (r=0.885,p=0.700),  time:41.366, tt:1116.889\n",
      "Ep:27, loss:0.00002, loss_test:0.01576, lr:6.00e-02, fs:0.79188 (r=0.897,p=0.709),  time:41.337, tt:1157.440\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01581, lr:6.00e-02, fs:0.80412 (r=0.897,p=0.729),  time:41.337, tt:1198.784\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01585, lr:6.00e-02, fs:0.80412 (r=0.897,p=0.729),  time:41.359, tt:1240.757\n",
      "Ep:30, loss:0.00002, loss_test:0.01582, lr:6.00e-02, fs:0.81026 (r=0.908,p=0.731),  time:41.396, tt:1283.288\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01582, lr:6.00e-02, fs:0.82723 (r=0.908,p=0.760),  time:41.452, tt:1326.453\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01582, lr:6.00e-02, fs:0.83158 (r=0.908,p=0.767),  time:41.464, tt:1368.315\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01584, lr:6.00e-02, fs:0.83598 (r=0.908,p=0.775),  time:41.424, tt:1408.421\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01587, lr:6.00e-02, fs:0.84043 (r=0.908,p=0.782),  time:41.411, tt:1449.389\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01594, lr:6.00e-02, fs:0.84492 (r=0.908,p=0.790),  time:41.434, tt:1491.632\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01599, lr:6.00e-02, fs:0.84492 (r=0.908,p=0.790),  time:41.516, tt:1536.096\n",
      "Ep:37, loss:0.00002, loss_test:0.01605, lr:6.00e-02, fs:0.83871 (r=0.897,p=0.788),  time:41.567, tt:1579.535\n",
      "Ep:38, loss:0.00002, loss_test:0.01611, lr:6.00e-02, fs:0.83871 (r=0.897,p=0.788),  time:41.561, tt:1620.865\n",
      "Ep:39, loss:0.00002, loss_test:0.01616, lr:6.00e-02, fs:0.83696 (r=0.885,p=0.794),  time:41.645, tt:1665.812\n",
      "Ep:40, loss:0.00002, loss_test:0.01619, lr:6.00e-02, fs:0.84153 (r=0.885,p=0.802),  time:41.658, tt:1707.973\n",
      "Ep:41, loss:0.00002, loss_test:0.01630, lr:6.00e-02, fs:0.84153 (r=0.885,p=0.802),  time:41.647, tt:1749.194\n",
      "Ep:42, loss:0.00002, loss_test:0.01634, lr:6.00e-02, fs:0.85246 (r=0.897,p=0.812),  time:41.648, tt:1790.846\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00001, loss_test:0.01641, lr:6.00e-02, fs:0.85246 (r=0.897,p=0.812),  time:41.647, tt:1832.455\n",
      "Ep:44, loss:0.00001, loss_test:0.01656, lr:6.00e-02, fs:0.86188 (r=0.897,p=0.830),  time:41.671, tt:1875.190\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.01669, lr:6.00e-02, fs:0.86667 (r=0.897,p=0.839),  time:41.689, tt:1917.690\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01675, lr:6.00e-02, fs:0.86667 (r=0.897,p=0.839),  time:41.689, tt:1959.365\n",
      "Ep:47, loss:0.00001, loss_test:0.01693, lr:6.00e-02, fs:0.86034 (r=0.885,p=0.837),  time:41.648, tt:1999.100\n",
      "Ep:48, loss:0.00001, loss_test:0.01696, lr:6.00e-02, fs:0.86517 (r=0.885,p=0.846),  time:41.705, tt:2043.528\n",
      "Ep:49, loss:0.00001, loss_test:0.01711, lr:6.00e-02, fs:0.85227 (r=0.862,p=0.843),  time:41.713, tt:2085.631\n",
      "Ep:50, loss:0.00001, loss_test:0.01724, lr:6.00e-02, fs:0.85057 (r=0.851,p=0.851),  time:41.713, tt:2127.378\n",
      "Ep:51, loss:0.00001, loss_test:0.01743, lr:6.00e-02, fs:0.85549 (r=0.851,p=0.860),  time:41.751, tt:2171.041\n",
      "Ep:52, loss:0.00001, loss_test:0.01763, lr:6.00e-02, fs:0.84884 (r=0.839,p=0.859),  time:41.750, tt:2212.755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:53, loss:0.00001, loss_test:0.01766, lr:6.00e-02, fs:0.84884 (r=0.839,p=0.859),  time:41.725, tt:2253.167\n",
      "Ep:54, loss:0.00001, loss_test:0.01776, lr:6.00e-02, fs:0.84884 (r=0.839,p=0.859),  time:41.706, tt:2293.817\n",
      "Ep:55, loss:0.00001, loss_test:0.01803, lr:6.00e-02, fs:0.84211 (r=0.828,p=0.857),  time:41.674, tt:2333.744\n",
      "Ep:56, loss:0.00001, loss_test:0.01811, lr:6.00e-02, fs:0.82840 (r=0.805,p=0.854),  time:41.660, tt:2374.627\n",
      "Ep:57, loss:0.00001, loss_test:0.01828, lr:5.94e-02, fs:0.82840 (r=0.805,p=0.854),  time:41.647, tt:2415.553\n",
      "Ep:58, loss:0.00001, loss_test:0.01851, lr:5.88e-02, fs:0.82143 (r=0.793,p=0.852),  time:41.652, tt:2457.464\n",
      "Ep:59, loss:0.00001, loss_test:0.01858, lr:5.82e-02, fs:0.81437 (r=0.782,p=0.850),  time:41.624, tt:2497.435\n",
      "Ep:60, loss:0.00001, loss_test:0.01876, lr:5.76e-02, fs:0.82143 (r=0.793,p=0.852),  time:41.665, tt:2541.582\n",
      "Ep:61, loss:0.00001, loss_test:0.01900, lr:5.71e-02, fs:0.82143 (r=0.793,p=0.852),  time:41.640, tt:2581.693\n",
      "Ep:62, loss:0.00001, loss_test:0.01910, lr:5.65e-02, fs:0.81928 (r=0.782,p=0.861),  time:41.641, tt:2623.375\n",
      "Ep:63, loss:0.00001, loss_test:0.01942, lr:5.59e-02, fs:0.81928 (r=0.782,p=0.861),  time:41.664, tt:2666.465\n",
      "Ep:64, loss:0.00001, loss_test:0.01941, lr:5.54e-02, fs:0.81212 (r=0.770,p=0.859),  time:41.660, tt:2707.924\n",
      "Ep:65, loss:0.00001, loss_test:0.01947, lr:5.48e-02, fs:0.81212 (r=0.770,p=0.859),  time:41.669, tt:2750.172\n",
      "Ep:66, loss:0.00001, loss_test:0.01958, lr:5.43e-02, fs:0.81928 (r=0.782,p=0.861),  time:41.693, tt:2793.406\n",
      "Ep:67, loss:0.00001, loss_test:0.01979, lr:5.37e-02, fs:0.81212 (r=0.770,p=0.859),  time:41.709, tt:2836.237\n",
      "Ep:68, loss:0.00001, loss_test:0.02004, lr:5.32e-02, fs:0.81928 (r=0.782,p=0.861),  time:41.703, tt:2877.504\n",
      "Ep:69, loss:0.00001, loss_test:0.02015, lr:5.27e-02, fs:0.81212 (r=0.770,p=0.859),  time:41.710, tt:2919.679\n",
      "Ep:70, loss:0.00001, loss_test:0.02016, lr:5.21e-02, fs:0.81212 (r=0.770,p=0.859),  time:41.723, tt:2962.319\n",
      "Ep:71, loss:0.00001, loss_test:0.02040, lr:5.16e-02, fs:0.81437 (r=0.782,p=0.850),  time:41.703, tt:3002.599\n",
      "Ep:72, loss:0.00001, loss_test:0.02030, lr:5.11e-02, fs:0.80488 (r=0.759,p=0.857),  time:41.712, tt:3044.969\n",
      "Ep:73, loss:0.00001, loss_test:0.02073, lr:5.06e-02, fs:0.81212 (r=0.770,p=0.859),  time:41.710, tt:3086.507\n",
      "Ep:74, loss:0.00001, loss_test:0.02092, lr:5.01e-02, fs:0.81212 (r=0.770,p=0.859),  time:41.713, tt:3128.438\n",
      "Ep:75, loss:0.00001, loss_test:0.02101, lr:4.96e-02, fs:0.81212 (r=0.770,p=0.859),  time:41.720, tt:3170.689\n",
      "Ep:76, loss:0.00001, loss_test:0.02114, lr:4.91e-02, fs:0.81212 (r=0.770,p=0.859),  time:41.728, tt:3213.068\n",
      "Ep:77, loss:0.00001, loss_test:0.02113, lr:4.86e-02, fs:0.80488 (r=0.759,p=0.857),  time:41.726, tt:3254.615\n",
      "Ep:78, loss:0.00001, loss_test:0.02159, lr:4.81e-02, fs:0.81212 (r=0.770,p=0.859),  time:41.706, tt:3294.766\n",
      "Ep:79, loss:0.00001, loss_test:0.02148, lr:4.76e-02, fs:0.80488 (r=0.759,p=0.857),  time:41.705, tt:3336.438\n",
      "Ep:80, loss:0.00001, loss_test:0.02179, lr:4.71e-02, fs:0.80488 (r=0.759,p=0.857),  time:41.720, tt:3379.333\n",
      "Ep:81, loss:0.00001, loss_test:0.02196, lr:4.67e-02, fs:0.81212 (r=0.770,p=0.859),  time:41.718, tt:3420.886\n",
      "Ep:82, loss:0.00001, loss_test:0.02181, lr:4.62e-02, fs:0.80488 (r=0.759,p=0.857),  time:41.717, tt:3462.521\n",
      "Ep:83, loss:0.00001, loss_test:0.02209, lr:4.57e-02, fs:0.81212 (r=0.770,p=0.859),  time:41.714, tt:3503.964\n",
      "Ep:84, loss:0.00001, loss_test:0.02217, lr:4.53e-02, fs:0.81707 (r=0.770,p=0.870),  time:41.708, tt:3545.195\n",
      "Ep:85, loss:0.00001, loss_test:0.02219, lr:4.48e-02, fs:0.80982 (r=0.759,p=0.868),  time:41.731, tt:3588.901\n",
      "Ep:86, loss:0.00001, loss_test:0.02251, lr:4.44e-02, fs:0.81707 (r=0.770,p=0.870),  time:41.724, tt:3629.957\n",
      "Ep:87, loss:0.00001, loss_test:0.02248, lr:4.39e-02, fs:0.80982 (r=0.759,p=0.868),  time:41.723, tt:3671.635\n",
      "Ep:88, loss:0.00001, loss_test:0.02270, lr:4.35e-02, fs:0.80982 (r=0.759,p=0.868),  time:41.727, tt:3713.686\n",
      "Ep:89, loss:0.00001, loss_test:0.02274, lr:4.31e-02, fs:0.80982 (r=0.759,p=0.868),  time:41.734, tt:3756.016\n",
      "Ep:90, loss:0.00001, loss_test:0.02284, lr:4.26e-02, fs:0.80982 (r=0.759,p=0.868),  time:41.745, tt:3798.823\n",
      "Ep:91, loss:0.00001, loss_test:0.02316, lr:4.22e-02, fs:0.81707 (r=0.770,p=0.870),  time:41.756, tt:3841.586\n",
      "Ep:92, loss:0.00001, loss_test:0.02305, lr:4.18e-02, fs:0.80982 (r=0.759,p=0.868),  time:41.756, tt:3883.337\n",
      "Ep:93, loss:0.00001, loss_test:0.02338, lr:4.14e-02, fs:0.82209 (r=0.770,p=0.882),  time:41.757, tt:3925.127\n",
      "Ep:94, loss:0.00001, loss_test:0.02327, lr:4.10e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.748, tt:3966.070\n",
      "Ep:95, loss:0.00001, loss_test:0.02357, lr:4.05e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.735, tt:4006.541\n",
      "Ep:96, loss:0.00001, loss_test:0.02361, lr:4.01e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.730, tt:4047.767\n",
      "Ep:97, loss:0.00001, loss_test:0.02357, lr:3.97e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.728, tt:4089.374\n",
      "Ep:98, loss:0.00001, loss_test:0.02386, lr:3.93e-02, fs:0.82716 (r=0.770,p=0.893),  time:41.726, tt:4130.841\n",
      "Ep:99, loss:0.00001, loss_test:0.02388, lr:3.89e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.744, tt:4174.445\n",
      "Ep:100, loss:0.00001, loss_test:0.02392, lr:3.86e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.749, tt:4216.657\n",
      "Ep:101, loss:0.00001, loss_test:0.02415, lr:3.82e-02, fs:0.82716 (r=0.770,p=0.893),  time:41.762, tt:4259.765\n",
      "Ep:102, loss:0.00001, loss_test:0.02407, lr:3.78e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.788, tt:4304.128\n",
      "Ep:103, loss:0.00001, loss_test:0.02438, lr:3.74e-02, fs:0.82716 (r=0.770,p=0.893),  time:41.792, tt:4346.322\n",
      "Ep:104, loss:0.00001, loss_test:0.02437, lr:3.70e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.791, tt:4388.058\n",
      "Ep:105, loss:0.00001, loss_test:0.02437, lr:3.67e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.807, tt:4431.577\n",
      "Ep:106, loss:0.00001, loss_test:0.02462, lr:3.63e-02, fs:0.82716 (r=0.770,p=0.893),  time:41.794, tt:4471.928\n",
      "Ep:107, loss:0.00001, loss_test:0.02464, lr:3.59e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.787, tt:4512.972\n",
      "Ep:108, loss:0.00001, loss_test:0.02475, lr:3.56e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.779, tt:4553.964\n",
      "Ep:109, loss:0.00001, loss_test:0.02482, lr:3.52e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.759, tt:4593.480\n",
      "Ep:110, loss:0.00000, loss_test:0.02503, lr:3.49e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.754, tt:4634.699\n",
      "Ep:111, loss:0.00000, loss_test:0.02494, lr:3.45e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.741, tt:4674.972\n",
      "Ep:112, loss:0.00000, loss_test:0.02503, lr:3.42e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.745, tt:4717.140\n",
      "Ep:113, loss:0.00000, loss_test:0.02528, lr:3.38e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.742, tt:4758.587\n",
      "Ep:114, loss:0.00000, loss_test:0.02532, lr:3.35e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.739, tt:4799.934\n",
      "Ep:115, loss:0.00000, loss_test:0.02535, lr:3.32e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.745, tt:4842.461\n",
      "Ep:116, loss:0.00000, loss_test:0.02534, lr:3.28e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.750, tt:4884.704\n",
      "Ep:117, loss:0.00000, loss_test:0.02561, lr:3.25e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.738, tt:4925.106\n",
      "Ep:118, loss:0.00000, loss_test:0.02543, lr:3.22e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.747, tt:4967.853\n",
      "Ep:119, loss:0.00000, loss_test:0.02561, lr:3.19e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.733, tt:5007.911\n",
      "Ep:120, loss:0.00000, loss_test:0.02582, lr:3.15e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.739, tt:5050.414\n",
      "Ep:121, loss:0.00000, loss_test:0.02581, lr:3.12e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.745, tt:5092.885\n",
      "Ep:122, loss:0.00000, loss_test:0.02588, lr:3.09e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.744, tt:5134.528\n",
      "Ep:123, loss:0.00000, loss_test:0.02600, lr:3.06e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.728, tt:5174.218\n",
      "Ep:124, loss:0.00000, loss_test:0.02603, lr:3.03e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.732, tt:5216.454\n",
      "Ep:125, loss:0.00000, loss_test:0.02603, lr:3.00e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.728, tt:5257.693\n",
      "Ep:126, loss:0.00000, loss_test:0.02623, lr:2.97e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.718, tt:5298.172\n",
      "Ep:127, loss:0.00000, loss_test:0.02632, lr:2.94e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.708, tt:5338.658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:128, loss:0.00000, loss_test:0.02627, lr:2.91e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.709, tt:5380.465\n",
      "Ep:129, loss:0.00000, loss_test:0.02634, lr:2.88e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.702, tt:5421.286\n",
      "Ep:130, loss:0.00000, loss_test:0.02649, lr:2.85e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.688, tt:5461.105\n",
      "Ep:131, loss:0.00000, loss_test:0.02645, lr:2.82e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.686, tt:5502.560\n",
      "Ep:132, loss:0.00000, loss_test:0.02670, lr:2.80e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.674, tt:5542.612\n",
      "Ep:133, loss:0.00000, loss_test:0.02660, lr:2.77e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.667, tt:5583.387\n",
      "Ep:134, loss:0.00000, loss_test:0.02669, lr:2.74e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.678, tt:5626.562\n",
      "Ep:135, loss:0.00000, loss_test:0.02686, lr:2.71e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.671, tt:5667.234\n",
      "Ep:136, loss:0.00000, loss_test:0.02669, lr:2.69e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.663, tt:5707.819\n",
      "Ep:137, loss:0.00000, loss_test:0.02684, lr:2.66e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.661, tt:5749.166\n",
      "Ep:138, loss:0.00000, loss_test:0.02706, lr:2.63e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.668, tt:5791.786\n",
      "Ep:139, loss:0.00000, loss_test:0.02687, lr:2.61e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.668, tt:5833.542\n",
      "Ep:140, loss:0.00000, loss_test:0.02715, lr:2.58e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.668, tt:5875.224\n",
      "Ep:141, loss:0.00000, loss_test:0.02729, lr:2.55e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.664, tt:5916.332\n",
      "Ep:142, loss:0.00000, loss_test:0.02709, lr:2.53e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.688, tt:5961.358\n",
      "Ep:143, loss:0.00000, loss_test:0.02732, lr:2.50e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.681, tt:6002.096\n",
      "Ep:144, loss:0.00000, loss_test:0.02724, lr:2.48e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.682, tt:6043.851\n",
      "Ep:145, loss:0.00000, loss_test:0.02729, lr:2.45e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.693, tt:6087.194\n",
      "Ep:146, loss:0.00000, loss_test:0.02740, lr:2.43e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.708, tt:6131.112\n",
      "Ep:147, loss:0.00000, loss_test:0.02742, lr:2.40e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.707, tt:6172.584\n",
      "Ep:148, loss:0.00000, loss_test:0.02745, lr:2.38e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.706, tt:6214.168\n",
      "Ep:149, loss:0.00000, loss_test:0.02760, lr:2.36e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.704, tt:6255.660\n",
      "Ep:150, loss:0.00000, loss_test:0.02749, lr:2.33e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.714, tt:6298.823\n",
      "Ep:151, loss:0.00000, loss_test:0.02775, lr:2.31e-02, fs:0.81988 (r=0.759,p=0.892),  time:41.718, tt:6341.159\n",
      "Ep:152, loss:0.00000, loss_test:0.02778, lr:2.29e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.720, tt:6383.183\n",
      "Ep:153, loss:0.00000, loss_test:0.02769, lr:2.26e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.724, tt:6425.510\n",
      "Ep:154, loss:0.00000, loss_test:0.02788, lr:2.24e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.741, tt:6469.794\n",
      "Ep:155, loss:0.00000, loss_test:0.02781, lr:2.22e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.738, tt:6511.157\n",
      "Ep:156, loss:0.00000, loss_test:0.02776, lr:2.20e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.752, tt:6555.035\n",
      "Ep:157, loss:0.00000, loss_test:0.02794, lr:2.17e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.772, tt:6599.951\n",
      "Ep:158, loss:0.00000, loss_test:0.02798, lr:2.15e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.785, tt:6643.869\n",
      "Ep:159, loss:0.00000, loss_test:0.02790, lr:2.13e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.802, tt:6688.276\n",
      "Ep:160, loss:0.00000, loss_test:0.02816, lr:2.11e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.804, tt:6730.419\n",
      "Ep:161, loss:0.00000, loss_test:0.02808, lr:2.09e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.819, tt:6774.689\n",
      "Ep:162, loss:0.00000, loss_test:0.02812, lr:2.07e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.838, tt:6819.605\n",
      "Ep:163, loss:0.00000, loss_test:0.02819, lr:2.05e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.843, tt:6862.193\n",
      "Ep:164, loss:0.00000, loss_test:0.02815, lr:2.03e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.847, tt:6904.745\n",
      "Ep:165, loss:0.00000, loss_test:0.02826, lr:2.01e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.870, tt:6950.436\n",
      "Ep:166, loss:0.00000, loss_test:0.02830, lr:1.99e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.876, tt:6993.223\n",
      "Ep:167, loss:0.00000, loss_test:0.02834, lr:1.97e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.872, tt:7034.481\n",
      "Ep:168, loss:0.00000, loss_test:0.02827, lr:1.95e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.870, tt:7076.011\n",
      "Ep:169, loss:0.00000, loss_test:0.02840, lr:1.93e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.872, tt:7118.275\n",
      "Ep:170, loss:0.00000, loss_test:0.02848, lr:1.91e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.872, tt:7160.114\n",
      "Ep:171, loss:0.00000, loss_test:0.02844, lr:1.89e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.867, tt:7201.192\n",
      "Ep:172, loss:0.00000, loss_test:0.02848, lr:1.87e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.862, tt:7242.085\n",
      "Ep:173, loss:0.00000, loss_test:0.02862, lr:1.85e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.871, tt:7285.616\n",
      "Ep:174, loss:0.00000, loss_test:0.02855, lr:1.83e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.878, tt:7328.672\n",
      "Ep:175, loss:0.00000, loss_test:0.02853, lr:1.81e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.865, tt:7368.191\n",
      "Ep:176, loss:0.00000, loss_test:0.02867, lr:1.80e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.860, tt:7409.142\n",
      "Ep:177, loss:0.00000, loss_test:0.02865, lr:1.78e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.846, tt:7448.524\n",
      "Ep:178, loss:0.00000, loss_test:0.02861, lr:1.76e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.838, tt:7489.089\n",
      "Ep:179, loss:0.00000, loss_test:0.02872, lr:1.74e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.830, tt:7529.475\n",
      "Ep:180, loss:0.00000, loss_test:0.02872, lr:1.73e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.839, tt:7572.939\n",
      "Ep:181, loss:0.00000, loss_test:0.02878, lr:1.71e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.837, tt:7614.378\n",
      "Ep:182, loss:0.00000, loss_test:0.02890, lr:1.69e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.838, tt:7656.328\n",
      "Ep:183, loss:0.00000, loss_test:0.02879, lr:1.67e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.836, tt:7697.904\n",
      "Ep:184, loss:0.00000, loss_test:0.02878, lr:1.66e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.831, tt:7738.728\n",
      "Ep:185, loss:0.00000, loss_test:0.02894, lr:1.64e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.823, tt:7779.141\n",
      "Ep:186, loss:0.00000, loss_test:0.02891, lr:1.62e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.824, tt:7821.163\n",
      "Ep:187, loss:0.00000, loss_test:0.02888, lr:1.61e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.823, tt:7862.805\n",
      "Ep:188, loss:0.00000, loss_test:0.02896, lr:1.59e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.824, tt:7904.764\n",
      "Ep:189, loss:0.00000, loss_test:0.02906, lr:1.58e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.822, tt:7946.203\n",
      "Ep:190, loss:0.00000, loss_test:0.02901, lr:1.56e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.837, tt:7990.910\n",
      "Ep:191, loss:0.00000, loss_test:0.02898, lr:1.54e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.844, tt:8033.960\n",
      "Ep:192, loss:0.00000, loss_test:0.02909, lr:1.53e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.848, tt:8076.608\n",
      "Ep:193, loss:0.00000, loss_test:0.02911, lr:1.51e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.854, tt:8119.718\n",
      "Ep:194, loss:0.00000, loss_test:0.02904, lr:1.50e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.857, tt:8162.030\n",
      "Ep:195, loss:0.00000, loss_test:0.02913, lr:1.48e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.868, tt:8206.208\n",
      "Ep:196, loss:0.00000, loss_test:0.02920, lr:1.47e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.873, tt:8248.919\n",
      "Ep:197, loss:0.00000, loss_test:0.02918, lr:1.45e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.871, tt:8290.417\n",
      "Ep:198, loss:0.00000, loss_test:0.02923, lr:1.44e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.870, tt:8332.168\n",
      "Ep:199, loss:0.00000, loss_test:0.02926, lr:1.43e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.866, tt:8373.160\n",
      "Ep:200, loss:0.00000, loss_test:0.02923, lr:1.41e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.861, tt:8414.006\n",
      "Ep:201, loss:0.00000, loss_test:0.02922, lr:1.40e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.855, tt:8454.649\n",
      "Ep:202, loss:0.00000, loss_test:0.02933, lr:1.38e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.860, tt:8497.546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:203, loss:0.00000, loss_test:0.02934, lr:1.37e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.869, tt:8541.284\n",
      "Ep:204, loss:0.00000, loss_test:0.02937, lr:1.36e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.881, tt:8585.588\n",
      "Ep:205, loss:0.00000, loss_test:0.02936, lr:1.34e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.879, tt:8627.138\n",
      "Ep:206, loss:0.00000, loss_test:0.02939, lr:1.33e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.900, tt:8673.262\n",
      "Ep:207, loss:0.00000, loss_test:0.02941, lr:1.32e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.897, tt:8714.597\n",
      "Ep:208, loss:0.00000, loss_test:0.02941, lr:1.30e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.896, tt:8756.363\n",
      "Ep:209, loss:0.00000, loss_test:0.02945, lr:1.29e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.891, tt:8797.061\n",
      "Ep:210, loss:0.00000, loss_test:0.02944, lr:1.28e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.882, tt:8837.017\n",
      "Ep:211, loss:0.00000, loss_test:0.02945, lr:1.26e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.877, tt:8877.971\n",
      "Ep:212, loss:0.00000, loss_test:0.02949, lr:1.25e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.833, tt:8910.439\n",
      "Ep:213, loss:0.00000, loss_test:0.02954, lr:1.24e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.797, tt:8944.566\n",
      "Ep:214, loss:0.00000, loss_test:0.02956, lr:1.23e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.772, tt:8980.902\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14392, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.339, tt:37.339\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14294, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.360, tt:80.720\n",
      "Ep:2, loss:0.00028, loss_test:0.14124, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.374, tt:121.121\n",
      "Ep:3, loss:0.00027, loss_test:0.13852, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.556, tt:162.224\n",
      "Ep:4, loss:0.00027, loss_test:0.13437, lr:1.00e-02, fs:0.66667 (r=0.989,p=0.503),  time:40.578, tt:202.888\n",
      "Ep:5, loss:0.00026, loss_test:0.12800, lr:1.00e-02, fs:0.68548 (r=0.977,p=0.528),  time:41.042, tt:246.252\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.12033, lr:1.00e-02, fs:0.65403 (r=0.793,p=0.556),  time:41.328, tt:289.294\n",
      "Ep:7, loss:0.00023, loss_test:0.11550, lr:1.00e-02, fs:0.67021 (r=0.724,p=0.624),  time:41.245, tt:329.962\n",
      "Ep:8, loss:0.00022, loss_test:0.11278, lr:1.00e-02, fs:0.67391 (r=0.713,p=0.639),  time:41.336, tt:372.025\n",
      "Ep:9, loss:0.00022, loss_test:0.11063, lr:1.00e-02, fs:0.72821 (r=0.816,p=0.657),  time:41.512, tt:415.124\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.10824, lr:1.00e-02, fs:0.72821 (r=0.816,p=0.657),  time:41.705, tt:458.752\n",
      "Ep:11, loss:0.00020, loss_test:0.10603, lr:1.00e-02, fs:0.72527 (r=0.759,p=0.695),  time:42.309, tt:507.711\n",
      "Ep:12, loss:0.00020, loss_test:0.10420, lr:1.00e-02, fs:0.72727 (r=0.736,p=0.719),  time:42.415, tt:551.389\n",
      "Ep:13, loss:0.00019, loss_test:0.10248, lr:1.00e-02, fs:0.73988 (r=0.736,p=0.744),  time:42.362, tt:593.068\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.10087, lr:1.00e-02, fs:0.75706 (r=0.770,p=0.744),  time:42.456, tt:636.835\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.09829, lr:1.00e-02, fs:0.77457 (r=0.770,p=0.779),  time:42.468, tt:679.493\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.09523, lr:1.00e-02, fs:0.79310 (r=0.793,p=0.793),  time:42.632, tt:724.749\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.09309, lr:1.00e-02, fs:0.80447 (r=0.828,p=0.783),  time:42.712, tt:768.820\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00016, loss_test:0.09140, lr:1.00e-02, fs:0.79532 (r=0.782,p=0.810),  time:42.693, tt:811.163\n",
      "Ep:19, loss:0.00015, loss_test:0.08857, lr:1.00e-02, fs:0.82759 (r=0.828,p=0.828),  time:42.829, tt:856.586\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00015, loss_test:0.08644, lr:1.00e-02, fs:0.83616 (r=0.851,p=0.822),  time:42.854, tt:899.930\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00014, loss_test:0.08509, lr:1.00e-02, fs:0.84571 (r=0.851,p=0.841),  time:42.898, tt:943.761\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00014, loss_test:0.08295, lr:1.00e-02, fs:0.84746 (r=0.862,p=0.833),  time:42.958, tt:988.036\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00013, loss_test:0.08151, lr:1.00e-02, fs:0.83721 (r=0.828,p=0.847),  time:42.896, tt:1029.508\n",
      "Ep:24, loss:0.00013, loss_test:0.08047, lr:1.00e-02, fs:0.84393 (r=0.839,p=0.849),  time:42.923, tt:1073.078\n",
      "Ep:25, loss:0.00012, loss_test:0.07971, lr:1.00e-02, fs:0.84024 (r=0.816,p=0.866),  time:42.939, tt:1116.418\n",
      "Ep:26, loss:0.00012, loss_test:0.07885, lr:1.00e-02, fs:0.84884 (r=0.839,p=0.859),  time:42.923, tt:1158.919\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00011, loss_test:0.07798, lr:1.00e-02, fs:0.86228 (r=0.828,p=0.900),  time:42.931, tt:1202.081\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00011, loss_test:0.07704, lr:1.00e-02, fs:0.86364 (r=0.874,p=0.854),  time:42.899, tt:1244.080\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00011, loss_test:0.07761, lr:1.00e-02, fs:0.87425 (r=0.839,p=0.912),  time:42.916, tt:1287.487\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00010, loss_test:0.07712, lr:1.00e-02, fs:0.88506 (r=0.885,p=0.885),  time:42.996, tt:1332.873\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00010, loss_test:0.07709, lr:1.00e-02, fs:0.89535 (r=0.885,p=0.906),  time:43.039, tt:1377.252\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00009, loss_test:0.07645, lr:1.00e-02, fs:0.90058 (r=0.885,p=0.917),  time:43.068, tt:1421.253\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00009, loss_test:0.07653, lr:1.00e-02, fs:0.88636 (r=0.897,p=0.876),  time:43.096, tt:1465.277\n",
      "Ep:34, loss:0.00009, loss_test:0.07520, lr:1.00e-02, fs:0.90058 (r=0.885,p=0.917),  time:43.134, tt:1509.706\n",
      "Ep:35, loss:0.00008, loss_test:0.07523, lr:1.00e-02, fs:0.89143 (r=0.897,p=0.886),  time:43.142, tt:1553.098\n",
      "Ep:36, loss:0.00008, loss_test:0.07464, lr:1.00e-02, fs:0.89655 (r=0.897,p=0.897),  time:43.099, tt:1594.653\n",
      "Ep:37, loss:0.00008, loss_test:0.07570, lr:1.00e-02, fs:0.92308 (r=0.897,p=0.951),  time:43.069, tt:1636.621\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00008, loss_test:0.07565, lr:1.00e-02, fs:0.88764 (r=0.908,p=0.868),  time:43.091, tt:1680.536\n",
      "Ep:39, loss:0.00007, loss_test:0.07500, lr:1.00e-02, fs:0.91124 (r=0.885,p=0.939),  time:43.082, tt:1723.263\n",
      "Ep:40, loss:0.00007, loss_test:0.07382, lr:1.00e-02, fs:0.89655 (r=0.897,p=0.897),  time:43.027, tt:1764.115\n",
      "Ep:41, loss:0.00007, loss_test:0.07350, lr:1.00e-02, fs:0.92398 (r=0.908,p=0.940),  time:43.011, tt:1806.472\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00006, loss_test:0.07481, lr:1.00e-02, fs:0.91765 (r=0.897,p=0.940),  time:43.014, tt:1849.605\n",
      "Ep:43, loss:0.00006, loss_test:0.07359, lr:1.00e-02, fs:0.92486 (r=0.920,p=0.930),  time:42.971, tt:1890.712\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00006, loss_test:0.07446, lr:1.00e-02, fs:0.92857 (r=0.897,p=0.963),  time:42.965, tt:1933.435\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00005, loss_test:0.07281, lr:1.00e-02, fs:0.90909 (r=0.920,p=0.899),  time:42.934, tt:1974.966\n",
      "Ep:46, loss:0.00005, loss_test:0.07616, lr:1.00e-02, fs:0.91566 (r=0.874,p=0.962),  time:42.919, tt:2017.199\n",
      "Ep:47, loss:0.00005, loss_test:0.07654, lr:1.00e-02, fs:0.92308 (r=0.897,p=0.951),  time:42.911, tt:2059.735\n",
      "Ep:48, loss:0.00005, loss_test:0.07796, lr:1.00e-02, fs:0.86957 (r=0.805,p=0.946),  time:42.878, tt:2101.037\n",
      "Ep:49, loss:0.00005, loss_test:0.07845, lr:1.00e-02, fs:0.90244 (r=0.851,p=0.961),  time:42.830, tt:2141.484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:50, loss:0.00005, loss_test:0.07467, lr:1.00e-02, fs:0.93023 (r=0.920,p=0.941),  time:42.799, tt:2182.754\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00004, loss_test:0.07915, lr:1.00e-02, fs:0.84810 (r=0.770,p=0.944),  time:42.736, tt:2222.294\n",
      "Ep:52, loss:0.00004, loss_test:0.07699, lr:1.00e-02, fs:0.93491 (r=0.908,p=0.963),  time:42.709, tt:2263.594\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00004, loss_test:0.08256, lr:1.00e-02, fs:0.82803 (r=0.747,p=0.929),  time:42.642, tt:2302.657\n",
      "Ep:54, loss:0.00004, loss_test:0.07908, lr:1.00e-02, fs:0.90588 (r=0.885,p=0.928),  time:42.585, tt:2342.165\n",
      "Ep:55, loss:0.00004, loss_test:0.08443, lr:1.00e-02, fs:0.84615 (r=0.759,p=0.957),  time:42.518, tt:2381.032\n",
      "Ep:56, loss:0.00004, loss_test:0.08049, lr:1.00e-02, fs:0.85350 (r=0.770,p=0.957),  time:42.457, tt:2420.023\n",
      "Ep:57, loss:0.00004, loss_test:0.08640, lr:1.00e-02, fs:0.82895 (r=0.724,p=0.969),  time:42.431, tt:2460.991\n",
      "Ep:58, loss:0.00003, loss_test:0.08337, lr:1.00e-02, fs:0.84615 (r=0.759,p=0.957),  time:42.429, tt:2503.302\n",
      "Ep:59, loss:0.00003, loss_test:0.08278, lr:1.00e-02, fs:0.85350 (r=0.770,p=0.957),  time:42.425, tt:2545.500\n",
      "Ep:60, loss:0.00003, loss_test:0.08448, lr:1.00e-02, fs:0.83660 (r=0.736,p=0.970),  time:42.425, tt:2587.935\n",
      "Ep:61, loss:0.00003, loss_test:0.08212, lr:1.00e-02, fs:0.83871 (r=0.747,p=0.956),  time:42.408, tt:2629.311\n",
      "Ep:62, loss:0.00003, loss_test:0.08570, lr:1.00e-02, fs:0.84416 (r=0.747,p=0.970),  time:42.434, tt:2673.325\n",
      "Ep:63, loss:0.00003, loss_test:0.08287, lr:1.00e-02, fs:0.85897 (r=0.770,p=0.971),  time:42.431, tt:2715.562\n",
      "Ep:64, loss:0.00002, loss_test:0.08565, lr:9.90e-03, fs:0.83660 (r=0.736,p=0.970),  time:42.432, tt:2758.070\n",
      "Ep:65, loss:0.00002, loss_test:0.08209, lr:9.80e-03, fs:0.86792 (r=0.793,p=0.958),  time:42.427, tt:2800.155\n",
      "Ep:66, loss:0.00002, loss_test:0.08686, lr:9.70e-03, fs:0.83660 (r=0.736,p=0.970),  time:42.438, tt:2843.354\n",
      "Ep:67, loss:0.00002, loss_test:0.08327, lr:9.61e-03, fs:0.85350 (r=0.770,p=0.957),  time:42.472, tt:2888.073\n",
      "Ep:68, loss:0.00002, loss_test:0.08641, lr:9.51e-03, fs:0.78082 (r=0.655,p=0.966),  time:42.515, tt:2933.543\n",
      "Ep:69, loss:0.00002, loss_test:0.08690, lr:9.41e-03, fs:0.83660 (r=0.736,p=0.970),  time:42.529, tt:2977.038\n",
      "Ep:70, loss:0.00002, loss_test:0.08435, lr:9.32e-03, fs:0.83660 (r=0.736,p=0.970),  time:42.542, tt:3020.470\n",
      "Ep:71, loss:0.00002, loss_test:0.08738, lr:9.23e-03, fs:0.83660 (r=0.736,p=0.970),  time:42.529, tt:3062.094\n",
      "Ep:72, loss:0.00002, loss_test:0.08334, lr:9.14e-03, fs:0.83660 (r=0.736,p=0.970),  time:42.529, tt:3104.625\n",
      "Ep:73, loss:0.00002, loss_test:0.08472, lr:9.04e-03, fs:0.83660 (r=0.736,p=0.970),  time:42.557, tt:3149.200\n",
      "Ep:74, loss:0.00002, loss_test:0.08628, lr:8.95e-03, fs:0.83660 (r=0.736,p=0.970),  time:42.539, tt:3190.399\n",
      "Ep:75, loss:0.00001, loss_test:0.08488, lr:8.86e-03, fs:0.83660 (r=0.736,p=0.970),  time:42.535, tt:3232.675\n",
      "Ep:76, loss:0.00001, loss_test:0.08554, lr:8.78e-03, fs:0.83660 (r=0.736,p=0.970),  time:42.553, tt:3276.599\n",
      "Ep:77, loss:0.00001, loss_test:0.08554, lr:8.69e-03, fs:0.82895 (r=0.724,p=0.969),  time:42.563, tt:3319.914\n",
      "Ep:78, loss:0.00001, loss_test:0.08533, lr:8.60e-03, fs:0.83660 (r=0.736,p=0.970),  time:42.614, tt:3366.505\n",
      "Ep:79, loss:0.00001, loss_test:0.08809, lr:8.51e-03, fs:0.82119 (r=0.713,p=0.969),  time:42.633, tt:3410.671\n",
      "Ep:80, loss:0.00001, loss_test:0.08626, lr:8.43e-03, fs:0.83660 (r=0.736,p=0.970),  time:42.618, tt:3452.095\n",
      "Ep:81, loss:0.00001, loss_test:0.08509, lr:8.35e-03, fs:0.82895 (r=0.724,p=0.969),  time:42.646, tt:3496.945\n",
      "Ep:82, loss:0.00001, loss_test:0.08579, lr:8.26e-03, fs:0.83660 (r=0.736,p=0.970),  time:42.640, tt:3539.147\n",
      "Ep:83, loss:0.00001, loss_test:0.08711, lr:8.18e-03, fs:0.82119 (r=0.713,p=0.969),  time:42.670, tt:3584.267\n",
      "Ep:84, loss:0.00001, loss_test:0.08556, lr:8.10e-03, fs:0.82119 (r=0.713,p=0.969),  time:42.692, tt:3628.779\n",
      "Ep:85, loss:0.00001, loss_test:0.08758, lr:8.02e-03, fs:0.81333 (r=0.701,p=0.968),  time:42.689, tt:3671.289\n",
      "Ep:86, loss:0.00001, loss_test:0.08869, lr:7.94e-03, fs:0.82119 (r=0.713,p=0.969),  time:42.672, tt:3712.424\n",
      "Ep:87, loss:0.00001, loss_test:0.08731, lr:7.86e-03, fs:0.81333 (r=0.701,p=0.968),  time:42.651, tt:3753.311\n",
      "Ep:88, loss:0.00001, loss_test:0.08720, lr:7.78e-03, fs:0.82119 (r=0.713,p=0.969),  time:42.650, tt:3795.846\n",
      "Ep:89, loss:0.00001, loss_test:0.08914, lr:7.70e-03, fs:0.76389 (r=0.632,p=0.965),  time:42.651, tt:3838.626\n",
      "Ep:90, loss:0.00001, loss_test:0.08852, lr:7.62e-03, fs:0.81333 (r=0.701,p=0.968),  time:42.631, tt:3879.393\n",
      "Ep:91, loss:0.00001, loss_test:0.08832, lr:7.55e-03, fs:0.80537 (r=0.690,p=0.968),  time:42.619, tt:3920.928\n",
      "Ep:92, loss:0.00001, loss_test:0.08653, lr:7.47e-03, fs:0.82119 (r=0.713,p=0.969),  time:42.596, tt:3961.420\n",
      "Ep:93, loss:0.00001, loss_test:0.09012, lr:7.40e-03, fs:0.80537 (r=0.690,p=0.968),  time:42.589, tt:4003.398\n",
      "Ep:94, loss:0.00001, loss_test:0.08788, lr:7.32e-03, fs:0.77241 (r=0.644,p=0.966),  time:42.588, tt:4045.828\n",
      "Ep:95, loss:0.00001, loss_test:0.09030, lr:7.25e-03, fs:0.81333 (r=0.701,p=0.968),  time:42.564, tt:4086.154\n",
      "Ep:96, loss:0.00001, loss_test:0.08817, lr:7.18e-03, fs:0.78082 (r=0.655,p=0.966),  time:42.548, tt:4127.157\n",
      "Ep:97, loss:0.00001, loss_test:0.09007, lr:7.11e-03, fs:0.79730 (r=0.678,p=0.967),  time:42.542, tt:4169.148\n",
      "Ep:98, loss:0.00001, loss_test:0.08958, lr:7.03e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.535, tt:4211.007\n",
      "Ep:99, loss:0.00001, loss_test:0.08865, lr:6.96e-03, fs:0.80537 (r=0.690,p=0.968),  time:42.516, tt:4251.566\n",
      "Ep:100, loss:0.00001, loss_test:0.08860, lr:6.89e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.495, tt:4291.981\n",
      "Ep:101, loss:0.00001, loss_test:0.09133, lr:6.83e-03, fs:0.79730 (r=0.678,p=0.967),  time:42.465, tt:4331.470\n",
      "Ep:102, loss:0.00001, loss_test:0.08908, lr:6.76e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.468, tt:4374.228\n",
      "Ep:103, loss:0.00001, loss_test:0.09060, lr:6.69e-03, fs:0.78082 (r=0.655,p=0.966),  time:42.457, tt:4415.579\n",
      "Ep:104, loss:0.00001, loss_test:0.08741, lr:6.62e-03, fs:0.79730 (r=0.678,p=0.967),  time:42.444, tt:4456.651\n",
      "Ep:105, loss:0.00001, loss_test:0.08904, lr:6.56e-03, fs:0.79730 (r=0.678,p=0.967),  time:42.392, tt:4493.583\n",
      "Ep:106, loss:0.00001, loss_test:0.08893, lr:6.49e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.402, tt:4537.021\n",
      "Ep:107, loss:0.00000, loss_test:0.08940, lr:6.43e-03, fs:0.78082 (r=0.655,p=0.966),  time:42.392, tt:4578.342\n",
      "Ep:108, loss:0.00000, loss_test:0.08926, lr:6.36e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.394, tt:4620.949\n",
      "Ep:109, loss:0.00000, loss_test:0.08948, lr:6.30e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.391, tt:4663.048\n",
      "Ep:110, loss:0.00000, loss_test:0.08954, lr:6.24e-03, fs:0.79730 (r=0.678,p=0.967),  time:42.364, tt:4702.445\n",
      "Ep:111, loss:0.00000, loss_test:0.08950, lr:6.17e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.345, tt:4742.656\n",
      "Ep:112, loss:0.00000, loss_test:0.08959, lr:6.11e-03, fs:0.80272 (r=0.678,p=0.983),  time:42.329, tt:4783.138\n",
      "Ep:113, loss:0.00000, loss_test:0.09021, lr:6.05e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.325, tt:4825.025\n",
      "Ep:114, loss:0.00000, loss_test:0.08939, lr:5.99e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.310, tt:4865.673\n",
      "Ep:115, loss:0.00000, loss_test:0.08932, lr:5.93e-03, fs:0.79730 (r=0.678,p=0.967),  time:42.304, tt:4907.285\n",
      "Ep:116, loss:0.00000, loss_test:0.08934, lr:5.87e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.296, tt:4948.584\n",
      "Ep:117, loss:0.00000, loss_test:0.09005, lr:5.81e-03, fs:0.79730 (r=0.678,p=0.967),  time:42.281, tt:4989.145\n",
      "Ep:118, loss:0.00000, loss_test:0.08927, lr:5.75e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.281, tt:5031.469\n",
      "Ep:119, loss:0.00000, loss_test:0.08905, lr:5.70e-03, fs:0.77241 (r=0.644,p=0.966),  time:42.283, tt:5073.971\n",
      "Ep:120, loss:0.00000, loss_test:0.08950, lr:5.64e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.266, tt:5114.145\n",
      "Ep:121, loss:0.00000, loss_test:0.08925, lr:5.58e-03, fs:0.76389 (r=0.632,p=0.965),  time:42.271, tt:5157.071\n",
      "Ep:122, loss:0.00000, loss_test:0.08889, lr:5.53e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.250, tt:5196.702\n",
      "Ep:123, loss:0.00000, loss_test:0.09074, lr:5.47e-03, fs:0.77241 (r=0.644,p=0.966),  time:42.237, tt:5237.332\n",
      "Ep:124, loss:0.00000, loss_test:0.09012, lr:5.42e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.225, tt:5278.151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:125, loss:0.00000, loss_test:0.09034, lr:5.36e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.237, tt:5321.873\n",
      "Ep:126, loss:0.00000, loss_test:0.08914, lr:5.31e-03, fs:0.79730 (r=0.678,p=0.967),  time:42.238, tt:5364.278\n",
      "Ep:127, loss:0.00000, loss_test:0.08902, lr:5.26e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.233, tt:5405.877\n",
      "Ep:128, loss:0.00000, loss_test:0.08974, lr:5.20e-03, fs:0.80272 (r=0.678,p=0.983),  time:42.234, tt:5448.209\n",
      "Ep:129, loss:0.00000, loss_test:0.08976, lr:5.15e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.222, tt:5488.848\n",
      "Ep:130, loss:0.00000, loss_test:0.08976, lr:5.10e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.223, tt:5531.227\n",
      "Ep:131, loss:0.00000, loss_test:0.08913, lr:5.05e-03, fs:0.79730 (r=0.678,p=0.967),  time:42.220, tt:5573.019\n",
      "Ep:132, loss:0.00000, loss_test:0.08945, lr:5.00e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.212, tt:5614.138\n",
      "Ep:133, loss:0.00000, loss_test:0.08974, lr:4.95e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.210, tt:5656.136\n",
      "Ep:134, loss:0.00000, loss_test:0.08926, lr:4.90e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.192, tt:5695.987\n",
      "Ep:135, loss:0.00000, loss_test:0.08939, lr:4.85e-03, fs:0.75524 (r=0.621,p=0.964),  time:42.176, tt:5735.997\n",
      "Ep:136, loss:0.00000, loss_test:0.08979, lr:4.80e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.160, tt:5775.921\n",
      "Ep:137, loss:0.00000, loss_test:0.08873, lr:4.75e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.141, tt:5815.487\n",
      "Ep:138, loss:0.00000, loss_test:0.08965, lr:4.71e-03, fs:0.80272 (r=0.678,p=0.983),  time:42.123, tt:5855.138\n",
      "Ep:139, loss:0.00000, loss_test:0.08922, lr:4.66e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.124, tt:5897.410\n",
      "Ep:140, loss:0.00000, loss_test:0.08951, lr:4.61e-03, fs:0.79730 (r=0.678,p=0.967),  time:42.120, tt:5938.982\n",
      "Ep:141, loss:0.00000, loss_test:0.09042, lr:4.57e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.124, tt:5981.561\n",
      "Ep:142, loss:0.00000, loss_test:0.09055, lr:4.52e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.111, tt:6021.887\n",
      "Ep:143, loss:0.00000, loss_test:0.09001, lr:4.48e-03, fs:0.80272 (r=0.678,p=0.983),  time:42.114, tt:6064.394\n",
      "Ep:144, loss:0.00000, loss_test:0.08949, lr:4.43e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.111, tt:6106.159\n",
      "Ep:145, loss:0.00000, loss_test:0.09054, lr:4.39e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.092, tt:6145.361\n",
      "Ep:146, loss:0.00000, loss_test:0.08957, lr:4.34e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.075, tt:6185.097\n",
      "Ep:147, loss:0.00000, loss_test:0.08925, lr:4.30e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.063, tt:6225.343\n",
      "Ep:148, loss:0.00000, loss_test:0.09006, lr:4.26e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.072, tt:6268.666\n",
      "Ep:149, loss:0.00000, loss_test:0.09005, lr:4.21e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.086, tt:6312.953\n",
      "Ep:150, loss:0.00000, loss_test:0.08884, lr:4.17e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.077, tt:6353.656\n",
      "Ep:151, loss:0.00000, loss_test:0.08950, lr:4.13e-03, fs:0.78912 (r=0.667,p=0.967),  time:42.105, tt:6399.971\n",
      "Ep:152, loss:0.00000, loss_test:0.09050, lr:4.09e-03, fs:0.74286 (r=0.598,p=0.981),  time:42.095, tt:6440.580\n",
      "Ep:153, loss:0.00000, loss_test:0.08994, lr:4.05e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.100, tt:6483.404\n",
      "Ep:154, loss:0.00000, loss_test:0.08934, lr:4.01e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.094, tt:6524.575\n",
      "Ep:155, loss:0.00000, loss_test:0.08926, lr:3.97e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.109, tt:6569.070\n",
      "Ep:156, loss:0.00000, loss_test:0.08927, lr:3.93e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.117, tt:6612.302\n",
      "Ep:157, loss:0.00000, loss_test:0.08952, lr:3.89e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.119, tt:6654.832\n",
      "Ep:158, loss:0.00000, loss_test:0.08936, lr:3.85e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.106, tt:6694.902\n",
      "Ep:159, loss:0.00000, loss_test:0.08925, lr:3.81e-03, fs:0.75524 (r=0.621,p=0.964),  time:42.108, tt:6737.270\n",
      "Ep:160, loss:0.00000, loss_test:0.08908, lr:3.77e-03, fs:0.79730 (r=0.678,p=0.967),  time:42.092, tt:6776.740\n",
      "Ep:161, loss:0.00000, loss_test:0.08893, lr:3.73e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.073, tt:6815.894\n",
      "Ep:162, loss:0.00000, loss_test:0.08985, lr:3.70e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.064, tt:6856.440\n",
      "Ep:163, loss:0.00000, loss_test:0.08941, lr:3.66e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.045, tt:6895.372\n",
      "Ep:164, loss:0.00000, loss_test:0.08920, lr:3.62e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.033, tt:6935.436\n",
      "Ep:165, loss:0.00000, loss_test:0.08920, lr:3.59e-03, fs:0.76389 (r=0.632,p=0.965),  time:42.022, tt:6975.671\n",
      "Ep:166, loss:0.00000, loss_test:0.08892, lr:3.55e-03, fs:0.78912 (r=0.667,p=0.967),  time:41.999, tt:7013.890\n",
      "Ep:167, loss:0.00000, loss_test:0.08916, lr:3.52e-03, fs:0.77241 (r=0.644,p=0.966),  time:41.994, tt:7054.930\n",
      "Ep:168, loss:0.00000, loss_test:0.08944, lr:3.48e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.995, tt:7097.100\n",
      "Ep:169, loss:0.00000, loss_test:0.08918, lr:3.45e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.972, tt:7135.267\n",
      "Ep:170, loss:0.00000, loss_test:0.08916, lr:3.41e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.977, tt:7178.059\n",
      "Ep:171, loss:0.00000, loss_test:0.08961, lr:3.38e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.005, tt:7224.918\n",
      "Ep:172, loss:0.00000, loss_test:0.08931, lr:3.34e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.001, tt:7266.124\n",
      "Ep:173, loss:0.00000, loss_test:0.08921, lr:3.31e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.999, tt:7307.899\n",
      "Ep:174, loss:0.00000, loss_test:0.08978, lr:3.28e-03, fs:0.80272 (r=0.678,p=0.983),  time:42.005, tt:7350.865\n",
      "Ep:175, loss:0.00000, loss_test:0.08949, lr:3.24e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.016, tt:7394.837\n",
      "Ep:176, loss:0.00000, loss_test:0.08930, lr:3.21e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.011, tt:7435.912\n",
      "Ep:177, loss:0.00000, loss_test:0.08959, lr:3.18e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.009, tt:7477.580\n",
      "Ep:178, loss:0.00000, loss_test:0.08961, lr:3.15e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.006, tt:7519.006\n",
      "Ep:179, loss:0.00000, loss_test:0.08960, lr:3.12e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.002, tt:7560.409\n",
      "Ep:180, loss:0.00000, loss_test:0.08959, lr:3.09e-03, fs:0.76389 (r=0.632,p=0.965),  time:41.997, tt:7601.504\n",
      "Ep:181, loss:0.00000, loss_test:0.08962, lr:3.05e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.993, tt:7642.811\n",
      "Ep:182, loss:0.00000, loss_test:0.08980, lr:3.02e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.997, tt:7685.384\n",
      "Ep:183, loss:0.00000, loss_test:0.08940, lr:2.99e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.992, tt:7726.577\n",
      "Ep:184, loss:0.00000, loss_test:0.08916, lr:2.96e-03, fs:0.75524 (r=0.621,p=0.964),  time:41.990, tt:7768.184\n",
      "Ep:185, loss:0.00000, loss_test:0.08958, lr:2.93e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.980, tt:7808.250\n",
      "Ep:186, loss:0.00000, loss_test:0.08960, lr:2.90e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.967, tt:7847.828\n",
      "Ep:187, loss:0.00000, loss_test:0.08943, lr:2.88e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.984, tt:7893.054\n",
      "Ep:188, loss:0.00000, loss_test:0.08960, lr:2.85e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.986, tt:7935.429\n",
      "Ep:189, loss:0.00000, loss_test:0.08997, lr:2.82e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.992, tt:7978.443\n",
      "Ep:190, loss:0.00000, loss_test:0.09023, lr:2.79e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.986, tt:8019.368\n",
      "Ep:191, loss:0.00000, loss_test:0.09006, lr:2.76e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.977, tt:8059.490\n",
      "Ep:192, loss:0.00000, loss_test:0.08963, lr:2.73e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.968, tt:8099.881\n",
      "Ep:193, loss:0.00000, loss_test:0.08950, lr:2.71e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.966, tt:8141.483\n",
      "Ep:194, loss:0.00000, loss_test:0.08971, lr:2.68e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.956, tt:8181.332\n",
      "Ep:195, loss:0.00000, loss_test:0.08940, lr:2.65e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.954, tt:8222.985\n",
      "Ep:196, loss:0.00000, loss_test:0.08944, lr:2.63e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.949, tt:8263.940\n",
      "Ep:197, loss:0.00000, loss_test:0.08950, lr:2.60e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.943, tt:8304.631\n",
      "Ep:198, loss:0.00000, loss_test:0.08936, lr:2.57e-03, fs:0.75524 (r=0.621,p=0.964),  time:41.941, tt:8346.285\n",
      "Ep:199, loss:0.00000, loss_test:0.08935, lr:2.55e-03, fs:0.75524 (r=0.621,p=0.964),  time:41.957, tt:8391.377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:200, loss:0.00000, loss_test:0.08955, lr:2.52e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.952, tt:8432.280\n",
      "Ep:201, loss:0.00000, loss_test:0.08965, lr:2.50e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.955, tt:8474.930\n",
      "Ep:202, loss:0.00000, loss_test:0.08966, lr:2.47e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.959, tt:8517.577\n",
      "Ep:203, loss:0.00000, loss_test:0.08979, lr:2.45e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.959, tt:8559.707\n",
      "Ep:204, loss:0.00000, loss_test:0.08967, lr:2.42e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.966, tt:8602.948\n",
      "Ep:205, loss:0.00000, loss_test:0.08933, lr:2.40e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.969, tt:8645.595\n",
      "Ep:206, loss:0.00000, loss_test:0.08941, lr:2.38e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.963, tt:8686.241\n",
      "Ep:207, loss:0.00000, loss_test:0.08968, lr:2.35e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.959, tt:8727.475\n",
      "Ep:208, loss:0.00000, loss_test:0.08956, lr:2.33e-03, fs:0.75177 (r=0.609,p=0.981),  time:41.970, tt:8771.822\n",
      "Ep:209, loss:0.00000, loss_test:0.08937, lr:2.31e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.951, tt:8809.656\n",
      "Ep:210, loss:0.00000, loss_test:0.08957, lr:2.28e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.952, tt:8851.972\n",
      "Ep:211, loss:0.00000, loss_test:0.08967, lr:2.26e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.907, tt:8884.356\n",
      "Ep:212, loss:0.00000, loss_test:0.08968, lr:2.24e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.805, tt:8904.539\n",
      "Ep:213, loss:0.00000, loss_test:0.08956, lr:2.21e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.681, tt:8919.740\n",
      "Ep:214, loss:0.00000, loss_test:0.08938, lr:2.19e-03, fs:0.75524 (r=0.621,p=0.964),  time:41.553, tt:8933.837\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,213,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,213,cv_number,2,False)\n",
    "\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,214,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,214,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,215,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,215,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02050, lr:6.00e-02, fs:0.64493 (r=0.899,p=0.503),  time:28.988, tt:28.988\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02274, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.864, tt:65.728\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02335, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.921, tt:104.762\n",
      "Ep:3, loss:0.00004, loss_test:0.02244, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.760, tt:143.041\n",
      "Ep:4, loss:0.00004, loss_test:0.02088, lr:6.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:36.619, tt:183.096\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.01941, lr:6.00e-02, fs:0.68085 (r=0.970,p=0.525),  time:36.936, tt:221.616\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01868, lr:6.00e-02, fs:0.67692 (r=0.889,p=0.547),  time:37.202, tt:260.417\n",
      "Ep:7, loss:0.00004, loss_test:0.01831, lr:6.00e-02, fs:0.69355 (r=0.869,p=0.577),  time:37.187, tt:297.497\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01788, lr:6.00e-02, fs:0.72308 (r=0.949,p=0.584),  time:37.340, tt:336.064\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01773, lr:6.00e-02, fs:0.72119 (r=0.980,p=0.571),  time:37.696, tt:376.962\n",
      "Ep:10, loss:0.00003, loss_test:0.01755, lr:6.00e-02, fs:0.71852 (r=0.980,p=0.567),  time:37.838, tt:416.213\n",
      "Ep:11, loss:0.00003, loss_test:0.01712, lr:6.00e-02, fs:0.72659 (r=0.980,p=0.577),  time:37.988, tt:455.860\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01672, lr:6.00e-02, fs:0.73282 (r=0.970,p=0.589),  time:38.007, tt:494.088\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01641, lr:6.00e-02, fs:0.76613 (r=0.960,p=0.638),  time:38.028, tt:532.391\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01622, lr:6.00e-02, fs:0.76033 (r=0.929,p=0.643),  time:38.057, tt:570.857\n",
      "Ep:15, loss:0.00003, loss_test:0.01600, lr:6.00e-02, fs:0.76543 (r=0.939,p=0.646),  time:38.099, tt:609.579\n",
      "Ep:16, loss:0.00003, loss_test:0.01582, lr:6.00e-02, fs:0.75918 (r=0.939,p=0.637),  time:38.152, tt:648.587\n",
      "Ep:17, loss:0.00003, loss_test:0.01569, lr:6.00e-02, fs:0.76735 (r=0.949,p=0.644),  time:38.139, tt:686.510\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01554, lr:6.00e-02, fs:0.77686 (r=0.949,p=0.657),  time:38.181, tt:725.432\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01540, lr:6.00e-02, fs:0.78333 (r=0.949,p=0.667),  time:38.129, tt:762.571\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01526, lr:6.00e-02, fs:0.78814 (r=0.939,p=0.679),  time:38.096, tt:800.022\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01514, lr:6.00e-02, fs:0.79487 (r=0.939,p=0.689),  time:38.132, tt:838.913\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01499, lr:6.00e-02, fs:0.79149 (r=0.939,p=0.684),  time:38.180, tt:878.129\n",
      "Ep:23, loss:0.00002, loss_test:0.01481, lr:6.00e-02, fs:0.80000 (r=0.949,p=0.691),  time:38.235, tt:917.632\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01465, lr:6.00e-02, fs:0.79828 (r=0.939,p=0.694),  time:38.296, tt:957.388\n",
      "Ep:25, loss:0.00002, loss_test:0.01451, lr:6.00e-02, fs:0.80342 (r=0.949,p=0.696),  time:38.339, tt:996.807\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01442, lr:6.00e-02, fs:0.80349 (r=0.929,p=0.708),  time:38.283, tt:1033.631\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01430, lr:6.00e-02, fs:0.80349 (r=0.929,p=0.708),  time:38.358, tt:1074.031\n",
      "Ep:28, loss:0.00002, loss_test:0.01417, lr:6.00e-02, fs:0.80349 (r=0.929,p=0.708),  time:38.397, tt:1113.510\n",
      "Ep:29, loss:0.00002, loss_test:0.01408, lr:6.00e-02, fs:0.81057 (r=0.929,p=0.719),  time:38.483, tt:1154.477\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01400, lr:6.00e-02, fs:0.81778 (r=0.929,p=0.730),  time:38.581, tt:1196.019\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01395, lr:6.00e-02, fs:0.82511 (r=0.929,p=0.742),  time:38.642, tt:1236.545\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01386, lr:6.00e-02, fs:0.82883 (r=0.929,p=0.748),  time:38.737, tt:1278.335\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01379, lr:6.00e-02, fs:0.82883 (r=0.929,p=0.748),  time:38.704, tt:1315.919\n",
      "Ep:34, loss:0.00002, loss_test:0.01373, lr:6.00e-02, fs:0.83258 (r=0.929,p=0.754),  time:38.697, tt:1354.407\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01369, lr:6.00e-02, fs:0.83636 (r=0.929,p=0.760),  time:38.763, tt:1395.462\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01360, lr:6.00e-02, fs:0.82727 (r=0.919,p=0.752),  time:38.804, tt:1435.746\n",
      "Ep:37, loss:0.00002, loss_test:0.01357, lr:6.00e-02, fs:0.84018 (r=0.929,p=0.767),  time:38.835, tt:1475.722\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01348, lr:6.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:38.868, tt:1515.860\n",
      "Ep:39, loss:0.00002, loss_test:0.01342, lr:6.00e-02, fs:0.82569 (r=0.909,p=0.756),  time:38.865, tt:1554.599\n",
      "Ep:40, loss:0.00002, loss_test:0.01340, lr:6.00e-02, fs:0.82949 (r=0.909,p=0.763),  time:38.851, tt:1592.880\n",
      "Ep:41, loss:0.00002, loss_test:0.01329, lr:6.00e-02, fs:0.82949 (r=0.909,p=0.763),  time:38.920, tt:1634.646\n",
      "Ep:42, loss:0.00002, loss_test:0.01323, lr:6.00e-02, fs:0.82949 (r=0.909,p=0.763),  time:39.002, tt:1677.102\n",
      "Ep:43, loss:0.00002, loss_test:0.01321, lr:6.00e-02, fs:0.82949 (r=0.909,p=0.763),  time:39.058, tt:1718.558\n",
      "Ep:44, loss:0.00002, loss_test:0.01313, lr:6.00e-02, fs:0.82949 (r=0.909,p=0.763),  time:39.076, tt:1758.428\n",
      "Ep:45, loss:0.00001, loss_test:0.01307, lr:6.00e-02, fs:0.82949 (r=0.909,p=0.763),  time:39.115, tt:1799.310\n",
      "Ep:46, loss:0.00001, loss_test:0.01301, lr:6.00e-02, fs:0.82949 (r=0.909,p=0.763),  time:39.154, tt:1840.235\n",
      "Ep:47, loss:0.00001, loss_test:0.01294, lr:6.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:39.189, tt:1881.059\n",
      "Ep:48, loss:0.00001, loss_test:0.01288, lr:6.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:39.250, tt:1923.245\n",
      "Ep:49, loss:0.00001, loss_test:0.01285, lr:5.94e-02, fs:0.84259 (r=0.919,p=0.778),  time:39.312, tt:1965.624\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01278, lr:5.94e-02, fs:0.84259 (r=0.919,p=0.778),  time:39.358, tt:2007.282\n",
      "Ep:51, loss:0.00001, loss_test:0.01274, lr:5.94e-02, fs:0.85047 (r=0.919,p=0.791),  time:39.394, tt:2048.509\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.01266, lr:5.94e-02, fs:0.84259 (r=0.919,p=0.778),  time:39.455, tt:2091.108\n",
      "Ep:53, loss:0.00001, loss_test:0.01264, lr:5.94e-02, fs:0.85047 (r=0.919,p=0.791),  time:39.479, tt:2131.847\n",
      "Ep:54, loss:0.00001, loss_test:0.01257, lr:5.94e-02, fs:0.85047 (r=0.919,p=0.791),  time:39.494, tt:2172.153\n",
      "Ep:55, loss:0.00001, loss_test:0.01252, lr:5.94e-02, fs:0.85047 (r=0.919,p=0.791),  time:39.524, tt:2213.344\n",
      "Ep:56, loss:0.00001, loss_test:0.01252, lr:5.94e-02, fs:0.86124 (r=0.909,p=0.818),  time:39.520, tt:2252.631\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.01243, lr:5.94e-02, fs:0.84762 (r=0.899,p=0.802),  time:39.528, tt:2292.616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00001, loss_test:0.01236, lr:5.94e-02, fs:0.86124 (r=0.909,p=0.818),  time:39.551, tt:2333.490\n",
      "Ep:59, loss:0.00001, loss_test:0.01237, lr:5.94e-02, fs:0.85577 (r=0.899,p=0.817),  time:39.569, tt:2374.154\n",
      "Ep:60, loss:0.00001, loss_test:0.01233, lr:5.94e-02, fs:0.85577 (r=0.899,p=0.817),  time:39.608, tt:2416.111\n",
      "Ep:61, loss:0.00001, loss_test:0.01233, lr:5.94e-02, fs:0.86408 (r=0.899,p=0.832),  time:39.653, tt:2458.462\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01221, lr:5.94e-02, fs:0.85990 (r=0.899,p=0.824),  time:39.666, tt:2498.967\n",
      "Ep:63, loss:0.00001, loss_test:0.01218, lr:5.94e-02, fs:0.86408 (r=0.899,p=0.832),  time:39.655, tt:2537.905\n",
      "Ep:64, loss:0.00001, loss_test:0.01218, lr:5.94e-02, fs:0.86408 (r=0.899,p=0.832),  time:39.679, tt:2579.112\n",
      "Ep:65, loss:0.00001, loss_test:0.01212, lr:5.94e-02, fs:0.86408 (r=0.899,p=0.832),  time:39.701, tt:2620.275\n",
      "Ep:66, loss:0.00001, loss_test:0.01212, lr:5.94e-02, fs:0.86829 (r=0.899,p=0.840),  time:39.718, tt:2661.113\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01208, lr:5.94e-02, fs:0.86829 (r=0.899,p=0.840),  time:39.704, tt:2699.885\n",
      "Ep:68, loss:0.00001, loss_test:0.01208, lr:5.94e-02, fs:0.87255 (r=0.899,p=0.848),  time:39.722, tt:2740.851\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01198, lr:5.94e-02, fs:0.87805 (r=0.909,p=0.849),  time:39.699, tt:2778.961\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.01200, lr:5.94e-02, fs:0.87255 (r=0.899,p=0.848),  time:39.663, tt:2816.074\n",
      "Ep:71, loss:0.00001, loss_test:0.01200, lr:5.94e-02, fs:0.87255 (r=0.899,p=0.848),  time:39.654, tt:2855.089\n",
      "Ep:72, loss:0.00001, loss_test:0.01197, lr:5.94e-02, fs:0.87255 (r=0.899,p=0.848),  time:39.665, tt:2895.512\n",
      "Ep:73, loss:0.00001, loss_test:0.01194, lr:5.94e-02, fs:0.87255 (r=0.899,p=0.848),  time:39.674, tt:2935.883\n",
      "Ep:74, loss:0.00001, loss_test:0.01191, lr:5.94e-02, fs:0.87255 (r=0.899,p=0.848),  time:39.720, tt:2978.994\n",
      "Ep:75, loss:0.00001, loss_test:0.01192, lr:5.94e-02, fs:0.87255 (r=0.899,p=0.848),  time:39.735, tt:3019.882\n",
      "Ep:76, loss:0.00001, loss_test:0.01193, lr:5.94e-02, fs:0.87255 (r=0.899,p=0.848),  time:39.732, tt:3059.358\n",
      "Ep:77, loss:0.00001, loss_test:0.01185, lr:5.94e-02, fs:0.87255 (r=0.899,p=0.848),  time:39.747, tt:3100.254\n",
      "Ep:78, loss:0.00001, loss_test:0.01189, lr:5.94e-02, fs:0.86700 (r=0.889,p=0.846),  time:39.725, tt:3138.268\n",
      "Ep:79, loss:0.00001, loss_test:0.01194, lr:5.94e-02, fs:0.85572 (r=0.869,p=0.843),  time:39.721, tt:3177.690\n",
      "Ep:80, loss:0.00001, loss_test:0.01188, lr:5.94e-02, fs:0.86139 (r=0.879,p=0.845),  time:39.731, tt:3218.209\n",
      "Ep:81, loss:0.00001, loss_test:0.01191, lr:5.88e-02, fs:0.86139 (r=0.879,p=0.845),  time:39.750, tt:3259.520\n",
      "Ep:82, loss:0.00001, loss_test:0.01190, lr:5.82e-02, fs:0.86567 (r=0.879,p=0.853),  time:39.753, tt:3299.486\n",
      "Ep:83, loss:0.00001, loss_test:0.01193, lr:5.76e-02, fs:0.86000 (r=0.869,p=0.851),  time:39.752, tt:3339.182\n",
      "Ep:84, loss:0.00001, loss_test:0.01193, lr:5.71e-02, fs:0.86000 (r=0.869,p=0.851),  time:39.781, tt:3381.416\n",
      "Ep:85, loss:0.00001, loss_test:0.01190, lr:5.65e-02, fs:0.86567 (r=0.879,p=0.853),  time:39.790, tt:3421.926\n",
      "Ep:86, loss:0.00001, loss_test:0.01195, lr:5.59e-02, fs:0.86000 (r=0.869,p=0.851),  time:39.792, tt:3461.897\n",
      "Ep:87, loss:0.00001, loss_test:0.01201, lr:5.54e-02, fs:0.85427 (r=0.859,p=0.850),  time:39.900, tt:3511.219\n",
      "Ep:88, loss:0.00001, loss_test:0.01199, lr:5.48e-02, fs:0.85859 (r=0.859,p=0.859),  time:39.898, tt:3550.906\n",
      "Ep:89, loss:0.00001, loss_test:0.01196, lr:5.43e-02, fs:0.84848 (r=0.848,p=0.848),  time:39.911, tt:3591.993\n",
      "Ep:90, loss:0.00001, loss_test:0.01197, lr:5.37e-02, fs:0.85859 (r=0.859,p=0.859),  time:39.904, tt:3631.252\n",
      "Ep:91, loss:0.00001, loss_test:0.01206, lr:5.32e-02, fs:0.85128 (r=0.838,p=0.865),  time:39.904, tt:3671.203\n",
      "Ep:92, loss:0.00001, loss_test:0.01205, lr:5.27e-02, fs:0.85279 (r=0.848,p=0.857),  time:39.894, tt:3710.121\n",
      "Ep:93, loss:0.00001, loss_test:0.01208, lr:5.21e-02, fs:0.85128 (r=0.838,p=0.865),  time:39.881, tt:3748.805\n",
      "Ep:94, loss:0.00001, loss_test:0.01209, lr:5.16e-02, fs:0.85128 (r=0.838,p=0.865),  time:39.875, tt:3788.141\n",
      "Ep:95, loss:0.00001, loss_test:0.01213, lr:5.11e-02, fs:0.84536 (r=0.828,p=0.863),  time:39.904, tt:3830.765\n",
      "Ep:96, loss:0.00001, loss_test:0.01211, lr:5.06e-02, fs:0.85128 (r=0.838,p=0.865),  time:39.916, tt:3871.833\n",
      "Ep:97, loss:0.00001, loss_test:0.01214, lr:5.01e-02, fs:0.83938 (r=0.818,p=0.862),  time:39.904, tt:3910.636\n",
      "Ep:98, loss:0.00001, loss_test:0.01218, lr:4.96e-02, fs:0.84536 (r=0.828,p=0.863),  time:39.889, tt:3949.055\n",
      "Ep:99, loss:0.00001, loss_test:0.01215, lr:4.91e-02, fs:0.83938 (r=0.818,p=0.862),  time:39.890, tt:3988.970\n",
      "Ep:100, loss:0.00001, loss_test:0.01221, lr:4.86e-02, fs:0.84536 (r=0.828,p=0.863),  time:39.905, tt:4030.367\n",
      "Ep:101, loss:0.00001, loss_test:0.01227, lr:4.81e-02, fs:0.81481 (r=0.778,p=0.856),  time:39.909, tt:4070.754\n",
      "Ep:102, loss:0.00001, loss_test:0.01228, lr:4.76e-02, fs:0.82723 (r=0.798,p=0.859),  time:39.918, tt:4111.554\n",
      "Ep:103, loss:0.00001, loss_test:0.01226, lr:4.71e-02, fs:0.82723 (r=0.798,p=0.859),  time:39.913, tt:4150.948\n",
      "Ep:104, loss:0.00001, loss_test:0.01235, lr:4.67e-02, fs:0.82105 (r=0.788,p=0.857),  time:39.914, tt:4190.929\n",
      "Ep:105, loss:0.00001, loss_test:0.01236, lr:4.62e-02, fs:0.81481 (r=0.778,p=0.856),  time:39.909, tt:4230.335\n",
      "Ep:106, loss:0.00001, loss_test:0.01233, lr:4.57e-02, fs:0.81481 (r=0.778,p=0.856),  time:39.921, tt:4271.523\n",
      "Ep:107, loss:0.00001, loss_test:0.01243, lr:4.53e-02, fs:0.81481 (r=0.778,p=0.856),  time:39.925, tt:4311.857\n",
      "Ep:108, loss:0.00001, loss_test:0.01246, lr:4.48e-02, fs:0.82353 (r=0.778,p=0.875),  time:40.001, tt:4360.080\n",
      "Ep:109, loss:0.00001, loss_test:0.01243, lr:4.44e-02, fs:0.81481 (r=0.778,p=0.856),  time:40.012, tt:4401.348\n",
      "Ep:110, loss:0.00001, loss_test:0.01251, lr:4.39e-02, fs:0.81915 (r=0.778,p=0.865),  time:40.016, tt:4441.779\n",
      "Ep:111, loss:0.00001, loss_test:0.01256, lr:4.35e-02, fs:0.82353 (r=0.778,p=0.875),  time:40.043, tt:4484.861\n",
      "Ep:112, loss:0.00001, loss_test:0.01258, lr:4.31e-02, fs:0.82353 (r=0.778,p=0.875),  time:40.052, tt:4525.835\n",
      "Ep:113, loss:0.00001, loss_test:0.01260, lr:4.26e-02, fs:0.82353 (r=0.778,p=0.875),  time:40.065, tt:4567.397\n",
      "Ep:114, loss:0.00001, loss_test:0.01263, lr:4.22e-02, fs:0.82353 (r=0.778,p=0.875),  time:40.075, tt:4608.602\n",
      "Ep:115, loss:0.00000, loss_test:0.01260, lr:4.18e-02, fs:0.81915 (r=0.778,p=0.865),  time:40.065, tt:4647.545\n",
      "Ep:116, loss:0.00000, loss_test:0.01266, lr:4.14e-02, fs:0.81915 (r=0.778,p=0.865),  time:40.062, tt:4687.298\n",
      "Ep:117, loss:0.00000, loss_test:0.01268, lr:4.10e-02, fs:0.82353 (r=0.778,p=0.875),  time:40.063, tt:4727.434\n",
      "Ep:118, loss:0.00000, loss_test:0.01276, lr:4.05e-02, fs:0.82353 (r=0.778,p=0.875),  time:40.061, tt:4767.211\n",
      "Ep:119, loss:0.00000, loss_test:0.01277, lr:4.01e-02, fs:0.81720 (r=0.768,p=0.874),  time:40.068, tt:4808.189\n",
      "Ep:120, loss:0.00000, loss_test:0.01276, lr:3.97e-02, fs:0.81720 (r=0.768,p=0.874),  time:40.091, tt:4850.963\n",
      "Ep:121, loss:0.00000, loss_test:0.01281, lr:3.93e-02, fs:0.81720 (r=0.768,p=0.874),  time:40.086, tt:4890.514\n",
      "Ep:122, loss:0.00000, loss_test:0.01286, lr:3.89e-02, fs:0.81720 (r=0.768,p=0.874),  time:40.096, tt:4931.825\n",
      "Ep:123, loss:0.00000, loss_test:0.01286, lr:3.86e-02, fs:0.81720 (r=0.768,p=0.874),  time:40.103, tt:4972.812\n",
      "Ep:124, loss:0.00000, loss_test:0.01288, lr:3.82e-02, fs:0.81720 (r=0.768,p=0.874),  time:40.114, tt:5014.195\n",
      "Ep:125, loss:0.00000, loss_test:0.01293, lr:3.78e-02, fs:0.81720 (r=0.768,p=0.874),  time:40.119, tt:5054.938\n",
      "Ep:126, loss:0.00000, loss_test:0.01295, lr:3.74e-02, fs:0.81720 (r=0.768,p=0.874),  time:40.115, tt:5094.630\n",
      "Ep:127, loss:0.00000, loss_test:0.01296, lr:3.70e-02, fs:0.81720 (r=0.768,p=0.874),  time:40.115, tt:5134.677\n",
      "Ep:128, loss:0.00000, loss_test:0.01301, lr:3.67e-02, fs:0.81720 (r=0.768,p=0.874),  time:40.118, tt:5175.286\n",
      "Ep:129, loss:0.00000, loss_test:0.01300, lr:3.63e-02, fs:0.81720 (r=0.768,p=0.874),  time:40.161, tt:5220.969\n",
      "Ep:130, loss:0.00000, loss_test:0.01301, lr:3.59e-02, fs:0.81720 (r=0.768,p=0.874),  time:40.161, tt:5261.075\n",
      "Ep:131, loss:0.00000, loss_test:0.01309, lr:3.56e-02, fs:0.81720 (r=0.768,p=0.874),  time:40.156, tt:5300.592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00000, loss_test:0.01314, lr:3.52e-02, fs:0.81720 (r=0.768,p=0.874),  time:40.162, tt:5341.507\n",
      "Ep:133, loss:0.00000, loss_test:0.01313, lr:3.49e-02, fs:0.81720 (r=0.768,p=0.874),  time:40.158, tt:5381.112\n",
      "Ep:134, loss:0.00000, loss_test:0.01319, lr:3.45e-02, fs:0.81720 (r=0.768,p=0.874),  time:40.158, tt:5421.264\n",
      "Ep:135, loss:0.00000, loss_test:0.01319, lr:3.42e-02, fs:0.82162 (r=0.768,p=0.884),  time:40.146, tt:5459.836\n",
      "Ep:136, loss:0.00000, loss_test:0.01327, lr:3.38e-02, fs:0.81720 (r=0.768,p=0.874),  time:40.148, tt:5500.295\n",
      "Ep:137, loss:0.00000, loss_test:0.01326, lr:3.35e-02, fs:0.81720 (r=0.768,p=0.874),  time:40.155, tt:5541.350\n",
      "Ep:138, loss:0.00000, loss_test:0.01324, lr:3.32e-02, fs:0.81720 (r=0.768,p=0.874),  time:40.161, tt:5582.423\n",
      "Ep:139, loss:0.00000, loss_test:0.01328, lr:3.28e-02, fs:0.81720 (r=0.768,p=0.874),  time:40.164, tt:5622.970\n",
      "Ep:140, loss:0.00000, loss_test:0.01332, lr:3.25e-02, fs:0.82162 (r=0.768,p=0.884),  time:40.162, tt:5662.777\n",
      "Ep:141, loss:0.00000, loss_test:0.01334, lr:3.22e-02, fs:0.82162 (r=0.768,p=0.884),  time:40.155, tt:5702.048\n",
      "Ep:142, loss:0.00000, loss_test:0.01337, lr:3.19e-02, fs:0.82162 (r=0.768,p=0.884),  time:40.146, tt:5740.891\n",
      "Ep:143, loss:0.00000, loss_test:0.01340, lr:3.15e-02, fs:0.81522 (r=0.758,p=0.882),  time:40.139, tt:5780.078\n",
      "Ep:144, loss:0.00000, loss_test:0.01344, lr:3.12e-02, fs:0.81522 (r=0.758,p=0.882),  time:40.132, tt:5819.174\n",
      "Ep:145, loss:0.00000, loss_test:0.01345, lr:3.09e-02, fs:0.81522 (r=0.758,p=0.882),  time:40.123, tt:5857.892\n",
      "Ep:146, loss:0.00000, loss_test:0.01346, lr:3.06e-02, fs:0.80874 (r=0.747,p=0.881),  time:40.127, tt:5898.596\n",
      "Ep:147, loss:0.00000, loss_test:0.01345, lr:3.03e-02, fs:0.82162 (r=0.768,p=0.884),  time:40.130, tt:5939.260\n",
      "Ep:148, loss:0.00000, loss_test:0.01352, lr:3.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:40.118, tt:5977.594\n",
      "Ep:149, loss:0.00000, loss_test:0.01352, lr:2.97e-02, fs:0.81967 (r=0.758,p=0.893),  time:40.114, tt:6017.062\n",
      "Ep:150, loss:0.00000, loss_test:0.01354, lr:2.94e-02, fs:0.81967 (r=0.758,p=0.893),  time:40.102, tt:6055.473\n",
      "Ep:151, loss:0.00000, loss_test:0.01362, lr:2.91e-02, fs:0.81111 (r=0.737,p=0.901),  time:40.102, tt:6095.516\n",
      "Ep:152, loss:0.00000, loss_test:0.01358, lr:2.88e-02, fs:0.81967 (r=0.758,p=0.893),  time:40.110, tt:6136.880\n",
      "Ep:153, loss:0.00000, loss_test:0.01361, lr:2.85e-02, fs:0.81319 (r=0.747,p=0.892),  time:40.113, tt:6177.350\n",
      "Ep:154, loss:0.00000, loss_test:0.01365, lr:2.82e-02, fs:0.81564 (r=0.737,p=0.912),  time:40.117, tt:6218.189\n",
      "Ep:155, loss:0.00000, loss_test:0.01365, lr:2.80e-02, fs:0.81967 (r=0.758,p=0.893),  time:40.129, tt:6260.074\n",
      "Ep:156, loss:0.00000, loss_test:0.01370, lr:2.77e-02, fs:0.81111 (r=0.737,p=0.901),  time:40.131, tt:6300.600\n",
      "Ep:157, loss:0.00000, loss_test:0.01372, lr:2.74e-02, fs:0.81111 (r=0.737,p=0.901),  time:40.128, tt:6340.204\n",
      "Ep:158, loss:0.00000, loss_test:0.01374, lr:2.71e-02, fs:0.81111 (r=0.737,p=0.901),  time:40.117, tt:6378.654\n",
      "Ep:159, loss:0.00000, loss_test:0.01376, lr:2.69e-02, fs:0.80447 (r=0.727,p=0.900),  time:40.112, tt:6417.857\n",
      "Ep:160, loss:0.00000, loss_test:0.01378, lr:2.66e-02, fs:0.80447 (r=0.727,p=0.900),  time:40.108, tt:6457.337\n",
      "Ep:161, loss:0.00000, loss_test:0.01381, lr:2.63e-02, fs:0.80447 (r=0.727,p=0.900),  time:40.099, tt:6496.000\n",
      "Ep:162, loss:0.00000, loss_test:0.01385, lr:2.61e-02, fs:0.80899 (r=0.727,p=0.911),  time:40.100, tt:6536.220\n",
      "Ep:163, loss:0.00000, loss_test:0.01384, lr:2.58e-02, fs:0.80899 (r=0.727,p=0.911),  time:40.103, tt:6576.931\n",
      "Ep:164, loss:0.00000, loss_test:0.01387, lr:2.55e-02, fs:0.80899 (r=0.727,p=0.911),  time:40.109, tt:6618.030\n",
      "Ep:165, loss:0.00000, loss_test:0.01389, lr:2.53e-02, fs:0.80899 (r=0.727,p=0.911),  time:40.100, tt:6656.561\n",
      "Ep:166, loss:0.00000, loss_test:0.01390, lr:2.50e-02, fs:0.80899 (r=0.727,p=0.911),  time:40.106, tt:6697.639\n",
      "Ep:167, loss:0.00000, loss_test:0.01395, lr:2.48e-02, fs:0.80899 (r=0.727,p=0.911),  time:40.099, tt:6736.554\n",
      "Ep:168, loss:0.00000, loss_test:0.01395, lr:2.45e-02, fs:0.80899 (r=0.727,p=0.911),  time:40.081, tt:6773.733\n",
      "Ep:169, loss:0.00000, loss_test:0.01395, lr:2.43e-02, fs:0.80899 (r=0.727,p=0.911),  time:40.089, tt:6815.065\n",
      "Ep:170, loss:0.00000, loss_test:0.01396, lr:2.40e-02, fs:0.80899 (r=0.727,p=0.911),  time:40.086, tt:6854.713\n",
      "Ep:171, loss:0.00000, loss_test:0.01400, lr:2.38e-02, fs:0.80226 (r=0.717,p=0.910),  time:40.096, tt:6896.529\n",
      "Ep:172, loss:0.00000, loss_test:0.01402, lr:2.36e-02, fs:0.80899 (r=0.727,p=0.911),  time:40.097, tt:6936.741\n",
      "Ep:173, loss:0.00000, loss_test:0.01401, lr:2.33e-02, fs:0.80899 (r=0.727,p=0.911),  time:40.088, tt:6975.377\n",
      "Ep:174, loss:0.00000, loss_test:0.01401, lr:2.31e-02, fs:0.80899 (r=0.727,p=0.911),  time:40.093, tt:7016.337\n",
      "Ep:175, loss:0.00000, loss_test:0.01409, lr:2.29e-02, fs:0.80899 (r=0.727,p=0.911),  time:40.092, tt:7056.123\n",
      "Ep:176, loss:0.00000, loss_test:0.01408, lr:2.26e-02, fs:0.80899 (r=0.727,p=0.911),  time:40.094, tt:7096.606\n",
      "Ep:177, loss:0.00000, loss_test:0.01408, lr:2.24e-02, fs:0.80226 (r=0.717,p=0.910),  time:40.095, tt:7136.965\n",
      "Ep:178, loss:0.00000, loss_test:0.01410, lr:2.22e-02, fs:0.80899 (r=0.727,p=0.911),  time:40.101, tt:7178.065\n",
      "Ep:179, loss:0.00000, loss_test:0.01415, lr:2.20e-02, fs:0.80899 (r=0.727,p=0.911),  time:40.130, tt:7223.376\n",
      "Ep:180, loss:0.00000, loss_test:0.01413, lr:2.17e-02, fs:0.80226 (r=0.717,p=0.910),  time:40.129, tt:7263.273\n",
      "Ep:181, loss:0.00000, loss_test:0.01414, lr:2.15e-02, fs:0.80226 (r=0.717,p=0.910),  time:40.126, tt:7302.987\n",
      "Ep:182, loss:0.00000, loss_test:0.01420, lr:2.13e-02, fs:0.80899 (r=0.727,p=0.911),  time:40.120, tt:7341.914\n",
      "Ep:183, loss:0.00000, loss_test:0.01419, lr:2.11e-02, fs:0.80226 (r=0.717,p=0.910),  time:40.117, tt:7381.559\n",
      "Ep:184, loss:0.00000, loss_test:0.01421, lr:2.09e-02, fs:0.80226 (r=0.717,p=0.910),  time:40.120, tt:7422.229\n",
      "Ep:185, loss:0.00000, loss_test:0.01423, lr:2.07e-02, fs:0.80226 (r=0.717,p=0.910),  time:40.119, tt:7462.216\n",
      "Ep:186, loss:0.00000, loss_test:0.01424, lr:2.05e-02, fs:0.80226 (r=0.717,p=0.910),  time:40.114, tt:7501.380\n",
      "Ep:187, loss:0.00000, loss_test:0.01426, lr:2.03e-02, fs:0.80226 (r=0.717,p=0.910),  time:40.117, tt:7542.006\n",
      "Ep:188, loss:0.00000, loss_test:0.01428, lr:2.01e-02, fs:0.80226 (r=0.717,p=0.910),  time:40.119, tt:7582.473\n",
      "Ep:189, loss:0.00000, loss_test:0.01427, lr:1.99e-02, fs:0.79545 (r=0.707,p=0.909),  time:40.114, tt:7621.565\n",
      "Ep:190, loss:0.00000, loss_test:0.01431, lr:1.97e-02, fs:0.79545 (r=0.707,p=0.909),  time:40.101, tt:7659.327\n",
      "Ep:191, loss:0.00000, loss_test:0.01431, lr:1.95e-02, fs:0.79545 (r=0.707,p=0.909),  time:40.095, tt:7698.247\n",
      "Ep:192, loss:0.00000, loss_test:0.01433, lr:1.93e-02, fs:0.79545 (r=0.707,p=0.909),  time:40.103, tt:7739.863\n",
      "Ep:193, loss:0.00000, loss_test:0.01436, lr:1.91e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.096, tt:7778.707\n",
      "Ep:194, loss:0.00000, loss_test:0.01435, lr:1.89e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.090, tt:7817.459\n",
      "Ep:195, loss:0.00000, loss_test:0.01436, lr:1.87e-02, fs:0.79545 (r=0.707,p=0.909),  time:40.077, tt:7855.077\n",
      "Ep:196, loss:0.00000, loss_test:0.01438, lr:1.85e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.072, tt:7894.217\n",
      "Ep:197, loss:0.00000, loss_test:0.01438, lr:1.83e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.067, tt:7933.324\n",
      "Ep:198, loss:0.00000, loss_test:0.01441, lr:1.81e-02, fs:0.78857 (r=0.697,p=0.908),  time:40.063, tt:7972.496\n",
      "Ep:199, loss:0.00000, loss_test:0.01442, lr:1.80e-02, fs:0.78161 (r=0.687,p=0.907),  time:40.060, tt:8011.923\n",
      "Ep:200, loss:0.00000, loss_test:0.01442, lr:1.78e-02, fs:0.78161 (r=0.687,p=0.907),  time:40.045, tt:8049.119\n",
      "Ep:201, loss:0.00000, loss_test:0.01444, lr:1.76e-02, fs:0.78161 (r=0.687,p=0.907),  time:40.037, tt:8087.482\n",
      "Ep:202, loss:0.00000, loss_test:0.01445, lr:1.74e-02, fs:0.78161 (r=0.687,p=0.907),  time:40.035, tt:8127.134\n",
      "Ep:203, loss:0.00000, loss_test:0.01447, lr:1.73e-02, fs:0.77457 (r=0.677,p=0.905),  time:40.029, tt:8165.956\n",
      "Ep:204, loss:0.00000, loss_test:0.01450, lr:1.71e-02, fs:0.76744 (r=0.667,p=0.904),  time:40.030, tt:8206.087\n",
      "Ep:205, loss:0.00000, loss_test:0.01448, lr:1.69e-02, fs:0.77457 (r=0.677,p=0.905),  time:40.028, tt:8245.734\n",
      "Ep:206, loss:0.00000, loss_test:0.01451, lr:1.67e-02, fs:0.76744 (r=0.667,p=0.904),  time:40.028, tt:8285.731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:207, loss:0.00000, loss_test:0.01451, lr:1.66e-02, fs:0.77193 (r=0.667,p=0.917),  time:40.029, tt:8326.050\n",
      "Ep:208, loss:0.00000, loss_test:0.01451, lr:1.64e-02, fs:0.77907 (r=0.677,p=0.918),  time:40.016, tt:8363.416\n",
      "Ep:209, loss:0.00000, loss_test:0.01454, lr:1.62e-02, fs:0.77193 (r=0.667,p=0.917),  time:40.036, tt:8407.488\n",
      "Ep:210, loss:0.00000, loss_test:0.01454, lr:1.61e-02, fs:0.77193 (r=0.667,p=0.917),  time:40.009, tt:8441.871\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14053, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.979, tt:33.979\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13713, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:33.192, tt:66.384\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.12995, lr:1.00e-02, fs:0.66901 (r=0.960,p=0.514),  time:34.931, tt:104.793\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00025, loss_test:0.11999, lr:1.00e-02, fs:0.67213 (r=0.828,p=0.566),  time:36.156, tt:144.625\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00023, loss_test:0.11342, lr:1.00e-02, fs:0.69194 (r=0.737,p=0.652),  time:36.731, tt:183.656\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00022, loss_test:0.11038, lr:1.00e-02, fs:0.72477 (r=0.798,p=0.664),  time:37.512, tt:225.075\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00022, loss_test:0.10948, lr:1.00e-02, fs:0.71730 (r=0.859,p=0.616),  time:38.085, tt:266.598\n",
      "Ep:7, loss:0.00021, loss_test:0.10391, lr:1.00e-02, fs:0.71560 (r=0.788,p=0.655),  time:38.838, tt:310.701\n",
      "Ep:8, loss:0.00020, loss_test:0.10076, lr:1.00e-02, fs:0.72906 (r=0.747,p=0.712),  time:39.248, tt:353.235\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00019, loss_test:0.09924, lr:1.00e-02, fs:0.76712 (r=0.848,p=0.700),  time:39.532, tt:395.317\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00018, loss_test:0.09593, lr:1.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:39.823, tt:438.052\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00017, loss_test:0.09318, lr:1.00e-02, fs:0.80189 (r=0.859,p=0.752),  time:39.840, tt:478.086\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00017, loss_test:0.09101, lr:1.00e-02, fs:0.81860 (r=0.889,p=0.759),  time:39.881, tt:518.453\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00016, loss_test:0.08808, lr:1.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:40.187, tt:562.614\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00015, loss_test:0.08679, lr:1.00e-02, fs:0.81860 (r=0.889,p=0.759),  time:40.381, tt:605.719\n",
      "Ep:15, loss:0.00014, loss_test:0.08510, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:40.482, tt:647.714\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00014, loss_test:0.08474, lr:1.00e-02, fs:0.84112 (r=0.909,p=0.783),  time:40.629, tt:690.696\n",
      "Ep:17, loss:0.00013, loss_test:0.08367, lr:1.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:40.822, tt:734.804\n",
      "Ep:18, loss:0.00013, loss_test:0.08173, lr:1.00e-02, fs:0.85308 (r=0.909,p=0.804),  time:40.859, tt:776.316\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00012, loss_test:0.08019, lr:1.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:40.968, tt:819.364\n",
      "Ep:20, loss:0.00012, loss_test:0.07874, lr:1.00e-02, fs:0.85308 (r=0.909,p=0.804),  time:41.023, tt:861.483\n",
      "Ep:21, loss:0.00011, loss_test:0.07942, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:41.128, tt:904.827\n",
      "Ep:22, loss:0.00011, loss_test:0.07564, lr:1.00e-02, fs:0.86792 (r=0.929,p=0.814),  time:41.166, tt:946.809\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00010, loss_test:0.07543, lr:1.00e-02, fs:0.84729 (r=0.869,p=0.827),  time:41.224, tt:989.368\n",
      "Ep:24, loss:0.00010, loss_test:0.07316, lr:1.00e-02, fs:0.86408 (r=0.899,p=0.832),  time:41.232, tt:1030.799\n",
      "Ep:25, loss:0.00009, loss_test:0.07339, lr:1.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:41.275, tt:1073.142\n",
      "Ep:26, loss:0.00009, loss_test:0.07229, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:41.303, tt:1115.187\n",
      "Ep:27, loss:0.00009, loss_test:0.07209, lr:1.00e-02, fs:0.85849 (r=0.919,p=0.805),  time:41.302, tt:1156.460\n",
      "Ep:28, loss:0.00008, loss_test:0.07029, lr:1.00e-02, fs:0.88889 (r=0.889,p=0.889),  time:41.379, tt:1199.981\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00008, loss_test:0.07025, lr:1.00e-02, fs:0.87324 (r=0.939,p=0.816),  time:41.414, tt:1242.419\n",
      "Ep:30, loss:0.00008, loss_test:0.06534, lr:1.00e-02, fs:0.89855 (r=0.939,p=0.861),  time:41.462, tt:1285.322\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00007, loss_test:0.07905, lr:1.00e-02, fs:0.77348 (r=0.707,p=0.854),  time:41.479, tt:1327.341\n",
      "Ep:32, loss:0.00007, loss_test:0.06580, lr:1.00e-02, fs:0.89498 (r=0.990,p=0.817),  time:41.464, tt:1368.297\n",
      "Ep:33, loss:0.00007, loss_test:0.07688, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:41.425, tt:1408.445\n",
      "Ep:34, loss:0.00007, loss_test:0.06582, lr:1.00e-02, fs:0.88182 (r=0.980,p=0.802),  time:41.411, tt:1449.391\n",
      "Ep:35, loss:0.00007, loss_test:0.06876, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:41.376, tt:1489.541\n",
      "Ep:36, loss:0.00007, loss_test:0.06630, lr:1.00e-02, fs:0.87179 (r=0.859,p=0.885),  time:41.348, tt:1529.861\n",
      "Ep:37, loss:0.00006, loss_test:0.06487, lr:1.00e-02, fs:0.88372 (r=0.960,p=0.819),  time:41.301, tt:1569.436\n",
      "Ep:38, loss:0.00006, loss_test:0.07358, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:41.258, tt:1609.066\n",
      "Ep:39, loss:0.00006, loss_test:0.06273, lr:1.00e-02, fs:0.89302 (r=0.970,p=0.828),  time:41.294, tt:1651.765\n",
      "Ep:40, loss:0.00005, loss_test:0.07113, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:41.368, tt:1696.088\n",
      "Ep:41, loss:0.00005, loss_test:0.06452, lr:1.00e-02, fs:0.84158 (r=0.859,p=0.825),  time:41.321, tt:1735.496\n",
      "Ep:42, loss:0.00005, loss_test:0.06307, lr:9.90e-03, fs:0.88462 (r=0.929,p=0.844),  time:41.295, tt:1775.666\n",
      "Ep:43, loss:0.00005, loss_test:0.06643, lr:9.80e-03, fs:0.83770 (r=0.808,p=0.870),  time:41.241, tt:1814.593\n",
      "Ep:44, loss:0.00004, loss_test:0.06167, lr:9.70e-03, fs:0.88462 (r=0.929,p=0.844),  time:41.241, tt:1855.847\n",
      "Ep:45, loss:0.00004, loss_test:0.06312, lr:9.61e-03, fs:0.85714 (r=0.818,p=0.900),  time:41.234, tt:1896.754\n",
      "Ep:46, loss:0.00004, loss_test:0.06641, lr:9.51e-03, fs:0.82105 (r=0.788,p=0.857),  time:41.204, tt:1936.590\n",
      "Ep:47, loss:0.00004, loss_test:0.06415, lr:9.41e-03, fs:0.85128 (r=0.838,p=0.865),  time:41.185, tt:1976.889\n",
      "Ep:48, loss:0.00004, loss_test:0.06531, lr:9.32e-03, fs:0.85567 (r=0.838,p=0.874),  time:41.173, tt:2017.490\n",
      "Ep:49, loss:0.00004, loss_test:0.06189, lr:9.23e-03, fs:0.89216 (r=0.919,p=0.867),  time:41.170, tt:2058.497\n",
      "Ep:50, loss:0.00003, loss_test:0.06454, lr:9.14e-03, fs:0.88889 (r=0.848,p=0.933),  time:41.156, tt:2098.977\n",
      "Ep:51, loss:0.00003, loss_test:0.06205, lr:9.04e-03, fs:0.85279 (r=0.848,p=0.857),  time:41.177, tt:2141.189\n",
      "Ep:52, loss:0.00003, loss_test:0.06400, lr:8.95e-03, fs:0.86154 (r=0.848,p=0.875),  time:41.186, tt:2182.860\n",
      "Ep:53, loss:0.00003, loss_test:0.06320, lr:8.86e-03, fs:0.85714 (r=0.848,p=0.866),  time:41.174, tt:2223.419\n",
      "Ep:54, loss:0.00003, loss_test:0.06487, lr:8.78e-03, fs:0.85128 (r=0.838,p=0.865),  time:41.192, tt:2265.553\n",
      "Ep:55, loss:0.00003, loss_test:0.06200, lr:8.69e-03, fs:0.84492 (r=0.798,p=0.898),  time:41.209, tt:2307.692\n",
      "Ep:56, loss:0.00003, loss_test:0.06623, lr:8.60e-03, fs:0.82540 (r=0.788,p=0.867),  time:41.199, tt:2348.368\n",
      "Ep:57, loss:0.00003, loss_test:0.06317, lr:8.51e-03, fs:0.85567 (r=0.838,p=0.874),  time:41.226, tt:2391.099\n",
      "Ep:58, loss:0.00003, loss_test:0.06247, lr:8.43e-03, fs:0.85405 (r=0.798,p=0.919),  time:41.246, tt:2433.502\n",
      "Ep:59, loss:0.00003, loss_test:0.06644, lr:8.35e-03, fs:0.81915 (r=0.778,p=0.865),  time:41.240, tt:2474.388\n",
      "Ep:60, loss:0.00002, loss_test:0.06356, lr:8.26e-03, fs:0.87831 (r=0.838,p=0.922),  time:41.248, tt:2516.111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00002, loss_test:0.06607, lr:8.18e-03, fs:0.82609 (r=0.768,p=0.894),  time:41.251, tt:2557.561\n",
      "Ep:62, loss:0.00002, loss_test:0.06323, lr:8.10e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.326, tt:2603.559\n",
      "Ep:63, loss:0.00002, loss_test:0.06390, lr:8.02e-03, fs:0.84324 (r=0.788,p=0.907),  time:41.322, tt:2644.625\n",
      "Ep:64, loss:0.00002, loss_test:0.06510, lr:7.94e-03, fs:0.84615 (r=0.778,p=0.928),  time:41.316, tt:2685.549\n",
      "Ep:65, loss:0.00002, loss_test:0.06295, lr:7.86e-03, fs:0.84783 (r=0.788,p=0.918),  time:41.306, tt:2726.217\n",
      "Ep:66, loss:0.00002, loss_test:0.06619, lr:7.78e-03, fs:0.83978 (r=0.768,p=0.927),  time:41.306, tt:2767.517\n",
      "Ep:67, loss:0.00002, loss_test:0.06431, lr:7.70e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.318, tt:2809.604\n",
      "Ep:68, loss:0.00002, loss_test:0.06488, lr:7.62e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.287, tt:2848.776\n",
      "Ep:69, loss:0.00002, loss_test:0.06530, lr:7.55e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.291, tt:2890.355\n",
      "Ep:70, loss:0.00002, loss_test:0.06456, lr:7.47e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.279, tt:2930.785\n",
      "Ep:71, loss:0.00002, loss_test:0.06397, lr:7.40e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.298, tt:2973.472\n",
      "Ep:72, loss:0.00002, loss_test:0.06442, lr:7.32e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.290, tt:3014.178\n",
      "Ep:73, loss:0.00002, loss_test:0.06389, lr:7.25e-03, fs:0.83978 (r=0.768,p=0.927),  time:41.287, tt:3055.265\n",
      "Ep:74, loss:0.00002, loss_test:0.06471, lr:7.18e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.295, tt:3097.136\n",
      "Ep:75, loss:0.00001, loss_test:0.06359, lr:7.11e-03, fs:0.83978 (r=0.768,p=0.927),  time:41.320, tt:3140.350\n",
      "Ep:76, loss:0.00001, loss_test:0.06406, lr:7.03e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.333, tt:3182.658\n",
      "Ep:77, loss:0.00001, loss_test:0.06677, lr:6.96e-03, fs:0.83616 (r=0.747,p=0.949),  time:41.303, tt:3221.605\n",
      "Ep:78, loss:0.00001, loss_test:0.06428, lr:6.89e-03, fs:0.83978 (r=0.768,p=0.927),  time:41.341, tt:3265.929\n",
      "Ep:79, loss:0.00001, loss_test:0.06479, lr:6.83e-03, fs:0.83146 (r=0.747,p=0.937),  time:41.309, tt:3304.727\n",
      "Ep:80, loss:0.00001, loss_test:0.06411, lr:6.76e-03, fs:0.83146 (r=0.747,p=0.937),  time:41.329, tt:3347.645\n",
      "Ep:81, loss:0.00001, loss_test:0.06676, lr:6.69e-03, fs:0.84916 (r=0.768,p=0.950),  time:41.311, tt:3387.528\n",
      "Ep:82, loss:0.00001, loss_test:0.06099, lr:6.62e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.301, tt:3428.008\n",
      "Ep:83, loss:0.00001, loss_test:0.06483, lr:6.56e-03, fs:0.80925 (r=0.707,p=0.946),  time:41.283, tt:3467.764\n",
      "Ep:84, loss:0.00001, loss_test:0.06400, lr:6.49e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.283, tt:3509.086\n",
      "Ep:85, loss:0.00001, loss_test:0.06304, lr:6.43e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.280, tt:3550.105\n",
      "Ep:86, loss:0.00001, loss_test:0.06473, lr:6.36e-03, fs:0.84270 (r=0.758,p=0.949),  time:41.294, tt:3592.620\n",
      "Ep:87, loss:0.00001, loss_test:0.06348, lr:6.30e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.313, tt:3635.507\n",
      "Ep:88, loss:0.00001, loss_test:0.06339, lr:6.24e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.311, tt:3676.717\n",
      "Ep:89, loss:0.00001, loss_test:0.06443, lr:6.17e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.342, tt:3720.749\n",
      "Ep:90, loss:0.00001, loss_test:0.06418, lr:6.11e-03, fs:0.83146 (r=0.747,p=0.937),  time:41.347, tt:3762.545\n",
      "Ep:91, loss:0.00001, loss_test:0.06403, lr:6.05e-03, fs:0.84916 (r=0.768,p=0.950),  time:41.364, tt:3805.524\n",
      "Ep:92, loss:0.00001, loss_test:0.06282, lr:5.99e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.372, tt:3847.629\n",
      "Ep:93, loss:0.00001, loss_test:0.06454, lr:5.93e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.380, tt:3889.759\n",
      "Ep:94, loss:0.00001, loss_test:0.06475, lr:5.87e-03, fs:0.82286 (r=0.727,p=0.947),  time:41.447, tt:3937.435\n",
      "Ep:95, loss:0.00001, loss_test:0.06451, lr:5.81e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.463, tt:3980.458\n",
      "Ep:96, loss:0.00001, loss_test:0.06323, lr:5.75e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.483, tt:4023.829\n",
      "Ep:97, loss:0.00001, loss_test:0.06442, lr:5.70e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.487, tt:4065.728\n",
      "Ep:98, loss:0.00001, loss_test:0.06360, lr:5.64e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.490, tt:4107.555\n",
      "Ep:99, loss:0.00001, loss_test:0.06428, lr:5.58e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.512, tt:4151.177\n",
      "Ep:100, loss:0.00001, loss_test:0.06568, lr:5.53e-03, fs:0.82955 (r=0.737,p=0.948),  time:41.511, tt:4192.575\n",
      "Ep:101, loss:0.00001, loss_test:0.06281, lr:5.47e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.534, tt:4236.518\n",
      "Ep:102, loss:0.00001, loss_test:0.06458, lr:5.42e-03, fs:0.83146 (r=0.747,p=0.937),  time:41.545, tt:4279.169\n",
      "Ep:103, loss:0.00001, loss_test:0.06408, lr:5.36e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.563, tt:4322.547\n",
      "Ep:104, loss:0.00001, loss_test:0.06342, lr:5.31e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.581, tt:4366.024\n",
      "Ep:105, loss:0.00001, loss_test:0.06404, lr:5.26e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.607, tt:4410.292\n",
      "Ep:106, loss:0.00001, loss_test:0.06529, lr:5.20e-03, fs:0.83146 (r=0.747,p=0.937),  time:41.632, tt:4454.639\n",
      "Ep:107, loss:0.00001, loss_test:0.06340, lr:5.15e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.651, tt:4498.331\n",
      "Ep:108, loss:0.00001, loss_test:0.06540, lr:5.10e-03, fs:0.80925 (r=0.707,p=0.946),  time:41.669, tt:4541.960\n",
      "Ep:109, loss:0.00001, loss_test:0.06559, lr:5.05e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.693, tt:4586.281\n",
      "Ep:110, loss:0.00001, loss_test:0.06379, lr:5.00e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.728, tt:4631.800\n",
      "Ep:111, loss:0.00001, loss_test:0.06429, lr:4.95e-03, fs:0.83799 (r=0.758,p=0.938),  time:41.754, tt:4676.443\n",
      "Ep:112, loss:0.00001, loss_test:0.06347, lr:4.90e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.782, tt:4721.369\n",
      "Ep:113, loss:0.00001, loss_test:0.06436, lr:4.85e-03, fs:0.83146 (r=0.747,p=0.937),  time:41.794, tt:4764.461\n",
      "Ep:114, loss:0.00001, loss_test:0.06313, lr:4.80e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.810, tt:4808.127\n",
      "Ep:115, loss:0.00001, loss_test:0.06552, lr:4.75e-03, fs:0.80460 (r=0.707,p=0.933),  time:41.828, tt:4852.099\n",
      "Ep:116, loss:0.00001, loss_test:0.06546, lr:4.71e-03, fs:0.81818 (r=0.727,p=0.935),  time:41.853, tt:4896.797\n",
      "Ep:117, loss:0.00001, loss_test:0.06436, lr:4.66e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.881, tt:4941.979\n",
      "Ep:118, loss:0.00001, loss_test:0.06341, lr:4.61e-03, fs:0.84916 (r=0.768,p=0.950),  time:41.891, tt:4985.040\n",
      "Ep:119, loss:0.00001, loss_test:0.06570, lr:4.57e-03, fs:0.80460 (r=0.707,p=0.933),  time:41.912, tt:5029.428\n",
      "Ep:120, loss:0.00001, loss_test:0.06452, lr:4.52e-03, fs:0.84916 (r=0.768,p=0.950),  time:41.918, tt:5072.087\n",
      "Ep:121, loss:0.00001, loss_test:0.06502, lr:4.48e-03, fs:0.82955 (r=0.737,p=0.948),  time:41.942, tt:5116.870\n",
      "Ep:122, loss:0.00001, loss_test:0.06400, lr:4.43e-03, fs:0.84916 (r=0.768,p=0.950),  time:41.954, tt:5160.350\n",
      "Ep:123, loss:0.00001, loss_test:0.06522, lr:4.39e-03, fs:0.84916 (r=0.768,p=0.950),  time:41.967, tt:5203.888\n",
      "Ep:124, loss:0.00001, loss_test:0.06402, lr:4.34e-03, fs:0.84916 (r=0.768,p=0.950),  time:41.989, tt:5248.623\n",
      "Ep:125, loss:0.00000, loss_test:0.06438, lr:4.30e-03, fs:0.84270 (r=0.758,p=0.949),  time:42.004, tt:5292.524\n",
      "Ep:126, loss:0.00000, loss_test:0.06596, lr:4.26e-03, fs:0.83616 (r=0.747,p=0.949),  time:42.028, tt:5337.615\n",
      "Ep:127, loss:0.00000, loss_test:0.06474, lr:4.21e-03, fs:0.84916 (r=0.768,p=0.950),  time:42.033, tt:5380.176\n",
      "Ep:128, loss:0.00000, loss_test:0.06495, lr:4.17e-03, fs:0.84916 (r=0.768,p=0.950),  time:42.030, tt:5421.836\n",
      "Ep:129, loss:0.00000, loss_test:0.06421, lr:4.13e-03, fs:0.84916 (r=0.768,p=0.950),  time:42.054, tt:5467.023\n",
      "Ep:130, loss:0.00000, loss_test:0.06529, lr:4.09e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.073, tt:5511.521\n",
      "Ep:131, loss:0.00000, loss_test:0.06468, lr:4.05e-03, fs:0.82955 (r=0.737,p=0.948),  time:42.079, tt:5554.439\n",
      "Ep:132, loss:0.00000, loss_test:0.06503, lr:4.01e-03, fs:0.84916 (r=0.768,p=0.950),  time:42.078, tt:5596.438\n",
      "Ep:133, loss:0.00000, loss_test:0.06452, lr:3.97e-03, fs:0.84270 (r=0.758,p=0.949),  time:42.086, tt:5639.575\n",
      "Ep:134, loss:0.00000, loss_test:0.06525, lr:3.93e-03, fs:0.82955 (r=0.737,p=0.948),  time:42.098, tt:5683.270\n",
      "Ep:135, loss:0.00000, loss_test:0.06491, lr:3.89e-03, fs:0.84916 (r=0.768,p=0.950),  time:42.101, tt:5725.676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:136, loss:0.00000, loss_test:0.06526, lr:3.85e-03, fs:0.82955 (r=0.737,p=0.948),  time:42.114, tt:5769.638\n",
      "Ep:137, loss:0.00000, loss_test:0.06539, lr:3.81e-03, fs:0.82955 (r=0.737,p=0.948),  time:42.125, tt:5813.288\n",
      "Ep:138, loss:0.00000, loss_test:0.06545, lr:3.77e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.146, tt:5858.261\n",
      "Ep:139, loss:0.00000, loss_test:0.06551, lr:3.73e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.151, tt:5901.095\n",
      "Ep:140, loss:0.00000, loss_test:0.06574, lr:3.70e-03, fs:0.82955 (r=0.737,p=0.948),  time:42.159, tt:5944.350\n",
      "Ep:141, loss:0.00000, loss_test:0.06589, lr:3.66e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.198, tt:5992.166\n",
      "Ep:142, loss:0.00000, loss_test:0.06576, lr:3.62e-03, fs:0.80925 (r=0.707,p=0.946),  time:42.209, tt:6035.828\n",
      "Ep:143, loss:0.00000, loss_test:0.06500, lr:3.59e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.215, tt:6078.959\n",
      "Ep:144, loss:0.00000, loss_test:0.06686, lr:3.55e-03, fs:0.80233 (r=0.697,p=0.945),  time:42.215, tt:6121.194\n",
      "Ep:145, loss:0.00000, loss_test:0.06586, lr:3.52e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.234, tt:6166.161\n",
      "Ep:146, loss:0.00000, loss_test:0.06624, lr:3.48e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.231, tt:6207.974\n",
      "Ep:147, loss:0.00000, loss_test:0.06608, lr:3.45e-03, fs:0.83616 (r=0.747,p=0.949),  time:42.240, tt:6251.465\n",
      "Ep:148, loss:0.00000, loss_test:0.06632, lr:3.41e-03, fs:0.80925 (r=0.707,p=0.946),  time:42.253, tt:6295.648\n",
      "Ep:149, loss:0.00000, loss_test:0.06612, lr:3.38e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.266, tt:6339.826\n",
      "Ep:150, loss:0.00000, loss_test:0.06584, lr:3.34e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.274, tt:6383.418\n",
      "Ep:151, loss:0.00000, loss_test:0.06620, lr:3.31e-03, fs:0.78824 (r=0.677,p=0.944),  time:42.288, tt:6427.781\n",
      "Ep:152, loss:0.00000, loss_test:0.06588, lr:3.28e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.299, tt:6471.739\n",
      "Ep:153, loss:0.00000, loss_test:0.06591, lr:3.24e-03, fs:0.79532 (r=0.687,p=0.944),  time:42.297, tt:6513.816\n",
      "Ep:154, loss:0.00000, loss_test:0.06582, lr:3.21e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.305, tt:6557.218\n",
      "Ep:155, loss:0.00000, loss_test:0.06603, lr:3.18e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.319, tt:6601.710\n",
      "Ep:156, loss:0.00000, loss_test:0.06532, lr:3.15e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.342, tt:6647.684\n",
      "Ep:157, loss:0.00000, loss_test:0.06674, lr:3.12e-03, fs:0.80233 (r=0.697,p=0.945),  time:42.356, tt:6692.309\n",
      "Ep:158, loss:0.00000, loss_test:0.06634, lr:3.09e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.355, tt:6734.413\n",
      "Ep:159, loss:0.00000, loss_test:0.06584, lr:3.05e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.365, tt:6778.347\n",
      "Ep:160, loss:0.00000, loss_test:0.06619, lr:3.02e-03, fs:0.80233 (r=0.697,p=0.945),  time:42.367, tt:6821.145\n",
      "Ep:161, loss:0.00000, loss_test:0.06521, lr:2.99e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.374, tt:6864.521\n",
      "Ep:162, loss:0.00000, loss_test:0.06652, lr:2.96e-03, fs:0.78107 (r=0.667,p=0.943),  time:42.376, tt:6907.363\n",
      "Ep:163, loss:0.00000, loss_test:0.06565, lr:2.93e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.365, tt:6947.875\n",
      "Ep:164, loss:0.00000, loss_test:0.06541, lr:2.90e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.395, tt:6995.198\n",
      "Ep:165, loss:0.00000, loss_test:0.06542, lr:2.88e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.404, tt:7039.144\n",
      "Ep:166, loss:0.00000, loss_test:0.06584, lr:2.85e-03, fs:0.80925 (r=0.707,p=0.946),  time:42.404, tt:7081.535\n",
      "Ep:167, loss:0.00000, loss_test:0.06544, lr:2.82e-03, fs:0.80925 (r=0.707,p=0.946),  time:42.407, tt:7124.362\n",
      "Ep:168, loss:0.00000, loss_test:0.06525, lr:2.79e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.413, tt:7167.796\n",
      "Ep:169, loss:0.00000, loss_test:0.06598, lr:2.76e-03, fs:0.80925 (r=0.707,p=0.946),  time:42.418, tt:7211.013\n",
      "Ep:170, loss:0.00000, loss_test:0.06539, lr:2.73e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.412, tt:7252.494\n",
      "Ep:171, loss:0.00000, loss_test:0.06637, lr:2.71e-03, fs:0.78824 (r=0.677,p=0.944),  time:42.419, tt:7296.013\n",
      "Ep:172, loss:0.00000, loss_test:0.06516, lr:2.68e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.423, tt:7339.145\n",
      "Ep:173, loss:0.00000, loss_test:0.06634, lr:2.65e-03, fs:0.78107 (r=0.667,p=0.943),  time:42.420, tt:7381.004\n",
      "Ep:174, loss:0.00000, loss_test:0.06676, lr:2.63e-03, fs:0.80925 (r=0.707,p=0.946),  time:42.411, tt:7421.999\n",
      "Ep:175, loss:0.00000, loss_test:0.06544, lr:2.60e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.416, tt:7465.138\n",
      "Ep:176, loss:0.00000, loss_test:0.06542, lr:2.57e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.420, tt:7508.345\n",
      "Ep:177, loss:0.00000, loss_test:0.06572, lr:2.55e-03, fs:0.80925 (r=0.707,p=0.946),  time:42.424, tt:7551.512\n",
      "Ep:178, loss:0.00000, loss_test:0.06565, lr:2.52e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.426, tt:7594.297\n",
      "Ep:179, loss:0.00000, loss_test:0.06529, lr:2.50e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.431, tt:7637.504\n",
      "Ep:180, loss:0.00000, loss_test:0.06653, lr:2.47e-03, fs:0.77381 (r=0.657,p=0.942),  time:42.444, tt:7682.296\n",
      "Ep:181, loss:0.00000, loss_test:0.06635, lr:2.45e-03, fs:0.82286 (r=0.727,p=0.947),  time:42.440, tt:7724.039\n",
      "Ep:182, loss:0.00000, loss_test:0.06566, lr:2.42e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.463, tt:7770.691\n",
      "Ep:183, loss:0.00000, loss_test:0.06601, lr:2.40e-03, fs:0.79532 (r=0.687,p=0.944),  time:42.479, tt:7816.223\n",
      "Ep:184, loss:0.00000, loss_test:0.06603, lr:2.38e-03, fs:0.80925 (r=0.707,p=0.946),  time:42.498, tt:7862.071\n",
      "Ep:185, loss:0.00000, loss_test:0.06567, lr:2.35e-03, fs:0.80925 (r=0.707,p=0.946),  time:42.504, tt:7905.805\n",
      "Ep:186, loss:0.00000, loss_test:0.06517, lr:2.33e-03, fs:0.80925 (r=0.707,p=0.946),  time:42.521, tt:7951.460\n",
      "Ep:187, loss:0.00000, loss_test:0.06580, lr:2.31e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.538, tt:7997.064\n",
      "Ep:188, loss:0.00000, loss_test:0.06579, lr:2.28e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.549, tt:8041.791\n",
      "Ep:189, loss:0.00000, loss_test:0.06553, lr:2.26e-03, fs:0.80925 (r=0.707,p=0.946),  time:42.563, tt:8086.989\n",
      "Ep:190, loss:0.00000, loss_test:0.06561, lr:2.24e-03, fs:0.80925 (r=0.707,p=0.946),  time:42.577, tt:8132.223\n",
      "Ep:191, loss:0.00000, loss_test:0.06552, lr:2.21e-03, fs:0.80925 (r=0.707,p=0.946),  time:42.593, tt:8177.802\n",
      "Ep:192, loss:0.00000, loss_test:0.06478, lr:2.19e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.600, tt:8221.750\n",
      "Ep:193, loss:0.00000, loss_test:0.06662, lr:2.17e-03, fs:0.77381 (r=0.657,p=0.942),  time:42.609, tt:8266.149\n",
      "Ep:194, loss:0.00000, loss_test:0.06612, lr:2.15e-03, fs:0.80925 (r=0.707,p=0.946),  time:42.618, tt:8310.584\n",
      "Ep:195, loss:0.00000, loss_test:0.06571, lr:2.13e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.621, tt:8353.647\n",
      "Ep:196, loss:0.00000, loss_test:0.06561, lr:2.11e-03, fs:0.80925 (r=0.707,p=0.946),  time:42.649, tt:8401.935\n",
      "Ep:197, loss:0.00000, loss_test:0.06562, lr:2.08e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.649, tt:8444.445\n",
      "Ep:198, loss:0.00000, loss_test:0.06570, lr:2.06e-03, fs:0.80925 (r=0.707,p=0.946),  time:42.651, tt:8487.604\n",
      "Ep:199, loss:0.00000, loss_test:0.06509, lr:2.04e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.654, tt:8530.743\n",
      "Ep:200, loss:0.00000, loss_test:0.06599, lr:2.02e-03, fs:0.80925 (r=0.707,p=0.946),  time:42.661, tt:8574.842\n",
      "Ep:201, loss:0.00000, loss_test:0.06541, lr:2.00e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.649, tt:8615.130\n",
      "Ep:202, loss:0.00000, loss_test:0.06584, lr:1.98e-03, fs:0.80925 (r=0.707,p=0.946),  time:42.654, tt:8658.812\n",
      "Ep:203, loss:0.00000, loss_test:0.06583, lr:1.96e-03, fs:0.80925 (r=0.707,p=0.946),  time:42.658, tt:8702.260\n",
      "Ep:204, loss:0.00000, loss_test:0.06521, lr:1.94e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.666, tt:8746.432\n",
      "Ep:205, loss:0.00000, loss_test:0.06526, lr:1.92e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.676, tt:8791.186\n",
      "Ep:206, loss:0.00000, loss_test:0.06627, lr:1.90e-03, fs:0.77381 (r=0.657,p=0.942),  time:42.687, tt:8836.157\n",
      "Ep:207, loss:0.00000, loss_test:0.06638, lr:1.89e-03, fs:0.78824 (r=0.677,p=0.944),  time:42.690, tt:8879.478\n",
      "Ep:208, loss:0.00000, loss_test:0.06585, lr:1.87e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.678, tt:8919.634\n",
      "Ep:209, loss:0.00000, loss_test:0.06593, lr:1.85e-03, fs:0.80925 (r=0.707,p=0.946),  time:42.635, tt:8953.314\n",
      "Ep:210, loss:0.00000, loss_test:0.06521, lr:1.83e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.606, tt:8989.780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02061, lr:6.00e-02, fs:0.66434 (r=0.960,p=0.508),  time:32.262, tt:32.262\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02350, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.318, tt:70.635\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02403, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.665, tt:112.994\n",
      "Ep:3, loss:0.00004, loss_test:0.02282, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.077, tt:156.308\n",
      "Ep:4, loss:0.00004, loss_test:0.02079, lr:6.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:40.189, tt:200.947\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.01891, lr:6.00e-02, fs:0.68551 (r=0.980,p=0.527),  time:40.766, tt:244.595\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01810, lr:6.00e-02, fs:0.69291 (r=0.889,p=0.568),  time:41.077, tt:287.537\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01775, lr:6.00e-02, fs:0.69787 (r=0.828,p=0.603),  time:41.242, tt:329.938\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00003, loss_test:0.01725, lr:6.00e-02, fs:0.72000 (r=0.909,p=0.596),  time:41.623, tt:374.606\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01704, lr:6.00e-02, fs:0.73962 (r=0.990,p=0.590),  time:41.768, tt:417.679\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01702, lr:6.00e-02, fs:0.72659 (r=0.980,p=0.577),  time:41.957, tt:461.532\n",
      "Ep:11, loss:0.00003, loss_test:0.01674, lr:6.00e-02, fs:0.72932 (r=0.980,p=0.581),  time:42.102, tt:505.222\n",
      "Ep:12, loss:0.00003, loss_test:0.01637, lr:6.00e-02, fs:0.74308 (r=0.949,p=0.610),  time:42.627, tt:554.153\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01602, lr:6.00e-02, fs:0.76113 (r=0.949,p=0.635),  time:42.443, tt:594.197\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01576, lr:6.00e-02, fs:0.76230 (r=0.939,p=0.641),  time:42.435, tt:636.530\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01552, lr:6.00e-02, fs:0.77049 (r=0.949,p=0.648),  time:42.338, tt:677.412\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01533, lr:6.00e-02, fs:0.77551 (r=0.960,p=0.651),  time:42.320, tt:719.441\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01519, lr:6.00e-02, fs:0.77551 (r=0.960,p=0.651),  time:42.292, tt:761.259\n",
      "Ep:18, loss:0.00003, loss_test:0.01503, lr:6.00e-02, fs:0.78189 (r=0.960,p=0.660),  time:42.258, tt:802.893\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00002, loss_test:0.01490, lr:6.00e-02, fs:0.79167 (r=0.960,p=0.674),  time:42.315, tt:846.300\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.01475, lr:6.00e-02, fs:0.78814 (r=0.939,p=0.679),  time:42.356, tt:889.475\n",
      "Ep:21, loss:0.00002, loss_test:0.01462, lr:6.00e-02, fs:0.79325 (r=0.949,p=0.681),  time:42.298, tt:930.558\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01454, lr:6.00e-02, fs:0.80342 (r=0.949,p=0.696),  time:42.312, tt:973.173\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01446, lr:6.00e-02, fs:0.81223 (r=0.939,p=0.715),  time:42.404, tt:1017.707\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01441, lr:6.00e-02, fs:0.80889 (r=0.919,p=0.722),  time:42.375, tt:1059.365\n",
      "Ep:25, loss:0.00002, loss_test:0.01431, lr:6.00e-02, fs:0.79821 (r=0.899,p=0.718),  time:42.280, tt:1099.272\n",
      "Ep:26, loss:0.00002, loss_test:0.01418, lr:6.00e-02, fs:0.81081 (r=0.909,p=0.732),  time:42.303, tt:1142.194\n",
      "Ep:27, loss:0.00002, loss_test:0.01412, lr:6.00e-02, fs:0.80543 (r=0.899,p=0.730),  time:42.261, tt:1183.311\n",
      "Ep:28, loss:0.00002, loss_test:0.01410, lr:6.00e-02, fs:0.80000 (r=0.889,p=0.727),  time:42.253, tt:1225.326\n",
      "Ep:29, loss:0.00002, loss_test:0.01405, lr:6.00e-02, fs:0.79452 (r=0.879,p=0.725),  time:42.285, tt:1268.565\n",
      "Ep:30, loss:0.00002, loss_test:0.01390, lr:6.00e-02, fs:0.80000 (r=0.889,p=0.727),  time:42.233, tt:1309.229\n",
      "Ep:31, loss:0.00002, loss_test:0.01384, lr:6.00e-02, fs:0.80000 (r=0.889,p=0.727),  time:42.240, tt:1351.668\n",
      "Ep:32, loss:0.00002, loss_test:0.01381, lr:6.00e-02, fs:0.79817 (r=0.879,p=0.731),  time:42.298, tt:1395.819\n",
      "Ep:33, loss:0.00002, loss_test:0.01374, lr:6.00e-02, fs:0.79817 (r=0.879,p=0.731),  time:42.282, tt:1437.595\n",
      "Ep:34, loss:0.00002, loss_test:0.01367, lr:6.00e-02, fs:0.79817 (r=0.879,p=0.731),  time:42.284, tt:1479.943\n",
      "Ep:35, loss:0.00002, loss_test:0.01363, lr:5.94e-02, fs:0.79263 (r=0.869,p=0.729),  time:42.235, tt:1520.451\n",
      "Ep:36, loss:0.00002, loss_test:0.01358, lr:5.88e-02, fs:0.79263 (r=0.869,p=0.729),  time:42.260, tt:1563.637\n",
      "Ep:37, loss:0.00002, loss_test:0.01350, lr:5.82e-02, fs:0.79817 (r=0.879,p=0.731),  time:42.267, tt:1606.152\n",
      "Ep:38, loss:0.00002, loss_test:0.01345, lr:5.76e-02, fs:0.79070 (r=0.859,p=0.733),  time:42.275, tt:1648.712\n",
      "Ep:39, loss:0.00002, loss_test:0.01343, lr:5.71e-02, fs:0.79070 (r=0.859,p=0.733),  time:42.212, tt:1688.488\n",
      "Ep:40, loss:0.00002, loss_test:0.01336, lr:5.65e-02, fs:0.79070 (r=0.859,p=0.733),  time:42.192, tt:1729.879\n",
      "Ep:41, loss:0.00002, loss_test:0.01332, lr:5.59e-02, fs:0.79070 (r=0.859,p=0.733),  time:42.159, tt:1770.671\n",
      "Ep:42, loss:0.00001, loss_test:0.01326, lr:5.54e-02, fs:0.79630 (r=0.869,p=0.735),  time:42.161, tt:1812.942\n",
      "Ep:43, loss:0.00001, loss_test:0.01324, lr:5.48e-02, fs:0.79070 (r=0.859,p=0.733),  time:42.175, tt:1855.720\n",
      "Ep:44, loss:0.00001, loss_test:0.01321, lr:5.43e-02, fs:0.78505 (r=0.848,p=0.730),  time:42.167, tt:1897.537\n",
      "Ep:45, loss:0.00001, loss_test:0.01312, lr:5.37e-02, fs:0.79439 (r=0.859,p=0.739),  time:42.124, tt:1937.707\n",
      "Ep:46, loss:0.00001, loss_test:0.01319, lr:5.32e-02, fs:0.79621 (r=0.848,p=0.750),  time:42.112, tt:1979.242\n",
      "Ep:47, loss:0.00001, loss_test:0.01318, lr:5.27e-02, fs:0.78469 (r=0.828,p=0.745),  time:42.106, tt:2021.093\n",
      "Ep:48, loss:0.00001, loss_test:0.01308, lr:5.21e-02, fs:0.79621 (r=0.848,p=0.750),  time:42.099, tt:2062.873\n",
      "Ep:49, loss:0.00001, loss_test:0.01305, lr:5.16e-02, fs:0.79621 (r=0.848,p=0.750),  time:42.092, tt:2104.605\n",
      "Ep:50, loss:0.00001, loss_test:0.01305, lr:5.11e-02, fs:0.79426 (r=0.838,p=0.755),  time:42.076, tt:2145.869\n",
      "Ep:51, loss:0.00001, loss_test:0.01301, lr:5.06e-02, fs:0.79808 (r=0.838,p=0.761),  time:42.027, tt:2185.413\n",
      "Ep:52, loss:0.00001, loss_test:0.01303, lr:5.01e-02, fs:0.80193 (r=0.838,p=0.769),  time:42.020, tt:2227.056\n",
      "Ep:53, loss:0.00001, loss_test:0.01299, lr:4.96e-02, fs:0.80193 (r=0.838,p=0.769),  time:41.968, tt:2266.291\n",
      "Ep:54, loss:0.00001, loss_test:0.01291, lr:4.91e-02, fs:0.80193 (r=0.838,p=0.769),  time:41.957, tt:2307.630\n",
      "Ep:55, loss:0.00001, loss_test:0.01294, lr:4.86e-02, fs:0.80193 (r=0.838,p=0.769),  time:41.920, tt:2347.517\n",
      "Ep:56, loss:0.00001, loss_test:0.01294, lr:4.81e-02, fs:0.79612 (r=0.828,p=0.766),  time:41.917, tt:2389.294\n",
      "Ep:57, loss:0.00001, loss_test:0.01289, lr:4.76e-02, fs:0.80000 (r=0.828,p=0.774),  time:41.922, tt:2431.497\n",
      "Ep:58, loss:0.00001, loss_test:0.01288, lr:4.71e-02, fs:0.80193 (r=0.838,p=0.769),  time:41.922, tt:2473.376\n",
      "Ep:59, loss:0.00001, loss_test:0.01287, lr:4.67e-02, fs:0.80193 (r=0.838,p=0.769),  time:41.935, tt:2516.116\n",
      "Ep:60, loss:0.00001, loss_test:0.01282, lr:4.62e-02, fs:0.80392 (r=0.828,p=0.781),  time:41.924, tt:2557.347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00001, loss_test:0.01284, lr:4.57e-02, fs:0.80392 (r=0.828,p=0.781),  time:41.904, tt:2598.073\n",
      "Ep:62, loss:0.00001, loss_test:0.01287, lr:4.53e-02, fs:0.80788 (r=0.828,p=0.788),  time:41.890, tt:2639.092\n",
      "Ep:63, loss:0.00001, loss_test:0.01280, lr:4.48e-02, fs:0.80788 (r=0.828,p=0.788),  time:41.923, tt:2683.088\n",
      "Ep:64, loss:0.00001, loss_test:0.01277, lr:4.44e-02, fs:0.80788 (r=0.828,p=0.788),  time:41.930, tt:2725.479\n",
      "Ep:65, loss:0.00001, loss_test:0.01282, lr:4.39e-02, fs:0.80788 (r=0.828,p=0.788),  time:41.934, tt:2767.615\n",
      "Ep:66, loss:0.00001, loss_test:0.01282, lr:4.35e-02, fs:0.80788 (r=0.828,p=0.788),  time:41.918, tt:2808.485\n",
      "Ep:67, loss:0.00001, loss_test:0.01276, lr:4.31e-02, fs:0.80788 (r=0.828,p=0.788),  time:41.914, tt:2850.157\n",
      "Ep:68, loss:0.00001, loss_test:0.01273, lr:4.26e-02, fs:0.80788 (r=0.828,p=0.788),  time:41.884, tt:2889.963\n",
      "Ep:69, loss:0.00001, loss_test:0.01276, lr:4.22e-02, fs:0.81592 (r=0.828,p=0.804),  time:41.907, tt:2933.491\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.01277, lr:4.22e-02, fs:0.81188 (r=0.828,p=0.796),  time:41.898, tt:2974.767\n",
      "Ep:71, loss:0.00001, loss_test:0.01274, lr:4.22e-02, fs:0.81592 (r=0.828,p=0.804),  time:41.878, tt:3015.224\n",
      "Ep:72, loss:0.00001, loss_test:0.01274, lr:4.22e-02, fs:0.82000 (r=0.828,p=0.812),  time:41.873, tt:3056.726\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.01272, lr:4.22e-02, fs:0.82000 (r=0.828,p=0.812),  time:41.909, tt:3101.246\n",
      "Ep:74, loss:0.00001, loss_test:0.01278, lr:4.22e-02, fs:0.82412 (r=0.828,p=0.820),  time:41.883, tt:3141.249\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00001, loss_test:0.01277, lr:4.22e-02, fs:0.82828 (r=0.828,p=0.828),  time:41.857, tt:3181.113\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.01276, lr:4.22e-02, fs:0.82828 (r=0.828,p=0.828),  time:41.826, tt:3220.636\n",
      "Ep:77, loss:0.00001, loss_test:0.01280, lr:4.22e-02, fs:0.82828 (r=0.828,p=0.828),  time:41.821, tt:3262.032\n",
      "Ep:78, loss:0.00001, loss_test:0.01279, lr:4.22e-02, fs:0.82828 (r=0.828,p=0.828),  time:41.817, tt:3303.528\n",
      "Ep:79, loss:0.00001, loss_test:0.01280, lr:4.22e-02, fs:0.82828 (r=0.828,p=0.828),  time:41.809, tt:3344.727\n",
      "Ep:80, loss:0.00001, loss_test:0.01279, lr:4.22e-02, fs:0.82828 (r=0.828,p=0.828),  time:41.782, tt:3384.355\n",
      "Ep:81, loss:0.00001, loss_test:0.01285, lr:4.22e-02, fs:0.82828 (r=0.828,p=0.828),  time:41.826, tt:3429.731\n",
      "Ep:82, loss:0.00001, loss_test:0.01285, lr:4.22e-02, fs:0.81633 (r=0.808,p=0.825),  time:41.778, tt:3467.544\n",
      "Ep:83, loss:0.00001, loss_test:0.01282, lr:4.22e-02, fs:0.81633 (r=0.808,p=0.825),  time:41.782, tt:3509.707\n",
      "Ep:84, loss:0.00001, loss_test:0.01290, lr:4.22e-02, fs:0.82051 (r=0.808,p=0.833),  time:41.779, tt:3551.234\n",
      "Ep:85, loss:0.00001, loss_test:0.01289, lr:4.22e-02, fs:0.82051 (r=0.808,p=0.833),  time:41.804, tt:3595.149\n",
      "Ep:86, loss:0.00001, loss_test:0.01286, lr:4.22e-02, fs:0.82051 (r=0.808,p=0.833),  time:41.805, tt:3637.011\n",
      "Ep:87, loss:0.00001, loss_test:0.01297, lr:4.18e-02, fs:0.82474 (r=0.808,p=0.842),  time:41.818, tt:3680.022\n",
      "Ep:88, loss:0.00001, loss_test:0.01300, lr:4.14e-02, fs:0.82474 (r=0.808,p=0.842),  time:41.842, tt:3723.933\n",
      "Ep:89, loss:0.00001, loss_test:0.01299, lr:4.10e-02, fs:0.83333 (r=0.808,p=0.860),  time:41.848, tt:3766.312\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00001, loss_test:0.01301, lr:4.10e-02, fs:0.84211 (r=0.808,p=0.879),  time:41.858, tt:3809.113\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00001, loss_test:0.01303, lr:4.10e-02, fs:0.84211 (r=0.808,p=0.879),  time:41.847, tt:3849.946\n",
      "Ep:92, loss:0.00001, loss_test:0.01303, lr:4.10e-02, fs:0.84211 (r=0.808,p=0.879),  time:41.831, tt:3890.294\n",
      "Ep:93, loss:0.00001, loss_test:0.01307, lr:4.10e-02, fs:0.84211 (r=0.808,p=0.879),  time:41.836, tt:3932.601\n",
      "Ep:94, loss:0.00001, loss_test:0.01314, lr:4.10e-02, fs:0.83598 (r=0.798,p=0.878),  time:41.837, tt:3974.483\n",
      "Ep:95, loss:0.00001, loss_test:0.01307, lr:4.10e-02, fs:0.83598 (r=0.798,p=0.878),  time:41.814, tt:4014.147\n",
      "Ep:96, loss:0.00001, loss_test:0.01309, lr:4.10e-02, fs:0.83598 (r=0.798,p=0.878),  time:41.796, tt:4054.189\n",
      "Ep:97, loss:0.00001, loss_test:0.01317, lr:4.10e-02, fs:0.83598 (r=0.798,p=0.878),  time:41.819, tt:4098.273\n",
      "Ep:98, loss:0.00001, loss_test:0.01321, lr:4.10e-02, fs:0.82979 (r=0.788,p=0.876),  time:41.807, tt:4138.927\n",
      "Ep:99, loss:0.00001, loss_test:0.01321, lr:4.10e-02, fs:0.82979 (r=0.788,p=0.876),  time:41.794, tt:4179.431\n",
      "Ep:100, loss:0.00001, loss_test:0.01321, lr:4.10e-02, fs:0.82979 (r=0.788,p=0.876),  time:41.784, tt:4220.146\n",
      "Ep:101, loss:0.00001, loss_test:0.01329, lr:4.10e-02, fs:0.82979 (r=0.788,p=0.876),  time:41.794, tt:4262.953\n",
      "Ep:102, loss:0.00001, loss_test:0.01337, lr:4.05e-02, fs:0.82353 (r=0.778,p=0.875),  time:41.797, tt:4305.061\n",
      "Ep:103, loss:0.00001, loss_test:0.01333, lr:4.01e-02, fs:0.81720 (r=0.768,p=0.874),  time:41.801, tt:4347.284\n",
      "Ep:104, loss:0.00001, loss_test:0.01337, lr:3.97e-02, fs:0.81720 (r=0.768,p=0.874),  time:41.803, tt:4389.267\n",
      "Ep:105, loss:0.00001, loss_test:0.01339, lr:3.93e-02, fs:0.81720 (r=0.768,p=0.874),  time:41.793, tt:4430.090\n",
      "Ep:106, loss:0.00001, loss_test:0.01339, lr:3.89e-02, fs:0.81081 (r=0.758,p=0.872),  time:41.779, tt:4470.375\n",
      "Ep:107, loss:0.00001, loss_test:0.01344, lr:3.86e-02, fs:0.81081 (r=0.758,p=0.872),  time:41.775, tt:4511.719\n",
      "Ep:108, loss:0.00001, loss_test:0.01349, lr:3.82e-02, fs:0.81081 (r=0.758,p=0.872),  time:41.750, tt:4550.732\n",
      "Ep:109, loss:0.00001, loss_test:0.01347, lr:3.78e-02, fs:0.81081 (r=0.758,p=0.872),  time:41.773, tt:4595.035\n",
      "Ep:110, loss:0.00001, loss_test:0.01347, lr:3.74e-02, fs:0.81081 (r=0.758,p=0.872),  time:41.765, tt:4635.902\n",
      "Ep:111, loss:0.00001, loss_test:0.01351, lr:3.70e-02, fs:0.81081 (r=0.758,p=0.872),  time:41.746, tt:4675.602\n",
      "Ep:112, loss:0.00001, loss_test:0.01352, lr:3.67e-02, fs:0.81081 (r=0.758,p=0.872),  time:41.740, tt:4716.663\n",
      "Ep:113, loss:0.00001, loss_test:0.01354, lr:3.63e-02, fs:0.80435 (r=0.747,p=0.871),  time:41.705, tt:4754.358\n",
      "Ep:114, loss:0.00001, loss_test:0.01359, lr:3.59e-02, fs:0.80435 (r=0.747,p=0.871),  time:41.691, tt:4794.454\n",
      "Ep:115, loss:0.00001, loss_test:0.01363, lr:3.56e-02, fs:0.79781 (r=0.737,p=0.869),  time:41.695, tt:4836.568\n",
      "Ep:116, loss:0.00001, loss_test:0.01361, lr:3.52e-02, fs:0.80435 (r=0.747,p=0.871),  time:41.682, tt:4876.794\n",
      "Ep:117, loss:0.00001, loss_test:0.01365, lr:3.49e-02, fs:0.79781 (r=0.737,p=0.869),  time:41.674, tt:4917.481\n",
      "Ep:118, loss:0.00001, loss_test:0.01374, lr:3.45e-02, fs:0.79121 (r=0.727,p=0.867),  time:41.678, tt:4959.721\n",
      "Ep:119, loss:0.00001, loss_test:0.01377, lr:3.42e-02, fs:0.79558 (r=0.727,p=0.878),  time:41.681, tt:5001.740\n",
      "Ep:120, loss:0.00001, loss_test:0.01380, lr:3.38e-02, fs:0.78889 (r=0.717,p=0.877),  time:41.679, tt:5043.175\n",
      "Ep:121, loss:0.00001, loss_test:0.01381, lr:3.35e-02, fs:0.78212 (r=0.707,p=0.875),  time:41.672, tt:5084.021\n",
      "Ep:122, loss:0.00001, loss_test:0.01380, lr:3.32e-02, fs:0.78212 (r=0.707,p=0.875),  time:41.658, tt:5123.952\n",
      "Ep:123, loss:0.00001, loss_test:0.01390, lr:3.28e-02, fs:0.78212 (r=0.707,p=0.875),  time:41.664, tt:5166.339\n",
      "Ep:124, loss:0.00001, loss_test:0.01391, lr:3.25e-02, fs:0.77528 (r=0.697,p=0.873),  time:41.671, tt:5208.885\n",
      "Ep:125, loss:0.00001, loss_test:0.01393, lr:3.22e-02, fs:0.76836 (r=0.687,p=0.872),  time:41.662, tt:5249.408\n",
      "Ep:126, loss:0.00001, loss_test:0.01397, lr:3.19e-02, fs:0.76836 (r=0.687,p=0.872),  time:41.673, tt:5292.506\n",
      "Ep:127, loss:0.00001, loss_test:0.01398, lr:3.15e-02, fs:0.76836 (r=0.687,p=0.872),  time:41.668, tt:5333.445\n",
      "Ep:128, loss:0.00001, loss_test:0.01403, lr:3.12e-02, fs:0.76136 (r=0.677,p=0.870),  time:41.660, tt:5374.097\n",
      "Ep:129, loss:0.00000, loss_test:0.01406, lr:3.09e-02, fs:0.75429 (r=0.667,p=0.868),  time:41.668, tt:5416.849\n",
      "Ep:130, loss:0.00000, loss_test:0.01407, lr:3.06e-02, fs:0.74713 (r=0.657,p=0.867),  time:41.651, tt:5456.313\n",
      "Ep:131, loss:0.00000, loss_test:0.01408, lr:3.03e-02, fs:0.74713 (r=0.657,p=0.867),  time:41.661, tt:5499.304\n",
      "Ep:132, loss:0.00000, loss_test:0.01411, lr:3.00e-02, fs:0.75581 (r=0.657,p=0.890),  time:41.659, tt:5540.672\n",
      "Ep:133, loss:0.00000, loss_test:0.01415, lr:2.97e-02, fs:0.75581 (r=0.657,p=0.890),  time:41.650, tt:5581.148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00000, loss_test:0.01418, lr:2.94e-02, fs:0.75145 (r=0.657,p=0.878),  time:41.656, tt:5623.620\n",
      "Ep:135, loss:0.00000, loss_test:0.01424, lr:2.91e-02, fs:0.75581 (r=0.657,p=0.890),  time:41.644, tt:5663.602\n",
      "Ep:136, loss:0.00000, loss_test:0.01424, lr:2.88e-02, fs:0.75581 (r=0.657,p=0.890),  time:41.628, tt:5702.973\n",
      "Ep:137, loss:0.00000, loss_test:0.01429, lr:2.85e-02, fs:0.74854 (r=0.646,p=0.889),  time:41.610, tt:5742.129\n",
      "Ep:138, loss:0.00000, loss_test:0.01432, lr:2.82e-02, fs:0.74854 (r=0.646,p=0.889),  time:41.602, tt:5782.648\n",
      "Ep:139, loss:0.00000, loss_test:0.01437, lr:2.80e-02, fs:0.74118 (r=0.636,p=0.887),  time:41.592, tt:5822.935\n",
      "Ep:140, loss:0.00000, loss_test:0.01438, lr:2.77e-02, fs:0.74118 (r=0.636,p=0.887),  time:41.588, tt:5863.934\n",
      "Ep:141, loss:0.00000, loss_test:0.01438, lr:2.74e-02, fs:0.74854 (r=0.646,p=0.889),  time:41.582, tt:5904.595\n",
      "Ep:142, loss:0.00000, loss_test:0.01442, lr:2.71e-02, fs:0.74118 (r=0.636,p=0.887),  time:41.585, tt:5946.641\n",
      "Ep:143, loss:0.00000, loss_test:0.01448, lr:2.69e-02, fs:0.74118 (r=0.636,p=0.887),  time:41.585, tt:5988.284\n",
      "Ep:144, loss:0.00000, loss_test:0.01448, lr:2.66e-02, fs:0.74118 (r=0.636,p=0.887),  time:41.587, tt:6030.138\n",
      "Ep:145, loss:0.00000, loss_test:0.01456, lr:2.63e-02, fs:0.74118 (r=0.636,p=0.887),  time:41.584, tt:6071.249\n",
      "Ep:146, loss:0.00000, loss_test:0.01458, lr:2.61e-02, fs:0.74118 (r=0.636,p=0.887),  time:41.582, tt:6112.536\n",
      "Ep:147, loss:0.00000, loss_test:0.01460, lr:2.58e-02, fs:0.74118 (r=0.636,p=0.887),  time:41.555, tt:6150.123\n",
      "Ep:148, loss:0.00000, loss_test:0.01464, lr:2.55e-02, fs:0.74118 (r=0.636,p=0.887),  time:41.547, tt:6190.551\n",
      "Ep:149, loss:0.00000, loss_test:0.01466, lr:2.53e-02, fs:0.74118 (r=0.636,p=0.887),  time:41.556, tt:6233.399\n",
      "Ep:150, loss:0.00000, loss_test:0.01468, lr:2.50e-02, fs:0.74118 (r=0.636,p=0.887),  time:41.549, tt:6273.939\n",
      "Ep:151, loss:0.00000, loss_test:0.01469, lr:2.48e-02, fs:0.74118 (r=0.636,p=0.887),  time:41.549, tt:6315.435\n",
      "Ep:152, loss:0.00000, loss_test:0.01472, lr:2.45e-02, fs:0.74118 (r=0.636,p=0.887),  time:41.540, tt:6355.561\n",
      "Ep:153, loss:0.00000, loss_test:0.01475, lr:2.43e-02, fs:0.74118 (r=0.636,p=0.887),  time:41.536, tt:6396.593\n",
      "Ep:154, loss:0.00000, loss_test:0.01475, lr:2.40e-02, fs:0.74118 (r=0.636,p=0.887),  time:41.534, tt:6437.759\n",
      "Ep:155, loss:0.00000, loss_test:0.01480, lr:2.38e-02, fs:0.74118 (r=0.636,p=0.887),  time:41.577, tt:6486.087\n",
      "Ep:156, loss:0.00000, loss_test:0.01484, lr:2.36e-02, fs:0.74118 (r=0.636,p=0.887),  time:41.563, tt:6525.400\n",
      "Ep:157, loss:0.00000, loss_test:0.01484, lr:2.33e-02, fs:0.74118 (r=0.636,p=0.887),  time:41.551, tt:6565.022\n",
      "Ep:158, loss:0.00000, loss_test:0.01485, lr:2.31e-02, fs:0.74118 (r=0.636,p=0.887),  time:41.548, tt:6606.077\n",
      "Ep:159, loss:0.00000, loss_test:0.01491, lr:2.29e-02, fs:0.74118 (r=0.636,p=0.887),  time:41.543, tt:6646.913\n",
      "Ep:160, loss:0.00000, loss_test:0.01496, lr:2.26e-02, fs:0.74118 (r=0.636,p=0.887),  time:41.540, tt:6687.928\n",
      "Ep:161, loss:0.00000, loss_test:0.01498, lr:2.24e-02, fs:0.74118 (r=0.636,p=0.887),  time:41.536, tt:6728.763\n",
      "Ep:162, loss:0.00000, loss_test:0.01498, lr:2.22e-02, fs:0.74118 (r=0.636,p=0.887),  time:41.530, tt:6769.458\n",
      "Ep:163, loss:0.00000, loss_test:0.01499, lr:2.20e-02, fs:0.74118 (r=0.636,p=0.887),  time:41.527, tt:6810.396\n",
      "Ep:164, loss:0.00000, loss_test:0.01504, lr:2.17e-02, fs:0.74118 (r=0.636,p=0.887),  time:41.519, tt:6850.559\n",
      "Ep:165, loss:0.00000, loss_test:0.01504, lr:2.15e-02, fs:0.74118 (r=0.636,p=0.887),  time:41.515, tt:6891.568\n",
      "Ep:166, loss:0.00000, loss_test:0.01505, lr:2.13e-02, fs:0.74118 (r=0.636,p=0.887),  time:41.515, tt:6933.082\n",
      "Ep:167, loss:0.00000, loss_test:0.01508, lr:2.11e-02, fs:0.74118 (r=0.636,p=0.887),  time:41.509, tt:6973.593\n",
      "Ep:168, loss:0.00000, loss_test:0.01514, lr:2.09e-02, fs:0.74118 (r=0.636,p=0.887),  time:41.504, tt:7014.247\n",
      "Ep:169, loss:0.00000, loss_test:0.01519, lr:2.07e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.502, tt:7055.373\n",
      "Ep:170, loss:0.00000, loss_test:0.01520, lr:2.05e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.493, tt:7095.373\n",
      "Ep:171, loss:0.00000, loss_test:0.01519, lr:2.03e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.487, tt:7135.692\n",
      "Ep:172, loss:0.00000, loss_test:0.01522, lr:2.01e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.477, tt:7175.495\n",
      "Ep:173, loss:0.00000, loss_test:0.01528, lr:1.99e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.467, tt:7215.259\n",
      "Ep:174, loss:0.00000, loss_test:0.01532, lr:1.97e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.466, tt:7256.597\n",
      "Ep:175, loss:0.00000, loss_test:0.01532, lr:1.95e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.452, tt:7295.572\n",
      "Ep:176, loss:0.00000, loss_test:0.01532, lr:1.93e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.454, tt:7337.290\n",
      "Ep:177, loss:0.00000, loss_test:0.01536, lr:1.91e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.452, tt:7378.412\n",
      "Ep:178, loss:0.00000, loss_test:0.01537, lr:1.89e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.448, tt:7419.163\n",
      "Ep:179, loss:0.00000, loss_test:0.01541, lr:1.87e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.442, tt:7459.529\n",
      "Ep:180, loss:0.00000, loss_test:0.01542, lr:1.85e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.437, tt:7500.024\n",
      "Ep:181, loss:0.00000, loss_test:0.01546, lr:1.83e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.429, tt:7540.144\n",
      "Ep:182, loss:0.00000, loss_test:0.01546, lr:1.81e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.424, tt:7580.566\n",
      "Ep:183, loss:0.00000, loss_test:0.01550, lr:1.80e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.417, tt:7620.656\n",
      "Ep:184, loss:0.00000, loss_test:0.01550, lr:1.78e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.410, tt:7660.894\n",
      "Ep:185, loss:0.00000, loss_test:0.01553, lr:1.76e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.410, tt:7702.182\n",
      "Ep:186, loss:0.00000, loss_test:0.01556, lr:1.74e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.403, tt:7742.352\n",
      "Ep:187, loss:0.00000, loss_test:0.01556, lr:1.73e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.398, tt:7782.895\n",
      "Ep:188, loss:0.00000, loss_test:0.01559, lr:1.71e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.383, tt:7821.385\n",
      "Ep:189, loss:0.00000, loss_test:0.01562, lr:1.69e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.364, tt:7859.148\n",
      "Ep:190, loss:0.00000, loss_test:0.01564, lr:1.67e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.365, tt:7900.739\n",
      "Ep:191, loss:0.00000, loss_test:0.01565, lr:1.66e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.361, tt:7941.378\n",
      "Ep:192, loss:0.00000, loss_test:0.01567, lr:1.64e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.346, tt:7979.746\n",
      "Ep:193, loss:0.00000, loss_test:0.01569, lr:1.62e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.328, tt:8017.725\n",
      "Ep:194, loss:0.00000, loss_test:0.01573, lr:1.61e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.333, tt:8060.010\n",
      "Ep:195, loss:0.00000, loss_test:0.01573, lr:1.59e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.324, tt:8099.484\n",
      "Ep:196, loss:0.00000, loss_test:0.01574, lr:1.58e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.317, tt:8139.539\n",
      "Ep:197, loss:0.00000, loss_test:0.01575, lr:1.56e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.347, tt:8186.647\n",
      "Ep:198, loss:0.00000, loss_test:0.01577, lr:1.54e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.338, tt:8226.247\n",
      "Ep:199, loss:0.00000, loss_test:0.01581, lr:1.53e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.333, tt:8266.583\n",
      "Ep:200, loss:0.00000, loss_test:0.01581, lr:1.51e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.322, tt:8305.758\n",
      "Ep:201, loss:0.00000, loss_test:0.01585, lr:1.50e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.307, tt:8344.029\n",
      "Ep:202, loss:0.00000, loss_test:0.01586, lr:1.48e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.303, tt:8384.407\n",
      "Ep:203, loss:0.00000, loss_test:0.01589, lr:1.47e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.290, tt:8423.102\n",
      "Ep:204, loss:0.00000, loss_test:0.01590, lr:1.45e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.287, tt:8463.856\n",
      "Ep:205, loss:0.00000, loss_test:0.01592, lr:1.44e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.289, tt:8505.588\n",
      "Ep:206, loss:0.00000, loss_test:0.01592, lr:1.43e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.290, tt:8546.971\n",
      "Ep:207, loss:0.00000, loss_test:0.01593, lr:1.41e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.276, tt:8585.306\n",
      "Ep:208, loss:0.00000, loss_test:0.01595, lr:1.40e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.269, tt:8625.204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:209, loss:0.00000, loss_test:0.01596, lr:1.38e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.239, tt:8660.258\n",
      "Ep:210, loss:0.00000, loss_test:0.01599, lr:1.37e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.217, tt:8696.821\n",
      "Ep:211, loss:0.00000, loss_test:0.01603, lr:1.36e-02, fs:0.73373 (r=0.626,p=0.886),  time:41.184, tt:8731.114\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14358, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.180, tt:30.180\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14219, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.184, tt:68.368\n",
      "Ep:2, loss:0.00027, loss_test:0.13968, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.224, tt:111.672\n",
      "Ep:3, loss:0.00027, loss_test:0.13564, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:38.462, tt:153.847\n",
      "Ep:4, loss:0.00026, loss_test:0.12903, lr:1.00e-02, fs:0.64727 (r=0.899,p=0.506),  time:39.067, tt:195.335\n",
      "Ep:5, loss:0.00025, loss_test:0.12052, lr:1.00e-02, fs:0.66932 (r=0.848,p=0.553),  time:39.954, tt:239.722\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.11414, lr:1.00e-02, fs:0.68103 (r=0.798,p=0.594),  time:40.135, tt:280.942\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.11156, lr:1.00e-02, fs:0.67544 (r=0.778,p=0.597),  time:40.453, tt:323.622\n",
      "Ep:8, loss:0.00022, loss_test:0.10939, lr:1.00e-02, fs:0.68722 (r=0.788,p=0.609),  time:40.708, tt:366.373\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.10787, lr:1.00e-02, fs:0.68996 (r=0.798,p=0.608),  time:40.850, tt:408.497\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.10485, lr:1.00e-02, fs:0.71171 (r=0.798,p=0.642),  time:40.999, tt:450.988\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.10130, lr:1.00e-02, fs:0.72300 (r=0.778,p=0.675),  time:41.194, tt:494.329\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.09960, lr:1.00e-02, fs:0.73488 (r=0.798,p=0.681),  time:41.373, tt:537.849\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.09849, lr:1.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:41.417, tt:579.833\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.09555, lr:1.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:41.492, tt:622.377\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.09363, lr:1.00e-02, fs:0.78140 (r=0.848,p=0.724),  time:41.477, tt:663.634\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.09209, lr:1.00e-02, fs:0.79630 (r=0.869,p=0.735),  time:41.469, tt:704.966\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.09118, lr:1.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:41.404, tt:745.265\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00016, loss_test:0.09056, lr:1.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:41.372, tt:786.065\n",
      "Ep:19, loss:0.00015, loss_test:0.08969, lr:1.00e-02, fs:0.79612 (r=0.828,p=0.766),  time:41.364, tt:827.275\n",
      "Ep:20, loss:0.00015, loss_test:0.08888, lr:1.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:41.417, tt:869.755\n",
      "Ep:21, loss:0.00014, loss_test:0.08820, lr:1.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:41.392, tt:910.635\n",
      "Ep:22, loss:0.00014, loss_test:0.08715, lr:1.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:41.416, tt:952.558\n",
      "Ep:23, loss:0.00013, loss_test:0.08582, lr:1.00e-02, fs:0.80769 (r=0.848,p=0.771),  time:41.275, tt:990.595\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00013, loss_test:0.08503, lr:1.00e-02, fs:0.80976 (r=0.838,p=0.783),  time:41.283, tt:1032.063\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00012, loss_test:0.08372, lr:1.00e-02, fs:0.83254 (r=0.879,p=0.791),  time:41.256, tt:1072.647\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00012, loss_test:0.08297, lr:1.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:41.262, tt:1114.066\n",
      "Ep:27, loss:0.00012, loss_test:0.08234, lr:1.00e-02, fs:0.82927 (r=0.859,p=0.802),  time:41.259, tt:1155.260\n",
      "Ep:28, loss:0.00011, loss_test:0.08139, lr:1.00e-02, fs:0.82927 (r=0.859,p=0.802),  time:41.242, tt:1196.016\n",
      "Ep:29, loss:0.00011, loss_test:0.08182, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:41.250, tt:1237.514\n",
      "Ep:30, loss:0.00010, loss_test:0.08068, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:41.206, tt:1277.377\n",
      "Ep:31, loss:0.00010, loss_test:0.07918, lr:1.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:41.252, tt:1320.071\n",
      "Ep:32, loss:0.00010, loss_test:0.07861, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:41.258, tt:1361.501\n",
      "Ep:33, loss:0.00009, loss_test:0.07936, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:41.235, tt:1401.980\n",
      "Ep:34, loss:0.00009, loss_test:0.07706, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:41.258, tt:1444.020\n",
      "Ep:35, loss:0.00009, loss_test:0.07684, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:41.278, tt:1486.007\n",
      "Ep:36, loss:0.00009, loss_test:0.07723, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:41.310, tt:1528.454\n",
      "Ep:37, loss:0.00008, loss_test:0.07516, lr:9.90e-03, fs:0.81818 (r=0.818,p=0.818),  time:41.353, tt:1571.423\n",
      "Ep:38, loss:0.00008, loss_test:0.07696, lr:9.80e-03, fs:0.82051 (r=0.808,p=0.833),  time:41.340, tt:1612.274\n",
      "Ep:39, loss:0.00008, loss_test:0.07572, lr:9.70e-03, fs:0.82234 (r=0.818,p=0.827),  time:41.357, tt:1654.284\n",
      "Ep:40, loss:0.00008, loss_test:0.07370, lr:9.61e-03, fs:0.83673 (r=0.828,p=0.845),  time:41.353, tt:1695.485\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00007, loss_test:0.07449, lr:9.61e-03, fs:0.81250 (r=0.788,p=0.839),  time:41.335, tt:1736.091\n",
      "Ep:42, loss:0.00007, loss_test:0.07318, lr:9.61e-03, fs:0.83838 (r=0.838,p=0.838),  time:41.344, tt:1777.782\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00007, loss_test:0.07458, lr:9.61e-03, fs:0.81250 (r=0.788,p=0.839),  time:41.381, tt:1820.749\n",
      "Ep:44, loss:0.00006, loss_test:0.07228, lr:9.61e-03, fs:0.81865 (r=0.798,p=0.840),  time:41.402, tt:1863.093\n",
      "Ep:45, loss:0.00006, loss_test:0.07241, lr:9.61e-03, fs:0.81250 (r=0.788,p=0.839),  time:41.396, tt:1904.224\n",
      "Ep:46, loss:0.00006, loss_test:0.07350, lr:9.61e-03, fs:0.82292 (r=0.798,p=0.849),  time:41.372, tt:1944.477\n",
      "Ep:47, loss:0.00006, loss_test:0.07123, lr:9.61e-03, fs:0.83333 (r=0.808,p=0.860),  time:41.384, tt:1986.429\n",
      "Ep:48, loss:0.00006, loss_test:0.07153, lr:9.61e-03, fs:0.82902 (r=0.808,p=0.851),  time:41.395, tt:2028.336\n",
      "Ep:49, loss:0.00006, loss_test:0.07191, lr:9.61e-03, fs:0.85714 (r=0.848,p=0.866),  time:41.382, tt:2069.092\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00006, loss_test:0.07086, lr:9.61e-03, fs:0.82723 (r=0.798,p=0.859),  time:41.425, tt:2112.675\n",
      "Ep:51, loss:0.00005, loss_test:0.06983, lr:9.61e-03, fs:0.82723 (r=0.798,p=0.859),  time:41.374, tt:2151.438\n",
      "Ep:52, loss:0.00005, loss_test:0.06747, lr:9.61e-03, fs:0.83938 (r=0.818,p=0.862),  time:41.362, tt:2192.186\n",
      "Ep:53, loss:0.00005, loss_test:0.06976, lr:9.61e-03, fs:0.83333 (r=0.808,p=0.860),  time:41.386, tt:2234.856\n",
      "Ep:54, loss:0.00005, loss_test:0.06709, lr:9.61e-03, fs:0.83333 (r=0.808,p=0.860),  time:41.405, tt:2277.281\n",
      "Ep:55, loss:0.00005, loss_test:0.06785, lr:9.61e-03, fs:0.83333 (r=0.808,p=0.860),  time:41.423, tt:2319.703\n",
      "Ep:56, loss:0.00004, loss_test:0.06504, lr:9.61e-03, fs:0.86294 (r=0.859,p=0.867),  time:41.425, tt:2361.229\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00004, loss_test:0.06882, lr:9.61e-03, fs:0.80851 (r=0.768,p=0.854),  time:41.430, tt:2402.937\n",
      "Ep:58, loss:0.00004, loss_test:0.06493, lr:9.61e-03, fs:0.86294 (r=0.859,p=0.867),  time:41.454, tt:2445.797\n",
      "Ep:59, loss:0.00004, loss_test:0.06873, lr:9.61e-03, fs:0.80851 (r=0.768,p=0.854),  time:41.486, tt:2489.135\n",
      "Ep:60, loss:0.00004, loss_test:0.06529, lr:9.61e-03, fs:0.83333 (r=0.808,p=0.860),  time:41.469, tt:2529.601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00004, loss_test:0.06768, lr:9.61e-03, fs:0.86458 (r=0.838,p=0.892),  time:41.479, tt:2571.702\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00004, loss_test:0.06613, lr:9.61e-03, fs:0.81481 (r=0.778,p=0.856),  time:41.496, tt:2614.262\n",
      "Ep:63, loss:0.00004, loss_test:0.06842, lr:9.61e-03, fs:0.83598 (r=0.798,p=0.878),  time:41.503, tt:2656.192\n",
      "Ep:64, loss:0.00004, loss_test:0.06533, lr:9.61e-03, fs:0.85417 (r=0.828,p=0.882),  time:41.471, tt:2695.588\n",
      "Ep:65, loss:0.00004, loss_test:0.06716, lr:9.61e-03, fs:0.80851 (r=0.768,p=0.854),  time:41.496, tt:2738.735\n",
      "Ep:66, loss:0.00004, loss_test:0.06898, lr:9.61e-03, fs:0.79558 (r=0.727,p=0.878),  time:41.491, tt:2779.930\n",
      "Ep:67, loss:0.00003, loss_test:0.06260, lr:9.61e-03, fs:0.88660 (r=0.869,p=0.905),  time:41.504, tt:2822.273\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00003, loss_test:0.06830, lr:9.61e-03, fs:0.79781 (r=0.737,p=0.869),  time:41.498, tt:2863.344\n",
      "Ep:69, loss:0.00003, loss_test:0.06327, lr:9.61e-03, fs:0.85405 (r=0.798,p=0.919),  time:41.507, tt:2905.480\n",
      "Ep:70, loss:0.00003, loss_test:0.06561, lr:9.61e-03, fs:0.83333 (r=0.758,p=0.926),  time:41.521, tt:2947.995\n",
      "Ep:71, loss:0.00003, loss_test:0.06785, lr:9.61e-03, fs:0.80000 (r=0.727,p=0.889),  time:41.528, tt:2989.996\n",
      "Ep:72, loss:0.00003, loss_test:0.06290, lr:9.61e-03, fs:0.89583 (r=0.869,p=0.925),  time:41.534, tt:3031.976\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00003, loss_test:0.06846, lr:9.61e-03, fs:0.79310 (r=0.697,p=0.920),  time:41.521, tt:3072.544\n",
      "Ep:74, loss:0.00003, loss_test:0.06250, lr:9.61e-03, fs:0.82486 (r=0.737,p=0.936),  time:41.578, tt:3118.328\n",
      "Ep:75, loss:0.00003, loss_test:0.06591, lr:9.61e-03, fs:0.79769 (r=0.697,p=0.932),  time:41.579, tt:3159.967\n",
      "Ep:76, loss:0.00003, loss_test:0.06819, lr:9.61e-03, fs:0.80682 (r=0.717,p=0.922),  time:41.589, tt:3202.341\n",
      "Ep:77, loss:0.00003, loss_test:0.06355, lr:9.61e-03, fs:0.81143 (r=0.717,p=0.934),  time:41.595, tt:3244.389\n",
      "Ep:78, loss:0.00003, loss_test:0.06882, lr:9.61e-03, fs:0.80682 (r=0.717,p=0.922),  time:41.601, tt:3286.479\n",
      "Ep:79, loss:0.00002, loss_test:0.06294, lr:9.61e-03, fs:0.82222 (r=0.747,p=0.914),  time:41.595, tt:3327.607\n",
      "Ep:80, loss:0.00003, loss_test:0.06507, lr:9.61e-03, fs:0.80233 (r=0.697,p=0.945),  time:41.577, tt:3367.741\n",
      "Ep:81, loss:0.00002, loss_test:0.07132, lr:9.61e-03, fs:0.80682 (r=0.717,p=0.922),  time:41.559, tt:3407.870\n",
      "Ep:82, loss:0.00002, loss_test:0.06469, lr:9.61e-03, fs:0.81143 (r=0.717,p=0.934),  time:41.554, tt:3449.001\n",
      "Ep:83, loss:0.00002, loss_test:0.06963, lr:9.61e-03, fs:0.80460 (r=0.707,p=0.933),  time:41.554, tt:3490.520\n",
      "Ep:84, loss:0.00002, loss_test:0.06419, lr:9.51e-03, fs:0.79769 (r=0.697,p=0.932),  time:41.542, tt:3531.042\n",
      "Ep:85, loss:0.00002, loss_test:0.06356, lr:9.41e-03, fs:0.80925 (r=0.707,p=0.946),  time:41.533, tt:3571.839\n",
      "Ep:86, loss:0.00002, loss_test:0.06896, lr:9.32e-03, fs:0.82286 (r=0.727,p=0.947),  time:41.530, tt:3613.069\n",
      "Ep:87, loss:0.00002, loss_test:0.06398, lr:9.23e-03, fs:0.82022 (r=0.737,p=0.924),  time:41.514, tt:3653.228\n",
      "Ep:88, loss:0.00002, loss_test:0.07221, lr:9.14e-03, fs:0.80460 (r=0.707,p=0.933),  time:41.514, tt:3694.721\n",
      "Ep:89, loss:0.00002, loss_test:0.06341, lr:9.04e-03, fs:0.80233 (r=0.697,p=0.945),  time:41.537, tt:3738.310\n",
      "Ep:90, loss:0.00002, loss_test:0.07137, lr:8.95e-03, fs:0.80702 (r=0.697,p=0.958),  time:41.550, tt:3781.075\n",
      "Ep:91, loss:0.00002, loss_test:0.06268, lr:8.86e-03, fs:0.80925 (r=0.707,p=0.946),  time:41.555, tt:3823.018\n",
      "Ep:92, loss:0.00002, loss_test:0.06862, lr:8.78e-03, fs:0.80925 (r=0.707,p=0.946),  time:41.559, tt:3865.023\n",
      "Ep:93, loss:0.00002, loss_test:0.06543, lr:8.69e-03, fs:0.79532 (r=0.687,p=0.944),  time:41.553, tt:3906.010\n",
      "Ep:94, loss:0.00001, loss_test:0.06476, lr:8.60e-03, fs:0.80925 (r=0.707,p=0.946),  time:41.544, tt:3946.637\n",
      "Ep:95, loss:0.00001, loss_test:0.06823, lr:8.51e-03, fs:0.79532 (r=0.687,p=0.944),  time:41.542, tt:3988.063\n",
      "Ep:96, loss:0.00001, loss_test:0.06462, lr:8.43e-03, fs:0.80925 (r=0.707,p=0.946),  time:41.549, tt:4030.210\n",
      "Ep:97, loss:0.00001, loss_test:0.07064, lr:8.35e-03, fs:0.80000 (r=0.687,p=0.958),  time:41.562, tt:4073.048\n",
      "Ep:98, loss:0.00001, loss_test:0.06615, lr:8.26e-03, fs:0.80000 (r=0.687,p=0.958),  time:41.563, tt:4114.719\n",
      "Ep:99, loss:0.00001, loss_test:0.06573, lr:8.18e-03, fs:0.82759 (r=0.727,p=0.960),  time:41.557, tt:4155.705\n",
      "Ep:100, loss:0.00001, loss_test:0.06853, lr:8.10e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.555, tt:4197.071\n",
      "Ep:101, loss:0.00001, loss_test:0.06642, lr:8.02e-03, fs:0.80702 (r=0.697,p=0.958),  time:41.559, tt:4239.017\n",
      "Ep:102, loss:0.00001, loss_test:0.06762, lr:7.94e-03, fs:0.80702 (r=0.697,p=0.958),  time:41.566, tt:4281.344\n",
      "Ep:103, loss:0.00001, loss_test:0.06684, lr:7.86e-03, fs:0.80000 (r=0.687,p=0.958),  time:41.576, tt:4323.906\n",
      "Ep:104, loss:0.00001, loss_test:0.06741, lr:7.78e-03, fs:0.80702 (r=0.697,p=0.958),  time:41.569, tt:4364.789\n",
      "Ep:105, loss:0.00001, loss_test:0.06719, lr:7.70e-03, fs:0.80000 (r=0.687,p=0.958),  time:41.574, tt:4406.864\n",
      "Ep:106, loss:0.00001, loss_test:0.06504, lr:7.62e-03, fs:0.80702 (r=0.697,p=0.958),  time:41.599, tt:4451.084\n",
      "Ep:107, loss:0.00001, loss_test:0.06856, lr:7.55e-03, fs:0.79290 (r=0.677,p=0.957),  time:41.598, tt:4492.552\n",
      "Ep:108, loss:0.00001, loss_test:0.06536, lr:7.47e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.618, tt:4536.344\n",
      "Ep:109, loss:0.00001, loss_test:0.06783, lr:7.40e-03, fs:0.80702 (r=0.697,p=0.958),  time:41.625, tt:4578.782\n",
      "Ep:110, loss:0.00001, loss_test:0.06677, lr:7.32e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.606, tt:4618.246\n",
      "Ep:111, loss:0.00001, loss_test:0.06657, lr:7.25e-03, fs:0.82081 (r=0.717,p=0.959),  time:41.610, tt:4660.339\n",
      "Ep:112, loss:0.00001, loss_test:0.06780, lr:7.18e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.616, tt:4702.618\n",
      "Ep:113, loss:0.00001, loss_test:0.06684, lr:7.11e-03, fs:0.82081 (r=0.717,p=0.959),  time:41.611, tt:4743.616\n",
      "Ep:114, loss:0.00001, loss_test:0.06953, lr:7.03e-03, fs:0.79042 (r=0.667,p=0.971),  time:41.614, tt:4785.592\n",
      "Ep:115, loss:0.00001, loss_test:0.06890, lr:6.96e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.610, tt:4826.771\n",
      "Ep:116, loss:0.00001, loss_test:0.06667, lr:6.89e-03, fs:0.81395 (r=0.707,p=0.959),  time:41.617, tt:4869.166\n",
      "Ep:117, loss:0.00001, loss_test:0.06718, lr:6.83e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.621, tt:4911.248\n",
      "Ep:118, loss:0.00001, loss_test:0.06867, lr:6.76e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.630, tt:4953.955\n",
      "Ep:119, loss:0.00001, loss_test:0.06549, lr:6.69e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.641, tt:4996.908\n",
      "Ep:120, loss:0.00001, loss_test:0.06896, lr:6.62e-03, fs:0.78313 (r=0.657,p=0.970),  time:41.614, tt:5035.355\n",
      "Ep:121, loss:0.00001, loss_test:0.06753, lr:6.56e-03, fs:0.81871 (r=0.707,p=0.972),  time:41.612, tt:5076.698\n",
      "Ep:122, loss:0.00001, loss_test:0.06801, lr:6.49e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.619, tt:5119.113\n",
      "Ep:123, loss:0.00001, loss_test:0.06870, lr:6.43e-03, fs:0.79762 (r=0.677,p=0.971),  time:41.624, tt:5161.424\n",
      "Ep:124, loss:0.00001, loss_test:0.06614, lr:6.36e-03, fs:0.82081 (r=0.717,p=0.959),  time:41.634, tt:5204.219\n",
      "Ep:125, loss:0.00001, loss_test:0.06806, lr:6.30e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.637, tt:5246.239\n",
      "Ep:126, loss:0.00001, loss_test:0.06851, lr:6.24e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.634, tt:5287.565\n",
      "Ep:127, loss:0.00001, loss_test:0.06625, lr:6.17e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.639, tt:5329.792\n",
      "Ep:128, loss:0.00001, loss_test:0.06751, lr:6.11e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.623, tt:5369.375\n",
      "Ep:129, loss:0.00001, loss_test:0.06808, lr:6.05e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.624, tt:5411.099\n",
      "Ep:130, loss:0.00001, loss_test:0.06639, lr:5.99e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.627, tt:5453.158\n",
      "Ep:131, loss:0.00001, loss_test:0.06843, lr:5.93e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.636, tt:5495.968\n",
      "Ep:132, loss:0.00001, loss_test:0.06659, lr:5.87e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.636, tt:5537.552\n",
      "Ep:133, loss:0.00001, loss_test:0.06765, lr:5.81e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.619, tt:5576.888\n",
      "Ep:134, loss:0.00001, loss_test:0.06736, lr:5.75e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.633, tt:5620.392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00001, loss_test:0.06680, lr:5.70e-03, fs:0.81871 (r=0.707,p=0.972),  time:41.633, tt:5662.057\n",
      "Ep:136, loss:0.00001, loss_test:0.06772, lr:5.64e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.636, tt:5704.174\n",
      "Ep:137, loss:0.00001, loss_test:0.06856, lr:5.58e-03, fs:0.79762 (r=0.677,p=0.971),  time:41.641, tt:5746.467\n",
      "Ep:138, loss:0.00001, loss_test:0.06670, lr:5.53e-03, fs:0.81871 (r=0.707,p=0.972),  time:41.638, tt:5787.698\n",
      "Ep:139, loss:0.00001, loss_test:0.06793, lr:5.47e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.635, tt:5828.887\n",
      "Ep:140, loss:0.00001, loss_test:0.06853, lr:5.42e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.644, tt:5871.738\n",
      "Ep:141, loss:0.00000, loss_test:0.06688, lr:5.36e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.640, tt:5912.930\n",
      "Ep:142, loss:0.00000, loss_test:0.06737, lr:5.31e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.651, tt:5956.156\n",
      "Ep:143, loss:0.00000, loss_test:0.06724, lr:5.26e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.653, tt:5998.019\n",
      "Ep:144, loss:0.00000, loss_test:0.06749, lr:5.20e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.644, tt:6038.343\n",
      "Ep:145, loss:0.00000, loss_test:0.06769, lr:5.15e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.647, tt:6080.526\n",
      "Ep:146, loss:0.00000, loss_test:0.06728, lr:5.10e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.628, tt:6119.300\n",
      "Ep:147, loss:0.00000, loss_test:0.06720, lr:5.05e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.668, tt:6166.932\n",
      "Ep:148, loss:0.00000, loss_test:0.06794, lr:5.00e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.669, tt:6208.746\n",
      "Ep:149, loss:0.00000, loss_test:0.06747, lr:4.95e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.656, tt:6248.464\n",
      "Ep:150, loss:0.00000, loss_test:0.06747, lr:4.90e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.641, tt:6287.779\n",
      "Ep:151, loss:0.00000, loss_test:0.06820, lr:4.85e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.652, tt:6331.058\n",
      "Ep:152, loss:0.00000, loss_test:0.06761, lr:4.80e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.665, tt:6374.729\n",
      "Ep:153, loss:0.00000, loss_test:0.06771, lr:4.75e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.657, tt:6415.116\n",
      "Ep:154, loss:0.00000, loss_test:0.06911, lr:4.71e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.659, tt:6457.170\n",
      "Ep:155, loss:0.00000, loss_test:0.06769, lr:4.66e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.642, tt:6496.128\n",
      "Ep:156, loss:0.00000, loss_test:0.06745, lr:4.61e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.649, tt:6538.891\n",
      "Ep:157, loss:0.00000, loss_test:0.06811, lr:4.57e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.651, tt:6580.810\n",
      "Ep:158, loss:0.00000, loss_test:0.06778, lr:4.52e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.637, tt:6620.213\n",
      "Ep:159, loss:0.00000, loss_test:0.06790, lr:4.48e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.643, tt:6662.827\n",
      "Ep:160, loss:0.00000, loss_test:0.06811, lr:4.43e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.630, tt:6702.358\n",
      "Ep:161, loss:0.00000, loss_test:0.06735, lr:4.39e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.623, tt:6742.933\n",
      "Ep:162, loss:0.00000, loss_test:0.06723, lr:4.34e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.625, tt:6784.951\n",
      "Ep:163, loss:0.00000, loss_test:0.06750, lr:4.30e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.626, tt:6826.667\n",
      "Ep:164, loss:0.00000, loss_test:0.06759, lr:4.26e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.622, tt:6867.614\n",
      "Ep:165, loss:0.00000, loss_test:0.06751, lr:4.21e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.601, tt:6905.706\n",
      "Ep:166, loss:0.00000, loss_test:0.06805, lr:4.17e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.594, tt:6946.277\n",
      "Ep:167, loss:0.00000, loss_test:0.06804, lr:4.13e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.623, tt:6992.640\n",
      "Ep:168, loss:0.00000, loss_test:0.06736, lr:4.09e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.627, tt:7034.962\n",
      "Ep:169, loss:0.00000, loss_test:0.06766, lr:4.05e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.618, tt:7075.031\n",
      "Ep:170, loss:0.00000, loss_test:0.06752, lr:4.01e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.615, tt:7116.194\n",
      "Ep:171, loss:0.00000, loss_test:0.06758, lr:3.97e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.604, tt:7155.855\n",
      "Ep:172, loss:0.00000, loss_test:0.06797, lr:3.93e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.599, tt:7196.651\n",
      "Ep:173, loss:0.00000, loss_test:0.06822, lr:3.89e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.582, tt:7235.191\n",
      "Ep:174, loss:0.00000, loss_test:0.06723, lr:3.85e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.577, tt:7276.022\n",
      "Ep:175, loss:0.00000, loss_test:0.06789, lr:3.81e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.581, tt:7318.329\n",
      "Ep:176, loss:0.00000, loss_test:0.06782, lr:3.77e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.570, tt:7357.825\n",
      "Ep:177, loss:0.00000, loss_test:0.06730, lr:3.73e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.554, tt:7396.632\n",
      "Ep:178, loss:0.00000, loss_test:0.06787, lr:3.70e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.545, tt:7436.593\n",
      "Ep:179, loss:0.00000, loss_test:0.06836, lr:3.66e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.546, tt:7478.281\n",
      "Ep:180, loss:0.00000, loss_test:0.06754, lr:3.62e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.531, tt:7517.029\n",
      "Ep:181, loss:0.00000, loss_test:0.06802, lr:3.59e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.514, tt:7555.520\n",
      "Ep:182, loss:0.00000, loss_test:0.06847, lr:3.55e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.509, tt:7596.111\n",
      "Ep:183, loss:0.00000, loss_test:0.06707, lr:3.52e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.500, tt:7635.953\n",
      "Ep:184, loss:0.00000, loss_test:0.06850, lr:3.48e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.507, tt:7678.805\n",
      "Ep:185, loss:0.00000, loss_test:0.06905, lr:3.45e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.516, tt:7721.968\n",
      "Ep:186, loss:0.00000, loss_test:0.06769, lr:3.41e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.523, tt:7764.855\n",
      "Ep:187, loss:0.00000, loss_test:0.06788, lr:3.38e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.533, tt:7808.176\n",
      "Ep:188, loss:0.00000, loss_test:0.06768, lr:3.34e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.532, tt:7849.558\n",
      "Ep:189, loss:0.00000, loss_test:0.06794, lr:3.31e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.525, tt:7889.745\n",
      "Ep:190, loss:0.00000, loss_test:0.06798, lr:3.28e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.517, tt:7929.805\n",
      "Ep:191, loss:0.00000, loss_test:0.06761, lr:3.24e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.519, tt:7971.697\n",
      "Ep:192, loss:0.00000, loss_test:0.06799, lr:3.21e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.515, tt:8012.467\n",
      "Ep:193, loss:0.00000, loss_test:0.06816, lr:3.18e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.517, tt:8054.270\n",
      "Ep:194, loss:0.00000, loss_test:0.06762, lr:3.15e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.515, tt:8095.366\n",
      "Ep:195, loss:0.00000, loss_test:0.06770, lr:3.12e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.499, tt:8133.821\n",
      "Ep:196, loss:0.00000, loss_test:0.06748, lr:3.09e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.511, tt:8177.682\n",
      "Ep:197, loss:0.00000, loss_test:0.06798, lr:3.05e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.500, tt:8216.965\n",
      "Ep:198, loss:0.00000, loss_test:0.06812, lr:3.02e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.512, tt:8260.904\n",
      "Ep:199, loss:0.00000, loss_test:0.06756, lr:2.99e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.508, tt:8301.518\n",
      "Ep:200, loss:0.00000, loss_test:0.06803, lr:2.96e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.502, tt:8341.868\n",
      "Ep:201, loss:0.00000, loss_test:0.06758, lr:2.93e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.498, tt:8382.500\n",
      "Ep:202, loss:0.00000, loss_test:0.06772, lr:2.90e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.500, tt:8424.510\n",
      "Ep:203, loss:0.00000, loss_test:0.06793, lr:2.88e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.490, tt:8464.029\n",
      "Ep:204, loss:0.00000, loss_test:0.06754, lr:2.85e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.481, tt:8503.528\n",
      "Ep:205, loss:0.00000, loss_test:0.06773, lr:2.82e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.478, tt:8544.427\n",
      "Ep:206, loss:0.00000, loss_test:0.06771, lr:2.79e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.468, tt:8583.850\n",
      "Ep:207, loss:0.00000, loss_test:0.06779, lr:2.76e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.462, tt:8624.004\n",
      "Ep:208, loss:0.00000, loss_test:0.06782, lr:2.73e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.467, tt:8666.560\n",
      "Ep:209, loss:0.00000, loss_test:0.06750, lr:2.71e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.453, tt:8705.194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:210, loss:0.00000, loss_test:0.06753, lr:2.68e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.407, tt:8736.966\n",
      "Ep:211, loss:0.00000, loss_test:0.06766, lr:2.65e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.350, tt:8766.240\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02180, lr:6.00e-02, fs:0.61864 (r=0.839,p=0.490),  time:29.751, tt:29.751\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02375, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.932, tt:65.865\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02459, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.645, tt:103.934\n",
      "Ep:3, loss:0.00005, loss_test:0.02394, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.697, tt:142.788\n",
      "Ep:4, loss:0.00004, loss_test:0.02269, lr:6.00e-02, fs:0.65098 (r=0.954,p=0.494),  time:36.364, tt:181.819\n",
      "Ep:5, loss:0.00004, loss_test:0.02194, lr:6.00e-02, fs:0.65833 (r=0.908,p=0.516),  time:36.616, tt:219.697\n",
      "Ep:6, loss:0.00004, loss_test:0.02196, lr:6.00e-02, fs:0.62037 (r=0.770,p=0.519),  time:36.673, tt:256.709\n",
      "Ep:7, loss:0.00004, loss_test:0.02184, lr:6.00e-02, fs:0.58128 (r=0.678,p=0.509),  time:37.135, tt:297.076\n",
      "Ep:8, loss:0.00004, loss_test:0.02101, lr:6.00e-02, fs:0.58824 (r=0.690,p=0.513),  time:37.240, tt:335.160\n",
      "Ep:9, loss:0.00003, loss_test:0.02008, lr:6.00e-02, fs:0.62037 (r=0.770,p=0.519),  time:37.451, tt:374.505\n",
      "Ep:10, loss:0.00003, loss_test:0.01963, lr:6.00e-02, fs:0.63636 (r=0.805,p=0.526),  time:37.635, tt:413.983\n",
      "Ep:11, loss:0.00003, loss_test:0.01935, lr:6.00e-02, fs:0.64455 (r=0.782,p=0.548),  time:37.652, tt:451.821\n",
      "Ep:12, loss:0.00003, loss_test:0.01920, lr:6.00e-02, fs:0.64390 (r=0.759,p=0.559),  time:37.751, tt:490.766\n",
      "Ep:13, loss:0.00003, loss_test:0.01899, lr:5.94e-02, fs:0.65657 (r=0.747,p=0.586),  time:37.916, tt:530.830\n",
      "Ep:14, loss:0.00003, loss_test:0.01850, lr:5.88e-02, fs:0.66327 (r=0.747,p=0.596),  time:37.842, tt:567.632\n",
      "Ep:15, loss:0.00003, loss_test:0.01806, lr:5.82e-02, fs:0.66327 (r=0.747,p=0.596),  time:37.837, tt:605.399\n",
      "Ep:16, loss:0.00003, loss_test:0.01765, lr:5.76e-02, fs:0.69000 (r=0.793,p=0.611),  time:37.941, tt:644.995\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01737, lr:5.76e-02, fs:0.70000 (r=0.805,p=0.619),  time:37.968, tt:683.423\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01721, lr:5.76e-02, fs:0.69697 (r=0.793,p=0.622),  time:38.073, tt:723.381\n",
      "Ep:19, loss:0.00003, loss_test:0.01709, lr:5.76e-02, fs:0.71134 (r=0.793,p=0.645),  time:38.051, tt:761.019\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.01694, lr:5.76e-02, fs:0.71958 (r=0.782,p=0.667),  time:37.971, tt:797.385\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01665, lr:5.76e-02, fs:0.73016 (r=0.793,p=0.676),  time:37.964, tt:835.199\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01634, lr:5.76e-02, fs:0.73684 (r=0.805,p=0.680),  time:38.016, tt:874.372\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01620, lr:5.76e-02, fs:0.73016 (r=0.793,p=0.676),  time:37.981, tt:911.550\n",
      "Ep:24, loss:0.00002, loss_test:0.01618, lr:5.76e-02, fs:0.73514 (r=0.782,p=0.694),  time:38.005, tt:950.130\n",
      "Ep:25, loss:0.00002, loss_test:0.01615, lr:5.76e-02, fs:0.75138 (r=0.782,p=0.723),  time:38.069, tt:989.797\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01594, lr:5.76e-02, fs:0.75824 (r=0.793,p=0.726),  time:38.105, tt:1028.834\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01582, lr:5.76e-02, fs:0.75824 (r=0.793,p=0.726),  time:38.149, tt:1068.177\n",
      "Ep:28, loss:0.00002, loss_test:0.01579, lr:5.76e-02, fs:0.76923 (r=0.805,p=0.737),  time:38.212, tt:1108.149\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01582, lr:5.76e-02, fs:0.76667 (r=0.793,p=0.742),  time:38.269, tt:1148.061\n",
      "Ep:30, loss:0.00002, loss_test:0.01583, lr:5.76e-02, fs:0.77095 (r=0.793,p=0.750),  time:38.297, tt:1187.204\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01565, lr:5.76e-02, fs:0.77778 (r=0.805,p=0.753),  time:38.293, tt:1225.380\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01563, lr:5.76e-02, fs:0.77095 (r=0.793,p=0.750),  time:38.324, tt:1264.686\n",
      "Ep:33, loss:0.00002, loss_test:0.01573, lr:5.76e-02, fs:0.77011 (r=0.770,p=0.770),  time:38.315, tt:1302.703\n",
      "Ep:34, loss:0.00002, loss_test:0.01578, lr:5.76e-02, fs:0.76301 (r=0.759,p=0.767),  time:38.347, tt:1342.158\n",
      "Ep:35, loss:0.00002, loss_test:0.01582, lr:5.76e-02, fs:0.76301 (r=0.759,p=0.767),  time:38.490, tt:1385.631\n",
      "Ep:36, loss:0.00001, loss_test:0.01584, lr:5.76e-02, fs:0.74854 (r=0.736,p=0.762),  time:38.547, tt:1426.237\n",
      "Ep:37, loss:0.00001, loss_test:0.01595, lr:5.76e-02, fs:0.75449 (r=0.724,p=0.787),  time:38.596, tt:1466.648\n",
      "Ep:38, loss:0.00001, loss_test:0.01585, lr:5.76e-02, fs:0.75449 (r=0.724,p=0.787),  time:38.623, tt:1506.298\n",
      "Ep:39, loss:0.00001, loss_test:0.01594, lr:5.76e-02, fs:0.75904 (r=0.724,p=0.797),  time:38.685, tt:1547.409\n",
      "Ep:40, loss:0.00001, loss_test:0.01625, lr:5.76e-02, fs:0.73620 (r=0.690,p=0.789),  time:38.706, tt:1586.944\n",
      "Ep:41, loss:0.00001, loss_test:0.01635, lr:5.76e-02, fs:0.73292 (r=0.678,p=0.797),  time:38.707, tt:1625.692\n",
      "Ep:42, loss:0.00001, loss_test:0.01626, lr:5.76e-02, fs:0.73292 (r=0.678,p=0.797),  time:38.738, tt:1665.735\n",
      "Ep:43, loss:0.00001, loss_test:0.01634, lr:5.71e-02, fs:0.73292 (r=0.678,p=0.797),  time:38.766, tt:1705.722\n",
      "Ep:44, loss:0.00001, loss_test:0.01651, lr:5.65e-02, fs:0.73750 (r=0.678,p=0.808),  time:38.767, tt:1744.520\n",
      "Ep:45, loss:0.00001, loss_test:0.01661, lr:5.59e-02, fs:0.74214 (r=0.678,p=0.819),  time:38.788, tt:1784.255\n",
      "Ep:46, loss:0.00001, loss_test:0.01666, lr:5.54e-02, fs:0.73418 (r=0.667,p=0.817),  time:38.831, tt:1825.061\n",
      "Ep:47, loss:0.00001, loss_test:0.01689, lr:5.48e-02, fs:0.71795 (r=0.644,p=0.812),  time:38.876, tt:1866.043\n",
      "Ep:48, loss:0.00001, loss_test:0.01712, lr:5.43e-02, fs:0.71795 (r=0.644,p=0.812),  time:38.918, tt:1906.991\n",
      "Ep:49, loss:0.00001, loss_test:0.01728, lr:5.37e-02, fs:0.72258 (r=0.644,p=0.824),  time:38.962, tt:1948.119\n",
      "Ep:50, loss:0.00001, loss_test:0.01746, lr:5.32e-02, fs:0.72258 (r=0.644,p=0.824),  time:38.994, tt:1988.699\n",
      "Ep:51, loss:0.00001, loss_test:0.01757, lr:5.27e-02, fs:0.72258 (r=0.644,p=0.824),  time:38.980, tt:2026.973\n",
      "Ep:52, loss:0.00001, loss_test:0.01766, lr:5.21e-02, fs:0.72727 (r=0.644,p=0.836),  time:39.065, tt:2070.426\n",
      "Ep:53, loss:0.00001, loss_test:0.01784, lr:5.16e-02, fs:0.72727 (r=0.644,p=0.836),  time:39.092, tt:2110.957\n",
      "Ep:54, loss:0.00001, loss_test:0.01786, lr:5.11e-02, fs:0.73203 (r=0.644,p=0.848),  time:39.117, tt:2151.447\n",
      "Ep:55, loss:0.00001, loss_test:0.01800, lr:5.06e-02, fs:0.73203 (r=0.644,p=0.848),  time:39.141, tt:2191.886\n",
      "Ep:56, loss:0.00001, loss_test:0.01810, lr:5.01e-02, fs:0.73203 (r=0.644,p=0.848),  time:39.180, tt:2233.267\n",
      "Ep:57, loss:0.00001, loss_test:0.01813, lr:4.96e-02, fs:0.73203 (r=0.644,p=0.848),  time:39.189, tt:2272.946\n",
      "Ep:58, loss:0.00001, loss_test:0.01843, lr:4.91e-02, fs:0.73203 (r=0.644,p=0.848),  time:39.227, tt:2314.368\n",
      "Ep:59, loss:0.00001, loss_test:0.01857, lr:4.86e-02, fs:0.73203 (r=0.644,p=0.848),  time:39.238, tt:2354.251\n",
      "Ep:60, loss:0.00001, loss_test:0.01868, lr:4.81e-02, fs:0.73203 (r=0.644,p=0.848),  time:39.274, tt:2395.723\n",
      "Ep:61, loss:0.00001, loss_test:0.01890, lr:4.76e-02, fs:0.73203 (r=0.644,p=0.848),  time:39.312, tt:2437.374\n",
      "Ep:62, loss:0.00001, loss_test:0.01914, lr:4.71e-02, fs:0.73203 (r=0.644,p=0.848),  time:39.332, tt:2477.896\n",
      "Ep:63, loss:0.00001, loss_test:0.01914, lr:4.67e-02, fs:0.73203 (r=0.644,p=0.848),  time:39.339, tt:2517.710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00001, loss_test:0.01917, lr:4.62e-02, fs:0.73203 (r=0.644,p=0.848),  time:39.324, tt:2556.078\n",
      "Ep:65, loss:0.00001, loss_test:0.01938, lr:4.57e-02, fs:0.73203 (r=0.644,p=0.848),  time:39.364, tt:2598.003\n",
      "Ep:66, loss:0.00001, loss_test:0.01949, lr:4.53e-02, fs:0.73203 (r=0.644,p=0.848),  time:39.394, tt:2639.375\n",
      "Ep:67, loss:0.00001, loss_test:0.01950, lr:4.48e-02, fs:0.73203 (r=0.644,p=0.848),  time:39.426, tt:2680.995\n",
      "Ep:68, loss:0.00001, loss_test:0.01971, lr:4.44e-02, fs:0.73203 (r=0.644,p=0.848),  time:39.434, tt:2720.950\n",
      "Ep:69, loss:0.00001, loss_test:0.01982, lr:4.39e-02, fs:0.73203 (r=0.644,p=0.848),  time:39.578, tt:2770.450\n",
      "Ep:70, loss:0.00001, loss_test:0.01990, lr:4.35e-02, fs:0.73203 (r=0.644,p=0.848),  time:39.601, tt:2811.689\n",
      "Ep:71, loss:0.00001, loss_test:0.01997, lr:4.31e-02, fs:0.73203 (r=0.644,p=0.848),  time:39.616, tt:2852.365\n",
      "Ep:72, loss:0.00001, loss_test:0.02017, lr:4.26e-02, fs:0.73203 (r=0.644,p=0.848),  time:39.621, tt:2892.308\n",
      "Ep:73, loss:0.00001, loss_test:0.02025, lr:4.22e-02, fs:0.73203 (r=0.644,p=0.848),  time:39.631, tt:2932.711\n",
      "Ep:74, loss:0.00001, loss_test:0.02029, lr:4.18e-02, fs:0.73203 (r=0.644,p=0.848),  time:39.642, tt:2973.166\n",
      "Ep:75, loss:0.00001, loss_test:0.02039, lr:4.14e-02, fs:0.73684 (r=0.644,p=0.862),  time:39.662, tt:3014.298\n",
      "Ep:76, loss:0.00000, loss_test:0.02053, lr:4.10e-02, fs:0.73684 (r=0.644,p=0.862),  time:39.649, tt:3052.959\n",
      "Ep:77, loss:0.00000, loss_test:0.02064, lr:4.05e-02, fs:0.73684 (r=0.644,p=0.862),  time:39.648, tt:3092.511\n",
      "Ep:78, loss:0.00000, loss_test:0.02069, lr:4.01e-02, fs:0.73684 (r=0.644,p=0.862),  time:39.655, tt:3132.723\n",
      "Ep:79, loss:0.00000, loss_test:0.02077, lr:3.97e-02, fs:0.73684 (r=0.644,p=0.862),  time:39.658, tt:3172.658\n",
      "Ep:80, loss:0.00000, loss_test:0.02092, lr:3.93e-02, fs:0.73684 (r=0.644,p=0.862),  time:39.643, tt:3211.072\n",
      "Ep:81, loss:0.00000, loss_test:0.02096, lr:3.89e-02, fs:0.73684 (r=0.644,p=0.862),  time:39.638, tt:3250.278\n",
      "Ep:82, loss:0.00000, loss_test:0.02114, lr:3.86e-02, fs:0.73684 (r=0.644,p=0.862),  time:39.629, tt:3289.188\n",
      "Ep:83, loss:0.00000, loss_test:0.02124, lr:3.82e-02, fs:0.73684 (r=0.644,p=0.862),  time:39.643, tt:3330.005\n",
      "Ep:84, loss:0.00000, loss_test:0.02112, lr:3.78e-02, fs:0.73684 (r=0.644,p=0.862),  time:39.632, tt:3368.732\n",
      "Ep:85, loss:0.00000, loss_test:0.02123, lr:3.74e-02, fs:0.73684 (r=0.644,p=0.862),  time:39.612, tt:3406.595\n",
      "Ep:86, loss:0.00000, loss_test:0.02139, lr:3.70e-02, fs:0.74172 (r=0.644,p=0.875),  time:39.610, tt:3446.062\n",
      "Ep:87, loss:0.00000, loss_test:0.02146, lr:3.67e-02, fs:0.74172 (r=0.644,p=0.875),  time:39.601, tt:3484.904\n",
      "Ep:88, loss:0.00000, loss_test:0.02158, lr:3.63e-02, fs:0.74172 (r=0.644,p=0.875),  time:39.579, tt:3522.511\n",
      "Ep:89, loss:0.00000, loss_test:0.02168, lr:3.59e-02, fs:0.74172 (r=0.644,p=0.875),  time:39.570, tt:3561.339\n",
      "Ep:90, loss:0.00000, loss_test:0.02161, lr:3.56e-02, fs:0.73333 (r=0.632,p=0.873),  time:39.617, tt:3605.186\n",
      "Ep:91, loss:0.00000, loss_test:0.02167, lr:3.52e-02, fs:0.73333 (r=0.632,p=0.873),  time:39.618, tt:3644.863\n",
      "Ep:92, loss:0.00000, loss_test:0.02178, lr:3.49e-02, fs:0.73333 (r=0.632,p=0.873),  time:39.611, tt:3683.835\n",
      "Ep:93, loss:0.00000, loss_test:0.02184, lr:3.45e-02, fs:0.73333 (r=0.632,p=0.873),  time:39.624, tt:3724.662\n",
      "Ep:94, loss:0.00000, loss_test:0.02195, lr:3.42e-02, fs:0.73333 (r=0.632,p=0.873),  time:39.605, tt:3762.516\n",
      "Ep:95, loss:0.00000, loss_test:0.02204, lr:3.38e-02, fs:0.73333 (r=0.632,p=0.873),  time:39.614, tt:3802.992\n",
      "Ep:96, loss:0.00000, loss_test:0.02209, lr:3.35e-02, fs:0.73826 (r=0.632,p=0.887),  time:39.608, tt:3841.988\n",
      "Ep:97, loss:0.00000, loss_test:0.02220, lr:3.32e-02, fs:0.73333 (r=0.632,p=0.873),  time:39.612, tt:3881.938\n",
      "Ep:98, loss:0.00000, loss_test:0.02218, lr:3.28e-02, fs:0.73333 (r=0.632,p=0.873),  time:39.611, tt:3921.478\n",
      "Ep:99, loss:0.00000, loss_test:0.02226, lr:3.25e-02, fs:0.73826 (r=0.632,p=0.887),  time:39.601, tt:3960.088\n",
      "Ep:100, loss:0.00000, loss_test:0.02235, lr:3.22e-02, fs:0.73826 (r=0.632,p=0.887),  time:39.603, tt:3999.875\n",
      "Ep:101, loss:0.00000, loss_test:0.02236, lr:3.19e-02, fs:0.74324 (r=0.632,p=0.902),  time:39.588, tt:4037.992\n",
      "Ep:102, loss:0.00000, loss_test:0.02233, lr:3.15e-02, fs:0.74324 (r=0.632,p=0.902),  time:39.603, tt:4079.138\n",
      "Ep:103, loss:0.00000, loss_test:0.02247, lr:3.12e-02, fs:0.74324 (r=0.632,p=0.902),  time:39.595, tt:4117.865\n",
      "Ep:104, loss:0.00000, loss_test:0.02259, lr:3.09e-02, fs:0.74324 (r=0.632,p=0.902),  time:39.570, tt:4154.868\n",
      "Ep:105, loss:0.00000, loss_test:0.02259, lr:3.06e-02, fs:0.74324 (r=0.632,p=0.902),  time:39.563, tt:4193.656\n",
      "Ep:106, loss:0.00000, loss_test:0.02264, lr:3.03e-02, fs:0.74324 (r=0.632,p=0.902),  time:39.558, tt:4232.663\n",
      "Ep:107, loss:0.00000, loss_test:0.02269, lr:3.00e-02, fs:0.74324 (r=0.632,p=0.902),  time:39.554, tt:4271.833\n",
      "Ep:108, loss:0.00000, loss_test:0.02266, lr:2.97e-02, fs:0.73469 (r=0.621,p=0.900),  time:39.541, tt:4309.996\n",
      "Ep:109, loss:0.00000, loss_test:0.02270, lr:2.94e-02, fs:0.73469 (r=0.621,p=0.900),  time:39.523, tt:4347.581\n",
      "Ep:110, loss:0.00000, loss_test:0.02278, lr:2.91e-02, fs:0.72603 (r=0.609,p=0.898),  time:39.517, tt:4386.393\n",
      "Ep:111, loss:0.00000, loss_test:0.02287, lr:2.88e-02, fs:0.72603 (r=0.609,p=0.898),  time:39.517, tt:4425.876\n",
      "Ep:112, loss:0.00000, loss_test:0.02290, lr:2.85e-02, fs:0.72603 (r=0.609,p=0.898),  time:39.511, tt:4464.713\n",
      "Ep:113, loss:0.00000, loss_test:0.02297, lr:2.82e-02, fs:0.71724 (r=0.598,p=0.897),  time:39.522, tt:4505.472\n",
      "Ep:114, loss:0.00000, loss_test:0.02297, lr:2.80e-02, fs:0.73103 (r=0.609,p=0.914),  time:39.520, tt:4544.767\n",
      "Ep:115, loss:0.00000, loss_test:0.02301, lr:2.77e-02, fs:0.72222 (r=0.598,p=0.912),  time:39.514, tt:4583.571\n",
      "Ep:116, loss:0.00000, loss_test:0.02308, lr:2.74e-02, fs:0.70423 (r=0.575,p=0.909),  time:39.508, tt:4622.386\n",
      "Ep:117, loss:0.00000, loss_test:0.02310, lr:2.71e-02, fs:0.72222 (r=0.598,p=0.912),  time:39.498, tt:4660.756\n",
      "Ep:118, loss:0.00000, loss_test:0.02316, lr:2.69e-02, fs:0.72222 (r=0.598,p=0.912),  time:39.503, tt:4700.840\n",
      "Ep:119, loss:0.00000, loss_test:0.02327, lr:2.66e-02, fs:0.68571 (r=0.552,p=0.906),  time:39.498, tt:4739.788\n",
      "Ep:120, loss:0.00000, loss_test:0.02324, lr:2.63e-02, fs:0.70423 (r=0.575,p=0.909),  time:39.491, tt:4778.414\n",
      "Ep:121, loss:0.00000, loss_test:0.02330, lr:2.61e-02, fs:0.70423 (r=0.575,p=0.909),  time:39.514, tt:4820.671\n",
      "Ep:122, loss:0.00000, loss_test:0.02339, lr:2.58e-02, fs:0.68571 (r=0.552,p=0.906),  time:39.509, tt:4859.658\n",
      "Ep:123, loss:0.00000, loss_test:0.02344, lr:2.55e-02, fs:0.67626 (r=0.540,p=0.904),  time:39.483, tt:4895.867\n",
      "Ep:124, loss:0.00000, loss_test:0.02345, lr:2.53e-02, fs:0.68571 (r=0.552,p=0.906),  time:39.469, tt:4933.662\n",
      "Ep:125, loss:0.00000, loss_test:0.02350, lr:2.50e-02, fs:0.68571 (r=0.552,p=0.906),  time:39.475, tt:4973.864\n",
      "Ep:126, loss:0.00000, loss_test:0.02355, lr:2.48e-02, fs:0.67626 (r=0.540,p=0.904),  time:39.464, tt:5011.875\n",
      "Ep:127, loss:0.00000, loss_test:0.02357, lr:2.45e-02, fs:0.67626 (r=0.540,p=0.904),  time:39.443, tt:5048.730\n",
      "Ep:128, loss:0.00000, loss_test:0.02357, lr:2.43e-02, fs:0.67626 (r=0.540,p=0.904),  time:39.424, tt:5085.744\n",
      "Ep:129, loss:0.00000, loss_test:0.02358, lr:2.40e-02, fs:0.68571 (r=0.552,p=0.906),  time:39.429, tt:5125.793\n",
      "Ep:130, loss:0.00000, loss_test:0.02364, lr:2.38e-02, fs:0.67626 (r=0.540,p=0.904),  time:39.435, tt:5166.048\n",
      "Ep:131, loss:0.00000, loss_test:0.02372, lr:2.36e-02, fs:0.67626 (r=0.540,p=0.904),  time:39.443, tt:5206.417\n",
      "Ep:132, loss:0.00000, loss_test:0.02380, lr:2.33e-02, fs:0.67626 (r=0.540,p=0.904),  time:39.432, tt:5244.420\n",
      "Ep:133, loss:0.00000, loss_test:0.02380, lr:2.31e-02, fs:0.66667 (r=0.529,p=0.902),  time:39.456, tt:5287.162\n",
      "Ep:134, loss:0.00000, loss_test:0.02385, lr:2.29e-02, fs:0.65693 (r=0.517,p=0.900),  time:39.444, tt:5324.985\n",
      "Ep:135, loss:0.00000, loss_test:0.02386, lr:2.26e-02, fs:0.65693 (r=0.517,p=0.900),  time:39.441, tt:5363.952\n",
      "Ep:136, loss:0.00000, loss_test:0.02385, lr:2.24e-02, fs:0.65693 (r=0.517,p=0.900),  time:39.433, tt:5402.377\n",
      "Ep:137, loss:0.00000, loss_test:0.02402, lr:2.22e-02, fs:0.63704 (r=0.494,p=0.896),  time:39.441, tt:5442.884\n",
      "Ep:138, loss:0.00000, loss_test:0.02401, lr:2.20e-02, fs:0.64706 (r=0.506,p=0.898),  time:39.424, tt:5479.966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:139, loss:0.00000, loss_test:0.02398, lr:2.17e-02, fs:0.64706 (r=0.506,p=0.898),  time:39.409, tt:5517.301\n",
      "Ep:140, loss:0.00000, loss_test:0.02406, lr:2.15e-02, fs:0.63704 (r=0.494,p=0.896),  time:39.416, tt:5557.713\n",
      "Ep:141, loss:0.00000, loss_test:0.02408, lr:2.13e-02, fs:0.63704 (r=0.494,p=0.896),  time:39.416, tt:5597.140\n",
      "Ep:142, loss:0.00000, loss_test:0.02416, lr:2.11e-02, fs:0.63704 (r=0.494,p=0.896),  time:39.414, tt:5636.155\n",
      "Ep:143, loss:0.00000, loss_test:0.02420, lr:2.09e-02, fs:0.62687 (r=0.483,p=0.894),  time:39.415, tt:5675.750\n",
      "Ep:144, loss:0.00000, loss_test:0.02420, lr:2.07e-02, fs:0.63704 (r=0.494,p=0.896),  time:39.424, tt:5716.410\n",
      "Ep:145, loss:0.00000, loss_test:0.02421, lr:2.05e-02, fs:0.63704 (r=0.494,p=0.896),  time:39.416, tt:5754.675\n",
      "Ep:146, loss:0.00000, loss_test:0.02424, lr:2.03e-02, fs:0.62687 (r=0.483,p=0.894),  time:39.427, tt:5795.814\n",
      "Ep:147, loss:0.00000, loss_test:0.02427, lr:2.01e-02, fs:0.62687 (r=0.483,p=0.894),  time:39.430, tt:5835.572\n",
      "Ep:148, loss:0.00000, loss_test:0.02429, lr:1.99e-02, fs:0.62687 (r=0.483,p=0.894),  time:39.435, tt:5875.782\n",
      "Ep:149, loss:0.00000, loss_test:0.02434, lr:1.97e-02, fs:0.62687 (r=0.483,p=0.894),  time:39.447, tt:5917.000\n",
      "Ep:150, loss:0.00000, loss_test:0.02439, lr:1.95e-02, fs:0.61654 (r=0.471,p=0.891),  time:39.476, tt:5960.872\n",
      "Ep:151, loss:0.00000, loss_test:0.02443, lr:1.93e-02, fs:0.61654 (r=0.471,p=0.891),  time:39.488, tt:6002.138\n",
      "Ep:152, loss:0.00000, loss_test:0.02446, lr:1.91e-02, fs:0.61654 (r=0.471,p=0.891),  time:39.501, tt:6043.696\n",
      "Ep:153, loss:0.00000, loss_test:0.02448, lr:1.89e-02, fs:0.61654 (r=0.471,p=0.891),  time:39.514, tt:6085.190\n",
      "Ep:154, loss:0.00000, loss_test:0.02450, lr:1.87e-02, fs:0.61654 (r=0.471,p=0.891),  time:39.548, tt:6129.894\n",
      "Ep:155, loss:0.00000, loss_test:0.02455, lr:1.85e-02, fs:0.61654 (r=0.471,p=0.891),  time:39.580, tt:6174.441\n",
      "Ep:156, loss:0.00000, loss_test:0.02457, lr:1.83e-02, fs:0.61654 (r=0.471,p=0.891),  time:39.596, tt:6216.555\n",
      "Ep:157, loss:0.00000, loss_test:0.02458, lr:1.81e-02, fs:0.61654 (r=0.471,p=0.891),  time:39.616, tt:6259.338\n",
      "Ep:158, loss:0.00000, loss_test:0.02462, lr:1.80e-02, fs:0.61654 (r=0.471,p=0.891),  time:39.631, tt:6301.253\n",
      "Ep:159, loss:0.00000, loss_test:0.02464, lr:1.78e-02, fs:0.61654 (r=0.471,p=0.891),  time:39.638, tt:6342.084\n",
      "Ep:160, loss:0.00000, loss_test:0.02468, lr:1.76e-02, fs:0.61654 (r=0.471,p=0.891),  time:39.663, tt:6385.796\n",
      "Ep:161, loss:0.00000, loss_test:0.02467, lr:1.74e-02, fs:0.61654 (r=0.471,p=0.891),  time:39.670, tt:6426.479\n",
      "Ep:162, loss:0.00000, loss_test:0.02474, lr:1.73e-02, fs:0.61654 (r=0.471,p=0.891),  time:39.690, tt:6469.401\n",
      "Ep:163, loss:0.00000, loss_test:0.02477, lr:1.71e-02, fs:0.61654 (r=0.471,p=0.891),  time:39.697, tt:6510.304\n",
      "Ep:164, loss:0.00000, loss_test:0.02477, lr:1.69e-02, fs:0.61654 (r=0.471,p=0.891),  time:39.704, tt:6551.131\n",
      "Ep:165, loss:0.00000, loss_test:0.02478, lr:1.67e-02, fs:0.60606 (r=0.460,p=0.889),  time:39.706, tt:6591.112\n",
      "Ep:166, loss:0.00000, loss_test:0.02482, lr:1.66e-02, fs:0.60606 (r=0.460,p=0.889),  time:39.734, tt:6635.535\n",
      "Ep:167, loss:0.00000, loss_test:0.02484, lr:1.64e-02, fs:0.60606 (r=0.460,p=0.889),  time:39.743, tt:6676.746\n",
      "Ep:168, loss:0.00000, loss_test:0.02484, lr:1.62e-02, fs:0.60606 (r=0.460,p=0.889),  time:39.755, tt:6718.535\n",
      "Ep:169, loss:0.00000, loss_test:0.02486, lr:1.61e-02, fs:0.59542 (r=0.448,p=0.886),  time:39.760, tt:6759.256\n",
      "Ep:170, loss:0.00000, loss_test:0.02490, lr:1.59e-02, fs:0.59542 (r=0.448,p=0.886),  time:39.752, tt:6797.539\n",
      "Ep:171, loss:0.00000, loss_test:0.02496, lr:1.58e-02, fs:0.59542 (r=0.448,p=0.886),  time:39.752, tt:6837.324\n",
      "Ep:172, loss:0.00000, loss_test:0.02495, lr:1.56e-02, fs:0.58462 (r=0.437,p=0.884),  time:39.758, tt:6878.128\n",
      "Ep:173, loss:0.00000, loss_test:0.02498, lr:1.54e-02, fs:0.58462 (r=0.437,p=0.884),  time:39.752, tt:6916.802\n",
      "Ep:174, loss:0.00000, loss_test:0.02504, lr:1.53e-02, fs:0.58462 (r=0.437,p=0.884),  time:39.757, tt:6957.453\n",
      "Ep:175, loss:0.00000, loss_test:0.02504, lr:1.51e-02, fs:0.58462 (r=0.437,p=0.884),  time:39.759, tt:6997.575\n",
      "Ep:176, loss:0.00000, loss_test:0.02503, lr:1.50e-02, fs:0.58462 (r=0.437,p=0.884),  time:39.770, tt:7039.374\n",
      "Ep:177, loss:0.00000, loss_test:0.02505, lr:1.48e-02, fs:0.58462 (r=0.437,p=0.884),  time:39.777, tt:7080.225\n",
      "Ep:178, loss:0.00000, loss_test:0.02507, lr:1.47e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.774, tt:7119.487\n",
      "Ep:179, loss:0.00000, loss_test:0.02512, lr:1.45e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.780, tt:7160.431\n",
      "Ep:180, loss:0.00000, loss_test:0.02514, lr:1.44e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.788, tt:7201.691\n",
      "Ep:181, loss:0.00000, loss_test:0.02517, lr:1.43e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.787, tt:7241.293\n",
      "Ep:182, loss:0.00000, loss_test:0.02517, lr:1.41e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.801, tt:7283.613\n",
      "Ep:183, loss:0.00000, loss_test:0.02520, lr:1.40e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.810, tt:7325.020\n",
      "Ep:184, loss:0.00000, loss_test:0.02524, lr:1.38e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.814, tt:7365.500\n",
      "Ep:185, loss:0.00000, loss_test:0.02526, lr:1.37e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.825, tt:7407.401\n",
      "Ep:186, loss:0.00000, loss_test:0.02525, lr:1.36e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.836, tt:7449.245\n",
      "Ep:187, loss:0.00000, loss_test:0.02530, lr:1.34e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.850, tt:7491.807\n",
      "Ep:188, loss:0.00000, loss_test:0.02530, lr:1.33e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.867, tt:7534.917\n",
      "Ep:189, loss:0.00000, loss_test:0.02532, lr:1.32e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.867, tt:7574.819\n",
      "Ep:190, loss:0.00000, loss_test:0.02533, lr:1.30e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.863, tt:7613.917\n",
      "Ep:191, loss:0.00000, loss_test:0.02533, lr:1.29e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.857, tt:7652.477\n",
      "Ep:192, loss:0.00000, loss_test:0.02536, lr:1.28e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.854, tt:7691.747\n",
      "Ep:193, loss:0.00000, loss_test:0.02538, lr:1.26e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.859, tt:7732.706\n",
      "Ep:194, loss:0.00000, loss_test:0.02538, lr:1.25e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.870, tt:7774.593\n",
      "Ep:195, loss:0.00000, loss_test:0.02541, lr:1.24e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.888, tt:7818.125\n",
      "Ep:196, loss:0.00000, loss_test:0.02542, lr:1.23e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.886, tt:7857.571\n",
      "Ep:197, loss:0.00000, loss_test:0.02543, lr:1.21e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.889, tt:7897.950\n",
      "Ep:198, loss:0.00000, loss_test:0.02547, lr:1.20e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.884, tt:7936.861\n",
      "Ep:199, loss:0.00000, loss_test:0.02547, lr:1.19e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.882, tt:7976.408\n",
      "Ep:200, loss:0.00000, loss_test:0.02550, lr:1.18e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.878, tt:8015.517\n",
      "Ep:201, loss:0.00000, loss_test:0.02549, lr:1.17e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.881, tt:8055.903\n",
      "Ep:202, loss:0.00000, loss_test:0.02550, lr:1.15e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.879, tt:8095.530\n",
      "Ep:203, loss:0.00000, loss_test:0.02551, lr:1.14e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.884, tt:8136.421\n",
      "Ep:204, loss:0.00000, loss_test:0.02554, lr:1.13e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.863, tt:8171.923\n",
      "Ep:205, loss:0.00000, loss_test:0.02554, lr:1.12e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.865, tt:8212.198\n",
      "Ep:206, loss:0.00000, loss_test:0.02557, lr:1.11e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.871, tt:8253.198\n",
      "Ep:207, loss:0.00000, loss_test:0.02559, lr:1.10e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.869, tt:8292.787\n",
      "Ep:208, loss:0.00000, loss_test:0.02559, lr:1.09e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.850, tt:8328.579\n",
      "Ep:209, loss:0.00000, loss_test:0.02561, lr:1.08e-02, fs:0.57364 (r=0.425,p=0.881),  time:39.816, tt:8361.396\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14651, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.147, tt:39.147\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14547, lr:1.00e-02, fs:0.64591 (r=0.954,p=0.488),  time:41.739, tt:83.479\n",
      "Ep:2, loss:0.00027, loss_test:0.14346, lr:1.00e-02, fs:0.64032 (r=0.931,p=0.488),  time:42.000, tt:125.999\n",
      "Ep:3, loss:0.00025, loss_test:0.13947, lr:1.00e-02, fs:0.63203 (r=0.839,p=0.507),  time:42.525, tt:170.098\n",
      "Ep:4, loss:0.00024, loss_test:0.13489, lr:1.00e-02, fs:0.60488 (r=0.713,p=0.525),  time:42.822, tt:214.109\n",
      "Ep:5, loss:0.00023, loss_test:0.13333, lr:1.00e-02, fs:0.55914 (r=0.598,p=0.525),  time:42.784, tt:256.705\n",
      "Ep:6, loss:0.00022, loss_test:0.13207, lr:1.00e-02, fs:0.58101 (r=0.598,p=0.565),  time:42.848, tt:299.939\n",
      "Ep:7, loss:0.00021, loss_test:0.13028, lr:1.00e-02, fs:0.58140 (r=0.575,p=0.588),  time:42.736, tt:341.890\n",
      "Ep:8, loss:0.00020, loss_test:0.12827, lr:1.00e-02, fs:0.55422 (r=0.529,p=0.582),  time:42.678, tt:384.104\n",
      "Ep:9, loss:0.00020, loss_test:0.12416, lr:1.00e-02, fs:0.60355 (r=0.586,p=0.622),  time:42.800, tt:428.000\n",
      "Ep:10, loss:0.00019, loss_test:0.12111, lr:1.00e-02, fs:0.59756 (r=0.563,p=0.636),  time:42.770, tt:470.473\n",
      "Ep:11, loss:0.00018, loss_test:0.11874, lr:1.00e-02, fs:0.62577 (r=0.586,p=0.671),  time:42.759, tt:513.113\n",
      "Ep:12, loss:0.00017, loss_test:0.11630, lr:9.90e-03, fs:0.61350 (r=0.575,p=0.658),  time:42.713, tt:555.267\n",
      "Ep:13, loss:0.00017, loss_test:0.11302, lr:9.80e-03, fs:0.66667 (r=0.655,p=0.679),  time:42.810, tt:599.335\n",
      "Ep:14, loss:0.00016, loss_test:0.11148, lr:9.70e-03, fs:0.62963 (r=0.586,p=0.680),  time:42.947, tt:644.199\n",
      "Ep:15, loss:0.00015, loss_test:0.10985, lr:9.61e-03, fs:0.65060 (r=0.621,p=0.684),  time:43.006, tt:688.091\n",
      "Ep:16, loss:0.00015, loss_test:0.10786, lr:9.51e-03, fs:0.67456 (r=0.655,p=0.695),  time:43.124, tt:733.101\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00014, loss_test:0.10809, lr:9.51e-03, fs:0.68293 (r=0.644,p=0.727),  time:42.927, tt:772.684\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.10678, lr:9.51e-03, fs:0.67925 (r=0.621,p=0.750),  time:43.070, tt:818.330\n",
      "Ep:19, loss:0.00013, loss_test:0.10360, lr:9.51e-03, fs:0.69939 (r=0.655,p=0.750),  time:43.045, tt:860.906\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00012, loss_test:0.10357, lr:9.51e-03, fs:0.66667 (r=0.598,p=0.754),  time:43.101, tt:905.113\n",
      "Ep:21, loss:0.00012, loss_test:0.10143, lr:9.51e-03, fs:0.66667 (r=0.598,p=0.754),  time:43.148, tt:949.247\n",
      "Ep:22, loss:0.00011, loss_test:0.09982, lr:9.51e-03, fs:0.67097 (r=0.598,p=0.765),  time:43.069, tt:990.581\n",
      "Ep:23, loss:0.00011, loss_test:0.09860, lr:9.51e-03, fs:0.67974 (r=0.598,p=0.788),  time:43.086, tt:1034.075\n",
      "Ep:24, loss:0.00010, loss_test:0.09871, lr:9.51e-03, fs:0.67114 (r=0.575,p=0.806),  time:43.102, tt:1077.558\n",
      "Ep:25, loss:0.00010, loss_test:0.09452, lr:9.51e-03, fs:0.70130 (r=0.621,p=0.806),  time:43.161, tt:1122.186\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00009, loss_test:0.09500, lr:9.51e-03, fs:0.69737 (r=0.609,p=0.815),  time:43.137, tt:1164.694\n",
      "Ep:27, loss:0.00009, loss_test:0.09589, lr:9.51e-03, fs:0.71622 (r=0.609,p=0.869),  time:43.147, tt:1208.114\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00008, loss_test:0.09183, lr:9.51e-03, fs:0.71053 (r=0.621,p=0.831),  time:43.146, tt:1251.235\n",
      "Ep:29, loss:0.00008, loss_test:0.08970, lr:9.51e-03, fs:0.71895 (r=0.632,p=0.833),  time:43.128, tt:1293.835\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00007, loss_test:0.08792, lr:9.51e-03, fs:0.74172 (r=0.644,p=0.875),  time:43.177, tt:1338.487\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00007, loss_test:0.09216, lr:9.51e-03, fs:0.72603 (r=0.609,p=0.898),  time:43.132, tt:1380.230\n",
      "Ep:32, loss:0.00007, loss_test:0.08312, lr:9.51e-03, fs:0.80488 (r=0.759,p=0.857),  time:43.120, tt:1422.965\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00006, loss_test:0.10419, lr:9.51e-03, fs:0.70073 (r=0.552,p=0.960),  time:43.146, tt:1466.976\n",
      "Ep:34, loss:0.00006, loss_test:0.08067, lr:9.51e-03, fs:0.80952 (r=0.782,p=0.840),  time:43.136, tt:1509.767\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00006, loss_test:0.10147, lr:9.51e-03, fs:0.72727 (r=0.598,p=0.929),  time:43.070, tt:1550.534\n",
      "Ep:36, loss:0.00005, loss_test:0.08439, lr:9.51e-03, fs:0.78431 (r=0.690,p=0.909),  time:43.052, tt:1592.938\n",
      "Ep:37, loss:0.00005, loss_test:0.10059, lr:9.51e-03, fs:0.71942 (r=0.575,p=0.962),  time:43.039, tt:1635.480\n",
      "Ep:38, loss:0.00005, loss_test:0.08533, lr:9.51e-03, fs:0.80255 (r=0.724,p=0.900),  time:42.918, tt:1673.812\n",
      "Ep:39, loss:0.00004, loss_test:0.09751, lr:9.51e-03, fs:0.72340 (r=0.586,p=0.944),  time:42.858, tt:1714.328\n",
      "Ep:40, loss:0.00004, loss_test:0.08833, lr:9.51e-03, fs:0.75497 (r=0.655,p=0.891),  time:42.824, tt:1755.772\n",
      "Ep:41, loss:0.00004, loss_test:0.09797, lr:9.51e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.829, tt:1798.815\n",
      "Ep:42, loss:0.00004, loss_test:0.09200, lr:9.51e-03, fs:0.74483 (r=0.621,p=0.931),  time:42.796, tt:1840.235\n",
      "Ep:43, loss:0.00003, loss_test:0.09695, lr:9.51e-03, fs:0.75524 (r=0.621,p=0.964),  time:42.737, tt:1880.437\n",
      "Ep:44, loss:0.00003, loss_test:0.09999, lr:9.51e-03, fs:0.75000 (r=0.621,p=0.947),  time:42.723, tt:1922.545\n",
      "Ep:45, loss:0.00003, loss_test:0.09604, lr:9.51e-03, fs:0.76389 (r=0.632,p=0.965),  time:42.733, tt:1965.703\n",
      "Ep:46, loss:0.00003, loss_test:0.10144, lr:9.41e-03, fs:0.73239 (r=0.598,p=0.945),  time:42.743, tt:2008.918\n",
      "Ep:47, loss:0.00003, loss_test:0.09311, lr:9.32e-03, fs:0.76389 (r=0.632,p=0.965),  time:42.725, tt:2050.797\n",
      "Ep:48, loss:0.00002, loss_test:0.10115, lr:9.23e-03, fs:0.75862 (r=0.632,p=0.948),  time:42.676, tt:2091.127\n",
      "Ep:49, loss:0.00002, loss_test:0.09812, lr:9.14e-03, fs:0.76389 (r=0.632,p=0.965),  time:42.674, tt:2133.714\n",
      "Ep:50, loss:0.00002, loss_test:0.10016, lr:9.04e-03, fs:0.66667 (r=0.517,p=0.938),  time:42.643, tt:2174.817\n",
      "Ep:51, loss:0.00002, loss_test:0.09850, lr:8.95e-03, fs:0.75862 (r=0.632,p=0.948),  time:42.604, tt:2215.411\n",
      "Ep:52, loss:0.00002, loss_test:0.11238, lr:8.86e-03, fs:0.71429 (r=0.575,p=0.943),  time:42.584, tt:2256.930\n",
      "Ep:53, loss:0.00002, loss_test:0.09784, lr:8.78e-03, fs:0.67164 (r=0.517,p=0.957),  time:42.596, tt:2300.181\n",
      "Ep:54, loss:0.00002, loss_test:0.10066, lr:8.69e-03, fs:0.75524 (r=0.621,p=0.964),  time:42.556, tt:2340.592\n",
      "Ep:55, loss:0.00002, loss_test:0.10998, lr:8.60e-03, fs:0.66165 (r=0.506,p=0.957),  time:42.540, tt:2382.255\n",
      "Ep:56, loss:0.00002, loss_test:0.09894, lr:8.51e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.558, tt:2425.819\n",
      "Ep:57, loss:0.00002, loss_test:0.10492, lr:8.43e-03, fs:0.66165 (r=0.506,p=0.957),  time:42.550, tt:2467.925\n",
      "Ep:58, loss:0.00002, loss_test:0.10242, lr:8.35e-03, fs:0.72857 (r=0.586,p=0.962),  time:42.537, tt:2509.684\n",
      "Ep:59, loss:0.00001, loss_test:0.10876, lr:8.26e-03, fs:0.66165 (r=0.506,p=0.957),  time:42.549, tt:2552.951\n",
      "Ep:60, loss:0.00001, loss_test:0.10280, lr:8.18e-03, fs:0.76389 (r=0.632,p=0.965),  time:42.538, tt:2594.815\n",
      "Ep:61, loss:0.00001, loss_test:0.10468, lr:8.10e-03, fs:0.67669 (r=0.517,p=0.978),  time:42.517, tt:2636.073\n",
      "Ep:62, loss:0.00001, loss_test:0.10531, lr:8.02e-03, fs:0.73239 (r=0.598,p=0.945),  time:42.492, tt:2677.017\n",
      "Ep:63, loss:0.00001, loss_test:0.10486, lr:7.94e-03, fs:0.61905 (r=0.448,p=1.000),  time:42.438, tt:2716.044\n",
      "Ep:64, loss:0.00001, loss_test:0.11297, lr:7.86e-03, fs:0.69565 (r=0.552,p=0.941),  time:42.422, tt:2757.399\n",
      "Ep:65, loss:0.00001, loss_test:0.09915, lr:7.78e-03, fs:0.76056 (r=0.621,p=0.982),  time:42.391, tt:2797.781\n",
      "Ep:66, loss:0.00001, loss_test:0.11743, lr:7.70e-03, fs:0.67669 (r=0.517,p=0.978),  time:42.362, tt:2838.256\n",
      "Ep:67, loss:0.00001, loss_test:0.10849, lr:7.62e-03, fs:0.66667 (r=0.506,p=0.978),  time:42.322, tt:2877.868\n",
      "Ep:68, loss:0.00001, loss_test:0.10983, lr:7.55e-03, fs:0.70073 (r=0.552,p=0.960),  time:42.291, tt:2918.072\n",
      "Ep:69, loss:0.00001, loss_test:0.11492, lr:7.47e-03, fs:0.66165 (r=0.506,p=0.957),  time:42.252, tt:2957.644\n",
      "Ep:70, loss:0.00001, loss_test:0.11025, lr:7.40e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.226, tt:2998.070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:71, loss:0.00001, loss_test:0.11330, lr:7.32e-03, fs:0.67669 (r=0.517,p=0.978),  time:42.204, tt:3038.688\n",
      "Ep:72, loss:0.00001, loss_test:0.11220, lr:7.25e-03, fs:0.67164 (r=0.517,p=0.957),  time:42.174, tt:3078.703\n",
      "Ep:73, loss:0.00001, loss_test:0.11346, lr:7.18e-03, fs:0.66667 (r=0.506,p=0.978),  time:42.125, tt:3117.221\n",
      "Ep:74, loss:0.00001, loss_test:0.11341, lr:7.11e-03, fs:0.66667 (r=0.506,p=0.978),  time:42.110, tt:3158.228\n",
      "Ep:75, loss:0.00001, loss_test:0.11360, lr:7.03e-03, fs:0.66165 (r=0.506,p=0.957),  time:42.070, tt:3197.303\n",
      "Ep:76, loss:0.00001, loss_test:0.11172, lr:6.96e-03, fs:0.67164 (r=0.517,p=0.957),  time:42.059, tt:3238.515\n",
      "Ep:77, loss:0.00001, loss_test:0.11405, lr:6.89e-03, fs:0.66667 (r=0.506,p=0.978),  time:42.037, tt:3278.890\n",
      "Ep:78, loss:0.00000, loss_test:0.11418, lr:6.83e-03, fs:0.66667 (r=0.506,p=0.978),  time:42.030, tt:3320.356\n",
      "Ep:79, loss:0.00000, loss_test:0.11505, lr:6.76e-03, fs:0.66667 (r=0.506,p=0.978),  time:42.011, tt:3360.911\n",
      "Ep:80, loss:0.00000, loss_test:0.11494, lr:6.69e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.999, tt:3401.905\n",
      "Ep:81, loss:0.00000, loss_test:0.11628, lr:6.62e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.950, tt:3439.902\n",
      "Ep:82, loss:0.00000, loss_test:0.11318, lr:6.56e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.913, tt:3478.740\n",
      "Ep:83, loss:0.00000, loss_test:0.11661, lr:6.49e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.903, tt:3519.851\n",
      "Ep:84, loss:0.00000, loss_test:0.11266, lr:6.43e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.897, tt:3561.252\n",
      "Ep:85, loss:0.00000, loss_test:0.11876, lr:6.36e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.908, tt:3604.048\n",
      "Ep:86, loss:0.00000, loss_test:0.11515, lr:6.30e-03, fs:0.67176 (r=0.506,p=1.000),  time:41.886, tt:3644.108\n",
      "Ep:87, loss:0.00000, loss_test:0.11533, lr:6.24e-03, fs:0.66165 (r=0.506,p=0.957),  time:41.881, tt:3685.538\n",
      "Ep:88, loss:0.00000, loss_test:0.11612, lr:6.17e-03, fs:0.67176 (r=0.506,p=1.000),  time:41.875, tt:3726.917\n",
      "Ep:89, loss:0.00000, loss_test:0.11528, lr:6.11e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.860, tt:3767.419\n",
      "Ep:90, loss:0.00000, loss_test:0.11542, lr:6.05e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.848, tt:3808.186\n",
      "Ep:91, loss:0.00000, loss_test:0.11580, lr:5.99e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.851, tt:3850.315\n",
      "Ep:92, loss:0.00000, loss_test:0.11854, lr:5.93e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.839, tt:3891.055\n",
      "Ep:93, loss:0.00000, loss_test:0.11694, lr:5.87e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.844, tt:3933.370\n",
      "Ep:94, loss:0.00000, loss_test:0.11667, lr:5.81e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.843, tt:3975.114\n",
      "Ep:95, loss:0.00000, loss_test:0.11616, lr:5.75e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.833, tt:4015.973\n",
      "Ep:96, loss:0.00000, loss_test:0.11841, lr:5.70e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.830, tt:4057.513\n",
      "Ep:97, loss:0.00000, loss_test:0.12041, lr:5.64e-03, fs:0.67176 (r=0.506,p=1.000),  time:41.837, tt:4100.000\n",
      "Ep:98, loss:0.00000, loss_test:0.11657, lr:5.58e-03, fs:0.65649 (r=0.494,p=0.977),  time:41.829, tt:4141.038\n",
      "Ep:99, loss:0.00000, loss_test:0.11910, lr:5.53e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.782, tt:4178.186\n",
      "Ep:100, loss:0.00000, loss_test:0.11608, lr:5.47e-03, fs:0.66154 (r=0.494,p=1.000),  time:41.791, tt:4220.874\n",
      "Ep:101, loss:0.00000, loss_test:0.11797, lr:5.42e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.810, tt:4264.664\n",
      "Ep:102, loss:0.00000, loss_test:0.11805, lr:5.36e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.803, tt:4305.737\n",
      "Ep:103, loss:0.00000, loss_test:0.11678, lr:5.31e-03, fs:0.66154 (r=0.494,p=1.000),  time:41.786, tt:4345.796\n",
      "Ep:104, loss:0.00000, loss_test:0.11737, lr:5.26e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.778, tt:4386.707\n",
      "Ep:105, loss:0.00000, loss_test:0.11750, lr:5.20e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.755, tt:4425.983\n",
      "Ep:106, loss:0.00000, loss_test:0.11666, lr:5.15e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.762, tt:4468.565\n",
      "Ep:107, loss:0.00000, loss_test:0.11986, lr:5.10e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.756, tt:4509.620\n",
      "Ep:108, loss:0.00000, loss_test:0.11883, lr:5.05e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.732, tt:4548.785\n",
      "Ep:109, loss:0.00000, loss_test:0.11656, lr:5.00e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.722, tt:4589.428\n",
      "Ep:110, loss:0.00000, loss_test:0.12349, lr:4.95e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.716, tt:4630.500\n",
      "Ep:111, loss:0.00000, loss_test:0.11830, lr:4.90e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.757, tt:4676.787\n",
      "Ep:112, loss:0.00000, loss_test:0.11726, lr:4.85e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.749, tt:4717.659\n",
      "Ep:113, loss:0.00000, loss_test:0.12050, lr:4.80e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.740, tt:4758.403\n",
      "Ep:114, loss:0.00000, loss_test:0.11841, lr:4.75e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.738, tt:4799.858\n",
      "Ep:115, loss:0.00000, loss_test:0.11844, lr:4.71e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.712, tt:4838.541\n",
      "Ep:116, loss:0.00000, loss_test:0.12001, lr:4.66e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.703, tt:4879.221\n",
      "Ep:117, loss:0.00000, loss_test:0.11926, lr:4.61e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.699, tt:4920.471\n",
      "Ep:118, loss:0.00000, loss_test:0.11931, lr:4.57e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.692, tt:4961.291\n",
      "Ep:119, loss:0.00000, loss_test:0.12002, lr:4.52e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.691, tt:5002.886\n",
      "Ep:120, loss:0.00000, loss_test:0.11933, lr:4.48e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.687, tt:5044.101\n",
      "Ep:121, loss:0.00000, loss_test:0.11888, lr:4.43e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.690, tt:5086.188\n",
      "Ep:122, loss:0.00000, loss_test:0.12112, lr:4.39e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.677, tt:5126.327\n",
      "Ep:123, loss:0.00000, loss_test:0.12186, lr:4.34e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.666, tt:5166.537\n",
      "Ep:124, loss:0.00000, loss_test:0.11945, lr:4.30e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.662, tt:5207.695\n",
      "Ep:125, loss:0.00000, loss_test:0.12067, lr:4.26e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.649, tt:5247.712\n",
      "Ep:126, loss:0.00000, loss_test:0.12041, lr:4.21e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.649, tt:5289.470\n",
      "Ep:127, loss:0.00000, loss_test:0.11931, lr:4.17e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.642, tt:5330.188\n",
      "Ep:128, loss:0.00000, loss_test:0.12298, lr:4.13e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.633, tt:5370.712\n",
      "Ep:129, loss:0.00000, loss_test:0.12272, lr:4.09e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.632, tt:5412.222\n",
      "Ep:130, loss:0.00000, loss_test:0.11957, lr:4.05e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.628, tt:5453.266\n",
      "Ep:131, loss:0.00000, loss_test:0.12250, lr:4.01e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.674, tt:5501.018\n",
      "Ep:132, loss:0.00000, loss_test:0.12352, lr:3.97e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.675, tt:5542.754\n",
      "Ep:133, loss:0.00000, loss_test:0.12129, lr:3.93e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.672, tt:5584.066\n",
      "Ep:134, loss:0.00000, loss_test:0.12112, lr:3.89e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.664, tt:5624.588\n",
      "Ep:135, loss:0.00000, loss_test:0.12323, lr:3.85e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.650, tt:5664.345\n",
      "Ep:136, loss:0.00000, loss_test:0.12292, lr:3.81e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.649, tt:5705.948\n",
      "Ep:137, loss:0.00000, loss_test:0.12189, lr:3.77e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.626, tt:5744.362\n",
      "Ep:138, loss:0.00000, loss_test:0.12285, lr:3.73e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.602, tt:5782.693\n",
      "Ep:139, loss:0.00000, loss_test:0.12378, lr:3.70e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.583, tt:5821.651\n",
      "Ep:140, loss:0.00000, loss_test:0.12243, lr:3.66e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.581, tt:5862.855\n",
      "Ep:141, loss:0.00000, loss_test:0.12247, lr:3.62e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.585, tt:5905.075\n",
      "Ep:142, loss:0.00000, loss_test:0.12597, lr:3.59e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.573, tt:5944.906\n",
      "Ep:143, loss:0.00000, loss_test:0.12472, lr:3.55e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.569, tt:5985.924\n",
      "Ep:144, loss:0.00000, loss_test:0.12312, lr:3.52e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.567, tt:6027.176\n",
      "Ep:145, loss:0.00000, loss_test:0.12333, lr:3.48e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.563, tt:6068.260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:146, loss:0.00000, loss_test:0.12367, lr:3.45e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.536, tt:6105.847\n",
      "Ep:147, loss:0.00000, loss_test:0.12387, lr:3.41e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.532, tt:6146.761\n",
      "Ep:148, loss:0.00000, loss_test:0.12387, lr:3.38e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.534, tt:6188.587\n",
      "Ep:149, loss:0.00000, loss_test:0.12464, lr:3.34e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.522, tt:6228.291\n",
      "Ep:150, loss:0.00000, loss_test:0.12531, lr:3.31e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.515, tt:6268.748\n",
      "Ep:151, loss:0.00000, loss_test:0.12375, lr:3.28e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.511, tt:6309.680\n",
      "Ep:152, loss:0.00000, loss_test:0.12330, lr:3.24e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.529, tt:6353.991\n",
      "Ep:153, loss:0.00000, loss_test:0.12403, lr:3.21e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.514, tt:6393.103\n",
      "Ep:154, loss:0.00000, loss_test:0.12459, lr:3.18e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.491, tt:6431.030\n",
      "Ep:155, loss:0.00000, loss_test:0.12330, lr:3.15e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.486, tt:6471.880\n",
      "Ep:156, loss:0.00000, loss_test:0.12364, lr:3.12e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.477, tt:6511.831\n",
      "Ep:157, loss:0.00000, loss_test:0.12425, lr:3.09e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.465, tt:6551.461\n",
      "Ep:158, loss:0.00000, loss_test:0.12374, lr:3.05e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.467, tt:6593.244\n",
      "Ep:159, loss:0.00000, loss_test:0.12268, lr:3.02e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.459, tt:6633.395\n",
      "Ep:160, loss:0.00000, loss_test:0.12541, lr:2.99e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.461, tt:6675.230\n",
      "Ep:161, loss:0.00000, loss_test:0.12460, lr:2.96e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.460, tt:6716.580\n",
      "Ep:162, loss:0.00000, loss_test:0.12257, lr:2.93e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.456, tt:6757.392\n",
      "Ep:163, loss:0.00000, loss_test:0.12339, lr:2.90e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.435, tt:6795.377\n",
      "Ep:164, loss:0.00000, loss_test:0.12588, lr:2.88e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.423, tt:6834.755\n",
      "Ep:165, loss:0.00000, loss_test:0.12473, lr:2.85e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.417, tt:6875.210\n",
      "Ep:166, loss:0.00000, loss_test:0.12270, lr:2.82e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.399, tt:6913.675\n",
      "Ep:167, loss:0.00000, loss_test:0.12621, lr:2.79e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.393, tt:6953.970\n",
      "Ep:168, loss:0.00000, loss_test:0.12664, lr:2.76e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.388, tt:6994.550\n",
      "Ep:169, loss:0.00000, loss_test:0.12396, lr:2.73e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.375, tt:7033.685\n",
      "Ep:170, loss:0.00000, loss_test:0.12349, lr:2.71e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.372, tt:7074.678\n",
      "Ep:171, loss:0.00000, loss_test:0.12496, lr:2.68e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.362, tt:7114.278\n",
      "Ep:172, loss:0.00000, loss_test:0.12511, lr:2.65e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.359, tt:7155.072\n",
      "Ep:173, loss:0.00000, loss_test:0.12368, lr:2.63e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.365, tt:7197.535\n",
      "Ep:174, loss:0.00000, loss_test:0.12325, lr:2.60e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.359, tt:7237.899\n",
      "Ep:175, loss:0.00000, loss_test:0.12339, lr:2.57e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.361, tt:7279.579\n",
      "Ep:176, loss:0.00000, loss_test:0.12363, lr:2.55e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.357, tt:7320.154\n",
      "Ep:177, loss:0.00000, loss_test:0.12371, lr:2.52e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.350, tt:7360.383\n",
      "Ep:178, loss:0.00000, loss_test:0.12368, lr:2.50e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.352, tt:7402.071\n",
      "Ep:179, loss:0.00000, loss_test:0.12384, lr:2.47e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.353, tt:7443.605\n",
      "Ep:180, loss:0.00000, loss_test:0.12382, lr:2.45e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.349, tt:7484.252\n",
      "Ep:181, loss:0.00000, loss_test:0.12415, lr:2.42e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.345, tt:7524.776\n",
      "Ep:182, loss:0.00000, loss_test:0.12323, lr:2.40e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.341, tt:7565.378\n",
      "Ep:183, loss:0.00000, loss_test:0.12464, lr:2.38e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.325, tt:7603.790\n",
      "Ep:184, loss:0.00000, loss_test:0.12648, lr:2.35e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.319, tt:7643.949\n",
      "Ep:185, loss:0.00000, loss_test:0.12488, lr:2.33e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.319, tt:7685.376\n",
      "Ep:186, loss:0.00000, loss_test:0.12301, lr:2.31e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.326, tt:7727.976\n",
      "Ep:187, loss:0.00000, loss_test:0.12369, lr:2.28e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.316, tt:7767.327\n",
      "Ep:188, loss:0.00000, loss_test:0.12453, lr:2.26e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.315, tt:7808.589\n",
      "Ep:189, loss:0.00000, loss_test:0.12424, lr:2.24e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.299, tt:7846.884\n",
      "Ep:190, loss:0.00000, loss_test:0.12333, lr:2.21e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.308, tt:7889.823\n",
      "Ep:191, loss:0.00000, loss_test:0.12343, lr:2.19e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.307, tt:7930.931\n",
      "Ep:192, loss:0.00000, loss_test:0.12358, lr:2.17e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.316, tt:7974.062\n",
      "Ep:193, loss:0.00000, loss_test:0.12382, lr:2.15e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.344, tt:8020.695\n",
      "Ep:194, loss:0.00000, loss_test:0.12359, lr:2.13e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.345, tt:8062.209\n",
      "Ep:195, loss:0.00000, loss_test:0.12361, lr:2.11e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.348, tt:8104.118\n",
      "Ep:196, loss:0.00000, loss_test:0.12381, lr:2.08e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.351, tt:8146.137\n",
      "Ep:197, loss:0.00000, loss_test:0.12330, lr:2.06e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.363, tt:8189.813\n",
      "Ep:198, loss:0.00000, loss_test:0.12336, lr:2.04e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.367, tt:8232.084\n",
      "Ep:199, loss:0.00000, loss_test:0.12350, lr:2.02e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.378, tt:8275.514\n",
      "Ep:200, loss:0.00000, loss_test:0.12325, lr:2.00e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.378, tt:8316.894\n",
      "Ep:201, loss:0.00000, loss_test:0.12296, lr:1.98e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.382, tt:8359.228\n",
      "Ep:202, loss:0.00000, loss_test:0.12310, lr:1.96e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.386, tt:8401.338\n",
      "Ep:203, loss:0.00000, loss_test:0.12351, lr:1.94e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.392, tt:8443.962\n",
      "Ep:204, loss:0.00000, loss_test:0.12309, lr:1.92e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.373, tt:8481.478\n",
      "Ep:205, loss:0.00000, loss_test:0.12301, lr:1.90e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.352, tt:8518.545\n",
      "Ep:206, loss:0.00000, loss_test:0.12326, lr:1.89e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.329, tt:8555.053\n",
      "Ep:207, loss:0.00000, loss_test:0.12332, lr:1.87e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.311, tt:8592.690\n",
      "Ep:208, loss:0.00000, loss_test:0.12291, lr:1.85e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.301, tt:8631.909\n",
      "Ep:209, loss:0.00000, loss_test:0.12276, lr:1.83e-03, fs:0.66667 (r=0.506,p=0.978),  time:41.210, tt:8654.173\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,210,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,210,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02138, lr:6.00e-02, fs:0.63248 (r=0.851,p=0.503),  time:21.552, tt:21.552\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02410, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.245, tt:48.490\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02531, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.684, tt:80.053\n",
      "Ep:3, loss:0.00005, loss_test:0.02493, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.696, tt:110.784\n",
      "Ep:4, loss:0.00004, loss_test:0.02387, lr:6.00e-02, fs:0.65116 (r=0.966,p=0.491),  time:28.360, tt:141.802\n",
      "Ep:5, loss:0.00004, loss_test:0.02301, lr:6.00e-02, fs:0.63636 (r=0.885,p=0.497),  time:28.708, tt:172.245\n",
      "Ep:6, loss:0.00004, loss_test:0.02300, lr:6.00e-02, fs:0.61538 (r=0.782,p=0.507),  time:28.717, tt:201.016\n",
      "Ep:7, loss:0.00004, loss_test:0.02325, lr:6.00e-02, fs:0.59898 (r=0.678,p=0.536),  time:28.738, tt:229.903\n",
      "Ep:8, loss:0.00004, loss_test:0.02243, lr:6.00e-02, fs:0.60914 (r=0.690,p=0.545),  time:28.814, tt:259.330\n",
      "Ep:9, loss:0.00003, loss_test:0.02118, lr:6.00e-02, fs:0.61972 (r=0.759,p=0.524),  time:29.022, tt:290.220\n",
      "Ep:10, loss:0.00003, loss_test:0.02051, lr:6.00e-02, fs:0.62673 (r=0.782,p=0.523),  time:29.157, tt:320.725\n",
      "Ep:11, loss:0.00003, loss_test:0.02011, lr:6.00e-02, fs:0.64151 (r=0.782,p=0.544),  time:29.288, tt:351.457\n",
      "Ep:12, loss:0.00003, loss_test:0.02001, lr:6.00e-02, fs:0.62376 (r=0.724,p=0.548),  time:29.362, tt:381.710\n",
      "Ep:13, loss:0.00003, loss_test:0.01976, lr:5.94e-02, fs:0.63265 (r=0.713,p=0.569),  time:29.457, tt:412.401\n",
      "Ep:14, loss:0.00003, loss_test:0.01916, lr:5.88e-02, fs:0.63590 (r=0.713,p=0.574),  time:29.679, tt:445.189\n",
      "Ep:15, loss:0.00003, loss_test:0.01821, lr:5.82e-02, fs:0.65000 (r=0.747,p=0.575),  time:29.886, tt:478.176\n",
      "Ep:16, loss:0.00003, loss_test:0.01751, lr:5.76e-02, fs:0.67633 (r=0.805,p=0.583),  time:30.161, tt:512.743\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01709, lr:5.76e-02, fs:0.68317 (r=0.793,p=0.600),  time:30.205, tt:543.694\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01692, lr:5.76e-02, fs:0.71503 (r=0.793,p=0.651),  time:30.194, tt:573.686\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01672, lr:5.76e-02, fs:0.73797 (r=0.793,p=0.690),  time:30.246, tt:604.923\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.01636, lr:5.76e-02, fs:0.74074 (r=0.805,p=0.686),  time:30.333, tt:636.984\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01592, lr:5.76e-02, fs:0.75393 (r=0.828,p=0.692),  time:30.452, tt:669.938\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01578, lr:5.76e-02, fs:0.75789 (r=0.828,p=0.699),  time:30.531, tt:702.206\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01575, lr:5.76e-02, fs:0.76190 (r=0.828,p=0.706),  time:30.484, tt:731.627\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01573, lr:5.76e-02, fs:0.76190 (r=0.828,p=0.706),  time:30.484, tt:762.112\n",
      "Ep:25, loss:0.00002, loss_test:0.01551, lr:5.76e-02, fs:0.76842 (r=0.839,p=0.709),  time:30.442, tt:791.496\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01530, lr:5.76e-02, fs:0.76190 (r=0.828,p=0.706),  time:30.508, tt:823.707\n",
      "Ep:27, loss:0.00002, loss_test:0.01533, lr:5.76e-02, fs:0.78261 (r=0.828,p=0.742),  time:30.637, tt:857.831\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01539, lr:5.76e-02, fs:0.78261 (r=0.828,p=0.742),  time:30.597, tt:887.308\n",
      "Ep:29, loss:0.00002, loss_test:0.01524, lr:5.76e-02, fs:0.78261 (r=0.828,p=0.742),  time:30.536, tt:916.086\n",
      "Ep:30, loss:0.00002, loss_test:0.01515, lr:5.76e-02, fs:0.79121 (r=0.828,p=0.758),  time:30.555, tt:947.194\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01518, lr:5.76e-02, fs:0.79096 (r=0.805,p=0.778),  time:30.567, tt:978.158\n",
      "Ep:32, loss:0.00002, loss_test:0.01522, lr:5.76e-02, fs:0.79096 (r=0.805,p=0.778),  time:30.593, tt:1009.558\n",
      "Ep:33, loss:0.00002, loss_test:0.01502, lr:5.76e-02, fs:0.79775 (r=0.816,p=0.780),  time:30.635, tt:1041.601\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01495, lr:5.76e-02, fs:0.79775 (r=0.816,p=0.780),  time:30.673, tt:1073.546\n",
      "Ep:35, loss:0.00002, loss_test:0.01501, lr:5.76e-02, fs:0.80000 (r=0.805,p=0.795),  time:30.702, tt:1105.286\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00001, loss_test:0.01498, lr:5.76e-02, fs:0.80460 (r=0.805,p=0.805),  time:30.759, tt:1138.071\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00001, loss_test:0.01499, lr:5.76e-02, fs:0.79532 (r=0.782,p=0.810),  time:30.744, tt:1168.253\n",
      "Ep:38, loss:0.00001, loss_test:0.01503, lr:5.76e-02, fs:0.80000 (r=0.782,p=0.819),  time:30.724, tt:1198.230\n",
      "Ep:39, loss:0.00001, loss_test:0.01515, lr:5.76e-02, fs:0.80952 (r=0.782,p=0.840),  time:30.692, tt:1227.693\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00001, loss_test:0.01506, lr:5.76e-02, fs:0.81437 (r=0.782,p=0.850),  time:30.678, tt:1257.810\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00001, loss_test:0.01509, lr:5.76e-02, fs:0.82143 (r=0.793,p=0.852),  time:30.683, tt:1288.705\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00001, loss_test:0.01525, lr:5.76e-02, fs:0.82635 (r=0.793,p=0.863),  time:30.692, tt:1319.763\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00001, loss_test:0.01538, lr:5.76e-02, fs:0.81212 (r=0.770,p=0.859),  time:30.701, tt:1350.829\n",
      "Ep:44, loss:0.00001, loss_test:0.01536, lr:5.76e-02, fs:0.81212 (r=0.770,p=0.859),  time:30.768, tt:1384.580\n",
      "Ep:45, loss:0.00001, loss_test:0.01550, lr:5.76e-02, fs:0.82209 (r=0.770,p=0.882),  time:30.740, tt:1414.022\n",
      "Ep:46, loss:0.00001, loss_test:0.01579, lr:5.76e-02, fs:0.81250 (r=0.747,p=0.890),  time:30.725, tt:1444.082\n",
      "Ep:47, loss:0.00001, loss_test:0.01562, lr:5.76e-02, fs:0.82716 (r=0.770,p=0.893),  time:30.737, tt:1475.393\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.01586, lr:5.76e-02, fs:0.81250 (r=0.747,p=0.890),  time:30.681, tt:1503.379\n",
      "Ep:49, loss:0.00001, loss_test:0.01598, lr:5.76e-02, fs:0.81761 (r=0.747,p=0.903),  time:30.657, tt:1532.858\n",
      "Ep:50, loss:0.00001, loss_test:0.01603, lr:5.76e-02, fs:0.81250 (r=0.747,p=0.890),  time:30.654, tt:1563.377\n",
      "Ep:51, loss:0.00001, loss_test:0.01615, lr:5.76e-02, fs:0.80503 (r=0.736,p=0.889),  time:30.647, tt:1593.652\n",
      "Ep:52, loss:0.00001, loss_test:0.01631, lr:5.76e-02, fs:0.81529 (r=0.736,p=0.914),  time:30.596, tt:1621.614\n",
      "Ep:53, loss:0.00001, loss_test:0.01639, lr:5.76e-02, fs:0.81529 (r=0.736,p=0.914),  time:30.576, tt:1651.105\n",
      "Ep:54, loss:0.00001, loss_test:0.01675, lr:5.76e-02, fs:0.81529 (r=0.736,p=0.914),  time:30.548, tt:1680.152\n",
      "Ep:55, loss:0.00001, loss_test:0.01687, lr:5.76e-02, fs:0.80769 (r=0.724,p=0.913),  time:30.502, tt:1708.093\n",
      "Ep:56, loss:0.00001, loss_test:0.01688, lr:5.76e-02, fs:0.80769 (r=0.724,p=0.913),  time:30.493, tt:1738.124\n",
      "Ep:57, loss:0.00001, loss_test:0.01700, lr:5.76e-02, fs:0.80769 (r=0.724,p=0.913),  time:30.475, tt:1767.535\n",
      "Ep:58, loss:0.00001, loss_test:0.01727, lr:5.76e-02, fs:0.80769 (r=0.724,p=0.913),  time:30.445, tt:1796.263\n",
      "Ep:59, loss:0.00001, loss_test:0.01725, lr:5.71e-02, fs:0.80769 (r=0.724,p=0.913),  time:30.402, tt:1824.142\n",
      "Ep:60, loss:0.00001, loss_test:0.01760, lr:5.65e-02, fs:0.81290 (r=0.724,p=0.926),  time:30.357, tt:1851.791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00001, loss_test:0.01762, lr:5.59e-02, fs:0.81290 (r=0.724,p=0.926),  time:30.345, tt:1881.384\n",
      "Ep:62, loss:0.00001, loss_test:0.01768, lr:5.54e-02, fs:0.81290 (r=0.724,p=0.926),  time:30.350, tt:1912.038\n",
      "Ep:63, loss:0.00001, loss_test:0.01803, lr:5.48e-02, fs:0.81290 (r=0.724,p=0.926),  time:30.342, tt:1941.913\n",
      "Ep:64, loss:0.00001, loss_test:0.01802, lr:5.43e-02, fs:0.81290 (r=0.724,p=0.926),  time:30.344, tt:1972.389\n",
      "Ep:65, loss:0.00001, loss_test:0.01822, lr:5.37e-02, fs:0.81290 (r=0.724,p=0.926),  time:30.345, tt:2002.745\n",
      "Ep:66, loss:0.00001, loss_test:0.01827, lr:5.32e-02, fs:0.81818 (r=0.724,p=0.940),  time:30.345, tt:2033.124\n",
      "Ep:67, loss:0.00001, loss_test:0.01843, lr:5.27e-02, fs:0.81818 (r=0.724,p=0.940),  time:30.364, tt:2064.737\n",
      "Ep:68, loss:0.00001, loss_test:0.01869, lr:5.21e-02, fs:0.81818 (r=0.724,p=0.940),  time:30.361, tt:2094.925\n",
      "Ep:69, loss:0.00001, loss_test:0.01876, lr:5.16e-02, fs:0.81818 (r=0.724,p=0.940),  time:30.371, tt:2126.003\n",
      "Ep:70, loss:0.00001, loss_test:0.01901, lr:5.11e-02, fs:0.80263 (r=0.701,p=0.938),  time:30.358, tt:2155.435\n",
      "Ep:71, loss:0.00001, loss_test:0.01926, lr:5.06e-02, fs:0.80263 (r=0.701,p=0.938),  time:30.379, tt:2187.322\n",
      "Ep:72, loss:0.00000, loss_test:0.01917, lr:5.01e-02, fs:0.81046 (r=0.713,p=0.939),  time:30.412, tt:2220.108\n",
      "Ep:73, loss:0.00000, loss_test:0.01930, lr:4.96e-02, fs:0.80263 (r=0.701,p=0.938),  time:30.417, tt:2250.863\n",
      "Ep:74, loss:0.00000, loss_test:0.01959, lr:4.91e-02, fs:0.79470 (r=0.690,p=0.938),  time:30.425, tt:2281.842\n",
      "Ep:75, loss:0.00000, loss_test:0.01964, lr:4.86e-02, fs:0.79470 (r=0.690,p=0.938),  time:30.426, tt:2312.345\n",
      "Ep:76, loss:0.00000, loss_test:0.01980, lr:4.81e-02, fs:0.79470 (r=0.690,p=0.938),  time:30.435, tt:2343.512\n",
      "Ep:77, loss:0.00000, loss_test:0.01991, lr:4.76e-02, fs:0.79470 (r=0.690,p=0.938),  time:30.448, tt:2374.912\n",
      "Ep:78, loss:0.00000, loss_test:0.02003, lr:4.71e-02, fs:0.79470 (r=0.690,p=0.938),  time:30.455, tt:2405.914\n",
      "Ep:79, loss:0.00000, loss_test:0.02034, lr:4.67e-02, fs:0.77852 (r=0.667,p=0.935),  time:30.470, tt:2437.595\n",
      "Ep:80, loss:0.00000, loss_test:0.02035, lr:4.62e-02, fs:0.79195 (r=0.678,p=0.952),  time:30.461, tt:2467.319\n",
      "Ep:81, loss:0.00000, loss_test:0.02030, lr:4.57e-02, fs:0.79195 (r=0.678,p=0.952),  time:30.417, tt:2494.192\n",
      "Ep:82, loss:0.00000, loss_test:0.02075, lr:4.53e-02, fs:0.75000 (r=0.621,p=0.947),  time:30.409, tt:2523.963\n",
      "Ep:83, loss:0.00000, loss_test:0.02064, lr:4.48e-02, fs:0.78378 (r=0.667,p=0.951),  time:30.369, tt:2551.031\n",
      "Ep:84, loss:0.00000, loss_test:0.02071, lr:4.44e-02, fs:0.75862 (r=0.632,p=0.948),  time:30.360, tt:2580.611\n",
      "Ep:85, loss:0.00000, loss_test:0.02106, lr:4.39e-02, fs:0.75000 (r=0.621,p=0.947),  time:30.334, tt:2608.758\n",
      "Ep:86, loss:0.00000, loss_test:0.02106, lr:4.35e-02, fs:0.77551 (r=0.655,p=0.950),  time:30.326, tt:2638.393\n",
      "Ep:87, loss:0.00000, loss_test:0.02110, lr:4.31e-02, fs:0.76712 (r=0.644,p=0.949),  time:30.318, tt:2667.976\n",
      "Ep:88, loss:0.00000, loss_test:0.02136, lr:4.26e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.290, tt:2695.807\n",
      "Ep:89, loss:0.00000, loss_test:0.02148, lr:4.22e-02, fs:0.75524 (r=0.621,p=0.964),  time:30.276, tt:2724.810\n",
      "Ep:90, loss:0.00000, loss_test:0.02145, lr:4.18e-02, fs:0.76389 (r=0.632,p=0.965),  time:30.261, tt:2753.788\n",
      "Ep:91, loss:0.00000, loss_test:0.02165, lr:4.14e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.239, tt:2781.971\n",
      "Ep:92, loss:0.00000, loss_test:0.02158, lr:4.10e-02, fs:0.75524 (r=0.621,p=0.964),  time:30.236, tt:2811.954\n",
      "Ep:93, loss:0.00000, loss_test:0.02162, lr:4.05e-02, fs:0.71942 (r=0.575,p=0.962),  time:30.218, tt:2840.446\n",
      "Ep:94, loss:0.00000, loss_test:0.02186, lr:4.01e-02, fs:0.71942 (r=0.575,p=0.962),  time:30.239, tt:2872.669\n",
      "Ep:95, loss:0.00000, loss_test:0.02199, lr:3.97e-02, fs:0.71014 (r=0.563,p=0.961),  time:30.220, tt:2901.095\n",
      "Ep:96, loss:0.00000, loss_test:0.02197, lr:3.93e-02, fs:0.71942 (r=0.575,p=0.962),  time:30.208, tt:2930.167\n",
      "Ep:97, loss:0.00000, loss_test:0.02220, lr:3.89e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.218, tt:2961.332\n",
      "Ep:98, loss:0.00000, loss_test:0.02218, lr:3.86e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.231, tt:2992.863\n",
      "Ep:99, loss:0.00000, loss_test:0.02237, lr:3.82e-02, fs:0.68148 (r=0.529,p=0.958),  time:30.223, tt:3022.290\n",
      "Ep:100, loss:0.00000, loss_test:0.02243, lr:3.78e-02, fs:0.68148 (r=0.529,p=0.958),  time:30.207, tt:3050.911\n",
      "Ep:101, loss:0.00000, loss_test:0.02255, lr:3.74e-02, fs:0.68148 (r=0.529,p=0.958),  time:30.216, tt:3082.062\n",
      "Ep:102, loss:0.00000, loss_test:0.02266, lr:3.70e-02, fs:0.68148 (r=0.529,p=0.958),  time:30.214, tt:3112.070\n",
      "Ep:103, loss:0.00000, loss_test:0.02268, lr:3.67e-02, fs:0.68148 (r=0.529,p=0.958),  time:30.218, tt:3142.690\n",
      "Ep:104, loss:0.00000, loss_test:0.02274, lr:3.63e-02, fs:0.67164 (r=0.517,p=0.957),  time:30.213, tt:3172.360\n",
      "Ep:105, loss:0.00000, loss_test:0.02299, lr:3.59e-02, fs:0.67669 (r=0.517,p=0.978),  time:30.228, tt:3204.211\n",
      "Ep:106, loss:0.00000, loss_test:0.02291, lr:3.56e-02, fs:0.67669 (r=0.517,p=0.978),  time:30.248, tt:3236.506\n",
      "Ep:107, loss:0.00000, loss_test:0.02298, lr:3.52e-02, fs:0.67669 (r=0.517,p=0.978),  time:30.273, tt:3269.470\n",
      "Ep:108, loss:0.00000, loss_test:0.02319, lr:3.49e-02, fs:0.67669 (r=0.517,p=0.978),  time:30.275, tt:3300.002\n",
      "Ep:109, loss:0.00000, loss_test:0.02324, lr:3.45e-02, fs:0.67669 (r=0.517,p=0.978),  time:30.293, tt:3332.241\n",
      "Ep:110, loss:0.00000, loss_test:0.02319, lr:3.42e-02, fs:0.67669 (r=0.517,p=0.978),  time:30.273, tt:3360.248\n",
      "Ep:111, loss:0.00000, loss_test:0.02337, lr:3.38e-02, fs:0.67669 (r=0.517,p=0.978),  time:30.287, tt:3392.092\n",
      "Ep:112, loss:0.00000, loss_test:0.02345, lr:3.35e-02, fs:0.67669 (r=0.517,p=0.978),  time:30.285, tt:3422.203\n",
      "Ep:113, loss:0.00000, loss_test:0.02356, lr:3.32e-02, fs:0.67669 (r=0.517,p=0.978),  time:30.276, tt:3451.467\n",
      "Ep:114, loss:0.00000, loss_test:0.02360, lr:3.28e-02, fs:0.67669 (r=0.517,p=0.978),  time:30.268, tt:3480.864\n",
      "Ep:115, loss:0.00000, loss_test:0.02367, lr:3.25e-02, fs:0.67669 (r=0.517,p=0.978),  time:30.251, tt:3509.070\n",
      "Ep:116, loss:0.00000, loss_test:0.02376, lr:3.22e-02, fs:0.67669 (r=0.517,p=0.978),  time:30.251, tt:3539.324\n",
      "Ep:117, loss:0.00000, loss_test:0.02379, lr:3.19e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.232, tt:3567.324\n",
      "Ep:118, loss:0.00000, loss_test:0.02395, lr:3.15e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.237, tt:3598.203\n",
      "Ep:119, loss:0.00000, loss_test:0.02396, lr:3.12e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.226, tt:3627.110\n",
      "Ep:120, loss:0.00000, loss_test:0.02394, lr:3.09e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.238, tt:3658.765\n",
      "Ep:121, loss:0.00000, loss_test:0.02409, lr:3.06e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.224, tt:3687.336\n",
      "Ep:122, loss:0.00000, loss_test:0.02413, lr:3.03e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.222, tt:3717.266\n",
      "Ep:123, loss:0.00000, loss_test:0.02424, lr:3.00e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.208, tt:3745.808\n",
      "Ep:124, loss:0.00000, loss_test:0.02425, lr:2.97e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.217, tt:3777.170\n",
      "Ep:125, loss:0.00000, loss_test:0.02431, lr:2.94e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.216, tt:3807.197\n",
      "Ep:126, loss:0.00000, loss_test:0.02433, lr:2.91e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.193, tt:3834.464\n",
      "Ep:127, loss:0.00000, loss_test:0.02438, lr:2.88e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.174, tt:3862.274\n",
      "Ep:128, loss:0.00000, loss_test:0.02450, lr:2.85e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.165, tt:3891.225\n",
      "Ep:129, loss:0.00000, loss_test:0.02450, lr:2.82e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.171, tt:3922.220\n",
      "Ep:130, loss:0.00000, loss_test:0.02450, lr:2.80e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.158, tt:3950.664\n",
      "Ep:131, loss:0.00000, loss_test:0.02465, lr:2.77e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.144, tt:3979.032\n",
      "Ep:132, loss:0.00000, loss_test:0.02471, lr:2.74e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.120, tt:4005.964\n",
      "Ep:133, loss:0.00000, loss_test:0.02466, lr:2.71e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.109, tt:4034.663\n",
      "Ep:134, loss:0.00000, loss_test:0.02481, lr:2.69e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.120, tt:4066.193\n",
      "Ep:135, loss:0.00000, loss_test:0.02486, lr:2.66e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.121, tt:4096.392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:136, loss:0.00000, loss_test:0.02486, lr:2.63e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.131, tt:4127.951\n",
      "Ep:137, loss:0.00000, loss_test:0.02491, lr:2.61e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.132, tt:4158.263\n",
      "Ep:138, loss:0.00000, loss_test:0.02501, lr:2.58e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.125, tt:4187.342\n",
      "Ep:139, loss:0.00000, loss_test:0.02504, lr:2.55e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.120, tt:4216.737\n",
      "Ep:140, loss:0.00000, loss_test:0.02508, lr:2.53e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.125, tt:4247.656\n",
      "Ep:141, loss:0.00000, loss_test:0.02513, lr:2.50e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.112, tt:4275.872\n",
      "Ep:142, loss:0.00000, loss_test:0.02522, lr:2.48e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.110, tt:4305.659\n",
      "Ep:143, loss:0.00000, loss_test:0.02517, lr:2.45e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.115, tt:4336.525\n",
      "Ep:144, loss:0.00000, loss_test:0.02527, lr:2.43e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.117, tt:4366.964\n",
      "Ep:145, loss:0.00000, loss_test:0.02535, lr:2.40e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.099, tt:4394.464\n",
      "Ep:146, loss:0.00000, loss_test:0.02537, lr:2.38e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.102, tt:4425.047\n",
      "Ep:147, loss:0.00000, loss_test:0.02543, lr:2.36e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.091, tt:4453.442\n",
      "Ep:148, loss:0.00000, loss_test:0.02553, lr:2.33e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.077, tt:4481.457\n",
      "Ep:149, loss:0.00000, loss_test:0.02547, lr:2.31e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.098, tt:4514.707\n",
      "Ep:150, loss:0.00000, loss_test:0.02549, lr:2.29e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.093, tt:4544.119\n",
      "Ep:151, loss:0.00000, loss_test:0.02566, lr:2.26e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.095, tt:4574.461\n",
      "Ep:152, loss:0.00000, loss_test:0.02571, lr:2.24e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.106, tt:4606.208\n",
      "Ep:153, loss:0.00000, loss_test:0.02563, lr:2.22e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.106, tt:4636.369\n",
      "Ep:154, loss:0.00000, loss_test:0.02568, lr:2.20e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.097, tt:4665.083\n",
      "Ep:155, loss:0.00000, loss_test:0.02591, lr:2.17e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.086, tt:4693.423\n",
      "Ep:156, loss:0.00000, loss_test:0.02587, lr:2.15e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.092, tt:4724.408\n",
      "Ep:157, loss:0.00000, loss_test:0.02578, lr:2.13e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.101, tt:4755.983\n",
      "Ep:158, loss:0.00000, loss_test:0.02589, lr:2.11e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.097, tt:4785.421\n",
      "Ep:159, loss:0.00000, loss_test:0.02594, lr:2.09e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.106, tt:4817.016\n",
      "Ep:160, loss:0.00000, loss_test:0.02595, lr:2.07e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.115, tt:4848.448\n",
      "Ep:161, loss:0.00000, loss_test:0.02591, lr:2.05e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.128, tt:4880.734\n",
      "Ep:162, loss:0.00000, loss_test:0.02610, lr:2.03e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.130, tt:4911.230\n",
      "Ep:163, loss:0.00000, loss_test:0.02612, lr:2.01e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.133, tt:4941.885\n",
      "Ep:164, loss:0.00000, loss_test:0.02608, lr:1.99e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.140, tt:4973.065\n",
      "Ep:165, loss:0.00000, loss_test:0.02612, lr:1.97e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.142, tt:5003.500\n",
      "Ep:166, loss:0.00000, loss_test:0.02623, lr:1.95e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.140, tt:5033.375\n",
      "Ep:167, loss:0.00000, loss_test:0.02622, lr:1.93e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.136, tt:5062.791\n",
      "Ep:168, loss:0.00000, loss_test:0.02624, lr:1.91e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.131, tt:5092.130\n",
      "Ep:169, loss:0.00000, loss_test:0.02628, lr:1.89e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.132, tt:5122.484\n",
      "Ep:170, loss:0.00000, loss_test:0.02629, lr:1.87e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.121, tt:5150.659\n",
      "Ep:171, loss:0.00000, loss_test:0.02631, lr:1.85e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.121, tt:5180.870\n",
      "Ep:172, loss:0.00000, loss_test:0.02638, lr:1.83e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.125, tt:5211.556\n",
      "Ep:173, loss:0.00000, loss_test:0.02643, lr:1.81e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.133, tt:5243.171\n",
      "Ep:174, loss:0.00000, loss_test:0.02641, lr:1.80e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.131, tt:5272.958\n",
      "Ep:175, loss:0.00000, loss_test:0.02646, lr:1.78e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.136, tt:5303.917\n",
      "Ep:176, loss:0.00000, loss_test:0.02654, lr:1.76e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.146, tt:5335.832\n",
      "Ep:177, loss:0.00000, loss_test:0.02651, lr:1.74e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.167, tt:5369.812\n",
      "Ep:178, loss:0.00000, loss_test:0.02653, lr:1.73e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.169, tt:5400.255\n",
      "Ep:179, loss:0.00000, loss_test:0.02657, lr:1.71e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.174, tt:5431.381\n",
      "Ep:180, loss:0.00000, loss_test:0.02661, lr:1.69e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.185, tt:5463.457\n",
      "Ep:181, loss:0.00000, loss_test:0.02664, lr:1.67e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.191, tt:5494.823\n",
      "Ep:182, loss:0.00000, loss_test:0.02662, lr:1.66e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.180, tt:5522.869\n",
      "Ep:183, loss:0.00000, loss_test:0.02663, lr:1.64e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.183, tt:5553.635\n",
      "Ep:184, loss:0.00000, loss_test:0.02669, lr:1.62e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.181, tt:5583.513\n",
      "Ep:185, loss:0.00000, loss_test:0.02674, lr:1.61e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.180, tt:5613.413\n",
      "Ep:186, loss:0.00000, loss_test:0.02676, lr:1.59e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.174, tt:5642.516\n",
      "Ep:187, loss:0.00000, loss_test:0.02675, lr:1.58e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.162, tt:5670.522\n",
      "Ep:188, loss:0.00000, loss_test:0.02679, lr:1.56e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.153, tt:5698.969\n",
      "Ep:189, loss:0.00000, loss_test:0.02682, lr:1.54e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.152, tt:5728.973\n",
      "Ep:190, loss:0.00000, loss_test:0.02685, lr:1.53e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.140, tt:5756.738\n",
      "Ep:191, loss:0.00000, loss_test:0.02688, lr:1.51e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.142, tt:5787.170\n",
      "Ep:192, loss:0.00000, loss_test:0.02693, lr:1.50e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.129, tt:5814.832\n",
      "Ep:193, loss:0.00000, loss_test:0.02691, lr:1.48e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.124, tt:5844.050\n",
      "Ep:194, loss:0.00000, loss_test:0.02697, lr:1.47e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.124, tt:5874.105\n",
      "Ep:195, loss:0.00000, loss_test:0.02700, lr:1.45e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.119, tt:5903.250\n",
      "Ep:196, loss:0.00000, loss_test:0.02701, lr:1.44e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.113, tt:5932.316\n",
      "Ep:197, loss:0.00000, loss_test:0.02702, lr:1.43e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.100, tt:5959.747\n",
      "Ep:198, loss:0.00000, loss_test:0.02700, lr:1.41e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.102, tt:5990.254\n",
      "Ep:199, loss:0.00000, loss_test:0.02704, lr:1.40e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.107, tt:6021.337\n",
      "Ep:200, loss:0.00000, loss_test:0.02711, lr:1.38e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.099, tt:6049.817\n",
      "Ep:201, loss:0.00000, loss_test:0.02711, lr:1.37e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.100, tt:6080.180\n",
      "Ep:202, loss:0.00000, loss_test:0.02713, lr:1.36e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.099, tt:6110.128\n",
      "Ep:203, loss:0.00000, loss_test:0.02715, lr:1.34e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.108, tt:6141.978\n",
      "Ep:204, loss:0.00000, loss_test:0.02717, lr:1.33e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.106, tt:6171.731\n",
      "Ep:205, loss:0.00000, loss_test:0.02719, lr:1.32e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.074, tt:6195.251\n",
      "Ep:206, loss:0.00000, loss_test:0.02722, lr:1.30e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.075, tt:6225.611\n",
      "Ep:207, loss:0.00000, loss_test:0.02721, lr:1.29e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.077, tt:6255.984\n",
      "Ep:208, loss:0.00000, loss_test:0.02726, lr:1.28e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.073, tt:6285.299\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14564, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.746, tt:27.746\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14436, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.295, tt:50.589\n",
      "Ep:2, loss:0.00027, loss_test:0.14176, lr:1.00e-02, fs:0.64062 (r=0.943,p=0.485),  time:25.932, tt:77.797\n",
      "Ep:3, loss:0.00025, loss_test:0.13692, lr:1.00e-02, fs:0.60793 (r=0.793,p=0.493),  time:26.123, tt:104.491\n",
      "Ep:4, loss:0.00023, loss_test:0.13136, lr:1.00e-02, fs:0.57895 (r=0.632,p=0.534),  time:27.157, tt:135.787\n",
      "Ep:5, loss:0.00022, loss_test:0.13094, lr:1.00e-02, fs:0.57143 (r=0.529,p=0.622),  time:27.875, tt:167.250\n",
      "Ep:6, loss:0.00021, loss_test:0.12671, lr:1.00e-02, fs:0.59880 (r=0.575,p=0.625),  time:28.360, tt:198.519\n",
      "Ep:7, loss:0.00021, loss_test:0.12511, lr:1.00e-02, fs:0.60227 (r=0.609,p=0.596),  time:28.861, tt:230.887\n",
      "Ep:8, loss:0.00020, loss_test:0.12431, lr:1.00e-02, fs:0.61446 (r=0.586,p=0.646),  time:29.147, tt:262.322\n",
      "Ep:9, loss:0.00019, loss_test:0.12452, lr:1.00e-02, fs:0.62195 (r=0.586,p=0.662),  time:29.380, tt:293.799\n",
      "Ep:10, loss:0.00018, loss_test:0.11943, lr:1.00e-02, fs:0.67429 (r=0.678,p=0.670),  time:29.644, tt:326.079\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00017, loss_test:0.11710, lr:1.00e-02, fs:0.69663 (r=0.713,p=0.681),  time:29.770, tt:357.236\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00016, loss_test:0.11738, lr:1.00e-02, fs:0.67470 (r=0.644,p=0.709),  time:30.008, tt:390.109\n",
      "Ep:13, loss:0.00016, loss_test:0.11270, lr:1.00e-02, fs:0.70238 (r=0.678,p=0.728),  time:30.099, tt:421.385\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00015, loss_test:0.11007, lr:1.00e-02, fs:0.73988 (r=0.736,p=0.744),  time:30.131, tt:451.962\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00014, loss_test:0.11004, lr:1.00e-02, fs:0.71515 (r=0.678,p=0.756),  time:30.145, tt:482.318\n",
      "Ep:16, loss:0.00014, loss_test:0.10737, lr:1.00e-02, fs:0.75000 (r=0.759,p=0.742),  time:30.296, tt:515.029\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00013, loss_test:0.10605, lr:1.00e-02, fs:0.75000 (r=0.759,p=0.742),  time:30.360, tt:546.477\n",
      "Ep:18, loss:0.00012, loss_test:0.10337, lr:1.00e-02, fs:0.75294 (r=0.736,p=0.771),  time:30.476, tt:579.048\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00012, loss_test:0.10194, lr:1.00e-02, fs:0.75740 (r=0.736,p=0.780),  time:30.584, tt:611.685\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00011, loss_test:0.10064, lr:1.00e-02, fs:0.77108 (r=0.736,p=0.810),  time:30.562, tt:641.793\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00010, loss_test:0.09725, lr:1.00e-02, fs:0.79532 (r=0.782,p=0.810),  time:30.534, tt:671.745\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00010, loss_test:0.09664, lr:1.00e-02, fs:0.76074 (r=0.713,p=0.816),  time:30.563, tt:702.952\n",
      "Ep:23, loss:0.00009, loss_test:0.09471, lr:1.00e-02, fs:0.80952 (r=0.782,p=0.840),  time:30.599, tt:734.369\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00009, loss_test:0.09389, lr:1.00e-02, fs:0.81437 (r=0.782,p=0.850),  time:30.581, tt:764.529\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00008, loss_test:0.09346, lr:1.00e-02, fs:0.80000 (r=0.736,p=0.877),  time:30.626, tt:796.283\n",
      "Ep:26, loss:0.00008, loss_test:0.09202, lr:1.00e-02, fs:0.83636 (r=0.793,p=0.885),  time:30.704, tt:829.014\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00007, loss_test:0.09505, lr:1.00e-02, fs:0.81988 (r=0.759,p=0.892),  time:30.774, tt:861.661\n",
      "Ep:28, loss:0.00007, loss_test:0.09636, lr:1.00e-02, fs:0.79747 (r=0.724,p=0.887),  time:30.759, tt:892.022\n",
      "Ep:29, loss:0.00007, loss_test:0.09209, lr:1.00e-02, fs:0.84146 (r=0.793,p=0.896),  time:30.735, tt:922.046\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00006, loss_test:0.09839, lr:1.00e-02, fs:0.77922 (r=0.690,p=0.896),  time:30.649, tt:950.125\n",
      "Ep:31, loss:0.00006, loss_test:0.09343, lr:1.00e-02, fs:0.81988 (r=0.759,p=0.892),  time:30.687, tt:981.993\n",
      "Ep:32, loss:0.00005, loss_test:0.09085, lr:1.00e-02, fs:0.84848 (r=0.805,p=0.897),  time:30.690, tt:1012.767\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00005, loss_test:0.09247, lr:1.00e-02, fs:0.81988 (r=0.759,p=0.892),  time:30.741, tt:1045.183\n",
      "Ep:34, loss:0.00005, loss_test:0.09317, lr:1.00e-02, fs:0.85366 (r=0.805,p=0.909),  time:30.709, tt:1074.823\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00005, loss_test:0.10107, lr:1.00e-02, fs:0.77922 (r=0.690,p=0.896),  time:30.732, tt:1106.351\n",
      "Ep:36, loss:0.00004, loss_test:0.09302, lr:1.00e-02, fs:0.85366 (r=0.805,p=0.909),  time:30.720, tt:1136.634\n",
      "Ep:37, loss:0.00004, loss_test:0.09353, lr:1.00e-02, fs:0.83951 (r=0.782,p=0.907),  time:30.702, tt:1166.658\n",
      "Ep:38, loss:0.00004, loss_test:0.09574, lr:1.00e-02, fs:0.79221 (r=0.701,p=0.910),  time:30.739, tt:1198.824\n",
      "Ep:39, loss:0.00004, loss_test:0.09163, lr:1.00e-02, fs:0.85890 (r=0.805,p=0.921),  time:30.828, tt:1233.126\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00004, loss_test:0.10033, lr:1.00e-02, fs:0.76000 (r=0.655,p=0.905),  time:30.838, tt:1264.354\n",
      "Ep:41, loss:0.00004, loss_test:0.09230, lr:1.00e-02, fs:0.81529 (r=0.736,p=0.914),  time:30.799, tt:1293.578\n",
      "Ep:42, loss:0.00003, loss_test:0.09195, lr:1.00e-02, fs:0.85890 (r=0.805,p=0.921),  time:30.810, tt:1324.809\n",
      "Ep:43, loss:0.00003, loss_test:0.09905, lr:1.00e-02, fs:0.78947 (r=0.690,p=0.923),  time:30.819, tt:1356.044\n",
      "Ep:44, loss:0.00003, loss_test:0.08954, lr:1.00e-02, fs:0.78710 (r=0.701,p=0.897),  time:30.838, tt:1387.703\n",
      "Ep:45, loss:0.00003, loss_test:0.10101, lr:1.00e-02, fs:0.73973 (r=0.621,p=0.915),  time:30.862, tt:1419.635\n",
      "Ep:46, loss:0.00003, loss_test:0.08941, lr:1.00e-02, fs:0.78431 (r=0.690,p=0.909),  time:30.838, tt:1449.403\n",
      "Ep:47, loss:0.00003, loss_test:0.09878, lr:1.00e-02, fs:0.73611 (r=0.609,p=0.930),  time:30.789, tt:1477.866\n",
      "Ep:48, loss:0.00003, loss_test:0.09407, lr:1.00e-02, fs:0.76821 (r=0.667,p=0.906),  time:30.743, tt:1506.400\n",
      "Ep:49, loss:0.00003, loss_test:0.09587, lr:1.00e-02, fs:0.73103 (r=0.609,p=0.914),  time:30.784, tt:1539.204\n",
      "Ep:50, loss:0.00002, loss_test:0.09269, lr:1.00e-02, fs:0.78431 (r=0.690,p=0.909),  time:30.774, tt:1569.491\n",
      "Ep:51, loss:0.00002, loss_test:0.10716, lr:9.90e-03, fs:0.70073 (r=0.552,p=0.960),  time:30.802, tt:1601.705\n",
      "Ep:52, loss:0.00002, loss_test:0.09005, lr:9.80e-03, fs:0.80769 (r=0.724,p=0.913),  time:30.795, tt:1632.113\n",
      "Ep:53, loss:0.00002, loss_test:0.10718, lr:9.70e-03, fs:0.71533 (r=0.563,p=0.980),  time:30.767, tt:1661.428\n",
      "Ep:54, loss:0.00002, loss_test:0.09205, lr:9.61e-03, fs:0.79739 (r=0.701,p=0.924),  time:30.738, tt:1690.582\n",
      "Ep:55, loss:0.00002, loss_test:0.10589, lr:9.51e-03, fs:0.72059 (r=0.563,p=1.000),  time:30.755, tt:1722.303\n",
      "Ep:56, loss:0.00002, loss_test:0.10199, lr:9.41e-03, fs:0.71429 (r=0.575,p=0.943),  time:30.760, tt:1753.319\n",
      "Ep:57, loss:0.00002, loss_test:0.09393, lr:9.32e-03, fs:0.80795 (r=0.701,p=0.953),  time:30.743, tt:1783.098\n",
      "Ep:58, loss:0.00002, loss_test:0.11214, lr:9.23e-03, fs:0.71111 (r=0.552,p=1.000),  time:30.756, tt:1814.597\n",
      "Ep:59, loss:0.00001, loss_test:0.10111, lr:9.14e-03, fs:0.75000 (r=0.621,p=0.947),  time:30.767, tt:1846.030\n",
      "Ep:60, loss:0.00001, loss_test:0.10372, lr:9.04e-03, fs:0.71533 (r=0.563,p=0.980),  time:30.769, tt:1876.904\n",
      "Ep:61, loss:0.00001, loss_test:0.10405, lr:8.95e-03, fs:0.80537 (r=0.690,p=0.968),  time:30.780, tt:1908.381\n",
      "Ep:62, loss:0.00001, loss_test:0.10125, lr:8.86e-03, fs:0.71533 (r=0.563,p=0.980),  time:30.824, tt:1941.940\n",
      "Ep:63, loss:0.00001, loss_test:0.10417, lr:8.78e-03, fs:0.71014 (r=0.563,p=0.961),  time:30.903, tt:1977.798\n",
      "Ep:64, loss:0.00001, loss_test:0.10453, lr:8.69e-03, fs:0.71533 (r=0.563,p=0.980),  time:30.985, tt:2014.057\n",
      "Ep:65, loss:0.00001, loss_test:0.10405, lr:8.60e-03, fs:0.71111 (r=0.552,p=1.000),  time:31.033, tt:2048.167\n",
      "Ep:66, loss:0.00001, loss_test:0.10571, lr:8.51e-03, fs:0.71533 (r=0.563,p=0.980),  time:31.057, tt:2080.838\n",
      "Ep:67, loss:0.00001, loss_test:0.10383, lr:8.43e-03, fs:0.72059 (r=0.563,p=1.000),  time:31.144, tt:2117.802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:68, loss:0.00001, loss_test:0.10553, lr:8.35e-03, fs:0.71533 (r=0.563,p=0.980),  time:31.223, tt:2154.420\n",
      "Ep:69, loss:0.00001, loss_test:0.10192, lr:8.26e-03, fs:0.71111 (r=0.552,p=1.000),  time:31.270, tt:2188.866\n",
      "Ep:70, loss:0.00001, loss_test:0.10696, lr:8.18e-03, fs:0.71533 (r=0.563,p=0.980),  time:31.336, tt:2224.873\n",
      "Ep:71, loss:0.00001, loss_test:0.10676, lr:8.10e-03, fs:0.72059 (r=0.563,p=1.000),  time:31.401, tt:2260.877\n",
      "Ep:72, loss:0.00001, loss_test:0.10649, lr:8.02e-03, fs:0.72059 (r=0.563,p=1.000),  time:31.463, tt:2296.833\n",
      "Ep:73, loss:0.00001, loss_test:0.10950, lr:7.94e-03, fs:0.72059 (r=0.563,p=1.000),  time:31.536, tt:2333.669\n",
      "Ep:74, loss:0.00001, loss_test:0.10665, lr:7.86e-03, fs:0.72059 (r=0.563,p=1.000),  time:31.606, tt:2370.440\n",
      "Ep:75, loss:0.00001, loss_test:0.11039, lr:7.78e-03, fs:0.72059 (r=0.563,p=1.000),  time:31.657, tt:2405.947\n",
      "Ep:76, loss:0.00001, loss_test:0.10654, lr:7.70e-03, fs:0.72059 (r=0.563,p=1.000),  time:31.695, tt:2440.491\n",
      "Ep:77, loss:0.00001, loss_test:0.11064, lr:7.62e-03, fs:0.72059 (r=0.563,p=1.000),  time:31.714, tt:2473.699\n",
      "Ep:78, loss:0.00000, loss_test:0.10836, lr:7.55e-03, fs:0.72059 (r=0.563,p=1.000),  time:31.755, tt:2508.628\n",
      "Ep:79, loss:0.00000, loss_test:0.10717, lr:7.47e-03, fs:0.72059 (r=0.563,p=1.000),  time:31.834, tt:2546.731\n",
      "Ep:80, loss:0.00000, loss_test:0.10878, lr:7.40e-03, fs:0.72059 (r=0.563,p=1.000),  time:31.898, tt:2583.758\n",
      "Ep:81, loss:0.00000, loss_test:0.10707, lr:7.32e-03, fs:0.72059 (r=0.563,p=1.000),  time:31.941, tt:2619.156\n",
      "Ep:82, loss:0.00000, loss_test:0.10859, lr:7.25e-03, fs:0.72059 (r=0.563,p=1.000),  time:31.999, tt:2655.928\n",
      "Ep:83, loss:0.00000, loss_test:0.10859, lr:7.18e-03, fs:0.72059 (r=0.563,p=1.000),  time:32.059, tt:2692.980\n",
      "Ep:84, loss:0.00000, loss_test:0.10807, lr:7.11e-03, fs:0.72059 (r=0.563,p=1.000),  time:32.142, tt:2732.043\n",
      "Ep:85, loss:0.00000, loss_test:0.10878, lr:7.03e-03, fs:0.72059 (r=0.563,p=1.000),  time:32.184, tt:2767.810\n",
      "Ep:86, loss:0.00000, loss_test:0.10987, lr:6.96e-03, fs:0.72059 (r=0.563,p=1.000),  time:32.219, tt:2803.072\n",
      "Ep:87, loss:0.00000, loss_test:0.10896, lr:6.89e-03, fs:0.72059 (r=0.563,p=1.000),  time:32.261, tt:2838.993\n",
      "Ep:88, loss:0.00000, loss_test:0.10904, lr:6.83e-03, fs:0.72059 (r=0.563,p=1.000),  time:32.299, tt:2874.632\n",
      "Ep:89, loss:0.00000, loss_test:0.10796, lr:6.76e-03, fs:0.72059 (r=0.563,p=1.000),  time:32.337, tt:2910.307\n",
      "Ep:90, loss:0.00000, loss_test:0.11104, lr:6.69e-03, fs:0.71111 (r=0.552,p=1.000),  time:32.386, tt:2947.110\n",
      "Ep:91, loss:0.00000, loss_test:0.10882, lr:6.62e-03, fs:0.72059 (r=0.563,p=1.000),  time:32.418, tt:2982.451\n",
      "Ep:92, loss:0.00000, loss_test:0.10897, lr:6.56e-03, fs:0.72059 (r=0.563,p=1.000),  time:32.460, tt:3018.797\n",
      "Ep:93, loss:0.00000, loss_test:0.10870, lr:6.49e-03, fs:0.72059 (r=0.563,p=1.000),  time:32.483, tt:3053.419\n",
      "Ep:94, loss:0.00000, loss_test:0.10934, lr:6.43e-03, fs:0.72059 (r=0.563,p=1.000),  time:32.508, tt:3088.270\n",
      "Ep:95, loss:0.00000, loss_test:0.10903, lr:6.36e-03, fs:0.72059 (r=0.563,p=1.000),  time:32.545, tt:3124.280\n",
      "Ep:96, loss:0.00000, loss_test:0.10750, lr:6.30e-03, fs:0.72059 (r=0.563,p=1.000),  time:32.566, tt:3158.921\n",
      "Ep:97, loss:0.00000, loss_test:0.11076, lr:6.24e-03, fs:0.72059 (r=0.563,p=1.000),  time:32.590, tt:3193.820\n",
      "Ep:98, loss:0.00000, loss_test:0.10899, lr:6.17e-03, fs:0.72059 (r=0.563,p=1.000),  time:32.647, tt:3232.087\n",
      "Ep:99, loss:0.00000, loss_test:0.10961, lr:6.11e-03, fs:0.72059 (r=0.563,p=1.000),  time:32.728, tt:3272.830\n",
      "Ep:100, loss:0.00000, loss_test:0.11047, lr:6.05e-03, fs:0.72059 (r=0.563,p=1.000),  time:32.742, tt:3306.913\n",
      "Ep:101, loss:0.00000, loss_test:0.10778, lr:5.99e-03, fs:0.72059 (r=0.563,p=1.000),  time:32.767, tt:3342.248\n",
      "Ep:102, loss:0.00000, loss_test:0.11076, lr:5.93e-03, fs:0.72059 (r=0.563,p=1.000),  time:32.790, tt:3377.319\n",
      "Ep:103, loss:0.00000, loss_test:0.10887, lr:5.87e-03, fs:0.72059 (r=0.563,p=1.000),  time:32.817, tt:3412.994\n",
      "Ep:104, loss:0.00000, loss_test:0.10914, lr:5.81e-03, fs:0.72059 (r=0.563,p=1.000),  time:32.845, tt:3448.745\n",
      "Ep:105, loss:0.00000, loss_test:0.10937, lr:5.75e-03, fs:0.71111 (r=0.552,p=1.000),  time:32.874, tt:3484.664\n",
      "Ep:106, loss:0.00000, loss_test:0.10781, lr:5.70e-03, fs:0.72059 (r=0.563,p=1.000),  time:32.914, tt:3521.767\n",
      "Ep:107, loss:0.00000, loss_test:0.11065, lr:5.64e-03, fs:0.71111 (r=0.552,p=1.000),  time:32.924, tt:3555.825\n",
      "Ep:108, loss:0.00000, loss_test:0.10816, lr:5.58e-03, fs:0.71111 (r=0.552,p=1.000),  time:32.960, tt:3592.607\n",
      "Ep:109, loss:0.00000, loss_test:0.10920, lr:5.53e-03, fs:0.72059 (r=0.563,p=1.000),  time:32.995, tt:3629.402\n",
      "Ep:110, loss:0.00000, loss_test:0.11077, lr:5.47e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.023, tt:3665.514\n",
      "Ep:111, loss:0.00000, loss_test:0.10784, lr:5.42e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.047, tt:3701.310\n",
      "Ep:112, loss:0.00000, loss_test:0.11221, lr:5.36e-03, fs:0.71111 (r=0.552,p=1.000),  time:33.107, tt:3741.101\n",
      "Ep:113, loss:0.00000, loss_test:0.10890, lr:5.31e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.143, tt:3778.341\n",
      "Ep:114, loss:0.00000, loss_test:0.10764, lr:5.26e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.189, tt:3816.684\n",
      "Ep:115, loss:0.00000, loss_test:0.11025, lr:5.20e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.214, tt:3852.844\n",
      "Ep:116, loss:0.00000, loss_test:0.10859, lr:5.15e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.209, tt:3885.468\n",
      "Ep:117, loss:0.00000, loss_test:0.10820, lr:5.10e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.252, tt:3923.735\n",
      "Ep:118, loss:0.00000, loss_test:0.10868, lr:5.05e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.283, tt:3960.663\n",
      "Ep:119, loss:0.00000, loss_test:0.10768, lr:5.00e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.293, tt:3995.213\n",
      "Ep:120, loss:0.00000, loss_test:0.10904, lr:4.95e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.331, tt:4033.037\n",
      "Ep:121, loss:0.00000, loss_test:0.10825, lr:4.90e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.356, tt:4069.461\n",
      "Ep:122, loss:0.00000, loss_test:0.10727, lr:4.85e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.393, tt:4107.384\n",
      "Ep:123, loss:0.00000, loss_test:0.11171, lr:4.80e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.400, tt:4141.591\n",
      "Ep:124, loss:0.00000, loss_test:0.11065, lr:4.75e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.402, tt:4175.206\n",
      "Ep:125, loss:0.00000, loss_test:0.10751, lr:4.71e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.421, tt:4211.033\n",
      "Ep:126, loss:0.00000, loss_test:0.10896, lr:4.66e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.424, tt:4244.900\n",
      "Ep:127, loss:0.00000, loss_test:0.10900, lr:4.61e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.446, tt:4281.045\n",
      "Ep:128, loss:0.00000, loss_test:0.10707, lr:4.57e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.460, tt:4316.277\n",
      "Ep:129, loss:0.00000, loss_test:0.10911, lr:4.52e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.491, tt:4353.828\n",
      "Ep:130, loss:0.00000, loss_test:0.10877, lr:4.48e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.509, tt:4389.662\n",
      "Ep:131, loss:0.00000, loss_test:0.10701, lr:4.43e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.527, tt:4425.573\n",
      "Ep:132, loss:0.00000, loss_test:0.10803, lr:4.39e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.552, tt:4462.357\n",
      "Ep:133, loss:0.00000, loss_test:0.10783, lr:4.34e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.570, tt:4498.415\n",
      "Ep:134, loss:0.00000, loss_test:0.10742, lr:4.30e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.595, tt:4535.342\n",
      "Ep:135, loss:0.00000, loss_test:0.10799, lr:4.26e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.622, tt:4572.536\n",
      "Ep:136, loss:0.00000, loss_test:0.10787, lr:4.21e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.679, tt:4613.978\n",
      "Ep:137, loss:0.00000, loss_test:0.10723, lr:4.17e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.691, tt:4649.422\n",
      "Ep:138, loss:0.00000, loss_test:0.10758, lr:4.13e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.717, tt:4686.656\n",
      "Ep:139, loss:0.00000, loss_test:0.10703, lr:4.09e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.736, tt:4722.974\n",
      "Ep:140, loss:0.00000, loss_test:0.10740, lr:4.05e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.755, tt:4759.417\n",
      "Ep:141, loss:0.00000, loss_test:0.10737, lr:4.01e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.763, tt:4794.336\n",
      "Ep:142, loss:0.00000, loss_test:0.10741, lr:3.97e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.762, tt:4827.955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:143, loss:0.00000, loss_test:0.10740, lr:3.93e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.767, tt:4862.513\n",
      "Ep:144, loss:0.00000, loss_test:0.10690, lr:3.89e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.781, tt:4898.273\n",
      "Ep:145, loss:0.00000, loss_test:0.10707, lr:3.85e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.787, tt:4932.951\n",
      "Ep:146, loss:0.00000, loss_test:0.10794, lr:3.81e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.798, tt:4968.245\n",
      "Ep:147, loss:0.00000, loss_test:0.10793, lr:3.77e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.820, tt:5005.291\n",
      "Ep:148, loss:0.00000, loss_test:0.10681, lr:3.73e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.837, tt:5041.638\n",
      "Ep:149, loss:0.00000, loss_test:0.10713, lr:3.70e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.849, tt:5077.355\n",
      "Ep:150, loss:0.00000, loss_test:0.10754, lr:3.66e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.868, tt:5114.043\n",
      "Ep:151, loss:0.00000, loss_test:0.10677, lr:3.62e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.877, tt:5149.314\n",
      "Ep:152, loss:0.00000, loss_test:0.10798, lr:3.59e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.882, tt:5183.926\n",
      "Ep:153, loss:0.00000, loss_test:0.10780, lr:3.55e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.896, tt:5220.049\n",
      "Ep:154, loss:0.00000, loss_test:0.10696, lr:3.52e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.908, tt:5255.672\n",
      "Ep:155, loss:0.00000, loss_test:0.10752, lr:3.48e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.937, tt:5294.175\n",
      "Ep:156, loss:0.00000, loss_test:0.10784, lr:3.45e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.937, tt:5328.081\n",
      "Ep:157, loss:0.00000, loss_test:0.10730, lr:3.41e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.940, tt:5362.534\n",
      "Ep:158, loss:0.00000, loss_test:0.10741, lr:3.38e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.948, tt:5397.805\n",
      "Ep:159, loss:0.00000, loss_test:0.10723, lr:3.34e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.962, tt:5433.998\n",
      "Ep:160, loss:0.00000, loss_test:0.10671, lr:3.31e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.959, tt:5467.349\n",
      "Ep:161, loss:0.00000, loss_test:0.10763, lr:3.28e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.949, tt:5499.728\n",
      "Ep:162, loss:0.00000, loss_test:0.10726, lr:3.24e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.943, tt:5532.691\n",
      "Ep:163, loss:0.00000, loss_test:0.10714, lr:3.21e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.956, tt:5568.798\n",
      "Ep:164, loss:0.00000, loss_test:0.10683, lr:3.18e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.965, tt:5604.299\n",
      "Ep:165, loss:0.00000, loss_test:0.10711, lr:3.15e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.965, tt:5638.251\n",
      "Ep:166, loss:0.00000, loss_test:0.10731, lr:3.12e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.984, tt:5675.383\n",
      "Ep:167, loss:0.00000, loss_test:0.10714, lr:3.09e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.985, tt:5709.397\n",
      "Ep:168, loss:0.00000, loss_test:0.10679, lr:3.05e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.987, tt:5743.853\n",
      "Ep:169, loss:0.00000, loss_test:0.10690, lr:3.02e-03, fs:0.72059 (r=0.563,p=1.000),  time:33.998, tt:5779.731\n",
      "Ep:170, loss:0.00000, loss_test:0.10725, lr:2.99e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.017, tt:5816.931\n",
      "Ep:171, loss:0.00000, loss_test:0.10695, lr:2.96e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.032, tt:5853.517\n",
      "Ep:172, loss:0.00000, loss_test:0.10669, lr:2.93e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.043, tt:5889.400\n",
      "Ep:173, loss:0.00000, loss_test:0.10698, lr:2.90e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.039, tt:5922.778\n",
      "Ep:174, loss:0.00000, loss_test:0.10714, lr:2.88e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.083, tt:5964.577\n",
      "Ep:175, loss:0.00000, loss_test:0.10673, lr:2.85e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.087, tt:5999.305\n",
      "Ep:176, loss:0.00000, loss_test:0.10654, lr:2.82e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.097, tt:6035.104\n",
      "Ep:177, loss:0.00000, loss_test:0.10724, lr:2.79e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.105, tt:6070.776\n",
      "Ep:178, loss:0.00000, loss_test:0.10762, lr:2.76e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.114, tt:6106.494\n",
      "Ep:179, loss:0.00000, loss_test:0.10678, lr:2.73e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.118, tt:6141.192\n",
      "Ep:180, loss:0.00000, loss_test:0.10615, lr:2.71e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.130, tt:6177.463\n",
      "Ep:181, loss:0.00000, loss_test:0.10660, lr:2.68e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.143, tt:6214.044\n",
      "Ep:182, loss:0.00000, loss_test:0.10732, lr:2.65e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.165, tt:6252.207\n",
      "Ep:183, loss:0.00000, loss_test:0.10702, lr:2.63e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.175, tt:6288.156\n",
      "Ep:184, loss:0.00000, loss_test:0.10638, lr:2.60e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.182, tt:6323.763\n",
      "Ep:185, loss:0.00000, loss_test:0.10739, lr:2.57e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.193, tt:6359.971\n",
      "Ep:186, loss:0.00000, loss_test:0.10748, lr:2.55e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.208, tt:6396.937\n",
      "Ep:187, loss:0.00000, loss_test:0.10644, lr:2.52e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.211, tt:6431.585\n",
      "Ep:188, loss:0.00000, loss_test:0.10709, lr:2.50e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.212, tt:6466.145\n",
      "Ep:189, loss:0.00000, loss_test:0.10724, lr:2.47e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.225, tt:6502.665\n",
      "Ep:190, loss:0.00000, loss_test:0.10680, lr:2.45e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.236, tt:6539.136\n",
      "Ep:191, loss:0.00000, loss_test:0.10635, lr:2.42e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.234, tt:6572.838\n",
      "Ep:192, loss:0.00000, loss_test:0.10598, lr:2.40e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.240, tt:6608.385\n",
      "Ep:193, loss:0.00000, loss_test:0.10640, lr:2.38e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.248, tt:6644.151\n",
      "Ep:194, loss:0.00000, loss_test:0.10679, lr:2.35e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.268, tt:6682.258\n",
      "Ep:195, loss:0.00000, loss_test:0.10671, lr:2.33e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.280, tt:6718.853\n",
      "Ep:196, loss:0.00000, loss_test:0.10642, lr:2.31e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.292, tt:6755.439\n",
      "Ep:197, loss:0.00000, loss_test:0.10631, lr:2.28e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.300, tt:6791.378\n",
      "Ep:198, loss:0.00000, loss_test:0.10630, lr:2.26e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.313, tt:6828.207\n",
      "Ep:199, loss:0.00000, loss_test:0.10683, lr:2.24e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.319, tt:6863.776\n",
      "Ep:200, loss:0.00000, loss_test:0.10699, lr:2.21e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.328, tt:6899.865\n",
      "Ep:201, loss:0.00000, loss_test:0.10670, lr:2.19e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.335, tt:6935.751\n",
      "Ep:202, loss:0.00000, loss_test:0.10665, lr:2.17e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.344, tt:6971.857\n",
      "Ep:203, loss:0.00000, loss_test:0.10665, lr:2.15e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.343, tt:7005.928\n",
      "Ep:204, loss:0.00000, loss_test:0.10682, lr:2.13e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.336, tt:7038.920\n",
      "Ep:205, loss:0.00000, loss_test:0.10641, lr:2.11e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.332, tt:7072.430\n",
      "Ep:206, loss:0.00000, loss_test:0.10612, lr:2.08e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.313, tt:7102.860\n",
      "Ep:207, loss:0.00000, loss_test:0.10677, lr:2.06e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.277, tt:7129.559\n",
      "Ep:208, loss:0.00000, loss_test:0.10675, lr:2.04e-03, fs:0.72059 (r=0.563,p=1.000),  time:34.236, tt:7155.303\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,209,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,209,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02083, lr:6.00e-02, fs:0.62882 (r=0.828,p=0.507),  time:26.171, tt:26.171\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02278, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.164, tt:54.328\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02380, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.988, tt:89.965\n",
      "Ep:3, loss:0.00005, loss_test:0.02325, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.409, tt:125.637\n",
      "Ep:4, loss:0.00004, loss_test:0.02185, lr:6.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:32.595, tt:162.976\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02037, lr:6.00e-02, fs:0.65060 (r=0.931,p=0.500),  time:33.274, tt:199.646\n",
      "Ep:6, loss:0.00004, loss_test:0.01979, lr:6.00e-02, fs:0.62673 (r=0.782,p=0.523),  time:34.073, tt:238.512\n",
      "Ep:7, loss:0.00004, loss_test:0.02054, lr:6.00e-02, fs:0.63158 (r=0.690,p=0.583),  time:34.269, tt:274.152\n",
      "Ep:8, loss:0.00004, loss_test:0.02094, lr:6.00e-02, fs:0.63736 (r=0.667,p=0.611),  time:34.602, tt:311.415\n",
      "Ep:9, loss:0.00003, loss_test:0.01984, lr:6.00e-02, fs:0.67016 (r=0.736,p=0.615),  time:34.937, tt:349.366\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01858, lr:6.00e-02, fs:0.70936 (r=0.828,p=0.621),  time:35.038, tt:385.419\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01795, lr:6.00e-02, fs:0.68868 (r=0.839,p=0.584),  time:35.011, tt:420.128\n",
      "Ep:12, loss:0.00003, loss_test:0.01771, lr:6.00e-02, fs:0.69856 (r=0.839,p=0.598),  time:35.091, tt:456.187\n",
      "Ep:13, loss:0.00003, loss_test:0.01784, lr:6.00e-02, fs:0.72000 (r=0.828,p=0.637),  time:35.134, tt:491.875\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01809, lr:6.00e-02, fs:0.72165 (r=0.805,p=0.654),  time:35.107, tt:526.612\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01815, lr:6.00e-02, fs:0.73684 (r=0.805,p=0.680),  time:35.182, tt:562.909\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01787, lr:6.00e-02, fs:0.74468 (r=0.805,p=0.693),  time:35.304, tt:600.170\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01751, lr:6.00e-02, fs:0.74468 (r=0.805,p=0.693),  time:35.416, tt:637.487\n",
      "Ep:18, loss:0.00002, loss_test:0.01715, lr:6.00e-02, fs:0.74468 (r=0.805,p=0.693),  time:35.468, tt:673.900\n",
      "Ep:19, loss:0.00002, loss_test:0.01709, lr:6.00e-02, fs:0.74866 (r=0.805,p=0.700),  time:35.483, tt:709.670\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.01711, lr:6.00e-02, fs:0.73797 (r=0.793,p=0.690),  time:35.652, tt:748.686\n",
      "Ep:21, loss:0.00002, loss_test:0.01721, lr:6.00e-02, fs:0.73913 (r=0.782,p=0.701),  time:35.649, tt:784.281\n",
      "Ep:22, loss:0.00002, loss_test:0.01715, lr:6.00e-02, fs:0.74317 (r=0.782,p=0.708),  time:35.640, tt:819.721\n",
      "Ep:23, loss:0.00002, loss_test:0.01715, lr:6.00e-02, fs:0.74725 (r=0.782,p=0.716),  time:35.675, tt:856.203\n",
      "Ep:24, loss:0.00002, loss_test:0.01721, lr:6.00e-02, fs:0.75556 (r=0.782,p=0.731),  time:35.729, tt:893.220\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01740, lr:6.00e-02, fs:0.75556 (r=0.782,p=0.731),  time:35.776, tt:930.180\n",
      "Ep:26, loss:0.00002, loss_test:0.01746, lr:6.00e-02, fs:0.75978 (r=0.782,p=0.739),  time:35.789, tt:966.291\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01757, lr:6.00e-02, fs:0.75978 (r=0.782,p=0.739),  time:35.763, tt:1001.355\n",
      "Ep:28, loss:0.00002, loss_test:0.01764, lr:6.00e-02, fs:0.75706 (r=0.770,p=0.744),  time:35.811, tt:1038.522\n",
      "Ep:29, loss:0.00002, loss_test:0.01765, lr:6.00e-02, fs:0.76136 (r=0.770,p=0.753),  time:35.837, tt:1075.112\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00001, loss_test:0.01770, lr:6.00e-02, fs:0.76571 (r=0.770,p=0.761),  time:35.845, tt:1111.186\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00001, loss_test:0.01789, lr:6.00e-02, fs:0.76571 (r=0.770,p=0.761),  time:35.832, tt:1146.618\n",
      "Ep:32, loss:0.00001, loss_test:0.01808, lr:6.00e-02, fs:0.75862 (r=0.759,p=0.759),  time:35.857, tt:1183.297\n",
      "Ep:33, loss:0.00001, loss_test:0.01829, lr:6.00e-02, fs:0.76301 (r=0.759,p=0.767),  time:35.851, tt:1218.925\n",
      "Ep:34, loss:0.00001, loss_test:0.01857, lr:6.00e-02, fs:0.76744 (r=0.759,p=0.776),  time:35.875, tt:1255.621\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00001, loss_test:0.01882, lr:6.00e-02, fs:0.77193 (r=0.759,p=0.786),  time:35.839, tt:1290.215\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00001, loss_test:0.01913, lr:6.00e-02, fs:0.78571 (r=0.759,p=0.815),  time:35.846, tt:1326.307\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00001, loss_test:0.01934, lr:6.00e-02, fs:0.78571 (r=0.759,p=0.815),  time:35.863, tt:1362.790\n",
      "Ep:38, loss:0.00001, loss_test:0.01947, lr:6.00e-02, fs:0.79042 (r=0.759,p=0.825),  time:35.886, tt:1399.558\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00001, loss_test:0.01967, lr:6.00e-02, fs:0.79518 (r=0.759,p=0.835),  time:35.935, tt:1437.387\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00001, loss_test:0.01990, lr:6.00e-02, fs:0.79518 (r=0.759,p=0.835),  time:35.952, tt:1474.037\n",
      "Ep:41, loss:0.00001, loss_test:0.02006, lr:6.00e-02, fs:0.80000 (r=0.759,p=0.846),  time:35.975, tt:1510.940\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00001, loss_test:0.02042, lr:6.00e-02, fs:0.80000 (r=0.759,p=0.846),  time:36.000, tt:1547.984\n",
      "Ep:43, loss:0.00001, loss_test:0.02053, lr:6.00e-02, fs:0.80982 (r=0.759,p=0.868),  time:36.073, tt:1587.191\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00001, loss_test:0.02091, lr:6.00e-02, fs:0.81481 (r=0.759,p=0.880),  time:36.102, tt:1624.611\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.02127, lr:6.00e-02, fs:0.81481 (r=0.759,p=0.880),  time:36.124, tt:1661.706\n",
      "Ep:46, loss:0.00001, loss_test:0.02167, lr:6.00e-02, fs:0.81761 (r=0.747,p=0.903),  time:36.168, tt:1699.873\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.02192, lr:6.00e-02, fs:0.81761 (r=0.747,p=0.903),  time:36.199, tt:1737.547\n",
      "Ep:48, loss:0.00001, loss_test:0.02222, lr:6.00e-02, fs:0.81013 (r=0.736,p=0.901),  time:36.198, tt:1773.705\n",
      "Ep:49, loss:0.00001, loss_test:0.02261, lr:6.00e-02, fs:0.82051 (r=0.736,p=0.928),  time:36.205, tt:1810.253\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.02286, lr:6.00e-02, fs:0.82581 (r=0.736,p=0.941),  time:36.211, tt:1846.760\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.02313, lr:6.00e-02, fs:0.82581 (r=0.736,p=0.941),  time:36.226, tt:1883.776\n",
      "Ep:52, loss:0.00001, loss_test:0.02345, lr:6.00e-02, fs:0.82581 (r=0.736,p=0.941),  time:36.219, tt:1919.623\n",
      "Ep:53, loss:0.00001, loss_test:0.02374, lr:6.00e-02, fs:0.82581 (r=0.736,p=0.941),  time:36.229, tt:1956.344\n",
      "Ep:54, loss:0.00001, loss_test:0.02408, lr:6.00e-02, fs:0.82581 (r=0.736,p=0.941),  time:36.229, tt:1992.570\n",
      "Ep:55, loss:0.00001, loss_test:0.02442, lr:6.00e-02, fs:0.83117 (r=0.736,p=0.955),  time:36.252, tt:2030.085\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.02474, lr:6.00e-02, fs:0.83117 (r=0.736,p=0.955),  time:36.285, tt:2068.243\n",
      "Ep:57, loss:0.00001, loss_test:0.02497, lr:6.00e-02, fs:0.83117 (r=0.736,p=0.955),  time:36.285, tt:2104.514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00000, loss_test:0.02522, lr:6.00e-02, fs:0.83117 (r=0.736,p=0.955),  time:36.300, tt:2141.714\n",
      "Ep:59, loss:0.00000, loss_test:0.02556, lr:6.00e-02, fs:0.83117 (r=0.736,p=0.955),  time:36.343, tt:2180.597\n",
      "Ep:60, loss:0.00000, loss_test:0.02594, lr:6.00e-02, fs:0.83117 (r=0.736,p=0.955),  time:36.361, tt:2218.001\n",
      "Ep:61, loss:0.00000, loss_test:0.02617, lr:6.00e-02, fs:0.82353 (r=0.724,p=0.955),  time:36.346, tt:2253.458\n",
      "Ep:62, loss:0.00000, loss_test:0.02632, lr:6.00e-02, fs:0.82353 (r=0.724,p=0.955),  time:36.513, tt:2300.307\n",
      "Ep:63, loss:0.00000, loss_test:0.02658, lr:6.00e-02, fs:0.82353 (r=0.724,p=0.955),  time:36.492, tt:2335.494\n",
      "Ep:64, loss:0.00000, loss_test:0.02687, lr:6.00e-02, fs:0.81579 (r=0.713,p=0.954),  time:36.484, tt:2371.429\n",
      "Ep:65, loss:0.00000, loss_test:0.02722, lr:6.00e-02, fs:0.81579 (r=0.713,p=0.954),  time:36.498, tt:2408.896\n",
      "Ep:66, loss:0.00000, loss_test:0.02738, lr:6.00e-02, fs:0.81579 (r=0.713,p=0.954),  time:36.496, tt:2445.228\n",
      "Ep:67, loss:0.00000, loss_test:0.02762, lr:5.94e-02, fs:0.81579 (r=0.713,p=0.954),  time:36.501, tt:2482.050\n",
      "Ep:68, loss:0.00000, loss_test:0.02783, lr:5.88e-02, fs:0.81579 (r=0.713,p=0.954),  time:36.509, tt:2519.130\n",
      "Ep:69, loss:0.00000, loss_test:0.02807, lr:5.82e-02, fs:0.82119 (r=0.713,p=0.969),  time:36.517, tt:2556.168\n",
      "Ep:70, loss:0.00000, loss_test:0.02825, lr:5.76e-02, fs:0.82119 (r=0.713,p=0.969),  time:36.549, tt:2594.979\n",
      "Ep:71, loss:0.00000, loss_test:0.02849, lr:5.71e-02, fs:0.82119 (r=0.713,p=0.969),  time:36.534, tt:2630.433\n",
      "Ep:72, loss:0.00000, loss_test:0.02866, lr:5.65e-02, fs:0.82119 (r=0.713,p=0.969),  time:36.549, tt:2668.076\n",
      "Ep:73, loss:0.00000, loss_test:0.02890, lr:5.59e-02, fs:0.82667 (r=0.713,p=0.984),  time:36.565, tt:2705.799\n",
      "Ep:74, loss:0.00000, loss_test:0.02907, lr:5.54e-02, fs:0.82667 (r=0.713,p=0.984),  time:36.579, tt:2743.459\n",
      "Ep:75, loss:0.00000, loss_test:0.02917, lr:5.48e-02, fs:0.82667 (r=0.713,p=0.984),  time:36.574, tt:2779.630\n",
      "Ep:76, loss:0.00000, loss_test:0.02943, lr:5.43e-02, fs:0.81081 (r=0.690,p=0.984),  time:36.564, tt:2815.406\n",
      "Ep:77, loss:0.00000, loss_test:0.02962, lr:5.37e-02, fs:0.82667 (r=0.713,p=0.984),  time:36.569, tt:2852.373\n",
      "Ep:78, loss:0.00000, loss_test:0.02965, lr:5.32e-02, fs:0.81081 (r=0.690,p=0.984),  time:36.592, tt:2890.756\n",
      "Ep:79, loss:0.00000, loss_test:0.02990, lr:5.27e-02, fs:0.81081 (r=0.690,p=0.984),  time:36.615, tt:2929.238\n",
      "Ep:80, loss:0.00000, loss_test:0.03010, lr:5.21e-02, fs:0.81081 (r=0.690,p=0.984),  time:36.633, tt:2967.242\n",
      "Ep:81, loss:0.00000, loss_test:0.03022, lr:5.16e-02, fs:0.81081 (r=0.690,p=0.984),  time:36.635, tt:3004.093\n",
      "Ep:82, loss:0.00000, loss_test:0.03050, lr:5.11e-02, fs:0.81081 (r=0.690,p=0.984),  time:36.632, tt:3040.464\n",
      "Ep:83, loss:0.00000, loss_test:0.03044, lr:5.06e-02, fs:0.80272 (r=0.678,p=0.983),  time:36.631, tt:3077.027\n",
      "Ep:84, loss:0.00000, loss_test:0.03065, lr:5.01e-02, fs:0.80272 (r=0.678,p=0.983),  time:36.657, tt:3115.854\n",
      "Ep:85, loss:0.00000, loss_test:0.03073, lr:4.96e-02, fs:0.80272 (r=0.678,p=0.983),  time:36.666, tt:3153.265\n",
      "Ep:86, loss:0.00000, loss_test:0.03087, lr:4.91e-02, fs:0.80272 (r=0.678,p=0.983),  time:36.675, tt:3190.698\n",
      "Ep:87, loss:0.00000, loss_test:0.03096, lr:4.86e-02, fs:0.80272 (r=0.678,p=0.983),  time:36.688, tt:3228.541\n",
      "Ep:88, loss:0.00000, loss_test:0.03110, lr:4.81e-02, fs:0.78621 (r=0.655,p=0.983),  time:36.693, tt:3265.714\n",
      "Ep:89, loss:0.00000, loss_test:0.03123, lr:4.76e-02, fs:0.78621 (r=0.655,p=0.983),  time:36.682, tt:3301.358\n",
      "Ep:90, loss:0.00000, loss_test:0.03134, lr:4.71e-02, fs:0.78621 (r=0.655,p=0.983),  time:36.676, tt:3337.501\n",
      "Ep:91, loss:0.00000, loss_test:0.03152, lr:4.67e-02, fs:0.76923 (r=0.632,p=0.982),  time:36.664, tt:3373.123\n",
      "Ep:92, loss:0.00000, loss_test:0.03157, lr:4.62e-02, fs:0.78621 (r=0.655,p=0.983),  time:36.666, tt:3409.938\n",
      "Ep:93, loss:0.00000, loss_test:0.03163, lr:4.57e-02, fs:0.77778 (r=0.644,p=0.982),  time:36.671, tt:3447.058\n",
      "Ep:94, loss:0.00000, loss_test:0.03180, lr:4.53e-02, fs:0.76056 (r=0.621,p=0.982),  time:36.687, tt:3485.270\n",
      "Ep:95, loss:0.00000, loss_test:0.03195, lr:4.48e-02, fs:0.73381 (r=0.586,p=0.981),  time:36.687, tt:3521.910\n",
      "Ep:96, loss:0.00000, loss_test:0.03198, lr:4.44e-02, fs:0.76056 (r=0.621,p=0.982),  time:36.679, tt:3557.853\n",
      "Ep:97, loss:0.00000, loss_test:0.03214, lr:4.39e-02, fs:0.73381 (r=0.586,p=0.981),  time:36.679, tt:3594.584\n",
      "Ep:98, loss:0.00000, loss_test:0.03220, lr:4.35e-02, fs:0.75177 (r=0.609,p=0.981),  time:36.668, tt:3630.139\n",
      "Ep:99, loss:0.00000, loss_test:0.03223, lr:4.31e-02, fs:0.73381 (r=0.586,p=0.981),  time:36.649, tt:3664.932\n",
      "Ep:100, loss:0.00000, loss_test:0.03234, lr:4.26e-02, fs:0.72464 (r=0.575,p=0.980),  time:36.633, tt:3699.960\n",
      "Ep:101, loss:0.00000, loss_test:0.03245, lr:4.22e-02, fs:0.70588 (r=0.552,p=0.980),  time:36.622, tt:3735.415\n",
      "Ep:102, loss:0.00000, loss_test:0.03256, lr:4.18e-02, fs:0.69630 (r=0.540,p=0.979),  time:36.613, tt:3771.138\n",
      "Ep:103, loss:0.00000, loss_test:0.03268, lr:4.14e-02, fs:0.69630 (r=0.540,p=0.979),  time:36.594, tt:3805.801\n",
      "Ep:104, loss:0.00000, loss_test:0.03275, lr:4.10e-02, fs:0.69630 (r=0.540,p=0.979),  time:36.597, tt:3842.713\n",
      "Ep:105, loss:0.00000, loss_test:0.03270, lr:4.05e-02, fs:0.69630 (r=0.540,p=0.979),  time:36.601, tt:3879.709\n",
      "Ep:106, loss:0.00000, loss_test:0.03280, lr:4.01e-02, fs:0.69630 (r=0.540,p=0.979),  time:36.567, tt:3912.645\n",
      "Ep:107, loss:0.00000, loss_test:0.03290, lr:3.97e-02, fs:0.68657 (r=0.529,p=0.979),  time:36.536, tt:3945.876\n",
      "Ep:108, loss:0.00000, loss_test:0.03295, lr:3.93e-02, fs:0.68657 (r=0.529,p=0.979),  time:36.469, tt:3975.110\n",
      "Ep:109, loss:0.00000, loss_test:0.03308, lr:3.89e-02, fs:0.68657 (r=0.529,p=0.979),  time:36.424, tt:4006.629\n",
      "Ep:110, loss:0.00000, loss_test:0.03319, lr:3.86e-02, fs:0.68657 (r=0.529,p=0.979),  time:36.371, tt:4037.169\n",
      "Ep:111, loss:0.00000, loss_test:0.03321, lr:3.82e-02, fs:0.68657 (r=0.529,p=0.979),  time:36.320, tt:4067.832\n",
      "Ep:112, loss:0.00000, loss_test:0.03328, lr:3.78e-02, fs:0.68657 (r=0.529,p=0.979),  time:36.270, tt:4098.474\n",
      "Ep:113, loss:0.00000, loss_test:0.03335, lr:3.74e-02, fs:0.68657 (r=0.529,p=0.979),  time:36.224, tt:4129.567\n",
      "Ep:114, loss:0.00000, loss_test:0.03341, lr:3.70e-02, fs:0.68657 (r=0.529,p=0.979),  time:36.282, tt:4172.386\n",
      "Ep:115, loss:0.00000, loss_test:0.03344, lr:3.67e-02, fs:0.68657 (r=0.529,p=0.979),  time:36.274, tt:4207.826\n",
      "Ep:116, loss:0.00000, loss_test:0.03351, lr:3.63e-02, fs:0.68657 (r=0.529,p=0.979),  time:36.262, tt:4242.662\n",
      "Ep:117, loss:0.00000, loss_test:0.03361, lr:3.59e-02, fs:0.68657 (r=0.529,p=0.979),  time:36.275, tt:4280.450\n",
      "Ep:118, loss:0.00000, loss_test:0.03363, lr:3.56e-02, fs:0.68657 (r=0.529,p=0.979),  time:36.285, tt:4317.892\n",
      "Ep:119, loss:0.00000, loss_test:0.03367, lr:3.52e-02, fs:0.68657 (r=0.529,p=0.979),  time:36.286, tt:4354.300\n",
      "Ep:120, loss:0.00000, loss_test:0.03375, lr:3.49e-02, fs:0.68657 (r=0.529,p=0.979),  time:36.263, tt:4387.867\n",
      "Ep:121, loss:0.00000, loss_test:0.03378, lr:3.45e-02, fs:0.68657 (r=0.529,p=0.979),  time:36.247, tt:4422.159\n",
      "Ep:122, loss:0.00000, loss_test:0.03382, lr:3.42e-02, fs:0.68657 (r=0.529,p=0.979),  time:36.236, tt:4457.073\n",
      "Ep:123, loss:0.00000, loss_test:0.03395, lr:3.38e-02, fs:0.68657 (r=0.529,p=0.979),  time:36.245, tt:4494.337\n",
      "Ep:124, loss:0.00000, loss_test:0.03397, lr:3.35e-02, fs:0.68657 (r=0.529,p=0.979),  time:36.243, tt:4530.374\n",
      "Ep:125, loss:0.00000, loss_test:0.03396, lr:3.32e-02, fs:0.68657 (r=0.529,p=0.979),  time:36.236, tt:4565.693\n",
      "Ep:126, loss:0.00000, loss_test:0.03399, lr:3.28e-02, fs:0.68657 (r=0.529,p=0.979),  time:36.236, tt:4601.920\n",
      "Ep:127, loss:0.00000, loss_test:0.03412, lr:3.25e-02, fs:0.68657 (r=0.529,p=0.979),  time:36.236, tt:4638.214\n",
      "Ep:128, loss:0.00000, loss_test:0.03414, lr:3.22e-02, fs:0.68657 (r=0.529,p=0.979),  time:36.227, tt:4673.339\n",
      "Ep:129, loss:0.00000, loss_test:0.03416, lr:3.19e-02, fs:0.68657 (r=0.529,p=0.979),  time:36.227, tt:4709.553\n",
      "Ep:130, loss:0.00000, loss_test:0.03431, lr:3.15e-02, fs:0.68657 (r=0.529,p=0.979),  time:36.221, tt:4745.001\n",
      "Ep:131, loss:0.00000, loss_test:0.03428, lr:3.12e-02, fs:0.68657 (r=0.529,p=0.979),  time:36.212, tt:4780.041\n",
      "Ep:132, loss:0.00000, loss_test:0.03428, lr:3.09e-02, fs:0.68657 (r=0.529,p=0.979),  time:36.211, tt:4816.121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00000, loss_test:0.03438, lr:3.06e-02, fs:0.68182 (r=0.517,p=1.000),  time:36.213, tt:4852.608\n",
      "Ep:134, loss:0.00000, loss_test:0.03440, lr:3.03e-02, fs:0.67669 (r=0.517,p=0.978),  time:36.220, tt:4889.643\n",
      "Ep:135, loss:0.00000, loss_test:0.03444, lr:3.00e-02, fs:0.67669 (r=0.517,p=0.978),  time:36.229, tt:4927.139\n",
      "Ep:136, loss:0.00000, loss_test:0.03449, lr:2.97e-02, fs:0.68182 (r=0.517,p=1.000),  time:36.227, tt:4963.160\n",
      "Ep:137, loss:0.00000, loss_test:0.03455, lr:2.94e-02, fs:0.68182 (r=0.517,p=1.000),  time:36.239, tt:5000.932\n",
      "Ep:138, loss:0.00000, loss_test:0.03456, lr:2.91e-02, fs:0.68182 (r=0.517,p=1.000),  time:36.304, tt:5046.223\n",
      "Ep:139, loss:0.00000, loss_test:0.03459, lr:2.88e-02, fs:0.68182 (r=0.517,p=1.000),  time:36.306, tt:5082.867\n",
      "Ep:140, loss:0.00000, loss_test:0.03459, lr:2.85e-02, fs:0.68182 (r=0.517,p=1.000),  time:36.304, tt:5118.878\n",
      "Ep:141, loss:0.00000, loss_test:0.03463, lr:2.82e-02, fs:0.68182 (r=0.517,p=1.000),  time:36.310, tt:5155.993\n",
      "Ep:142, loss:0.00000, loss_test:0.03467, lr:2.80e-02, fs:0.68182 (r=0.517,p=1.000),  time:36.345, tt:5197.310\n",
      "Ep:143, loss:0.00000, loss_test:0.03473, lr:2.77e-02, fs:0.68182 (r=0.517,p=1.000),  time:36.361, tt:5235.977\n",
      "Ep:144, loss:0.00000, loss_test:0.03470, lr:2.74e-02, fs:0.68182 (r=0.517,p=1.000),  time:36.366, tt:5273.020\n",
      "Ep:145, loss:0.00000, loss_test:0.03478, lr:2.71e-02, fs:0.68182 (r=0.517,p=1.000),  time:36.365, tt:5309.351\n",
      "Ep:146, loss:0.00000, loss_test:0.03478, lr:2.69e-02, fs:0.68182 (r=0.517,p=1.000),  time:36.377, tt:5347.422\n",
      "Ep:147, loss:0.00000, loss_test:0.03480, lr:2.66e-02, fs:0.68182 (r=0.517,p=1.000),  time:36.375, tt:5383.541\n",
      "Ep:148, loss:0.00000, loss_test:0.03486, lr:2.63e-02, fs:0.68182 (r=0.517,p=1.000),  time:36.356, tt:5416.992\n",
      "Ep:149, loss:0.00000, loss_test:0.03493, lr:2.61e-02, fs:0.68182 (r=0.517,p=1.000),  time:36.350, tt:5452.522\n",
      "Ep:150, loss:0.00000, loss_test:0.03492, lr:2.58e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.338, tt:5487.007\n",
      "Ep:151, loss:0.00000, loss_test:0.03493, lr:2.55e-02, fs:0.68182 (r=0.517,p=1.000),  time:36.336, tt:5523.031\n",
      "Ep:152, loss:0.00000, loss_test:0.03497, lr:2.53e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.337, tt:5559.630\n",
      "Ep:153, loss:0.00000, loss_test:0.03499, lr:2.50e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.331, tt:5594.931\n",
      "Ep:154, loss:0.00000, loss_test:0.03504, lr:2.48e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.332, tt:5631.390\n",
      "Ep:155, loss:0.00000, loss_test:0.03505, lr:2.45e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.328, tt:5667.169\n",
      "Ep:156, loss:0.00000, loss_test:0.03508, lr:2.43e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.327, tt:5703.280\n",
      "Ep:157, loss:0.00000, loss_test:0.03511, lr:2.40e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.305, tt:5736.267\n",
      "Ep:158, loss:0.00000, loss_test:0.03515, lr:2.38e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.301, tt:5771.850\n",
      "Ep:159, loss:0.00000, loss_test:0.03518, lr:2.36e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.288, tt:5806.133\n",
      "Ep:160, loss:0.00000, loss_test:0.03523, lr:2.33e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.298, tt:5843.945\n",
      "Ep:161, loss:0.00000, loss_test:0.03522, lr:2.31e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.299, tt:5880.404\n",
      "Ep:162, loss:0.00000, loss_test:0.03526, lr:2.29e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.298, tt:5916.540\n",
      "Ep:163, loss:0.00000, loss_test:0.03533, lr:2.26e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.301, tt:5953.444\n",
      "Ep:164, loss:0.00000, loss_test:0.03537, lr:2.24e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.296, tt:5988.876\n",
      "Ep:165, loss:0.00000, loss_test:0.03538, lr:2.22e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.290, tt:6024.167\n",
      "Ep:166, loss:0.00000, loss_test:0.03539, lr:2.20e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.290, tt:6060.379\n",
      "Ep:167, loss:0.00000, loss_test:0.03543, lr:2.17e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.284, tt:6095.692\n",
      "Ep:168, loss:0.00000, loss_test:0.03546, lr:2.15e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.294, tt:6133.654\n",
      "Ep:169, loss:0.00000, loss_test:0.03547, lr:2.13e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.286, tt:6168.639\n",
      "Ep:170, loss:0.00000, loss_test:0.03549, lr:2.11e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.295, tt:6206.486\n",
      "Ep:171, loss:0.00000, loss_test:0.03551, lr:2.09e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.297, tt:6243.009\n",
      "Ep:172, loss:0.00000, loss_test:0.03549, lr:2.07e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.292, tt:6278.492\n",
      "Ep:173, loss:0.00000, loss_test:0.03554, lr:2.05e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.292, tt:6314.891\n",
      "Ep:174, loss:0.00000, loss_test:0.03556, lr:2.03e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.296, tt:6351.758\n",
      "Ep:175, loss:0.00000, loss_test:0.03558, lr:2.01e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.295, tt:6387.973\n",
      "Ep:176, loss:0.00000, loss_test:0.03561, lr:1.99e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.296, tt:6424.375\n",
      "Ep:177, loss:0.00000, loss_test:0.03561, lr:1.97e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.294, tt:6460.317\n",
      "Ep:178, loss:0.00000, loss_test:0.03562, lr:1.95e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.293, tt:6496.448\n",
      "Ep:179, loss:0.00000, loss_test:0.03565, lr:1.93e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.299, tt:6533.897\n",
      "Ep:180, loss:0.00000, loss_test:0.03567, lr:1.91e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.285, tt:6567.495\n",
      "Ep:181, loss:0.00000, loss_test:0.03567, lr:1.89e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.281, tt:6603.054\n",
      "Ep:182, loss:0.00000, loss_test:0.03569, lr:1.87e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.265, tt:6636.493\n",
      "Ep:183, loss:0.00000, loss_test:0.03572, lr:1.85e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.256, tt:6671.031\n",
      "Ep:184, loss:0.00000, loss_test:0.03573, lr:1.83e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.253, tt:6706.803\n",
      "Ep:185, loss:0.00000, loss_test:0.03576, lr:1.81e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.252, tt:6742.953\n",
      "Ep:186, loss:0.00000, loss_test:0.03577, lr:1.80e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.246, tt:6778.085\n",
      "Ep:187, loss:0.00000, loss_test:0.03576, lr:1.78e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.246, tt:6814.334\n",
      "Ep:188, loss:0.00000, loss_test:0.03580, lr:1.76e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.246, tt:6850.575\n",
      "Ep:189, loss:0.00000, loss_test:0.03582, lr:1.74e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.267, tt:6890.790\n",
      "Ep:190, loss:0.00000, loss_test:0.03584, lr:1.73e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.264, tt:6926.368\n",
      "Ep:191, loss:0.00000, loss_test:0.03585, lr:1.71e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.266, tt:6963.065\n",
      "Ep:192, loss:0.00000, loss_test:0.03585, lr:1.69e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.269, tt:6999.824\n",
      "Ep:193, loss:0.00000, loss_test:0.03588, lr:1.67e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.262, tt:7034.760\n",
      "Ep:194, loss:0.00000, loss_test:0.03592, lr:1.66e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.259, tt:7070.450\n",
      "Ep:195, loss:0.00000, loss_test:0.03591, lr:1.64e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.253, tt:7105.545\n",
      "Ep:196, loss:0.00000, loss_test:0.03591, lr:1.62e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.244, tt:7140.036\n",
      "Ep:197, loss:0.00000, loss_test:0.03594, lr:1.61e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.240, tt:7175.512\n",
      "Ep:198, loss:0.00000, loss_test:0.03597, lr:1.59e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.241, tt:7212.039\n",
      "Ep:199, loss:0.00000, loss_test:0.03597, lr:1.58e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.223, tt:7244.604\n",
      "Ep:200, loss:0.00000, loss_test:0.03600, lr:1.56e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.222, tt:7280.548\n",
      "Ep:201, loss:0.00000, loss_test:0.03601, lr:1.54e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.218, tt:7316.036\n",
      "Ep:202, loss:0.00000, loss_test:0.03604, lr:1.53e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.221, tt:7352.785\n",
      "Ep:203, loss:0.00000, loss_test:0.03604, lr:1.51e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.224, tt:7389.596\n",
      "Ep:204, loss:0.00000, loss_test:0.03603, lr:1.50e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.222, tt:7425.511\n",
      "Ep:205, loss:0.00000, loss_test:0.03606, lr:1.48e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.208, tt:7458.791\n",
      "Ep:206, loss:0.00000, loss_test:0.03607, lr:1.47e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.200, tt:7493.488\n",
      "Ep:207, loss:0.00000, loss_test:0.03608, lr:1.45e-02, fs:0.67176 (r=0.506,p=1.000),  time:36.209, tt:7531.535\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14423, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.865, tt:31.865\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14297, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.429, tt:66.857\n",
      "Ep:2, loss:0.00027, loss_test:0.14067, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.145, tt:99.434\n",
      "Ep:3, loss:0.00027, loss_test:0.13659, lr:1.00e-02, fs:0.66667 (r=0.989,p=0.503),  time:34.260, tt:137.042\n",
      "Ep:4, loss:0.00026, loss_test:0.12926, lr:1.00e-02, fs:0.64730 (r=0.897,p=0.506),  time:34.429, tt:172.144\n",
      "Ep:5, loss:0.00024, loss_test:0.11889, lr:1.00e-02, fs:0.65574 (r=0.690,p=0.625),  time:34.611, tt:207.663\n",
      "Ep:6, loss:0.00022, loss_test:0.11627, lr:1.00e-02, fs:0.62577 (r=0.586,p=0.671),  time:34.721, tt:243.048\n",
      "Ep:7, loss:0.00021, loss_test:0.11158, lr:1.00e-02, fs:0.65169 (r=0.667,p=0.637),  time:34.797, tt:278.375\n",
      "Ep:8, loss:0.00021, loss_test:0.11084, lr:1.00e-02, fs:0.65641 (r=0.736,p=0.593),  time:35.092, tt:315.825\n",
      "Ep:9, loss:0.00020, loss_test:0.10620, lr:1.00e-02, fs:0.68235 (r=0.667,p=0.699),  time:35.176, tt:351.760\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00019, loss_test:0.10671, lr:1.00e-02, fs:0.67081 (r=0.621,p=0.730),  time:35.332, tt:388.656\n",
      "Ep:11, loss:0.00018, loss_test:0.10158, lr:1.00e-02, fs:0.69364 (r=0.690,p=0.698),  time:35.483, tt:425.800\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00017, loss_test:0.09993, lr:1.00e-02, fs:0.71823 (r=0.747,p=0.691),  time:35.579, tt:462.522\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00017, loss_test:0.10011, lr:1.00e-02, fs:0.72189 (r=0.701,p=0.744),  time:35.818, tt:501.455\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00016, loss_test:0.09910, lr:1.00e-02, fs:0.73054 (r=0.701,p=0.762),  time:35.757, tt:536.348\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00015, loss_test:0.09697, lr:1.00e-02, fs:0.73143 (r=0.736,p=0.727),  time:35.732, tt:571.715\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.09561, lr:1.00e-02, fs:0.72832 (r=0.724,p=0.733),  time:35.830, tt:609.110\n",
      "Ep:17, loss:0.00014, loss_test:0.09580, lr:1.00e-02, fs:0.74251 (r=0.713,p=0.775),  time:35.707, tt:642.719\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00013, loss_test:0.09411, lr:1.00e-02, fs:0.73988 (r=0.736,p=0.744),  time:35.829, tt:680.746\n",
      "Ep:19, loss:0.00013, loss_test:0.09319, lr:1.00e-02, fs:0.73988 (r=0.736,p=0.744),  time:35.908, tt:718.165\n",
      "Ep:20, loss:0.00012, loss_test:0.09390, lr:1.00e-02, fs:0.76923 (r=0.747,p=0.793),  time:35.924, tt:754.400\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00012, loss_test:0.09310, lr:1.00e-02, fs:0.76923 (r=0.747,p=0.793),  time:35.895, tt:789.691\n",
      "Ep:22, loss:0.00011, loss_test:0.09245, lr:1.00e-02, fs:0.77844 (r=0.747,p=0.812),  time:35.902, tt:825.752\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00010, loss_test:0.08948, lr:1.00e-02, fs:0.77381 (r=0.747,p=0.802),  time:35.811, tt:859.459\n",
      "Ep:24, loss:0.00010, loss_test:0.09134, lr:1.00e-02, fs:0.79503 (r=0.736,p=0.865),  time:35.726, tt:893.141\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00009, loss_test:0.08847, lr:1.00e-02, fs:0.77576 (r=0.736,p=0.821),  time:35.684, tt:927.781\n",
      "Ep:26, loss:0.00009, loss_test:0.08856, lr:1.00e-02, fs:0.80982 (r=0.759,p=0.868),  time:35.790, tt:966.329\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00008, loss_test:0.08754, lr:1.00e-02, fs:0.79503 (r=0.736,p=0.865),  time:35.801, tt:1002.426\n",
      "Ep:28, loss:0.00008, loss_test:0.08500, lr:1.00e-02, fs:0.80488 (r=0.759,p=0.857),  time:35.802, tt:1038.245\n",
      "Ep:29, loss:0.00007, loss_test:0.08767, lr:1.00e-02, fs:0.77707 (r=0.701,p=0.871),  time:35.843, tt:1075.281\n",
      "Ep:30, loss:0.00007, loss_test:0.08514, lr:1.00e-02, fs:0.77215 (r=0.701,p=0.859),  time:35.929, tt:1113.784\n",
      "Ep:31, loss:0.00006, loss_test:0.08419, lr:1.00e-02, fs:0.80745 (r=0.747,p=0.878),  time:35.903, tt:1148.903\n",
      "Ep:32, loss:0.00006, loss_test:0.08826, lr:1.00e-02, fs:0.77333 (r=0.667,p=0.921),  time:35.915, tt:1185.210\n",
      "Ep:33, loss:0.00006, loss_test:0.07956, lr:1.00e-02, fs:0.83436 (r=0.782,p=0.895),  time:35.946, tt:1222.158\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00005, loss_test:0.08919, lr:1.00e-02, fs:0.76056 (r=0.621,p=0.982),  time:35.899, tt:1256.482\n",
      "Ep:35, loss:0.00005, loss_test:0.08174, lr:1.00e-02, fs:0.79487 (r=0.713,p=0.899),  time:35.832, tt:1289.958\n",
      "Ep:36, loss:0.00004, loss_test:0.08886, lr:1.00e-02, fs:0.76056 (r=0.621,p=0.982),  time:35.891, tt:1327.977\n",
      "Ep:37, loss:0.00004, loss_test:0.08199, lr:1.00e-02, fs:0.79470 (r=0.690,p=0.938),  time:35.857, tt:1362.583\n",
      "Ep:38, loss:0.00004, loss_test:0.08851, lr:1.00e-02, fs:0.76923 (r=0.632,p=0.982),  time:35.876, tt:1399.151\n",
      "Ep:39, loss:0.00004, loss_test:0.08413, lr:1.00e-02, fs:0.81081 (r=0.690,p=0.984),  time:35.891, tt:1435.628\n",
      "Ep:40, loss:0.00003, loss_test:0.08734, lr:1.00e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.855, tt:1470.064\n",
      "Ep:41, loss:0.00003, loss_test:0.08781, lr:1.00e-02, fs:0.77778 (r=0.644,p=0.982),  time:35.825, tt:1504.669\n",
      "Ep:42, loss:0.00003, loss_test:0.08511, lr:1.00e-02, fs:0.79452 (r=0.667,p=0.983),  time:35.774, tt:1538.295\n",
      "Ep:43, loss:0.00003, loss_test:0.08718, lr:1.00e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.777, tt:1574.173\n",
      "Ep:44, loss:0.00002, loss_test:0.08922, lr:1.00e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.787, tt:1610.416\n",
      "Ep:45, loss:0.00002, loss_test:0.08743, lr:9.90e-03, fs:0.77778 (r=0.644,p=0.982),  time:35.769, tt:1645.396\n",
      "Ep:46, loss:0.00002, loss_test:0.09254, lr:9.80e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.737, tt:1679.635\n",
      "Ep:47, loss:0.00002, loss_test:0.08954, lr:9.70e-03, fs:0.81333 (r=0.701,p=0.968),  time:35.730, tt:1715.055\n",
      "Ep:48, loss:0.00002, loss_test:0.08970, lr:9.61e-03, fs:0.77465 (r=0.632,p=1.000),  time:35.669, tt:1747.776\n",
      "Ep:49, loss:0.00002, loss_test:0.08593, lr:9.51e-03, fs:0.79452 (r=0.667,p=0.983),  time:35.664, tt:1783.223\n",
      "Ep:50, loss:0.00002, loss_test:0.08822, lr:9.41e-03, fs:0.73759 (r=0.598,p=0.963),  time:35.622, tt:1816.701\n",
      "Ep:51, loss:0.00002, loss_test:0.08716, lr:9.32e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.577, tt:1849.989\n",
      "Ep:52, loss:0.00002, loss_test:0.08503, lr:9.23e-03, fs:0.78322 (r=0.644,p=1.000),  time:35.533, tt:1883.261\n",
      "Ep:53, loss:0.00001, loss_test:0.08775, lr:9.14e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.533, tt:1918.761\n",
      "Ep:54, loss:0.00001, loss_test:0.08527, lr:9.04e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.553, tt:1955.420\n",
      "Ep:55, loss:0.00001, loss_test:0.08603, lr:8.95e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.542, tt:1990.328\n",
      "Ep:56, loss:0.00001, loss_test:0.08496, lr:8.86e-03, fs:0.78322 (r=0.644,p=1.000),  time:35.549, tt:2026.311\n",
      "Ep:57, loss:0.00001, loss_test:0.08310, lr:8.78e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.565, tt:2062.747\n",
      "Ep:58, loss:0.00001, loss_test:0.08697, lr:8.69e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.548, tt:2097.318\n",
      "Ep:59, loss:0.00001, loss_test:0.08820, lr:8.60e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.545, tt:2132.674\n",
      "Ep:60, loss:0.00001, loss_test:0.08500, lr:8.51e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.553, tt:2168.741\n",
      "Ep:61, loss:0.00001, loss_test:0.08749, lr:8.43e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.565, tt:2205.005\n",
      "Ep:62, loss:0.00001, loss_test:0.08760, lr:8.35e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.553, tt:2239.832\n",
      "Ep:63, loss:0.00001, loss_test:0.08694, lr:8.26e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.551, tt:2275.256\n",
      "Ep:64, loss:0.00001, loss_test:0.08850, lr:8.18e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.545, tt:2310.425\n",
      "Ep:65, loss:0.00001, loss_test:0.08868, lr:8.10e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.554, tt:2346.571\n",
      "Ep:66, loss:0.00001, loss_test:0.08922, lr:8.02e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.526, tt:2380.218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:67, loss:0.00001, loss_test:0.08971, lr:7.94e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.507, tt:2414.495\n",
      "Ep:68, loss:0.00001, loss_test:0.08853, lr:7.86e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.515, tt:2450.503\n",
      "Ep:69, loss:0.00001, loss_test:0.09045, lr:7.78e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.562, tt:2489.367\n",
      "Ep:70, loss:0.00001, loss_test:0.09243, lr:7.70e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.541, tt:2523.383\n",
      "Ep:71, loss:0.00000, loss_test:0.09016, lr:7.62e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.550, tt:2559.631\n",
      "Ep:72, loss:0.00000, loss_test:0.09118, lr:7.55e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.548, tt:2594.993\n",
      "Ep:73, loss:0.00000, loss_test:0.09199, lr:7.47e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.559, tt:2631.329\n",
      "Ep:74, loss:0.00000, loss_test:0.09118, lr:7.40e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.587, tt:2669.020\n",
      "Ep:75, loss:0.00000, loss_test:0.09183, lr:7.32e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.589, tt:2704.800\n",
      "Ep:76, loss:0.00000, loss_test:0.09255, lr:7.25e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.573, tt:2739.116\n",
      "Ep:77, loss:0.00000, loss_test:0.09326, lr:7.18e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.560, tt:2773.689\n",
      "Ep:78, loss:0.00000, loss_test:0.09280, lr:7.11e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.559, tt:2809.175\n",
      "Ep:79, loss:0.00000, loss_test:0.09337, lr:7.03e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.562, tt:2844.948\n",
      "Ep:80, loss:0.00000, loss_test:0.09400, lr:6.96e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.580, tt:2881.963\n",
      "Ep:81, loss:0.00000, loss_test:0.09413, lr:6.89e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.580, tt:2917.581\n",
      "Ep:82, loss:0.00000, loss_test:0.09477, lr:6.83e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.606, tt:2955.336\n",
      "Ep:83, loss:0.00000, loss_test:0.09526, lr:6.76e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.625, tt:2992.463\n",
      "Ep:84, loss:0.00000, loss_test:0.09290, lr:6.69e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.634, tt:3028.869\n",
      "Ep:85, loss:0.00000, loss_test:0.09699, lr:6.62e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.640, tt:3065.077\n",
      "Ep:86, loss:0.00000, loss_test:0.09443, lr:6.56e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.629, tt:3099.732\n",
      "Ep:87, loss:0.00000, loss_test:0.09437, lr:6.49e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.660, tt:3138.100\n",
      "Ep:88, loss:0.00000, loss_test:0.09462, lr:6.43e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.680, tt:3175.543\n",
      "Ep:89, loss:0.00000, loss_test:0.09421, lr:6.36e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.680, tt:3211.243\n",
      "Ep:90, loss:0.00000, loss_test:0.09585, lr:6.30e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.693, tt:3248.045\n",
      "Ep:91, loss:0.00000, loss_test:0.09405, lr:6.24e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.703, tt:3284.660\n",
      "Ep:92, loss:0.00000, loss_test:0.09522, lr:6.17e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.731, tt:3323.020\n",
      "Ep:93, loss:0.00000, loss_test:0.09764, lr:6.11e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.751, tt:3360.561\n",
      "Ep:94, loss:0.00000, loss_test:0.09424, lr:6.05e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.756, tt:3396.837\n",
      "Ep:95, loss:0.00000, loss_test:0.09564, lr:5.99e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.748, tt:3431.780\n",
      "Ep:96, loss:0.00000, loss_test:0.09641, lr:5.93e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.759, tt:3468.668\n",
      "Ep:97, loss:0.00000, loss_test:0.09465, lr:5.87e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.752, tt:3503.715\n",
      "Ep:98, loss:0.00000, loss_test:0.09579, lr:5.81e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.740, tt:3538.292\n",
      "Ep:99, loss:0.00000, loss_test:0.09751, lr:5.75e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.743, tt:3574.320\n",
      "Ep:100, loss:0.00000, loss_test:0.09566, lr:5.70e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.748, tt:3610.541\n",
      "Ep:101, loss:0.00000, loss_test:0.09671, lr:5.64e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.770, tt:3648.492\n",
      "Ep:102, loss:0.00000, loss_test:0.09666, lr:5.58e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.772, tt:3684.473\n",
      "Ep:103, loss:0.00000, loss_test:0.09650, lr:5.53e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.771, tt:3720.191\n",
      "Ep:104, loss:0.00000, loss_test:0.09673, lr:5.47e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.743, tt:3752.994\n",
      "Ep:105, loss:0.00000, loss_test:0.09682, lr:5.42e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.688, tt:3782.875\n",
      "Ep:106, loss:0.00000, loss_test:0.09713, lr:5.36e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.651, tt:3814.626\n",
      "Ep:107, loss:0.00000, loss_test:0.09675, lr:5.31e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.643, tt:3849.421\n",
      "Ep:108, loss:0.00000, loss_test:0.09621, lr:5.26e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.606, tt:3881.072\n",
      "Ep:109, loss:0.00000, loss_test:0.09594, lr:5.20e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.589, tt:3914.821\n",
      "Ep:110, loss:0.00000, loss_test:0.09604, lr:5.15e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.559, tt:3947.024\n",
      "Ep:111, loss:0.00000, loss_test:0.09672, lr:5.10e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.502, tt:3976.178\n",
      "Ep:112, loss:0.00000, loss_test:0.09672, lr:5.05e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.470, tt:4008.058\n",
      "Ep:113, loss:0.00000, loss_test:0.09586, lr:5.00e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.435, tt:4039.626\n",
      "Ep:114, loss:0.00000, loss_test:0.09608, lr:4.95e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.411, tt:4072.286\n",
      "Ep:115, loss:0.00000, loss_test:0.09630, lr:4.90e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.379, tt:4104.014\n",
      "Ep:116, loss:0.00000, loss_test:0.09672, lr:4.85e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.362, tt:4137.364\n",
      "Ep:117, loss:0.00000, loss_test:0.09608, lr:4.80e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.306, tt:4166.140\n",
      "Ep:118, loss:0.00000, loss_test:0.09623, lr:4.75e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.289, tt:4199.391\n",
      "Ep:119, loss:0.00000, loss_test:0.09692, lr:4.71e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.247, tt:4229.647\n",
      "Ep:120, loss:0.00000, loss_test:0.09666, lr:4.66e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.220, tt:4261.666\n",
      "Ep:121, loss:0.00000, loss_test:0.09577, lr:4.61e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.192, tt:4293.414\n",
      "Ep:122, loss:0.00000, loss_test:0.09744, lr:4.57e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.148, tt:4323.152\n",
      "Ep:123, loss:0.00000, loss_test:0.09693, lr:4.52e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.130, tt:4356.109\n",
      "Ep:124, loss:0.00000, loss_test:0.09571, lr:4.48e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.111, tt:4388.842\n",
      "Ep:125, loss:0.00000, loss_test:0.09661, lr:4.43e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.075, tt:4419.458\n",
      "Ep:126, loss:0.00000, loss_test:0.09768, lr:4.39e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.056, tt:4452.126\n",
      "Ep:127, loss:0.00000, loss_test:0.09640, lr:4.34e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.037, tt:4484.689\n",
      "Ep:128, loss:0.00000, loss_test:0.09616, lr:4.30e-03, fs:0.79167 (r=0.655,p=1.000),  time:35.025, tt:4518.228\n",
      "Ep:129, loss:0.00000, loss_test:0.09698, lr:4.26e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.990, tt:4548.687\n",
      "Ep:130, loss:0.00000, loss_test:0.09660, lr:4.21e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.963, tt:4580.139\n",
      "Ep:131, loss:0.00000, loss_test:0.09583, lr:4.17e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.936, tt:4611.512\n",
      "Ep:132, loss:0.00000, loss_test:0.09614, lr:4.13e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.923, tt:4644.731\n",
      "Ep:133, loss:0.00000, loss_test:0.09658, lr:4.09e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.916, tt:4678.738\n",
      "Ep:134, loss:0.00000, loss_test:0.09636, lr:4.05e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.896, tt:4710.912\n",
      "Ep:135, loss:0.00000, loss_test:0.09614, lr:4.01e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.860, tt:4740.927\n",
      "Ep:136, loss:0.00000, loss_test:0.09587, lr:3.97e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.824, tt:4770.827\n",
      "Ep:137, loss:0.00000, loss_test:0.09566, lr:3.93e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.793, tt:4801.434\n",
      "Ep:138, loss:0.00000, loss_test:0.09674, lr:3.89e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.747, tt:4829.827\n",
      "Ep:139, loss:0.00000, loss_test:0.09660, lr:3.85e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.714, tt:4859.898\n",
      "Ep:140, loss:0.00000, loss_test:0.09586, lr:3.81e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.679, tt:4889.807\n",
      "Ep:141, loss:0.00000, loss_test:0.09572, lr:3.77e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.655, tt:4921.063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:142, loss:0.00000, loss_test:0.09619, lr:3.73e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.629, tt:4951.983\n",
      "Ep:143, loss:0.00000, loss_test:0.09615, lr:3.70e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.608, tt:4983.541\n",
      "Ep:144, loss:0.00000, loss_test:0.09571, lr:3.66e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.614, tt:5019.083\n",
      "Ep:145, loss:0.00000, loss_test:0.09588, lr:3.62e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.597, tt:5051.097\n",
      "Ep:146, loss:0.00000, loss_test:0.09667, lr:3.59e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.572, tt:5082.143\n",
      "Ep:147, loss:0.00000, loss_test:0.09612, lr:3.55e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.553, tt:5113.894\n",
      "Ep:148, loss:0.00000, loss_test:0.09547, lr:3.52e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.551, tt:5148.089\n",
      "Ep:149, loss:0.00000, loss_test:0.09607, lr:3.48e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.538, tt:5180.762\n",
      "Ep:150, loss:0.00000, loss_test:0.09699, lr:3.45e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.523, tt:5212.908\n",
      "Ep:151, loss:0.00000, loss_test:0.09670, lr:3.41e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.512, tt:5245.803\n",
      "Ep:152, loss:0.00000, loss_test:0.09588, lr:3.38e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.493, tt:5277.498\n",
      "Ep:153, loss:0.00000, loss_test:0.09595, lr:3.34e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.474, tt:5309.041\n",
      "Ep:154, loss:0.00000, loss_test:0.09640, lr:3.31e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.455, tt:5340.495\n",
      "Ep:155, loss:0.00000, loss_test:0.09643, lr:3.28e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.423, tt:5369.917\n",
      "Ep:156, loss:0.00000, loss_test:0.09595, lr:3.24e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.407, tt:5401.971\n",
      "Ep:157, loss:0.00000, loss_test:0.09562, lr:3.21e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.395, tt:5434.375\n",
      "Ep:158, loss:0.00000, loss_test:0.09601, lr:3.18e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.379, tt:5466.230\n",
      "Ep:159, loss:0.00000, loss_test:0.09636, lr:3.15e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.355, tt:5496.749\n",
      "Ep:160, loss:0.00000, loss_test:0.09608, lr:3.12e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.339, tt:5528.654\n",
      "Ep:161, loss:0.00000, loss_test:0.09584, lr:3.09e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.330, tt:5561.521\n",
      "Ep:162, loss:0.00000, loss_test:0.09641, lr:3.05e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.315, tt:5593.424\n",
      "Ep:163, loss:0.00000, loss_test:0.09657, lr:3.02e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.282, tt:5622.264\n",
      "Ep:164, loss:0.00000, loss_test:0.09633, lr:2.99e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.249, tt:5651.079\n",
      "Ep:165, loss:0.00000, loss_test:0.09611, lr:2.96e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.230, tt:5682.102\n",
      "Ep:166, loss:0.00000, loss_test:0.09601, lr:2.93e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.213, tt:5713.531\n",
      "Ep:167, loss:0.00000, loss_test:0.09587, lr:2.90e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.205, tt:5746.464\n",
      "Ep:168, loss:0.00000, loss_test:0.09594, lr:2.88e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.198, tt:5779.386\n",
      "Ep:169, loss:0.00000, loss_test:0.09615, lr:2.85e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.177, tt:5810.049\n",
      "Ep:170, loss:0.00000, loss_test:0.09630, lr:2.82e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.163, tt:5841.896\n",
      "Ep:171, loss:0.00000, loss_test:0.09619, lr:2.79e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.132, tt:5870.623\n",
      "Ep:172, loss:0.00000, loss_test:0.09588, lr:2.76e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.119, tt:5902.670\n",
      "Ep:173, loss:0.00000, loss_test:0.09584, lr:2.73e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.108, tt:5934.838\n",
      "Ep:174, loss:0.00000, loss_test:0.09589, lr:2.71e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.108, tt:5968.860\n",
      "Ep:175, loss:0.00000, loss_test:0.09603, lr:2.68e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.097, tt:6001.001\n",
      "Ep:176, loss:0.00000, loss_test:0.09602, lr:2.65e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.081, tt:6032.418\n",
      "Ep:177, loss:0.00000, loss_test:0.09610, lr:2.63e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.066, tt:6063.685\n",
      "Ep:178, loss:0.00000, loss_test:0.09612, lr:2.60e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.049, tt:6094.829\n",
      "Ep:179, loss:0.00000, loss_test:0.09588, lr:2.57e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.028, tt:6125.076\n",
      "Ep:180, loss:0.00000, loss_test:0.09606, lr:2.55e-03, fs:0.79167 (r=0.655,p=1.000),  time:34.001, tt:6154.167\n",
      "Ep:181, loss:0.00000, loss_test:0.09604, lr:2.52e-03, fs:0.79167 (r=0.655,p=1.000),  time:33.975, tt:6183.469\n",
      "Ep:182, loss:0.00000, loss_test:0.09613, lr:2.50e-03, fs:0.79167 (r=0.655,p=1.000),  time:33.962, tt:6215.034\n",
      "Ep:183, loss:0.00000, loss_test:0.09604, lr:2.47e-03, fs:0.79167 (r=0.655,p=1.000),  time:33.959, tt:6248.436\n",
      "Ep:184, loss:0.00000, loss_test:0.09578, lr:2.45e-03, fs:0.79167 (r=0.655,p=1.000),  time:33.950, tt:6280.740\n",
      "Ep:185, loss:0.00000, loss_test:0.09583, lr:2.42e-03, fs:0.79167 (r=0.655,p=1.000),  time:33.933, tt:6311.613\n",
      "Ep:186, loss:0.00000, loss_test:0.09614, lr:2.40e-03, fs:0.79167 (r=0.655,p=1.000),  time:33.904, tt:6340.116\n",
      "Ep:187, loss:0.00000, loss_test:0.09624, lr:2.38e-03, fs:0.79167 (r=0.655,p=1.000),  time:33.913, tt:6375.698\n",
      "Ep:188, loss:0.00000, loss_test:0.09607, lr:2.35e-03, fs:0.79167 (r=0.655,p=1.000),  time:33.899, tt:6406.881\n",
      "Ep:189, loss:0.00000, loss_test:0.09614, lr:2.33e-03, fs:0.79167 (r=0.655,p=1.000),  time:33.897, tt:6440.515\n",
      "Ep:190, loss:0.00000, loss_test:0.09639, lr:2.31e-03, fs:0.79167 (r=0.655,p=1.000),  time:33.879, tt:6470.888\n",
      "Ep:191, loss:0.00000, loss_test:0.09630, lr:2.28e-03, fs:0.79167 (r=0.655,p=1.000),  time:33.865, tt:6502.069\n",
      "Ep:192, loss:0.00000, loss_test:0.09616, lr:2.26e-03, fs:0.79167 (r=0.655,p=1.000),  time:33.853, tt:6533.643\n",
      "Ep:193, loss:0.00000, loss_test:0.09598, lr:2.24e-03, fs:0.79167 (r=0.655,p=1.000),  time:33.831, tt:6563.196\n",
      "Ep:194, loss:0.00000, loss_test:0.09589, lr:2.21e-03, fs:0.79167 (r=0.655,p=1.000),  time:33.811, tt:6593.110\n",
      "Ep:195, loss:0.00000, loss_test:0.09595, lr:2.19e-03, fs:0.79167 (r=0.655,p=1.000),  time:33.788, tt:6622.397\n",
      "Ep:196, loss:0.00000, loss_test:0.09601, lr:2.17e-03, fs:0.79167 (r=0.655,p=1.000),  time:33.762, tt:6651.205\n",
      "Ep:197, loss:0.00000, loss_test:0.09599, lr:2.15e-03, fs:0.79167 (r=0.655,p=1.000),  time:33.742, tt:6680.825\n",
      "Ep:198, loss:0.00000, loss_test:0.09593, lr:2.13e-03, fs:0.79167 (r=0.655,p=1.000),  time:33.723, tt:6710.972\n",
      "Ep:199, loss:0.00000, loss_test:0.09608, lr:2.11e-03, fs:0.79167 (r=0.655,p=1.000),  time:33.716, tt:6743.131\n",
      "Ep:200, loss:0.00000, loss_test:0.09596, lr:2.08e-03, fs:0.79167 (r=0.655,p=1.000),  time:33.707, tt:6775.171\n",
      "Ep:201, loss:0.00000, loss_test:0.09577, lr:2.06e-03, fs:0.79167 (r=0.655,p=1.000),  time:33.696, tt:6806.634\n",
      "Ep:202, loss:0.00000, loss_test:0.09577, lr:2.04e-03, fs:0.79167 (r=0.655,p=1.000),  time:33.679, tt:6836.766\n",
      "Ep:203, loss:0.00000, loss_test:0.09579, lr:2.02e-03, fs:0.79167 (r=0.655,p=1.000),  time:33.686, tt:6871.945\n",
      "Ep:204, loss:0.00000, loss_test:0.09584, lr:2.00e-03, fs:0.79167 (r=0.655,p=1.000),  time:33.665, tt:6901.224\n",
      "Ep:205, loss:0.00000, loss_test:0.09598, lr:1.98e-03, fs:0.79167 (r=0.655,p=1.000),  time:33.633, tt:6928.390\n",
      "Ep:206, loss:0.00000, loss_test:0.09601, lr:1.96e-03, fs:0.79167 (r=0.655,p=1.000),  time:33.592, tt:6953.449\n",
      "Ep:207, loss:0.00000, loss_test:0.09586, lr:1.94e-03, fs:0.79167 (r=0.655,p=1.000),  time:33.551, tt:6978.556\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,208,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,208,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02039, lr:6.00e-02, fs:0.65035 (r=0.939,p=0.497),  time:30.847, tt:30.847\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02399, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.162, tt:66.324\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02554, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.785, tt:101.354\n",
      "Ep:3, loss:0.00005, loss_test:0.02532, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.872, tt:139.489\n",
      "Ep:4, loss:0.00005, loss_test:0.02388, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.773, tt:178.864\n",
      "Ep:5, loss:0.00004, loss_test:0.02184, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.041, tt:216.246\n",
      "Ep:6, loss:0.00004, loss_test:0.01974, lr:6.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:36.612, tt:256.286\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01830, lr:6.00e-02, fs:0.69434 (r=0.929,p=0.554),  time:37.075, tt:296.597\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01774, lr:6.00e-02, fs:0.70492 (r=0.869,p=0.593),  time:36.815, tt:331.337\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01739, lr:6.00e-02, fs:0.71369 (r=0.869,p=0.606),  time:36.447, tt:364.468\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01705, lr:6.00e-02, fs:0.72800 (r=0.919,p=0.603),  time:36.450, tt:400.946\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01686, lr:6.00e-02, fs:0.72941 (r=0.939,p=0.596),  time:36.350, tt:436.198\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01669, lr:6.00e-02, fs:0.72031 (r=0.949,p=0.580),  time:36.748, tt:477.729\n",
      "Ep:13, loss:0.00003, loss_test:0.01636, lr:6.00e-02, fs:0.71756 (r=0.949,p=0.577),  time:36.585, tt:512.191\n",
      "Ep:14, loss:0.00003, loss_test:0.01599, lr:6.00e-02, fs:0.73228 (r=0.939,p=0.600),  time:36.352, tt:545.286\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01572, lr:6.00e-02, fs:0.75000 (r=0.939,p=0.624),  time:36.093, tt:577.493\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01552, lr:6.00e-02, fs:0.76230 (r=0.939,p=0.641),  time:36.035, tt:612.593\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01528, lr:6.00e-02, fs:0.75720 (r=0.929,p=0.639),  time:35.875, tt:645.745\n",
      "Ep:18, loss:0.00003, loss_test:0.01506, lr:6.00e-02, fs:0.77049 (r=0.949,p=0.648),  time:35.859, tt:681.316\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01482, lr:6.00e-02, fs:0.76735 (r=0.949,p=0.644),  time:35.834, tt:716.681\n",
      "Ep:20, loss:0.00003, loss_test:0.01458, lr:6.00e-02, fs:0.76735 (r=0.949,p=0.644),  time:35.821, tt:752.248\n",
      "Ep:21, loss:0.00003, loss_test:0.01435, lr:6.00e-02, fs:0.78189 (r=0.960,p=0.660),  time:35.783, tt:787.230\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01415, lr:6.00e-02, fs:0.77824 (r=0.939,p=0.664),  time:35.777, tt:822.881\n",
      "Ep:23, loss:0.00002, loss_test:0.01395, lr:6.00e-02, fs:0.78814 (r=0.939,p=0.679),  time:35.766, tt:858.391\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01374, lr:6.00e-02, fs:0.79828 (r=0.939,p=0.694),  time:35.730, tt:893.256\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01352, lr:6.00e-02, fs:0.82203 (r=0.980,p=0.708),  time:35.817, tt:931.247\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01331, lr:6.00e-02, fs:0.83051 (r=0.990,p=0.715),  time:35.800, tt:966.609\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01312, lr:6.00e-02, fs:0.84120 (r=0.990,p=0.731),  time:35.796, tt:1002.300\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01295, lr:6.00e-02, fs:0.83621 (r=0.980,p=0.729),  time:35.832, tt:1039.124\n",
      "Ep:29, loss:0.00002, loss_test:0.01280, lr:6.00e-02, fs:0.83621 (r=0.980,p=0.729),  time:35.844, tt:1075.331\n",
      "Ep:30, loss:0.00002, loss_test:0.01262, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:35.838, tt:1110.990\n",
      "Ep:31, loss:0.00002, loss_test:0.01248, lr:6.00e-02, fs:0.82969 (r=0.960,p=0.731),  time:35.858, tt:1147.440\n",
      "Ep:32, loss:0.00002, loss_test:0.01238, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:35.858, tt:1183.324\n",
      "Ep:33, loss:0.00002, loss_test:0.01228, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:35.822, tt:1217.939\n",
      "Ep:34, loss:0.00002, loss_test:0.01215, lr:6.00e-02, fs:0.83556 (r=0.949,p=0.746),  time:35.819, tt:1253.655\n",
      "Ep:35, loss:0.00002, loss_test:0.01203, lr:6.00e-02, fs:0.83556 (r=0.949,p=0.746),  time:35.810, tt:1289.167\n",
      "Ep:36, loss:0.00002, loss_test:0.01193, lr:6.00e-02, fs:0.82511 (r=0.929,p=0.742),  time:35.759, tt:1323.074\n",
      "Ep:37, loss:0.00002, loss_test:0.01182, lr:6.00e-02, fs:0.82511 (r=0.929,p=0.742),  time:35.758, tt:1358.801\n",
      "Ep:38, loss:0.00002, loss_test:0.01172, lr:6.00e-02, fs:0.83258 (r=0.929,p=0.754),  time:35.714, tt:1392.846\n",
      "Ep:39, loss:0.00002, loss_test:0.01162, lr:5.94e-02, fs:0.83258 (r=0.929,p=0.754),  time:35.681, tt:1427.222\n",
      "Ep:40, loss:0.00002, loss_test:0.01151, lr:5.88e-02, fs:0.83784 (r=0.939,p=0.756),  time:35.605, tt:1459.797\n",
      "Ep:41, loss:0.00002, loss_test:0.01142, lr:5.82e-02, fs:0.83636 (r=0.929,p=0.760),  time:35.601, tt:1495.227\n",
      "Ep:42, loss:0.00002, loss_test:0.01134, lr:5.76e-02, fs:0.84163 (r=0.939,p=0.762),  time:35.557, tt:1528.949\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01127, lr:5.76e-02, fs:0.84163 (r=0.939,p=0.762),  time:35.531, tt:1563.364\n",
      "Ep:44, loss:0.00001, loss_test:0.01121, lr:5.76e-02, fs:0.83333 (r=0.909,p=0.769),  time:35.510, tt:1597.948\n",
      "Ep:45, loss:0.00001, loss_test:0.01115, lr:5.76e-02, fs:0.83721 (r=0.909,p=0.776),  time:35.497, tt:1632.876\n",
      "Ep:46, loss:0.00001, loss_test:0.01106, lr:5.76e-02, fs:0.84651 (r=0.919,p=0.784),  time:35.468, tt:1667.012\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01097, lr:5.76e-02, fs:0.84259 (r=0.919,p=0.778),  time:35.413, tt:1699.846\n",
      "Ep:48, loss:0.00001, loss_test:0.01090, lr:5.76e-02, fs:0.84651 (r=0.919,p=0.784),  time:35.403, tt:1734.725\n",
      "Ep:49, loss:0.00001, loss_test:0.01082, lr:5.76e-02, fs:0.84651 (r=0.919,p=0.784),  time:35.387, tt:1769.337\n",
      "Ep:50, loss:0.00001, loss_test:0.01076, lr:5.76e-02, fs:0.85047 (r=0.919,p=0.791),  time:35.382, tt:1804.492\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01068, lr:5.76e-02, fs:0.85047 (r=0.919,p=0.791),  time:35.351, tt:1838.268\n",
      "Ep:52, loss:0.00001, loss_test:0.01064, lr:5.76e-02, fs:0.85446 (r=0.919,p=0.798),  time:35.353, tt:1873.702\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.01058, lr:5.76e-02, fs:0.85849 (r=0.919,p=0.805),  time:35.304, tt:1906.423\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.01051, lr:5.76e-02, fs:0.85849 (r=0.919,p=0.805),  time:35.332, tt:1943.285\n",
      "Ep:55, loss:0.00001, loss_test:0.01046, lr:5.76e-02, fs:0.85849 (r=0.919,p=0.805),  time:35.302, tt:1976.904\n",
      "Ep:56, loss:0.00001, loss_test:0.01041, lr:5.76e-02, fs:0.85849 (r=0.919,p=0.805),  time:35.306, tt:2012.415\n",
      "Ep:57, loss:0.00001, loss_test:0.01033, lr:5.76e-02, fs:0.85849 (r=0.919,p=0.805),  time:35.330, tt:2049.146\n",
      "Ep:58, loss:0.00001, loss_test:0.01030, lr:5.76e-02, fs:0.86256 (r=0.919,p=0.812),  time:35.276, tt:2081.296\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01023, lr:5.76e-02, fs:0.86667 (r=0.919,p=0.820),  time:35.224, tt:2113.436\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01017, lr:5.76e-02, fs:0.86256 (r=0.919,p=0.812),  time:35.182, tt:2146.111\n",
      "Ep:61, loss:0.00001, loss_test:0.01014, lr:5.76e-02, fs:0.86256 (r=0.919,p=0.812),  time:35.119, tt:2177.404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00001, loss_test:0.01010, lr:5.76e-02, fs:0.88571 (r=0.939,p=0.838),  time:35.085, tt:2210.332\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.01006, lr:5.76e-02, fs:0.88995 (r=0.939,p=0.845),  time:35.075, tt:2244.778\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01003, lr:5.76e-02, fs:0.88995 (r=0.939,p=0.845),  time:35.053, tt:2278.427\n",
      "Ep:65, loss:0.00001, loss_test:0.00998, lr:5.76e-02, fs:0.88995 (r=0.939,p=0.845),  time:35.051, tt:2313.366\n",
      "Ep:66, loss:0.00001, loss_test:0.00990, lr:5.76e-02, fs:0.88571 (r=0.939,p=0.838),  time:35.013, tt:2345.878\n",
      "Ep:67, loss:0.00001, loss_test:0.00990, lr:5.76e-02, fs:0.88571 (r=0.939,p=0.838),  time:34.996, tt:2379.737\n",
      "Ep:68, loss:0.00001, loss_test:0.00986, lr:5.76e-02, fs:0.89855 (r=0.939,p=0.861),  time:35.000, tt:2415.028\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.00982, lr:5.76e-02, fs:0.89855 (r=0.939,p=0.861),  time:35.018, tt:2451.229\n",
      "Ep:70, loss:0.00001, loss_test:0.00981, lr:5.76e-02, fs:0.89855 (r=0.939,p=0.861),  time:35.001, tt:2485.100\n",
      "Ep:71, loss:0.00001, loss_test:0.00977, lr:5.76e-02, fs:0.89855 (r=0.939,p=0.861),  time:34.936, tt:2515.369\n",
      "Ep:72, loss:0.00001, loss_test:0.00976, lr:5.76e-02, fs:0.90385 (r=0.949,p=0.862),  time:34.940, tt:2550.620\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.00975, lr:5.76e-02, fs:0.90385 (r=0.949,p=0.862),  time:34.900, tt:2582.610\n",
      "Ep:74, loss:0.00001, loss_test:0.00971, lr:5.76e-02, fs:0.89855 (r=0.939,p=0.861),  time:34.876, tt:2615.701\n",
      "Ep:75, loss:0.00001, loss_test:0.00969, lr:5.76e-02, fs:0.89855 (r=0.939,p=0.861),  time:34.870, tt:2650.136\n",
      "Ep:76, loss:0.00001, loss_test:0.00968, lr:5.76e-02, fs:0.89855 (r=0.939,p=0.861),  time:34.856, tt:2683.938\n",
      "Ep:77, loss:0.00001, loss_test:0.00966, lr:5.76e-02, fs:0.89855 (r=0.939,p=0.861),  time:34.851, tt:2718.390\n",
      "Ep:78, loss:0.00001, loss_test:0.00964, lr:5.76e-02, fs:0.89855 (r=0.939,p=0.861),  time:34.827, tt:2751.349\n",
      "Ep:79, loss:0.00001, loss_test:0.00962, lr:5.76e-02, fs:0.89855 (r=0.939,p=0.861),  time:34.837, tt:2786.937\n",
      "Ep:80, loss:0.00001, loss_test:0.00960, lr:5.76e-02, fs:0.89855 (r=0.939,p=0.861),  time:34.847, tt:2822.584\n",
      "Ep:81, loss:0.00001, loss_test:0.00960, lr:5.76e-02, fs:0.89855 (r=0.939,p=0.861),  time:34.853, tt:2857.943\n",
      "Ep:82, loss:0.00001, loss_test:0.00960, lr:5.76e-02, fs:0.89855 (r=0.939,p=0.861),  time:34.852, tt:2892.749\n",
      "Ep:83, loss:0.00001, loss_test:0.00960, lr:5.76e-02, fs:0.90291 (r=0.939,p=0.869),  time:34.847, tt:2927.125\n",
      "Ep:84, loss:0.00001, loss_test:0.00960, lr:5.71e-02, fs:0.90291 (r=0.939,p=0.869),  time:34.855, tt:2962.639\n",
      "Ep:85, loss:0.00001, loss_test:0.00960, lr:5.65e-02, fs:0.90291 (r=0.939,p=0.869),  time:34.853, tt:2997.395\n",
      "Ep:86, loss:0.00001, loss_test:0.00962, lr:5.59e-02, fs:0.90291 (r=0.939,p=0.869),  time:34.851, tt:3032.016\n",
      "Ep:87, loss:0.00001, loss_test:0.00964, lr:5.54e-02, fs:0.90291 (r=0.939,p=0.869),  time:34.857, tt:3067.419\n",
      "Ep:88, loss:0.00001, loss_test:0.00963, lr:5.48e-02, fs:0.90291 (r=0.939,p=0.869),  time:34.929, tt:3108.705\n",
      "Ep:89, loss:0.00001, loss_test:0.00964, lr:5.43e-02, fs:0.90291 (r=0.939,p=0.869),  time:34.929, tt:3143.625\n",
      "Ep:90, loss:0.00001, loss_test:0.00966, lr:5.37e-02, fs:0.90291 (r=0.939,p=0.869),  time:34.938, tt:3179.341\n",
      "Ep:91, loss:0.00001, loss_test:0.00968, lr:5.32e-02, fs:0.90291 (r=0.939,p=0.869),  time:34.930, tt:3213.533\n",
      "Ep:92, loss:0.00001, loss_test:0.00968, lr:5.27e-02, fs:0.90291 (r=0.939,p=0.869),  time:34.924, tt:3247.935\n",
      "Ep:93, loss:0.00001, loss_test:0.00971, lr:5.21e-02, fs:0.90291 (r=0.939,p=0.869),  time:34.925, tt:3282.912\n",
      "Ep:94, loss:0.00001, loss_test:0.00972, lr:5.16e-02, fs:0.90291 (r=0.939,p=0.869),  time:34.920, tt:3317.398\n",
      "Ep:95, loss:0.00001, loss_test:0.00973, lr:5.11e-02, fs:0.90732 (r=0.939,p=0.877),  time:34.929, tt:3353.145\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00001, loss_test:0.00975, lr:5.11e-02, fs:0.90732 (r=0.939,p=0.877),  time:34.922, tt:3387.399\n",
      "Ep:97, loss:0.00001, loss_test:0.00975, lr:5.11e-02, fs:0.91176 (r=0.939,p=0.886),  time:34.929, tt:3423.042\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00001, loss_test:0.00975, lr:5.11e-02, fs:0.91626 (r=0.939,p=0.894),  time:34.928, tt:3457.867\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00001, loss_test:0.00979, lr:5.11e-02, fs:0.91626 (r=0.939,p=0.894),  time:34.927, tt:3492.652\n",
      "Ep:100, loss:0.00001, loss_test:0.00982, lr:5.11e-02, fs:0.91626 (r=0.939,p=0.894),  time:34.934, tt:3528.344\n",
      "Ep:101, loss:0.00001, loss_test:0.00981, lr:5.11e-02, fs:0.91626 (r=0.939,p=0.894),  time:34.954, tt:3565.262\n",
      "Ep:102, loss:0.00001, loss_test:0.00983, lr:5.11e-02, fs:0.92079 (r=0.939,p=0.903),  time:34.954, tt:3600.265\n",
      "##########Best model found so far##########\n",
      "Ep:103, loss:0.00001, loss_test:0.00985, lr:5.11e-02, fs:0.91626 (r=0.939,p=0.894),  time:34.961, tt:3635.907\n",
      "Ep:104, loss:0.00001, loss_test:0.00989, lr:5.11e-02, fs:0.92079 (r=0.939,p=0.903),  time:34.960, tt:3670.844\n",
      "Ep:105, loss:0.00001, loss_test:0.00990, lr:5.11e-02, fs:0.92079 (r=0.939,p=0.903),  time:34.979, tt:3707.808\n",
      "Ep:106, loss:0.00001, loss_test:0.00992, lr:5.11e-02, fs:0.92079 (r=0.939,p=0.903),  time:34.982, tt:3743.091\n",
      "Ep:107, loss:0.00000, loss_test:0.00994, lr:5.11e-02, fs:0.92079 (r=0.939,p=0.903),  time:35.001, tt:3780.154\n",
      "Ep:108, loss:0.00000, loss_test:0.00994, lr:5.11e-02, fs:0.92079 (r=0.939,p=0.903),  time:34.996, tt:3814.592\n",
      "Ep:109, loss:0.00000, loss_test:0.00998, lr:5.11e-02, fs:0.92537 (r=0.939,p=0.912),  time:34.992, tt:3849.168\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00000, loss_test:0.00999, lr:5.11e-02, fs:0.92537 (r=0.939,p=0.912),  time:34.996, tt:3884.577\n",
      "Ep:111, loss:0.00000, loss_test:0.01001, lr:5.11e-02, fs:0.92537 (r=0.939,p=0.912),  time:34.998, tt:3919.752\n",
      "Ep:112, loss:0.00000, loss_test:0.01005, lr:5.11e-02, fs:0.92537 (r=0.939,p=0.912),  time:34.997, tt:3954.606\n",
      "Ep:113, loss:0.00000, loss_test:0.01008, lr:5.11e-02, fs:0.92537 (r=0.939,p=0.912),  time:34.997, tt:3989.700\n",
      "Ep:114, loss:0.00000, loss_test:0.01010, lr:5.11e-02, fs:0.92537 (r=0.939,p=0.912),  time:34.988, tt:4023.632\n",
      "Ep:115, loss:0.00000, loss_test:0.01012, lr:5.11e-02, fs:0.92537 (r=0.939,p=0.912),  time:34.992, tt:4059.067\n",
      "Ep:116, loss:0.00000, loss_test:0.01011, lr:5.11e-02, fs:0.92537 (r=0.939,p=0.912),  time:35.005, tt:4095.529\n",
      "Ep:117, loss:0.00000, loss_test:0.01018, lr:5.11e-02, fs:0.92537 (r=0.939,p=0.912),  time:35.041, tt:4134.831\n",
      "Ep:118, loss:0.00000, loss_test:0.01020, lr:5.11e-02, fs:0.92537 (r=0.939,p=0.912),  time:35.036, tt:4169.241\n",
      "Ep:119, loss:0.00000, loss_test:0.01019, lr:5.11e-02, fs:0.92537 (r=0.939,p=0.912),  time:35.053, tt:4206.396\n",
      "Ep:120, loss:0.00000, loss_test:0.01024, lr:5.11e-02, fs:0.92537 (r=0.939,p=0.912),  time:35.042, tt:4240.062\n",
      "Ep:121, loss:0.00000, loss_test:0.01030, lr:5.06e-02, fs:0.92537 (r=0.939,p=0.912),  time:35.032, tt:4273.912\n",
      "Ep:122, loss:0.00000, loss_test:0.01031, lr:5.01e-02, fs:0.93000 (r=0.939,p=0.921),  time:35.034, tt:4309.172\n",
      "##########Best model found so far##########\n",
      "Ep:123, loss:0.00000, loss_test:0.01030, lr:5.01e-02, fs:0.93000 (r=0.939,p=0.921),  time:35.026, tt:4343.215\n",
      "Ep:124, loss:0.00000, loss_test:0.01034, lr:5.01e-02, fs:0.93000 (r=0.939,p=0.921),  time:35.032, tt:4379.039\n",
      "Ep:125, loss:0.00000, loss_test:0.01039, lr:5.01e-02, fs:0.93000 (r=0.939,p=0.921),  time:35.028, tt:4413.518\n",
      "Ep:126, loss:0.00000, loss_test:0.01040, lr:5.01e-02, fs:0.93000 (r=0.939,p=0.921),  time:35.019, tt:4447.369\n",
      "Ep:127, loss:0.00000, loss_test:0.01040, lr:5.01e-02, fs:0.93000 (r=0.939,p=0.921),  time:35.016, tt:4482.056\n",
      "Ep:128, loss:0.00000, loss_test:0.01045, lr:5.01e-02, fs:0.93000 (r=0.939,p=0.921),  time:35.026, tt:4518.364\n",
      "Ep:129, loss:0.00000, loss_test:0.01047, lr:5.01e-02, fs:0.93000 (r=0.939,p=0.921),  time:35.029, tt:4553.781\n",
      "Ep:130, loss:0.00000, loss_test:0.01051, lr:5.01e-02, fs:0.93467 (r=0.939,p=0.930),  time:35.030, tt:4588.980\n",
      "##########Best model found so far##########\n",
      "Ep:131, loss:0.00000, loss_test:0.01055, lr:5.01e-02, fs:0.93467 (r=0.939,p=0.930),  time:35.034, tt:4624.437\n",
      "Ep:132, loss:0.00000, loss_test:0.01055, lr:5.01e-02, fs:0.93000 (r=0.939,p=0.921),  time:35.049, tt:4661.460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00000, loss_test:0.01057, lr:5.01e-02, fs:0.93467 (r=0.939,p=0.930),  time:35.053, tt:4697.076\n",
      "Ep:134, loss:0.00000, loss_test:0.01060, lr:5.01e-02, fs:0.93467 (r=0.939,p=0.930),  time:35.051, tt:4731.931\n",
      "Ep:135, loss:0.00000, loss_test:0.01063, lr:5.01e-02, fs:0.93939 (r=0.939,p=0.939),  time:35.048, tt:4766.512\n",
      "##########Best model found so far##########\n",
      "Ep:136, loss:0.00000, loss_test:0.01065, lr:5.01e-02, fs:0.93939 (r=0.939,p=0.939),  time:35.052, tt:4802.063\n",
      "Ep:137, loss:0.00000, loss_test:0.01071, lr:5.01e-02, fs:0.93401 (r=0.929,p=0.939),  time:35.045, tt:4836.146\n",
      "Ep:138, loss:0.00000, loss_test:0.01072, lr:5.01e-02, fs:0.93401 (r=0.929,p=0.939),  time:35.049, tt:4871.745\n",
      "Ep:139, loss:0.00000, loss_test:0.01073, lr:5.01e-02, fs:0.93878 (r=0.929,p=0.948),  time:35.057, tt:4908.012\n",
      "Ep:140, loss:0.00000, loss_test:0.01077, lr:5.01e-02, fs:0.93878 (r=0.929,p=0.948),  time:35.072, tt:4945.087\n",
      "Ep:141, loss:0.00000, loss_test:0.01079, lr:5.01e-02, fs:0.93878 (r=0.929,p=0.948),  time:35.113, tt:4986.051\n",
      "Ep:142, loss:0.00000, loss_test:0.01083, lr:5.01e-02, fs:0.94359 (r=0.929,p=0.958),  time:35.116, tt:5021.616\n",
      "##########Best model found so far##########\n",
      "Ep:143, loss:0.00000, loss_test:0.01088, lr:5.01e-02, fs:0.94359 (r=0.929,p=0.958),  time:35.123, tt:5057.686\n",
      "Ep:144, loss:0.00000, loss_test:0.01091, lr:5.01e-02, fs:0.94359 (r=0.929,p=0.958),  time:35.114, tt:5091.488\n",
      "Ep:145, loss:0.00000, loss_test:0.01092, lr:5.01e-02, fs:0.94359 (r=0.929,p=0.958),  time:35.120, tt:5127.483\n",
      "Ep:146, loss:0.00000, loss_test:0.01097, lr:5.01e-02, fs:0.94359 (r=0.929,p=0.958),  time:35.128, tt:5163.857\n",
      "Ep:147, loss:0.00000, loss_test:0.01101, lr:5.01e-02, fs:0.93814 (r=0.919,p=0.958),  time:35.125, tt:5198.563\n",
      "Ep:148, loss:0.00000, loss_test:0.01104, lr:5.01e-02, fs:0.93814 (r=0.919,p=0.958),  time:35.132, tt:5234.601\n",
      "Ep:149, loss:0.00000, loss_test:0.01109, lr:5.01e-02, fs:0.93814 (r=0.919,p=0.958),  time:35.129, tt:5269.357\n",
      "Ep:150, loss:0.00000, loss_test:0.01112, lr:5.01e-02, fs:0.93814 (r=0.919,p=0.958),  time:35.105, tt:5300.913\n",
      "Ep:151, loss:0.00000, loss_test:0.01113, lr:5.01e-02, fs:0.93814 (r=0.919,p=0.958),  time:35.106, tt:5336.148\n",
      "Ep:152, loss:0.00000, loss_test:0.01118, lr:5.01e-02, fs:0.93814 (r=0.919,p=0.958),  time:35.113, tt:5372.348\n",
      "Ep:153, loss:0.00000, loss_test:0.01119, lr:5.01e-02, fs:0.93814 (r=0.919,p=0.958),  time:35.123, tt:5408.977\n",
      "Ep:154, loss:0.00000, loss_test:0.01120, lr:4.96e-02, fs:0.93814 (r=0.919,p=0.958),  time:35.110, tt:5442.011\n",
      "Ep:155, loss:0.00000, loss_test:0.01128, lr:4.91e-02, fs:0.93814 (r=0.919,p=0.958),  time:35.106, tt:5476.574\n",
      "Ep:156, loss:0.00000, loss_test:0.01130, lr:4.86e-02, fs:0.93814 (r=0.919,p=0.958),  time:35.117, tt:5513.313\n",
      "Ep:157, loss:0.00000, loss_test:0.01131, lr:4.81e-02, fs:0.93814 (r=0.919,p=0.958),  time:35.126, tt:5549.879\n",
      "Ep:158, loss:0.00000, loss_test:0.01140, lr:4.76e-02, fs:0.93814 (r=0.919,p=0.958),  time:35.139, tt:5587.070\n",
      "Ep:159, loss:0.00000, loss_test:0.01139, lr:4.71e-02, fs:0.93814 (r=0.919,p=0.958),  time:35.143, tt:5622.894\n",
      "Ep:160, loss:0.00000, loss_test:0.01142, lr:4.67e-02, fs:0.93814 (r=0.919,p=0.958),  time:35.132, tt:5656.239\n",
      "Ep:161, loss:0.00000, loss_test:0.01144, lr:4.62e-02, fs:0.93264 (r=0.909,p=0.957),  time:35.130, tt:5691.070\n",
      "Ep:162, loss:0.00000, loss_test:0.01145, lr:4.57e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.126, tt:5725.565\n",
      "Ep:163, loss:0.00000, loss_test:0.01149, lr:4.53e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.124, tt:5760.384\n",
      "Ep:164, loss:0.00000, loss_test:0.01154, lr:4.48e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.119, tt:5794.703\n",
      "Ep:165, loss:0.00000, loss_test:0.01157, lr:4.44e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.152, tt:5835.215\n",
      "Ep:166, loss:0.00000, loss_test:0.01158, lr:4.39e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.145, tt:5869.260\n",
      "Ep:167, loss:0.00000, loss_test:0.01162, lr:4.35e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.143, tt:5903.975\n",
      "Ep:168, loss:0.00000, loss_test:0.01161, lr:4.31e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.147, tt:5939.889\n",
      "Ep:169, loss:0.00000, loss_test:0.01165, lr:4.26e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.152, tt:5975.812\n",
      "Ep:170, loss:0.00000, loss_test:0.01170, lr:4.22e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.155, tt:6011.510\n",
      "Ep:171, loss:0.00000, loss_test:0.01174, lr:4.18e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.153, tt:6046.281\n",
      "Ep:172, loss:0.00000, loss_test:0.01175, lr:4.14e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.159, tt:6082.553\n",
      "Ep:173, loss:0.00000, loss_test:0.01176, lr:4.10e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.163, tt:6118.354\n",
      "Ep:174, loss:0.00000, loss_test:0.01177, lr:4.05e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.165, tt:6153.953\n",
      "Ep:175, loss:0.00000, loss_test:0.01180, lr:4.01e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.161, tt:6188.305\n",
      "Ep:176, loss:0.00000, loss_test:0.01185, lr:3.97e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.161, tt:6223.503\n",
      "Ep:177, loss:0.00000, loss_test:0.01185, lr:3.93e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.159, tt:6258.232\n",
      "Ep:178, loss:0.00000, loss_test:0.01188, lr:3.89e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.159, tt:6293.402\n",
      "Ep:179, loss:0.00000, loss_test:0.01193, lr:3.86e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.170, tt:6330.652\n",
      "Ep:180, loss:0.00000, loss_test:0.01193, lr:3.82e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.179, tt:6367.408\n",
      "Ep:181, loss:0.00000, loss_test:0.01195, lr:3.78e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.183, tt:6403.230\n",
      "Ep:182, loss:0.00000, loss_test:0.01200, lr:3.74e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.183, tt:6438.510\n",
      "Ep:183, loss:0.00000, loss_test:0.01201, lr:3.70e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.184, tt:6473.869\n",
      "Ep:184, loss:0.00000, loss_test:0.01203, lr:3.67e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.194, tt:6510.811\n",
      "Ep:185, loss:0.00000, loss_test:0.01206, lr:3.63e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.184, tt:6544.202\n",
      "Ep:186, loss:0.00000, loss_test:0.01208, lr:3.59e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.177, tt:6578.167\n",
      "Ep:187, loss:0.00000, loss_test:0.01210, lr:3.56e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.172, tt:6612.303\n",
      "Ep:188, loss:0.00000, loss_test:0.01212, lr:3.52e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.153, tt:6643.994\n",
      "Ep:189, loss:0.00000, loss_test:0.01214, lr:3.49e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.156, tt:6679.642\n",
      "Ep:190, loss:0.00000, loss_test:0.01217, lr:3.45e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.154, tt:6714.325\n",
      "Ep:191, loss:0.00000, loss_test:0.01218, lr:3.42e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.151, tt:6749.086\n",
      "Ep:192, loss:0.00000, loss_test:0.01221, lr:3.38e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.139, tt:6781.849\n",
      "Ep:193, loss:0.00000, loss_test:0.01222, lr:3.35e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.135, tt:6816.284\n",
      "Ep:194, loss:0.00000, loss_test:0.01223, lr:3.32e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.124, tt:6849.202\n",
      "Ep:195, loss:0.00000, loss_test:0.01228, lr:3.28e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.115, tt:6882.617\n",
      "Ep:196, loss:0.00000, loss_test:0.01229, lr:3.25e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.109, tt:6916.566\n",
      "Ep:197, loss:0.00000, loss_test:0.01230, lr:3.22e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.113, tt:6952.287\n",
      "Ep:198, loss:0.00000, loss_test:0.01232, lr:3.19e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.110, tt:6986.815\n",
      "Ep:199, loss:0.00000, loss_test:0.01235, lr:3.15e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.107, tt:7021.336\n",
      "Ep:200, loss:0.00000, loss_test:0.01236, lr:3.12e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.099, tt:7054.956\n",
      "Ep:201, loss:0.00000, loss_test:0.01235, lr:3.09e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.093, tt:7088.719\n",
      "Ep:202, loss:0.00000, loss_test:0.01238, lr:3.06e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.093, tt:7123.890\n",
      "Ep:203, loss:0.00000, loss_test:0.01241, lr:3.03e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.092, tt:7158.793\n",
      "Ep:204, loss:0.00000, loss_test:0.01242, lr:3.00e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.089, tt:7193.327\n",
      "Ep:205, loss:0.00000, loss_test:0.01245, lr:2.97e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.076, tt:7225.590\n",
      "Ep:206, loss:0.00000, loss_test:0.01246, lr:2.94e-02, fs:0.92708 (r=0.899,p=0.957),  time:35.041, tt:7253.452\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00013, loss_test:0.03745, lr:1.00e-02, fs:0.57143 (r=0.505,p=0.658),  time:21.836, tt:21.836\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00008, loss_test:0.02466, lr:1.00e-02, fs:0.62555 (r=0.717,p=0.555),  time:22.685, tt:45.370\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02274, lr:1.00e-02, fs:0.63197 (r=0.859,p=0.500),  time:24.272, tt:72.815\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02395, lr:1.00e-02, fs:0.65753 (r=0.970,p=0.497),  time:26.826, tt:107.304\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00005, loss_test:0.02527, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:28.532, tt:142.662\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00005, loss_test:0.02615, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.696, tt:178.178\n",
      "Ep:6, loss:0.00005, loss_test:0.02658, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.445, tt:213.117\n",
      "Ep:7, loss:0.00005, loss_test:0.02665, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.058, tt:248.460\n",
      "Ep:8, loss:0.00005, loss_test:0.02647, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.550, tt:283.951\n",
      "Ep:9, loss:0.00005, loss_test:0.02607, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.915, tt:319.151\n",
      "Ep:10, loss:0.00005, loss_test:0.02550, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.234, tt:354.577\n",
      "Ep:11, loss:0.00005, loss_test:0.02481, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.495, tt:389.940\n",
      "Ep:12, loss:0.00005, loss_test:0.02405, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.753, tt:425.788\n",
      "Ep:13, loss:0.00005, loss_test:0.02323, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.952, tt:461.332\n",
      "Ep:14, loss:0.00004, loss_test:0.02243, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:33.102, tt:496.530\n",
      "Ep:15, loss:0.00004, loss_test:0.02167, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:33.307, tt:532.914\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.02097, lr:1.00e-02, fs:0.67820 (r=0.990,p=0.516),  time:33.401, tt:567.825\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.02037, lr:1.00e-02, fs:0.69039 (r=0.980,p=0.533),  time:33.488, tt:602.779\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.01986, lr:1.00e-02, fs:0.69065 (r=0.970,p=0.536),  time:33.632, tt:639.000\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00004, loss_test:0.01947, lr:1.00e-02, fs:0.68864 (r=0.949,p=0.540),  time:33.705, tt:674.092\n",
      "Ep:20, loss:0.00004, loss_test:0.01918, lr:1.00e-02, fs:0.68382 (r=0.939,p=0.538),  time:33.791, tt:709.605\n",
      "Ep:21, loss:0.00004, loss_test:0.01898, lr:1.00e-02, fs:0.68148 (r=0.929,p=0.538),  time:33.868, tt:745.092\n",
      "Ep:22, loss:0.00004, loss_test:0.01883, lr:1.00e-02, fs:0.69145 (r=0.939,p=0.547),  time:34.007, tt:782.171\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00004, loss_test:0.01872, lr:1.00e-02, fs:0.69403 (r=0.939,p=0.550),  time:34.081, tt:817.955\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00004, loss_test:0.01866, lr:1.00e-02, fs:0.69403 (r=0.939,p=0.550),  time:34.130, tt:853.260\n",
      "Ep:25, loss:0.00004, loss_test:0.01860, lr:1.00e-02, fs:0.69403 (r=0.939,p=0.550),  time:34.198, tt:889.139\n",
      "Ep:26, loss:0.00004, loss_test:0.01851, lr:1.00e-02, fs:0.70412 (r=0.949,p=0.560),  time:34.189, tt:923.116\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00004, loss_test:0.01841, lr:1.00e-02, fs:0.70677 (r=0.949,p=0.563),  time:34.251, tt:959.032\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00004, loss_test:0.01829, lr:1.00e-02, fs:0.70412 (r=0.949,p=0.560),  time:34.329, tt:995.530\n",
      "Ep:29, loss:0.00004, loss_test:0.01818, lr:1.00e-02, fs:0.70677 (r=0.949,p=0.563),  time:34.328, tt:1029.849\n",
      "Ep:30, loss:0.00004, loss_test:0.01807, lr:1.00e-02, fs:0.71756 (r=0.949,p=0.577),  time:34.315, tt:1063.769\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00004, loss_test:0.01795, lr:1.00e-02, fs:0.72308 (r=0.949,p=0.584),  time:34.310, tt:1097.929\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00004, loss_test:0.01785, lr:1.00e-02, fs:0.72093 (r=0.939,p=0.585),  time:34.339, tt:1133.201\n",
      "Ep:33, loss:0.00003, loss_test:0.01776, lr:1.00e-02, fs:0.72587 (r=0.949,p=0.588),  time:34.324, tt:1167.016\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01769, lr:1.00e-02, fs:0.72587 (r=0.949,p=0.588),  time:34.287, tt:1200.048\n",
      "Ep:35, loss:0.00003, loss_test:0.01762, lr:1.00e-02, fs:0.72587 (r=0.949,p=0.588),  time:34.292, tt:1234.499\n",
      "Ep:36, loss:0.00003, loss_test:0.01755, lr:1.00e-02, fs:0.72587 (r=0.949,p=0.588),  time:34.271, tt:1268.016\n",
      "Ep:37, loss:0.00003, loss_test:0.01750, lr:1.00e-02, fs:0.72587 (r=0.949,p=0.588),  time:34.261, tt:1301.935\n",
      "Ep:38, loss:0.00003, loss_test:0.01744, lr:1.00e-02, fs:0.72868 (r=0.949,p=0.591),  time:34.274, tt:1336.694\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.01739, lr:1.00e-02, fs:0.73152 (r=0.949,p=0.595),  time:34.279, tt:1371.173\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.01733, lr:1.00e-02, fs:0.73725 (r=0.949,p=0.603),  time:34.278, tt:1405.409\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00003, loss_test:0.01728, lr:1.00e-02, fs:0.73437 (r=0.949,p=0.599),  time:34.255, tt:1438.706\n",
      "Ep:42, loss:0.00003, loss_test:0.01723, lr:1.00e-02, fs:0.73437 (r=0.949,p=0.599),  time:34.285, tt:1474.266\n",
      "Ep:43, loss:0.00003, loss_test:0.01718, lr:1.00e-02, fs:0.73725 (r=0.949,p=0.603),  time:34.280, tt:1508.298\n",
      "Ep:44, loss:0.00003, loss_test:0.01713, lr:1.00e-02, fs:0.74016 (r=0.949,p=0.606),  time:34.302, tt:1543.605\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00003, loss_test:0.01709, lr:1.00e-02, fs:0.74016 (r=0.949,p=0.606),  time:34.301, tt:1577.840\n",
      "Ep:46, loss:0.00003, loss_test:0.01703, lr:1.00e-02, fs:0.74603 (r=0.949,p=0.614),  time:34.322, tt:1613.146\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00003, loss_test:0.01697, lr:1.00e-02, fs:0.74603 (r=0.949,p=0.614),  time:34.371, tt:1649.828\n",
      "Ep:48, loss:0.00003, loss_test:0.01691, lr:1.00e-02, fs:0.74308 (r=0.949,p=0.610),  time:34.356, tt:1683.444\n",
      "Ep:49, loss:0.00003, loss_test:0.01684, lr:1.00e-02, fs:0.74900 (r=0.949,p=0.618),  time:34.361, tt:1718.062\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00003, loss_test:0.01677, lr:1.00e-02, fs:0.74900 (r=0.949,p=0.618),  time:34.378, tt:1753.282\n",
      "Ep:51, loss:0.00003, loss_test:0.01671, lr:1.00e-02, fs:0.74900 (r=0.949,p=0.618),  time:34.400, tt:1788.813\n",
      "Ep:52, loss:0.00003, loss_test:0.01665, lr:1.00e-02, fs:0.75397 (r=0.960,p=0.621),  time:34.371, tt:1821.686\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00003, loss_test:0.01660, lr:1.00e-02, fs:0.75697 (r=0.960,p=0.625),  time:34.393, tt:1857.212\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00003, loss_test:0.01654, lr:1.00e-02, fs:0.75697 (r=0.960,p=0.625),  time:34.400, tt:1891.975\n",
      "Ep:55, loss:0.00003, loss_test:0.01649, lr:1.00e-02, fs:0.76000 (r=0.960,p=0.629),  time:34.393, tt:1926.002\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00003, loss_test:0.01642, lr:1.00e-02, fs:0.76305 (r=0.960,p=0.633),  time:34.385, tt:1959.962\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00003, loss_test:0.01637, lr:1.00e-02, fs:0.76613 (r=0.960,p=0.638),  time:34.398, tt:1995.059\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00003, loss_test:0.01632, lr:1.00e-02, fs:0.76923 (r=0.960,p=0.642),  time:34.375, tt:2028.101\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00003, loss_test:0.01627, lr:1.00e-02, fs:0.76923 (r=0.960,p=0.642),  time:34.367, tt:2061.994\n",
      "Ep:60, loss:0.00003, loss_test:0.01621, lr:1.00e-02, fs:0.76923 (r=0.960,p=0.642),  time:34.360, tt:2095.949\n",
      "Ep:61, loss:0.00003, loss_test:0.01615, lr:1.00e-02, fs:0.76923 (r=0.960,p=0.642),  time:34.352, tt:2129.801\n",
      "Ep:62, loss:0.00003, loss_test:0.01610, lr:1.00e-02, fs:0.76923 (r=0.960,p=0.642),  time:34.344, tt:2163.703\n",
      "Ep:63, loss:0.00003, loss_test:0.01604, lr:1.00e-02, fs:0.76923 (r=0.960,p=0.642),  time:34.336, tt:2197.479\n",
      "Ep:64, loss:0.00003, loss_test:0.01598, lr:1.00e-02, fs:0.77236 (r=0.960,p=0.646),  time:34.337, tt:2231.882\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00003, loss_test:0.01592, lr:1.00e-02, fs:0.77236 (r=0.960,p=0.646),  time:34.338, tt:2266.284\n",
      "Ep:66, loss:0.00003, loss_test:0.01586, lr:1.00e-02, fs:0.77733 (r=0.970,p=0.649),  time:34.325, tt:2299.795\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00003, loss_test:0.01580, lr:1.00e-02, fs:0.77733 (r=0.970,p=0.649),  time:34.314, tt:2333.367\n",
      "Ep:68, loss:0.00003, loss_test:0.01574, lr:1.00e-02, fs:0.77733 (r=0.970,p=0.649),  time:34.292, tt:2366.127\n",
      "Ep:69, loss:0.00003, loss_test:0.01568, lr:1.00e-02, fs:0.77733 (r=0.970,p=0.649),  time:34.294, tt:2400.590\n",
      "Ep:70, loss:0.00003, loss_test:0.01563, lr:1.00e-02, fs:0.78049 (r=0.970,p=0.653),  time:34.307, tt:2435.809\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00003, loss_test:0.01557, lr:1.00e-02, fs:0.78049 (r=0.970,p=0.653),  time:34.313, tt:2470.503\n",
      "Ep:72, loss:0.00003, loss_test:0.01552, lr:1.00e-02, fs:0.78367 (r=0.970,p=0.658),  time:34.308, tt:2504.455\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00003, loss_test:0.01546, lr:1.00e-02, fs:0.78049 (r=0.970,p=0.653),  time:34.308, tt:2538.798\n",
      "Ep:74, loss:0.00003, loss_test:0.01539, lr:1.00e-02, fs:0.78049 (r=0.970,p=0.653),  time:34.331, tt:2574.832\n",
      "Ep:75, loss:0.00003, loss_test:0.01533, lr:1.00e-02, fs:0.77869 (r=0.960,p=0.655),  time:34.335, tt:2609.459\n",
      "Ep:76, loss:0.00003, loss_test:0.01528, lr:1.00e-02, fs:0.77869 (r=0.960,p=0.655),  time:34.354, tt:2645.247\n",
      "Ep:77, loss:0.00002, loss_test:0.01523, lr:1.00e-02, fs:0.77869 (r=0.960,p=0.655),  time:34.363, tt:2680.322\n",
      "Ep:78, loss:0.00002, loss_test:0.01518, lr:1.00e-02, fs:0.77869 (r=0.960,p=0.655),  time:34.383, tt:2716.270\n",
      "Ep:79, loss:0.00002, loss_test:0.01512, lr:1.00e-02, fs:0.78367 (r=0.970,p=0.658),  time:34.383, tt:2750.661\n",
      "Ep:80, loss:0.00002, loss_test:0.01507, lr:1.00e-02, fs:0.78689 (r=0.970,p=0.662),  time:34.397, tt:2786.135\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00002, loss_test:0.01501, lr:1.00e-02, fs:0.78689 (r=0.970,p=0.662),  time:34.405, tt:2821.211\n",
      "Ep:82, loss:0.00002, loss_test:0.01496, lr:1.00e-02, fs:0.79012 (r=0.970,p=0.667),  time:34.416, tt:2856.517\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00002, loss_test:0.01491, lr:1.00e-02, fs:0.79012 (r=0.970,p=0.667),  time:34.428, tt:2891.964\n",
      "Ep:84, loss:0.00002, loss_test:0.01486, lr:1.00e-02, fs:0.79012 (r=0.970,p=0.667),  time:34.438, tt:2927.211\n",
      "Ep:85, loss:0.00002, loss_test:0.01480, lr:1.00e-02, fs:0.79508 (r=0.980,p=0.669),  time:34.449, tt:2962.618\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00002, loss_test:0.01475, lr:1.00e-02, fs:0.79508 (r=0.980,p=0.669),  time:34.467, tt:2998.614\n",
      "Ep:87, loss:0.00002, loss_test:0.01470, lr:1.00e-02, fs:0.79508 (r=0.980,p=0.669),  time:34.493, tt:3035.372\n",
      "Ep:88, loss:0.00002, loss_test:0.01466, lr:1.00e-02, fs:0.79508 (r=0.980,p=0.669),  time:34.518, tt:3072.127\n",
      "Ep:89, loss:0.00002, loss_test:0.01461, lr:1.00e-02, fs:0.79835 (r=0.980,p=0.674),  time:34.529, tt:3107.626\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00002, loss_test:0.01455, lr:1.00e-02, fs:0.80000 (r=0.970,p=0.681),  time:34.548, tt:3143.851\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00002, loss_test:0.01451, lr:1.00e-02, fs:0.80000 (r=0.970,p=0.681),  time:34.555, tt:3179.100\n",
      "Ep:92, loss:0.00002, loss_test:0.01446, lr:1.00e-02, fs:0.80000 (r=0.970,p=0.681),  time:34.573, tt:3215.283\n",
      "Ep:93, loss:0.00002, loss_test:0.01441, lr:1.00e-02, fs:0.80335 (r=0.970,p=0.686),  time:34.574, tt:3249.919\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00002, loss_test:0.01437, lr:1.00e-02, fs:0.80335 (r=0.970,p=0.686),  time:34.583, tt:3285.372\n",
      "Ep:95, loss:0.00002, loss_test:0.01432, lr:1.00e-02, fs:0.80672 (r=0.970,p=0.691),  time:34.589, tt:3320.508\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00002, loss_test:0.01427, lr:1.00e-02, fs:0.80672 (r=0.970,p=0.691),  time:34.596, tt:3355.792\n",
      "Ep:97, loss:0.00002, loss_test:0.01422, lr:1.00e-02, fs:0.80672 (r=0.970,p=0.691),  time:34.600, tt:3390.795\n",
      "Ep:98, loss:0.00002, loss_test:0.01418, lr:1.00e-02, fs:0.80672 (r=0.970,p=0.691),  time:34.612, tt:3426.586\n",
      "Ep:99, loss:0.00002, loss_test:0.01413, lr:1.00e-02, fs:0.80672 (r=0.970,p=0.691),  time:34.612, tt:3461.153\n",
      "Ep:100, loss:0.00002, loss_test:0.01409, lr:1.00e-02, fs:0.81013 (r=0.970,p=0.696),  time:34.624, tt:3496.980\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00002, loss_test:0.01404, lr:1.00e-02, fs:0.81013 (r=0.970,p=0.696),  time:34.635, tt:3532.801\n",
      "Ep:102, loss:0.00002, loss_test:0.01400, lr:1.00e-02, fs:0.81013 (r=0.970,p=0.696),  time:34.645, tt:3568.470\n",
      "Ep:103, loss:0.00002, loss_test:0.01395, lr:1.00e-02, fs:0.81013 (r=0.970,p=0.696),  time:34.661, tt:3604.729\n",
      "Ep:104, loss:0.00002, loss_test:0.01391, lr:1.00e-02, fs:0.81013 (r=0.970,p=0.696),  time:34.657, tt:3639.017\n",
      "Ep:105, loss:0.00002, loss_test:0.01387, lr:1.00e-02, fs:0.81013 (r=0.970,p=0.696),  time:34.662, tt:3674.167\n",
      "Ep:106, loss:0.00002, loss_test:0.01383, lr:1.00e-02, fs:0.81013 (r=0.970,p=0.696),  time:34.665, tt:3709.150\n",
      "Ep:107, loss:0.00002, loss_test:0.01379, lr:1.00e-02, fs:0.81013 (r=0.970,p=0.696),  time:34.679, tt:3745.285\n",
      "Ep:108, loss:0.00002, loss_test:0.01376, lr:1.00e-02, fs:0.81013 (r=0.970,p=0.696),  time:34.678, tt:3779.944\n",
      "Ep:109, loss:0.00002, loss_test:0.01372, lr:1.00e-02, fs:0.81356 (r=0.970,p=0.701),  time:34.693, tt:3816.269\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00002, loss_test:0.01368, lr:1.00e-02, fs:0.81356 (r=0.970,p=0.701),  time:34.698, tt:3851.521\n",
      "Ep:111, loss:0.00002, loss_test:0.01365, lr:1.00e-02, fs:0.81356 (r=0.970,p=0.701),  time:34.691, tt:3885.356\n",
      "Ep:112, loss:0.00002, loss_test:0.01361, lr:1.00e-02, fs:0.81356 (r=0.970,p=0.701),  time:34.701, tt:3921.224\n",
      "Ep:113, loss:0.00002, loss_test:0.01357, lr:1.00e-02, fs:0.81356 (r=0.970,p=0.701),  time:34.716, tt:3957.571\n",
      "Ep:114, loss:0.00002, loss_test:0.01354, lr:1.00e-02, fs:0.81356 (r=0.970,p=0.701),  time:34.727, tt:3993.603\n",
      "Ep:115, loss:0.00002, loss_test:0.01350, lr:1.00e-02, fs:0.81356 (r=0.970,p=0.701),  time:34.732, tt:4028.897\n",
      "Ep:116, loss:0.00002, loss_test:0.01347, lr:1.00e-02, fs:0.81702 (r=0.970,p=0.706),  time:34.738, tt:4064.342\n",
      "##########Best model found so far##########\n",
      "Ep:117, loss:0.00002, loss_test:0.01344, lr:1.00e-02, fs:0.81702 (r=0.970,p=0.706),  time:34.748, tt:4100.319\n",
      "Ep:118, loss:0.00002, loss_test:0.01340, lr:1.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:34.760, tt:4136.495\n",
      "##########Best model found so far##########\n",
      "Ep:119, loss:0.00002, loss_test:0.01337, lr:1.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:34.758, tt:4170.955\n",
      "Ep:120, loss:0.00002, loss_test:0.01334, lr:1.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:34.783, tt:4208.719\n",
      "Ep:121, loss:0.00002, loss_test:0.01331, lr:1.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:34.797, tt:4245.255\n",
      "Ep:122, loss:0.00002, loss_test:0.01327, lr:1.00e-02, fs:0.82759 (r=0.970,p=0.722),  time:34.805, tt:4281.070\n",
      "##########Best model found so far##########\n",
      "Ep:123, loss:0.00002, loss_test:0.01324, lr:1.00e-02, fs:0.83117 (r=0.970,p=0.727),  time:34.817, tt:4317.257\n",
      "##########Best model found so far##########\n",
      "Ep:124, loss:0.00002, loss_test:0.01321, lr:1.00e-02, fs:0.83117 (r=0.970,p=0.727),  time:34.819, tt:4352.333\n",
      "Ep:125, loss:0.00002, loss_test:0.01319, lr:1.00e-02, fs:0.83117 (r=0.970,p=0.727),  time:34.830, tt:4388.569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:126, loss:0.00002, loss_test:0.01316, lr:1.00e-02, fs:0.83117 (r=0.970,p=0.727),  time:34.842, tt:4424.911\n",
      "Ep:127, loss:0.00002, loss_test:0.01314, lr:1.00e-02, fs:0.83117 (r=0.970,p=0.727),  time:34.864, tt:4462.622\n",
      "Ep:128, loss:0.00002, loss_test:0.01312, lr:1.00e-02, fs:0.83117 (r=0.970,p=0.727),  time:34.855, tt:4496.335\n",
      "Ep:129, loss:0.00002, loss_test:0.01309, lr:1.00e-02, fs:0.83117 (r=0.970,p=0.727),  time:34.852, tt:4530.797\n",
      "Ep:130, loss:0.00002, loss_test:0.01307, lr:1.00e-02, fs:0.83117 (r=0.970,p=0.727),  time:34.875, tt:4568.647\n",
      "Ep:131, loss:0.00002, loss_test:0.01304, lr:1.00e-02, fs:0.83117 (r=0.970,p=0.727),  time:34.884, tt:4604.630\n",
      "Ep:132, loss:0.00002, loss_test:0.01302, lr:1.00e-02, fs:0.83983 (r=0.980,p=0.735),  time:34.893, tt:4640.790\n",
      "##########Best model found so far##########\n",
      "Ep:133, loss:0.00002, loss_test:0.01299, lr:1.00e-02, fs:0.83983 (r=0.980,p=0.735),  time:34.899, tt:4676.411\n",
      "Ep:134, loss:0.00002, loss_test:0.01296, lr:1.00e-02, fs:0.83983 (r=0.980,p=0.735),  time:34.909, tt:4712.714\n",
      "Ep:135, loss:0.00002, loss_test:0.01293, lr:1.00e-02, fs:0.83983 (r=0.980,p=0.735),  time:34.913, tt:4748.217\n",
      "Ep:136, loss:0.00002, loss_test:0.01291, lr:1.00e-02, fs:0.83983 (r=0.980,p=0.735),  time:34.912, tt:4783.000\n",
      "Ep:137, loss:0.00002, loss_test:0.01288, lr:1.00e-02, fs:0.83983 (r=0.980,p=0.735),  time:34.917, tt:4818.511\n",
      "Ep:138, loss:0.00002, loss_test:0.01285, lr:1.00e-02, fs:0.83983 (r=0.980,p=0.735),  time:34.927, tt:4854.910\n",
      "Ep:139, loss:0.00002, loss_test:0.01282, lr:1.00e-02, fs:0.83983 (r=0.980,p=0.735),  time:34.934, tt:4890.745\n",
      "Ep:140, loss:0.00002, loss_test:0.01280, lr:1.00e-02, fs:0.83983 (r=0.980,p=0.735),  time:34.922, tt:4924.015\n",
      "Ep:141, loss:0.00002, loss_test:0.01278, lr:1.00e-02, fs:0.83983 (r=0.980,p=0.735),  time:34.927, tt:4959.566\n",
      "Ep:142, loss:0.00002, loss_test:0.01275, lr:1.00e-02, fs:0.84348 (r=0.980,p=0.740),  time:34.929, tt:4994.796\n",
      "##########Best model found so far##########\n",
      "Ep:143, loss:0.00002, loss_test:0.01272, lr:1.00e-02, fs:0.84716 (r=0.980,p=0.746),  time:34.931, tt:5030.060\n",
      "##########Best model found so far##########\n",
      "Ep:144, loss:0.00002, loss_test:0.01269, lr:1.00e-02, fs:0.85463 (r=0.980,p=0.758),  time:34.936, tt:5065.718\n",
      "##########Best model found so far##########\n",
      "Ep:145, loss:0.00002, loss_test:0.01267, lr:1.00e-02, fs:0.85463 (r=0.980,p=0.758),  time:34.942, tt:5101.504\n",
      "Ep:146, loss:0.00002, loss_test:0.01265, lr:1.00e-02, fs:0.85463 (r=0.980,p=0.758),  time:34.943, tt:5136.669\n",
      "Ep:147, loss:0.00002, loss_test:0.01264, lr:1.00e-02, fs:0.85841 (r=0.980,p=0.764),  time:34.948, tt:5172.252\n",
      "##########Best model found so far##########\n",
      "Ep:148, loss:0.00002, loss_test:0.01262, lr:1.00e-02, fs:0.85841 (r=0.980,p=0.764),  time:34.960, tt:5209.077\n",
      "Ep:149, loss:0.00002, loss_test:0.01259, lr:1.00e-02, fs:0.85841 (r=0.980,p=0.764),  time:34.969, tt:5245.288\n",
      "Ep:150, loss:0.00002, loss_test:0.01256, lr:1.00e-02, fs:0.85841 (r=0.980,p=0.764),  time:34.978, tt:5281.736\n",
      "Ep:151, loss:0.00002, loss_test:0.01254, lr:1.00e-02, fs:0.85841 (r=0.980,p=0.764),  time:34.981, tt:5317.063\n",
      "Ep:152, loss:0.00002, loss_test:0.01252, lr:1.00e-02, fs:0.85841 (r=0.980,p=0.764),  time:34.983, tt:5352.344\n",
      "Ep:153, loss:0.00002, loss_test:0.01250, lr:1.00e-02, fs:0.85841 (r=0.980,p=0.764),  time:34.981, tt:5387.083\n",
      "Ep:154, loss:0.00002, loss_test:0.01248, lr:1.00e-02, fs:0.85841 (r=0.980,p=0.764),  time:34.986, tt:5422.818\n",
      "Ep:155, loss:0.00002, loss_test:0.01247, lr:1.00e-02, fs:0.86222 (r=0.980,p=0.770),  time:34.988, tt:5458.201\n",
      "##########Best model found so far##########\n",
      "Ep:156, loss:0.00002, loss_test:0.01246, lr:1.00e-02, fs:0.86607 (r=0.980,p=0.776),  time:35.000, tt:5495.013\n",
      "##########Best model found so far##########\n",
      "Ep:157, loss:0.00002, loss_test:0.01244, lr:1.00e-02, fs:0.86607 (r=0.980,p=0.776),  time:35.001, tt:5530.119\n",
      "Ep:158, loss:0.00002, loss_test:0.01242, lr:1.00e-02, fs:0.86607 (r=0.980,p=0.776),  time:35.006, tt:5565.942\n",
      "Ep:159, loss:0.00001, loss_test:0.01240, lr:1.00e-02, fs:0.86607 (r=0.980,p=0.776),  time:35.005, tt:5600.746\n",
      "Ep:160, loss:0.00001, loss_test:0.01239, lr:1.00e-02, fs:0.86996 (r=0.980,p=0.782),  time:35.014, tt:5637.205\n",
      "##########Best model found so far##########\n",
      "Ep:161, loss:0.00001, loss_test:0.01239, lr:1.00e-02, fs:0.86996 (r=0.980,p=0.782),  time:35.033, tt:5675.274\n",
      "Ep:162, loss:0.00001, loss_test:0.01237, lr:1.00e-02, fs:0.86996 (r=0.980,p=0.782),  time:35.042, tt:5711.792\n",
      "Ep:163, loss:0.00001, loss_test:0.01235, lr:1.00e-02, fs:0.86996 (r=0.980,p=0.782),  time:35.045, tt:5747.397\n",
      "Ep:164, loss:0.00001, loss_test:0.01235, lr:1.00e-02, fs:0.86996 (r=0.980,p=0.782),  time:35.050, tt:5783.252\n",
      "Ep:165, loss:0.00001, loss_test:0.01232, lr:1.00e-02, fs:0.86996 (r=0.980,p=0.782),  time:35.059, tt:5819.770\n",
      "Ep:166, loss:0.00001, loss_test:0.01230, lr:1.00e-02, fs:0.86996 (r=0.980,p=0.782),  time:35.055, tt:5854.129\n",
      "Ep:167, loss:0.00001, loss_test:0.01229, lr:1.00e-02, fs:0.88182 (r=0.980,p=0.802),  time:35.055, tt:5889.313\n",
      "##########Best model found so far##########\n",
      "Ep:168, loss:0.00001, loss_test:0.01226, lr:1.00e-02, fs:0.88182 (r=0.980,p=0.802),  time:35.062, tt:5925.542\n",
      "Ep:169, loss:0.00001, loss_test:0.01224, lr:1.00e-02, fs:0.87783 (r=0.980,p=0.795),  time:35.060, tt:5960.258\n",
      "Ep:170, loss:0.00001, loss_test:0.01224, lr:1.00e-02, fs:0.87783 (r=0.980,p=0.795),  time:35.049, tt:5993.454\n",
      "Ep:171, loss:0.00001, loss_test:0.01223, lr:1.00e-02, fs:0.87783 (r=0.980,p=0.795),  time:35.045, tt:6027.666\n",
      "Ep:172, loss:0.00001, loss_test:0.01222, lr:1.00e-02, fs:0.87783 (r=0.980,p=0.795),  time:35.049, tt:6063.493\n",
      "Ep:173, loss:0.00001, loss_test:0.01221, lr:1.00e-02, fs:0.87783 (r=0.980,p=0.795),  time:35.045, tt:6097.778\n",
      "Ep:174, loss:0.00001, loss_test:0.01220, lr:1.00e-02, fs:0.87783 (r=0.980,p=0.795),  time:35.050, tt:6133.681\n",
      "Ep:175, loss:0.00001, loss_test:0.01219, lr:1.00e-02, fs:0.87783 (r=0.980,p=0.795),  time:35.047, tt:6168.205\n",
      "Ep:176, loss:0.00001, loss_test:0.01218, lr:1.00e-02, fs:0.87783 (r=0.980,p=0.795),  time:35.050, tt:6203.925\n",
      "Ep:177, loss:0.00001, loss_test:0.01215, lr:1.00e-02, fs:0.87783 (r=0.980,p=0.795),  time:35.056, tt:6239.961\n",
      "Ep:178, loss:0.00001, loss_test:0.01213, lr:1.00e-02, fs:0.87783 (r=0.980,p=0.795),  time:35.062, tt:6276.125\n",
      "Ep:179, loss:0.00001, loss_test:0.01213, lr:9.90e-03, fs:0.87783 (r=0.980,p=0.795),  time:35.071, tt:6312.746\n",
      "Ep:180, loss:0.00001, loss_test:0.01211, lr:9.80e-03, fs:0.87783 (r=0.980,p=0.795),  time:35.084, tt:6350.200\n",
      "Ep:181, loss:0.00001, loss_test:0.01210, lr:9.70e-03, fs:0.87273 (r=0.970,p=0.793),  time:35.088, tt:6386.076\n",
      "Ep:182, loss:0.00001, loss_test:0.01209, lr:9.61e-03, fs:0.87783 (r=0.980,p=0.795),  time:35.093, tt:6422.007\n",
      "Ep:183, loss:0.00001, loss_test:0.01208, lr:9.51e-03, fs:0.87273 (r=0.970,p=0.793),  time:35.089, tt:6456.413\n",
      "Ep:184, loss:0.00001, loss_test:0.01207, lr:9.41e-03, fs:0.87273 (r=0.970,p=0.793),  time:35.090, tt:6491.705\n",
      "Ep:185, loss:0.00001, loss_test:0.01207, lr:9.32e-03, fs:0.87273 (r=0.970,p=0.793),  time:35.094, tt:6527.479\n",
      "Ep:186, loss:0.00001, loss_test:0.01207, lr:9.23e-03, fs:0.87273 (r=0.970,p=0.793),  time:35.095, tt:6562.679\n",
      "Ep:187, loss:0.00001, loss_test:0.01206, lr:9.14e-03, fs:0.87273 (r=0.970,p=0.793),  time:35.098, tt:6598.407\n",
      "Ep:188, loss:0.00001, loss_test:0.01205, lr:9.04e-03, fs:0.87273 (r=0.970,p=0.793),  time:35.098, tt:6633.443\n",
      "Ep:189, loss:0.00001, loss_test:0.01204, lr:8.95e-03, fs:0.86758 (r=0.960,p=0.792),  time:35.120, tt:6672.848\n",
      "Ep:190, loss:0.00001, loss_test:0.01204, lr:8.86e-03, fs:0.86758 (r=0.960,p=0.792),  time:35.122, tt:6708.328\n",
      "Ep:191, loss:0.00001, loss_test:0.01203, lr:8.78e-03, fs:0.86758 (r=0.960,p=0.792),  time:35.124, tt:6743.724\n",
      "Ep:192, loss:0.00001, loss_test:0.01202, lr:8.69e-03, fs:0.86239 (r=0.949,p=0.790),  time:35.124, tt:6779.026\n",
      "Ep:193, loss:0.00001, loss_test:0.01201, lr:8.60e-03, fs:0.86239 (r=0.949,p=0.790),  time:35.128, tt:6814.881\n",
      "Ep:194, loss:0.00001, loss_test:0.01201, lr:8.51e-03, fs:0.86239 (r=0.949,p=0.790),  time:35.133, tt:6850.941\n",
      "Ep:195, loss:0.00001, loss_test:0.01200, lr:8.43e-03, fs:0.86239 (r=0.949,p=0.790),  time:35.137, tt:6886.853\n",
      "Ep:196, loss:0.00001, loss_test:0.01199, lr:8.35e-03, fs:0.86239 (r=0.949,p=0.790),  time:35.135, tt:6921.550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:197, loss:0.00001, loss_test:0.01199, lr:8.26e-03, fs:0.86239 (r=0.949,p=0.790),  time:35.132, tt:6956.137\n",
      "Ep:198, loss:0.00001, loss_test:0.01198, lr:8.18e-03, fs:0.86239 (r=0.949,p=0.790),  time:35.139, tt:6992.613\n",
      "Ep:199, loss:0.00001, loss_test:0.01198, lr:8.10e-03, fs:0.86239 (r=0.949,p=0.790),  time:35.133, tt:7026.533\n",
      "Ep:200, loss:0.00001, loss_test:0.01197, lr:8.02e-03, fs:0.86239 (r=0.949,p=0.790),  time:35.133, tt:7061.793\n",
      "Ep:201, loss:0.00001, loss_test:0.01196, lr:7.94e-03, fs:0.86239 (r=0.949,p=0.790),  time:35.130, tt:7096.201\n",
      "Ep:202, loss:0.00001, loss_test:0.01196, lr:7.86e-03, fs:0.86239 (r=0.949,p=0.790),  time:35.131, tt:7131.520\n",
      "Ep:203, loss:0.00001, loss_test:0.01196, lr:7.78e-03, fs:0.86239 (r=0.949,p=0.790),  time:35.132, tt:7166.864\n",
      "Ep:204, loss:0.00001, loss_test:0.01195, lr:7.70e-03, fs:0.86239 (r=0.949,p=0.790),  time:35.127, tt:7201.020\n",
      "Ep:205, loss:0.00001, loss_test:0.01195, lr:7.62e-03, fs:0.86636 (r=0.949,p=0.797),  time:35.104, tt:7231.494\n",
      "Ep:206, loss:0.00001, loss_test:0.01194, lr:7.55e-03, fs:0.86636 (r=0.949,p=0.797),  time:35.063, tt:7257.981\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02682, lr:1.00e-02, fs:0.56442 (r=0.465,p=0.719),  time:31.427, tt:31.427\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00006, loss_test:0.02074, lr:1.00e-02, fs:0.61472 (r=0.717,p=0.538),  time:34.304, tt:68.608\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02020, lr:1.00e-02, fs:0.67138 (r=0.960,p=0.516),  time:35.812, tt:107.437\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02126, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:36.777, tt:147.109\n",
      "Ep:4, loss:0.00004, loss_test:0.02217, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.010, tt:185.049\n",
      "Ep:5, loss:0.00004, loss_test:0.02258, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.811, tt:226.867\n",
      "Ep:6, loss:0.00004, loss_test:0.02254, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.844, tt:264.906\n",
      "Ep:7, loss:0.00004, loss_test:0.02221, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.784, tt:302.273\n",
      "Ep:8, loss:0.00004, loss_test:0.02173, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.104, tt:342.932\n",
      "Ep:9, loss:0.00004, loss_test:0.02111, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.233, tt:382.327\n",
      "Ep:10, loss:0.00004, loss_test:0.02043, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.152, tt:419.677\n",
      "Ep:11, loss:0.00004, loss_test:0.01975, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:38.243, tt:458.917\n",
      "Ep:12, loss:0.00004, loss_test:0.01912, lr:1.00e-02, fs:0.67808 (r=1.000,p=0.513),  time:38.500, tt:500.506\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01858, lr:1.00e-02, fs:0.68293 (r=0.990,p=0.521),  time:38.610, tt:540.538\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01815, lr:1.00e-02, fs:0.69314 (r=0.970,p=0.539),  time:38.682, tt:580.238\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.01781, lr:1.00e-02, fs:0.70632 (r=0.960,p=0.559),  time:38.630, tt:618.073\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.01756, lr:1.00e-02, fs:0.70455 (r=0.939,p=0.564),  time:38.604, tt:656.267\n",
      "Ep:17, loss:0.00003, loss_test:0.01738, lr:1.00e-02, fs:0.71264 (r=0.939,p=0.574),  time:38.631, tt:695.365\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01724, lr:1.00e-02, fs:0.72510 (r=0.919,p=0.599),  time:38.598, tt:733.363\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01711, lr:1.00e-02, fs:0.72800 (r=0.919,p=0.603),  time:38.687, tt:773.746\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01701, lr:1.00e-02, fs:0.73307 (r=0.929,p=0.605),  time:38.738, tt:813.494\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01691, lr:1.00e-02, fs:0.73228 (r=0.939,p=0.600),  time:38.648, tt:850.263\n",
      "Ep:22, loss:0.00003, loss_test:0.01683, lr:1.00e-02, fs:0.72868 (r=0.949,p=0.591),  time:38.667, tt:889.338\n",
      "Ep:23, loss:0.00003, loss_test:0.01674, lr:1.00e-02, fs:0.72308 (r=0.949,p=0.584),  time:38.641, tt:927.381\n",
      "Ep:24, loss:0.00003, loss_test:0.01664, lr:1.00e-02, fs:0.72587 (r=0.949,p=0.588),  time:38.669, tt:966.728\n",
      "Ep:25, loss:0.00003, loss_test:0.01654, lr:1.00e-02, fs:0.73077 (r=0.960,p=0.590),  time:38.728, tt:1006.935\n",
      "Ep:26, loss:0.00003, loss_test:0.01644, lr:1.00e-02, fs:0.73643 (r=0.960,p=0.597),  time:38.667, tt:1044.010\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01634, lr:1.00e-02, fs:0.73930 (r=0.960,p=0.601),  time:38.699, tt:1083.558\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01624, lr:1.00e-02, fs:0.74510 (r=0.960,p=0.609),  time:38.765, tt:1124.182\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01615, lr:1.00e-02, fs:0.74510 (r=0.960,p=0.609),  time:38.776, tt:1163.281\n",
      "Ep:30, loss:0.00003, loss_test:0.01607, lr:1.00e-02, fs:0.74803 (r=0.960,p=0.613),  time:38.834, tt:1203.848\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01599, lr:1.00e-02, fs:0.74803 (r=0.960,p=0.613),  time:38.836, tt:1242.767\n",
      "Ep:32, loss:0.00003, loss_test:0.01592, lr:1.00e-02, fs:0.74803 (r=0.960,p=0.613),  time:38.793, tt:1280.166\n",
      "Ep:33, loss:0.00003, loss_test:0.01584, lr:1.00e-02, fs:0.75294 (r=0.970,p=0.615),  time:38.761, tt:1317.857\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01578, lr:1.00e-02, fs:0.75294 (r=0.970,p=0.615),  time:38.774, tt:1357.092\n",
      "Ep:35, loss:0.00003, loss_test:0.01571, lr:1.00e-02, fs:0.75591 (r=0.970,p=0.619),  time:38.832, tt:1397.946\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01563, lr:1.00e-02, fs:0.75889 (r=0.970,p=0.623),  time:38.861, tt:1437.868\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00003, loss_test:0.01556, lr:1.00e-02, fs:0.76190 (r=0.970,p=0.627),  time:38.885, tt:1477.627\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.01548, lr:1.00e-02, fs:0.76494 (r=0.970,p=0.632),  time:38.954, tt:1519.220\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.01541, lr:1.00e-02, fs:0.76494 (r=0.970,p=0.632),  time:39.020, tt:1560.780\n",
      "Ep:40, loss:0.00003, loss_test:0.01535, lr:1.00e-02, fs:0.76494 (r=0.970,p=0.632),  time:39.020, tt:1599.802\n",
      "Ep:41, loss:0.00003, loss_test:0.01528, lr:1.00e-02, fs:0.77291 (r=0.980,p=0.638),  time:39.052, tt:1640.197\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.01522, lr:1.00e-02, fs:0.77600 (r=0.980,p=0.642),  time:39.066, tt:1679.845\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00003, loss_test:0.01516, lr:1.00e-02, fs:0.77600 (r=0.980,p=0.642),  time:39.062, tt:1718.733\n",
      "Ep:44, loss:0.00003, loss_test:0.01510, lr:1.00e-02, fs:0.78226 (r=0.980,p=0.651),  time:39.090, tt:1759.028\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00003, loss_test:0.01505, lr:1.00e-02, fs:0.78862 (r=0.980,p=0.660),  time:39.075, tt:1797.449\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00003, loss_test:0.01500, lr:1.00e-02, fs:0.78862 (r=0.980,p=0.660),  time:39.085, tt:1837.015\n",
      "Ep:47, loss:0.00003, loss_test:0.01495, lr:1.00e-02, fs:0.78862 (r=0.980,p=0.660),  time:39.090, tt:1876.330\n",
      "Ep:48, loss:0.00003, loss_test:0.01489, lr:1.00e-02, fs:0.78862 (r=0.980,p=0.660),  time:39.105, tt:1916.153\n",
      "Ep:49, loss:0.00003, loss_test:0.01484, lr:1.00e-02, fs:0.79184 (r=0.980,p=0.664),  time:39.145, tt:1957.240\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00003, loss_test:0.01479, lr:1.00e-02, fs:0.79508 (r=0.980,p=0.669),  time:39.180, tt:1998.202\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:51, loss:0.00003, loss_test:0.01473, lr:1.00e-02, fs:0.79835 (r=0.980,p=0.674),  time:39.168, tt:2036.712\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00003, loss_test:0.01468, lr:1.00e-02, fs:0.79835 (r=0.980,p=0.674),  time:39.191, tt:2077.140\n",
      "Ep:53, loss:0.00003, loss_test:0.01463, lr:1.00e-02, fs:0.80165 (r=0.980,p=0.678),  time:39.181, tt:2115.775\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00003, loss_test:0.01457, lr:1.00e-02, fs:0.80165 (r=0.980,p=0.678),  time:39.190, tt:2155.453\n",
      "Ep:55, loss:0.00003, loss_test:0.01452, lr:1.00e-02, fs:0.80165 (r=0.980,p=0.678),  time:39.190, tt:2194.628\n",
      "Ep:56, loss:0.00003, loss_test:0.01446, lr:1.00e-02, fs:0.80498 (r=0.980,p=0.683),  time:39.205, tt:2234.699\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00003, loss_test:0.01441, lr:1.00e-02, fs:0.80498 (r=0.980,p=0.683),  time:39.228, tt:2275.238\n",
      "Ep:58, loss:0.00003, loss_test:0.01436, lr:1.00e-02, fs:0.80498 (r=0.980,p=0.683),  time:39.231, tt:2314.640\n",
      "Ep:59, loss:0.00002, loss_test:0.01431, lr:1.00e-02, fs:0.80498 (r=0.980,p=0.683),  time:39.268, tt:2356.084\n",
      "Ep:60, loss:0.00002, loss_test:0.01426, lr:1.00e-02, fs:0.80498 (r=0.980,p=0.683),  time:39.275, tt:2395.775\n",
      "Ep:61, loss:0.00002, loss_test:0.01421, lr:1.00e-02, fs:0.80498 (r=0.980,p=0.683),  time:39.276, tt:2435.127\n",
      "Ep:62, loss:0.00002, loss_test:0.01417, lr:1.00e-02, fs:0.80498 (r=0.980,p=0.683),  time:39.284, tt:2474.906\n",
      "Ep:63, loss:0.00002, loss_test:0.01412, lr:1.00e-02, fs:0.80498 (r=0.980,p=0.683),  time:39.303, tt:2515.411\n",
      "Ep:64, loss:0.00002, loss_test:0.01408, lr:1.00e-02, fs:0.81172 (r=0.980,p=0.693),  time:39.309, tt:2555.107\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00002, loss_test:0.01404, lr:1.00e-02, fs:0.81172 (r=0.980,p=0.693),  time:39.359, tt:2597.692\n",
      "Ep:66, loss:0.00002, loss_test:0.01399, lr:1.00e-02, fs:0.81513 (r=0.980,p=0.698),  time:39.360, tt:2637.111\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00002, loss_test:0.01395, lr:1.00e-02, fs:0.81513 (r=0.980,p=0.698),  time:39.365, tt:2676.791\n",
      "Ep:68, loss:0.00002, loss_test:0.01390, lr:1.00e-02, fs:0.81513 (r=0.980,p=0.698),  time:39.353, tt:2715.358\n",
      "Ep:69, loss:0.00002, loss_test:0.01386, lr:1.00e-02, fs:0.81513 (r=0.980,p=0.698),  time:39.371, tt:2755.949\n",
      "Ep:70, loss:0.00002, loss_test:0.01382, lr:1.00e-02, fs:0.81513 (r=0.980,p=0.698),  time:39.382, tt:2796.112\n",
      "Ep:71, loss:0.00002, loss_test:0.01378, lr:1.00e-02, fs:0.81513 (r=0.980,p=0.698),  time:39.392, tt:2836.228\n",
      "Ep:72, loss:0.00002, loss_test:0.01374, lr:1.00e-02, fs:0.81513 (r=0.980,p=0.698),  time:39.397, tt:2875.967\n",
      "Ep:73, loss:0.00002, loss_test:0.01370, lr:1.00e-02, fs:0.81857 (r=0.980,p=0.703),  time:39.418, tt:2916.938\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00002, loss_test:0.01366, lr:1.00e-02, fs:0.81857 (r=0.980,p=0.703),  time:39.400, tt:2954.993\n",
      "Ep:75, loss:0.00002, loss_test:0.01362, lr:1.00e-02, fs:0.81857 (r=0.980,p=0.703),  time:39.397, tt:2994.188\n",
      "Ep:76, loss:0.00002, loss_test:0.01358, lr:1.00e-02, fs:0.81513 (r=0.980,p=0.698),  time:39.406, tt:3034.287\n",
      "Ep:77, loss:0.00002, loss_test:0.01355, lr:1.00e-02, fs:0.81857 (r=0.980,p=0.703),  time:39.404, tt:3073.525\n",
      "Ep:78, loss:0.00002, loss_test:0.01352, lr:1.00e-02, fs:0.82203 (r=0.980,p=0.708),  time:39.377, tt:3110.760\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00002, loss_test:0.01349, lr:1.00e-02, fs:0.82553 (r=0.980,p=0.713),  time:39.367, tt:3149.384\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00002, loss_test:0.01346, lr:1.00e-02, fs:0.82906 (r=0.980,p=0.719),  time:39.379, tt:3189.738\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00002, loss_test:0.01343, lr:1.00e-02, fs:0.82906 (r=0.980,p=0.719),  time:39.396, tt:3230.452\n",
      "Ep:82, loss:0.00002, loss_test:0.01340, lr:1.00e-02, fs:0.82906 (r=0.980,p=0.719),  time:39.412, tt:3271.236\n",
      "Ep:83, loss:0.00002, loss_test:0.01337, lr:1.00e-02, fs:0.82906 (r=0.980,p=0.719),  time:39.412, tt:3310.587\n",
      "Ep:84, loss:0.00002, loss_test:0.01334, lr:1.00e-02, fs:0.82906 (r=0.980,p=0.719),  time:39.421, tt:3350.751\n",
      "Ep:85, loss:0.00002, loss_test:0.01331, lr:1.00e-02, fs:0.82906 (r=0.980,p=0.719),  time:39.418, tt:3389.974\n",
      "Ep:86, loss:0.00002, loss_test:0.01328, lr:1.00e-02, fs:0.83621 (r=0.980,p=0.729),  time:39.423, tt:3429.781\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00002, loss_test:0.01324, lr:1.00e-02, fs:0.83621 (r=0.980,p=0.729),  time:39.422, tt:3469.125\n",
      "Ep:88, loss:0.00002, loss_test:0.01321, lr:1.00e-02, fs:0.83621 (r=0.980,p=0.729),  time:39.413, tt:3507.800\n",
      "Ep:89, loss:0.00002, loss_test:0.01318, lr:1.00e-02, fs:0.83621 (r=0.980,p=0.729),  time:39.409, tt:3546.766\n",
      "Ep:90, loss:0.00002, loss_test:0.01315, lr:1.00e-02, fs:0.83621 (r=0.980,p=0.729),  time:39.418, tt:3587.080\n",
      "Ep:91, loss:0.00002, loss_test:0.01312, lr:1.00e-02, fs:0.83621 (r=0.980,p=0.729),  time:39.412, tt:3625.943\n",
      "Ep:92, loss:0.00002, loss_test:0.01309, lr:1.00e-02, fs:0.83621 (r=0.980,p=0.729),  time:39.417, tt:3665.778\n",
      "Ep:93, loss:0.00002, loss_test:0.01306, lr:1.00e-02, fs:0.84120 (r=0.990,p=0.731),  time:39.409, tt:3704.486\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00002, loss_test:0.01303, lr:1.00e-02, fs:0.84120 (r=0.990,p=0.731),  time:39.410, tt:3743.932\n",
      "Ep:95, loss:0.00002, loss_test:0.01300, lr:1.00e-02, fs:0.84120 (r=0.990,p=0.731),  time:39.456, tt:3787.778\n",
      "Ep:96, loss:0.00002, loss_test:0.01297, lr:1.00e-02, fs:0.84120 (r=0.990,p=0.731),  time:39.457, tt:3827.369\n",
      "Ep:97, loss:0.00002, loss_test:0.01294, lr:1.00e-02, fs:0.84120 (r=0.990,p=0.731),  time:39.482, tt:3869.204\n",
      "Ep:98, loss:0.00002, loss_test:0.01290, lr:1.00e-02, fs:0.84120 (r=0.990,p=0.731),  time:39.486, tt:3909.075\n",
      "Ep:99, loss:0.00002, loss_test:0.01287, lr:1.00e-02, fs:0.84483 (r=0.990,p=0.737),  time:39.493, tt:3949.286\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00002, loss_test:0.01284, lr:1.00e-02, fs:0.84483 (r=0.990,p=0.737),  time:39.484, tt:3987.919\n",
      "Ep:101, loss:0.00002, loss_test:0.01280, lr:1.00e-02, fs:0.84483 (r=0.990,p=0.737),  time:39.485, tt:4027.421\n",
      "Ep:102, loss:0.00002, loss_test:0.01277, lr:1.00e-02, fs:0.84483 (r=0.990,p=0.737),  time:39.482, tt:4066.671\n",
      "Ep:103, loss:0.00002, loss_test:0.01275, lr:1.00e-02, fs:0.84848 (r=0.990,p=0.742),  time:39.475, tt:4105.407\n",
      "##########Best model found so far##########\n",
      "Ep:104, loss:0.00002, loss_test:0.01272, lr:1.00e-02, fs:0.84848 (r=0.990,p=0.742),  time:39.485, tt:4145.971\n",
      "Ep:105, loss:0.00002, loss_test:0.01269, lr:1.00e-02, fs:0.84848 (r=0.990,p=0.742),  time:39.490, tt:4185.945\n",
      "Ep:106, loss:0.00002, loss_test:0.01266, lr:1.00e-02, fs:0.85590 (r=0.990,p=0.754),  time:39.490, tt:4225.427\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00002, loss_test:0.01263, lr:1.00e-02, fs:0.85590 (r=0.990,p=0.754),  time:39.473, tt:4263.065\n",
      "Ep:108, loss:0.00002, loss_test:0.01260, lr:1.00e-02, fs:0.85590 (r=0.990,p=0.754),  time:39.479, tt:4303.197\n",
      "Ep:109, loss:0.00002, loss_test:0.01258, lr:1.00e-02, fs:0.84581 (r=0.970,p=0.750),  time:39.487, tt:4343.620\n",
      "Ep:110, loss:0.00002, loss_test:0.01254, lr:1.00e-02, fs:0.84581 (r=0.970,p=0.750),  time:39.475, tt:4381.754\n",
      "Ep:111, loss:0.00002, loss_test:0.01252, lr:1.00e-02, fs:0.84581 (r=0.970,p=0.750),  time:39.440, tt:4417.233\n",
      "Ep:112, loss:0.00002, loss_test:0.01249, lr:1.00e-02, fs:0.84581 (r=0.970,p=0.750),  time:39.443, tt:4457.053\n",
      "Ep:113, loss:0.00002, loss_test:0.01246, lr:1.00e-02, fs:0.84956 (r=0.970,p=0.756),  time:39.433, tt:4495.329\n",
      "Ep:114, loss:0.00002, loss_test:0.01243, lr:1.00e-02, fs:0.84956 (r=0.970,p=0.756),  time:39.441, tt:4535.713\n",
      "Ep:115, loss:0.00002, loss_test:0.01241, lr:1.00e-02, fs:0.85333 (r=0.970,p=0.762),  time:39.430, tt:4573.829\n",
      "Ep:116, loss:0.00002, loss_test:0.01238, lr:1.00e-02, fs:0.85714 (r=0.970,p=0.768),  time:39.428, tt:4613.019\n",
      "##########Best model found so far##########\n",
      "Ep:117, loss:0.00002, loss_test:0.01236, lr:1.00e-02, fs:0.85714 (r=0.970,p=0.768),  time:39.426, tt:4652.248\n",
      "Ep:118, loss:0.00002, loss_test:0.01233, lr:1.00e-02, fs:0.85714 (r=0.970,p=0.768),  time:39.428, tt:4691.951\n",
      "Ep:119, loss:0.00002, loss_test:0.01231, lr:1.00e-02, fs:0.85714 (r=0.970,p=0.768),  time:39.430, tt:4731.594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:120, loss:0.00002, loss_test:0.01228, lr:1.00e-02, fs:0.86099 (r=0.970,p=0.774),  time:39.426, tt:4770.585\n",
      "##########Best model found so far##########\n",
      "Ep:121, loss:0.00002, loss_test:0.01226, lr:1.00e-02, fs:0.86099 (r=0.970,p=0.774),  time:39.418, tt:4808.976\n",
      "Ep:122, loss:0.00002, loss_test:0.01223, lr:1.00e-02, fs:0.86099 (r=0.970,p=0.774),  time:39.419, tt:4848.558\n",
      "Ep:123, loss:0.00002, loss_test:0.01221, lr:1.00e-02, fs:0.86486 (r=0.970,p=0.780),  time:39.427, tt:4888.928\n",
      "##########Best model found so far##########\n",
      "Ep:124, loss:0.00002, loss_test:0.01219, lr:1.00e-02, fs:0.86486 (r=0.970,p=0.780),  time:39.436, tt:4929.477\n",
      "Ep:125, loss:0.00002, loss_test:0.01217, lr:1.00e-02, fs:0.86486 (r=0.970,p=0.780),  time:39.440, tt:4969.496\n",
      "Ep:126, loss:0.00002, loss_test:0.01215, lr:1.00e-02, fs:0.86486 (r=0.970,p=0.780),  time:39.467, tt:5012.330\n",
      "Ep:127, loss:0.00002, loss_test:0.01212, lr:1.00e-02, fs:0.86486 (r=0.970,p=0.780),  time:39.479, tt:5053.373\n",
      "Ep:128, loss:0.00002, loss_test:0.01210, lr:1.00e-02, fs:0.86486 (r=0.970,p=0.780),  time:39.486, tt:5093.672\n",
      "Ep:129, loss:0.00002, loss_test:0.01208, lr:1.00e-02, fs:0.86486 (r=0.970,p=0.780),  time:39.490, tt:5133.696\n",
      "Ep:130, loss:0.00002, loss_test:0.01205, lr:1.00e-02, fs:0.86486 (r=0.970,p=0.780),  time:39.493, tt:5173.615\n",
      "Ep:131, loss:0.00002, loss_test:0.01203, lr:1.00e-02, fs:0.86486 (r=0.970,p=0.780),  time:39.497, tt:5213.579\n",
      "Ep:132, loss:0.00002, loss_test:0.01201, lr:1.00e-02, fs:0.86486 (r=0.970,p=0.780),  time:39.493, tt:5252.543\n",
      "Ep:133, loss:0.00002, loss_test:0.01199, lr:1.00e-02, fs:0.86486 (r=0.970,p=0.780),  time:39.502, tt:5293.212\n",
      "Ep:134, loss:0.00002, loss_test:0.01197, lr:1.00e-02, fs:0.86486 (r=0.970,p=0.780),  time:39.492, tt:5331.368\n",
      "Ep:135, loss:0.00002, loss_test:0.01195, lr:9.90e-03, fs:0.86486 (r=0.970,p=0.780),  time:39.493, tt:5371.051\n",
      "Ep:136, loss:0.00002, loss_test:0.01193, lr:9.80e-03, fs:0.86486 (r=0.970,p=0.780),  time:39.493, tt:5410.487\n",
      "Ep:137, loss:0.00002, loss_test:0.01191, lr:9.70e-03, fs:0.86486 (r=0.970,p=0.780),  time:39.493, tt:5450.026\n",
      "Ep:138, loss:0.00002, loss_test:0.01189, lr:9.61e-03, fs:0.86486 (r=0.970,p=0.780),  time:39.480, tt:5487.782\n",
      "Ep:139, loss:0.00002, loss_test:0.01187, lr:9.51e-03, fs:0.86486 (r=0.970,p=0.780),  time:39.481, tt:5527.386\n",
      "Ep:140, loss:0.00002, loss_test:0.01186, lr:9.41e-03, fs:0.86486 (r=0.970,p=0.780),  time:39.487, tt:5567.655\n",
      "Ep:141, loss:0.00002, loss_test:0.01184, lr:9.32e-03, fs:0.86486 (r=0.970,p=0.780),  time:39.477, tt:5605.786\n",
      "Ep:142, loss:0.00002, loss_test:0.01182, lr:9.23e-03, fs:0.86486 (r=0.970,p=0.780),  time:39.499, tt:5648.369\n",
      "Ep:143, loss:0.00002, loss_test:0.01180, lr:9.14e-03, fs:0.86486 (r=0.970,p=0.780),  time:39.507, tt:5688.972\n",
      "Ep:144, loss:0.00002, loss_test:0.01178, lr:9.04e-03, fs:0.86486 (r=0.970,p=0.780),  time:39.516, tt:5729.876\n",
      "Ep:145, loss:0.00002, loss_test:0.01176, lr:8.95e-03, fs:0.86486 (r=0.970,p=0.780),  time:39.511, tt:5768.611\n",
      "Ep:146, loss:0.00002, loss_test:0.01175, lr:8.86e-03, fs:0.86486 (r=0.970,p=0.780),  time:39.513, tt:5808.483\n",
      "Ep:147, loss:0.00002, loss_test:0.01173, lr:8.78e-03, fs:0.86486 (r=0.970,p=0.780),  time:39.510, tt:5847.518\n",
      "Ep:148, loss:0.00002, loss_test:0.01172, lr:8.69e-03, fs:0.86486 (r=0.970,p=0.780),  time:39.515, tt:5887.781\n",
      "Ep:149, loss:0.00002, loss_test:0.01170, lr:8.60e-03, fs:0.86486 (r=0.970,p=0.780),  time:39.511, tt:5926.676\n",
      "Ep:150, loss:0.00002, loss_test:0.01168, lr:8.51e-03, fs:0.86486 (r=0.970,p=0.780),  time:39.528, tt:5968.654\n",
      "Ep:151, loss:0.00002, loss_test:0.01167, lr:8.43e-03, fs:0.86486 (r=0.970,p=0.780),  time:39.528, tt:6008.325\n",
      "Ep:152, loss:0.00001, loss_test:0.01166, lr:8.35e-03, fs:0.86486 (r=0.970,p=0.780),  time:39.536, tt:6048.952\n",
      "Ep:153, loss:0.00001, loss_test:0.01164, lr:8.26e-03, fs:0.86486 (r=0.970,p=0.780),  time:39.536, tt:6088.546\n",
      "Ep:154, loss:0.00001, loss_test:0.01163, lr:8.18e-03, fs:0.86486 (r=0.970,p=0.780),  time:39.527, tt:6126.648\n",
      "Ep:155, loss:0.00001, loss_test:0.01161, lr:8.10e-03, fs:0.86486 (r=0.970,p=0.780),  time:39.525, tt:6165.851\n",
      "Ep:156, loss:0.00001, loss_test:0.01160, lr:8.02e-03, fs:0.86486 (r=0.970,p=0.780),  time:39.526, tt:6205.634\n",
      "Ep:157, loss:0.00001, loss_test:0.01159, lr:7.94e-03, fs:0.86486 (r=0.970,p=0.780),  time:39.525, tt:6245.027\n",
      "Ep:158, loss:0.00001, loss_test:0.01158, lr:7.86e-03, fs:0.86878 (r=0.970,p=0.787),  time:39.534, tt:6285.983\n",
      "##########Best model found so far##########\n",
      "Ep:159, loss:0.00001, loss_test:0.01156, lr:7.86e-03, fs:0.86878 (r=0.970,p=0.787),  time:39.546, tt:6327.354\n",
      "Ep:160, loss:0.00001, loss_test:0.01155, lr:7.86e-03, fs:0.86878 (r=0.970,p=0.787),  time:39.544, tt:6366.586\n",
      "Ep:161, loss:0.00001, loss_test:0.01154, lr:7.86e-03, fs:0.86878 (r=0.970,p=0.787),  time:39.542, tt:6405.821\n",
      "Ep:162, loss:0.00001, loss_test:0.01153, lr:7.86e-03, fs:0.86878 (r=0.970,p=0.787),  time:39.538, tt:6444.661\n",
      "Ep:163, loss:0.00001, loss_test:0.01151, lr:7.86e-03, fs:0.86878 (r=0.970,p=0.787),  time:39.539, tt:6484.439\n",
      "Ep:164, loss:0.00001, loss_test:0.01150, lr:7.86e-03, fs:0.86878 (r=0.970,p=0.787),  time:39.536, tt:6523.367\n",
      "Ep:165, loss:0.00001, loss_test:0.01149, lr:7.86e-03, fs:0.86878 (r=0.970,p=0.787),  time:39.532, tt:6562.287\n",
      "Ep:166, loss:0.00001, loss_test:0.01147, lr:7.86e-03, fs:0.86878 (r=0.970,p=0.787),  time:39.533, tt:6602.074\n",
      "Ep:167, loss:0.00001, loss_test:0.01146, lr:7.86e-03, fs:0.86878 (r=0.970,p=0.787),  time:39.538, tt:6642.327\n",
      "Ep:168, loss:0.00001, loss_test:0.01145, lr:7.86e-03, fs:0.86878 (r=0.970,p=0.787),  time:39.533, tt:6681.010\n",
      "Ep:169, loss:0.00001, loss_test:0.01143, lr:7.86e-03, fs:0.86878 (r=0.970,p=0.787),  time:39.525, tt:6719.305\n",
      "Ep:170, loss:0.00001, loss_test:0.01142, lr:7.78e-03, fs:0.86878 (r=0.970,p=0.787),  time:39.522, tt:6758.342\n",
      "Ep:171, loss:0.00001, loss_test:0.01141, lr:7.70e-03, fs:0.86878 (r=0.970,p=0.787),  time:39.528, tt:6798.750\n",
      "Ep:172, loss:0.00001, loss_test:0.01140, lr:7.62e-03, fs:0.86878 (r=0.970,p=0.787),  time:39.536, tt:6839.653\n",
      "Ep:173, loss:0.00001, loss_test:0.01138, lr:7.55e-03, fs:0.86878 (r=0.970,p=0.787),  time:39.542, tt:6880.229\n",
      "Ep:174, loss:0.00001, loss_test:0.01137, lr:7.47e-03, fs:0.86878 (r=0.970,p=0.787),  time:39.548, tt:6920.817\n",
      "Ep:175, loss:0.00001, loss_test:0.01136, lr:7.40e-03, fs:0.86878 (r=0.970,p=0.787),  time:39.549, tt:6960.610\n",
      "Ep:176, loss:0.00001, loss_test:0.01135, lr:7.32e-03, fs:0.87273 (r=0.970,p=0.793),  time:39.565, tt:7003.058\n",
      "##########Best model found so far##########\n",
      "Ep:177, loss:0.00001, loss_test:0.01134, lr:7.32e-03, fs:0.87671 (r=0.970,p=0.800),  time:39.562, tt:7042.106\n",
      "##########Best model found so far##########\n",
      "Ep:178, loss:0.00001, loss_test:0.01133, lr:7.32e-03, fs:0.88073 (r=0.970,p=0.807),  time:39.555, tt:7080.379\n",
      "##########Best model found so far##########\n",
      "Ep:179, loss:0.00001, loss_test:0.01132, lr:7.32e-03, fs:0.88073 (r=0.970,p=0.807),  time:39.560, tt:7120.861\n",
      "Ep:180, loss:0.00001, loss_test:0.01131, lr:7.32e-03, fs:0.88073 (r=0.970,p=0.807),  time:39.558, tt:7160.029\n",
      "Ep:181, loss:0.00001, loss_test:0.01130, lr:7.32e-03, fs:0.88073 (r=0.970,p=0.807),  time:39.561, tt:7200.047\n",
      "Ep:182, loss:0.00001, loss_test:0.01129, lr:7.32e-03, fs:0.88073 (r=0.970,p=0.807),  time:39.561, tt:7239.721\n",
      "Ep:183, loss:0.00001, loss_test:0.01128, lr:7.32e-03, fs:0.88073 (r=0.970,p=0.807),  time:39.563, tt:7279.629\n",
      "Ep:184, loss:0.00001, loss_test:0.01127, lr:7.32e-03, fs:0.88073 (r=0.970,p=0.807),  time:39.567, tt:7319.899\n",
      "Ep:185, loss:0.00001, loss_test:0.01126, lr:7.32e-03, fs:0.88073 (r=0.970,p=0.807),  time:39.564, tt:7358.950\n",
      "Ep:186, loss:0.00001, loss_test:0.01125, lr:7.32e-03, fs:0.88479 (r=0.970,p=0.814),  time:39.568, tt:7399.151\n",
      "##########Best model found so far##########\n",
      "Ep:187, loss:0.00001, loss_test:0.01124, lr:7.32e-03, fs:0.88889 (r=0.970,p=0.821),  time:39.565, tt:7438.294\n",
      "##########Best model found so far##########\n",
      "Ep:188, loss:0.00001, loss_test:0.01123, lr:7.32e-03, fs:0.88889 (r=0.970,p=0.821),  time:39.576, tt:7479.862\n",
      "Ep:189, loss:0.00001, loss_test:0.01123, lr:7.32e-03, fs:0.88889 (r=0.970,p=0.821),  time:39.580, tt:7520.190\n",
      "Ep:190, loss:0.00001, loss_test:0.01121, lr:7.32e-03, fs:0.88889 (r=0.970,p=0.821),  time:39.582, tt:7560.094\n",
      "Ep:191, loss:0.00001, loss_test:0.01120, lr:7.32e-03, fs:0.88889 (r=0.970,p=0.821),  time:39.594, tt:7602.045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:192, loss:0.00001, loss_test:0.01119, lr:7.32e-03, fs:0.88889 (r=0.970,p=0.821),  time:39.609, tt:7644.471\n",
      "Ep:193, loss:0.00001, loss_test:0.01118, lr:7.32e-03, fs:0.88889 (r=0.970,p=0.821),  time:39.614, tt:7685.082\n",
      "Ep:194, loss:0.00001, loss_test:0.01117, lr:7.32e-03, fs:0.88889 (r=0.970,p=0.821),  time:39.617, tt:7725.325\n",
      "Ep:195, loss:0.00001, loss_test:0.01117, lr:7.32e-03, fs:0.88889 (r=0.970,p=0.821),  time:39.621, tt:7765.695\n",
      "Ep:196, loss:0.00001, loss_test:0.01116, lr:7.32e-03, fs:0.88889 (r=0.970,p=0.821),  time:39.633, tt:7807.662\n",
      "Ep:197, loss:0.00001, loss_test:0.01115, lr:7.32e-03, fs:0.88889 (r=0.970,p=0.821),  time:39.644, tt:7849.437\n",
      "Ep:198, loss:0.00001, loss_test:0.01114, lr:7.32e-03, fs:0.88889 (r=0.970,p=0.821),  time:39.650, tt:7890.362\n",
      "Ep:199, loss:0.00001, loss_test:0.01113, lr:7.25e-03, fs:0.88889 (r=0.970,p=0.821),  time:39.650, tt:7929.912\n",
      "Ep:200, loss:0.00001, loss_test:0.01112, lr:7.18e-03, fs:0.88889 (r=0.970,p=0.821),  time:39.648, tt:7969.195\n",
      "Ep:201, loss:0.00001, loss_test:0.01112, lr:7.11e-03, fs:0.88889 (r=0.970,p=0.821),  time:39.647, tt:8008.669\n",
      "Ep:202, loss:0.00001, loss_test:0.01111, lr:7.03e-03, fs:0.88889 (r=0.970,p=0.821),  time:39.643, tt:8047.595\n",
      "Ep:203, loss:0.00001, loss_test:0.01110, lr:6.96e-03, fs:0.88889 (r=0.970,p=0.821),  time:39.648, tt:8088.230\n",
      "Ep:204, loss:0.00001, loss_test:0.01110, lr:6.89e-03, fs:0.88889 (r=0.970,p=0.821),  time:39.638, tt:8125.708\n",
      "Ep:205, loss:0.00001, loss_test:0.01109, lr:6.83e-03, fs:0.88889 (r=0.970,p=0.821),  time:39.588, tt:8155.159\n",
      "Ep:206, loss:0.00001, loss_test:0.01108, lr:6.76e-03, fs:0.88889 (r=0.970,p=0.821),  time:39.553, tt:8187.537\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13962, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:30.736, tt:30.736\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13634, lr:1.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:32.189, tt:64.377\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.13168, lr:1.00e-02, fs:0.68571 (r=0.970,p=0.530),  time:33.557, tt:100.671\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12654, lr:1.00e-02, fs:0.66667 (r=0.899,p=0.530),  time:34.521, tt:138.084\n",
      "Ep:4, loss:0.00025, loss_test:0.12212, lr:1.00e-02, fs:0.68726 (r=0.899,p=0.556),  time:34.922, tt:174.608\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.11879, lr:1.00e-02, fs:0.69323 (r=0.879,p=0.572),  time:35.121, tt:210.729\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.11515, lr:1.00e-02, fs:0.71020 (r=0.879,p=0.596),  time:35.094, tt:245.661\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.11172, lr:1.00e-02, fs:0.71311 (r=0.879,p=0.600),  time:35.786, tt:286.286\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.10891, lr:1.00e-02, fs:0.71020 (r=0.879,p=0.596),  time:35.857, tt:322.717\n",
      "Ep:9, loss:0.00022, loss_test:0.10620, lr:1.00e-02, fs:0.73029 (r=0.889,p=0.620),  time:36.093, tt:360.931\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.10415, lr:1.00e-02, fs:0.75105 (r=0.899,p=0.645),  time:36.077, tt:396.843\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.10293, lr:1.00e-02, fs:0.73950 (r=0.889,p=0.633),  time:36.098, tt:433.173\n",
      "Ep:12, loss:0.00020, loss_test:0.10124, lr:1.00e-02, fs:0.73418 (r=0.879,p=0.630),  time:36.139, tt:469.812\n",
      "Ep:13, loss:0.00019, loss_test:0.10026, lr:1.00e-02, fs:0.73504 (r=0.869,p=0.637),  time:36.124, tt:505.739\n",
      "Ep:14, loss:0.00019, loss_test:0.09950, lr:1.00e-02, fs:0.74459 (r=0.869,p=0.652),  time:36.192, tt:542.875\n",
      "Ep:15, loss:0.00018, loss_test:0.09772, lr:1.00e-02, fs:0.75771 (r=0.869,p=0.672),  time:36.151, tt:578.416\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.09686, lr:1.00e-02, fs:0.75676 (r=0.848,p=0.683),  time:36.061, tt:613.037\n",
      "Ep:17, loss:0.00017, loss_test:0.09684, lr:1.00e-02, fs:0.74775 (r=0.838,p=0.675),  time:36.109, tt:649.965\n",
      "Ep:18, loss:0.00017, loss_test:0.09376, lr:1.00e-02, fs:0.75926 (r=0.828,p=0.701),  time:36.081, tt:685.540\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.09400, lr:1.00e-02, fs:0.76147 (r=0.838,p=0.697),  time:36.088, tt:721.752\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.09294, lr:1.00e-02, fs:0.75576 (r=0.828,p=0.695),  time:36.030, tt:756.629\n",
      "Ep:21, loss:0.00015, loss_test:0.09211, lr:1.00e-02, fs:0.76712 (r=0.848,p=0.700),  time:36.097, tt:794.133\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.09177, lr:1.00e-02, fs:0.76923 (r=0.859,p=0.697),  time:36.080, tt:829.840\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.09004, lr:1.00e-02, fs:0.77273 (r=0.859,p=0.702),  time:36.034, tt:864.810\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.08980, lr:1.00e-02, fs:0.74545 (r=0.828,p=0.678),  time:36.018, tt:900.441\n",
      "Ep:25, loss:0.00013, loss_test:0.08743, lr:1.00e-02, fs:0.77828 (r=0.869,p=0.705),  time:36.012, tt:936.300\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.08777, lr:1.00e-02, fs:0.75229 (r=0.828,p=0.689),  time:35.987, tt:971.656\n",
      "Ep:27, loss:0.00013, loss_test:0.08515, lr:1.00e-02, fs:0.75576 (r=0.828,p=0.695),  time:35.993, tt:1007.803\n",
      "Ep:28, loss:0.00012, loss_test:0.08469, lr:1.00e-02, fs:0.76364 (r=0.848,p=0.694),  time:35.933, tt:1042.062\n",
      "Ep:29, loss:0.00012, loss_test:0.08320, lr:1.00e-02, fs:0.77358 (r=0.828,p=0.726),  time:35.914, tt:1077.429\n",
      "Ep:30, loss:0.00012, loss_test:0.08225, lr:1.00e-02, fs:0.78539 (r=0.869,p=0.717),  time:35.962, tt:1114.829\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00011, loss_test:0.08074, lr:1.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:35.951, tt:1150.435\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00011, loss_test:0.07974, lr:1.00e-02, fs:0.80000 (r=0.869,p=0.741),  time:35.953, tt:1186.459\n",
      "Ep:33, loss:0.00011, loss_test:0.07909, lr:1.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:35.954, tt:1222.450\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.07887, lr:1.00e-02, fs:0.81690 (r=0.879,p=0.763),  time:35.999, tt:1259.971\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00010, loss_test:0.07730, lr:1.00e-02, fs:0.82075 (r=0.879,p=0.770),  time:35.939, tt:1293.802\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00009, loss_test:0.07853, lr:1.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:35.934, tt:1329.551\n",
      "Ep:37, loss:0.00009, loss_test:0.07486, lr:1.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:35.935, tt:1365.522\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.07984, lr:1.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:35.920, tt:1400.874\n",
      "Ep:39, loss:0.00009, loss_test:0.07386, lr:1.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:36.004, tt:1440.170\n",
      "Ep:40, loss:0.00009, loss_test:0.07524, lr:1.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:35.960, tt:1474.345\n",
      "Ep:41, loss:0.00008, loss_test:0.07622, lr:1.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:35.922, tt:1508.707\n",
      "Ep:42, loss:0.00008, loss_test:0.07204, lr:1.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:35.904, tt:1543.875\n",
      "Ep:43, loss:0.00008, loss_test:0.07320, lr:1.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:35.889, tt:1579.122\n",
      "Ep:44, loss:0.00007, loss_test:0.07200, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:35.898, tt:1615.405\n",
      "Ep:45, loss:0.00007, loss_test:0.07329, lr:1.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:35.876, tt:1650.277\n",
      "Ep:46, loss:0.00007, loss_test:0.07574, lr:1.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:35.886, tt:1686.628\n",
      "Ep:47, loss:0.00007, loss_test:0.07077, lr:1.00e-02, fs:0.85149 (r=0.869,p=0.835),  time:35.866, tt:1721.548\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:48, loss:0.00007, loss_test:0.06862, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:35.861, tt:1757.201\n",
      "Ep:49, loss:0.00007, loss_test:0.07428, lr:1.00e-02, fs:0.80392 (r=0.828,p=0.781),  time:35.852, tt:1792.604\n",
      "Ep:50, loss:0.00006, loss_test:0.07217, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:35.849, tt:1828.287\n",
      "Ep:51, loss:0.00006, loss_test:0.06711, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:35.808, tt:1862.014\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00006, loss_test:0.07139, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:35.798, tt:1897.314\n",
      "Ep:53, loss:0.00006, loss_test:0.07443, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:35.776, tt:1931.890\n",
      "Ep:54, loss:0.00006, loss_test:0.07282, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:35.735, tt:1965.417\n",
      "Ep:55, loss:0.00005, loss_test:0.06633, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:35.739, tt:2001.384\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00005, loss_test:0.06968, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:35.745, tt:2037.481\n",
      "Ep:57, loss:0.00005, loss_test:0.06784, lr:1.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:35.762, tt:2074.205\n",
      "Ep:58, loss:0.00005, loss_test:0.07067, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:35.793, tt:2111.807\n",
      "Ep:59, loss:0.00005, loss_test:0.06559, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.820, tt:2149.226\n",
      "Ep:60, loss:0.00005, loss_test:0.06650, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:35.874, tt:2188.310\n",
      "Ep:61, loss:0.00005, loss_test:0.06129, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:35.895, tt:2225.477\n",
      "Ep:62, loss:0.00005, loss_test:0.06397, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.940, tt:2264.214\n",
      "Ep:63, loss:0.00005, loss_test:0.07892, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:35.936, tt:2299.916\n",
      "Ep:64, loss:0.00005, loss_test:0.06177, lr:1.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:35.943, tt:2336.300\n",
      "Ep:65, loss:0.00005, loss_test:0.06581, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:35.931, tt:2371.434\n",
      "Ep:66, loss:0.00004, loss_test:0.06847, lr:1.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:35.975, tt:2410.306\n",
      "Ep:67, loss:0.00004, loss_test:0.07240, lr:9.90e-03, fs:0.83243 (r=0.778,p=0.895),  time:36.030, tt:2450.046\n",
      "Ep:68, loss:0.00004, loss_test:0.06236, lr:9.80e-03, fs:0.86598 (r=0.848,p=0.884),  time:36.056, tt:2487.892\n",
      "Ep:69, loss:0.00004, loss_test:0.07308, lr:9.70e-03, fs:0.80851 (r=0.768,p=0.854),  time:36.057, tt:2523.964\n",
      "Ep:70, loss:0.00004, loss_test:0.07196, lr:9.61e-03, fs:0.81720 (r=0.768,p=0.874),  time:36.042, tt:2558.956\n",
      "Ep:71, loss:0.00004, loss_test:0.06300, lr:9.51e-03, fs:0.86458 (r=0.838,p=0.892),  time:36.050, tt:2595.623\n",
      "Ep:72, loss:0.00004, loss_test:0.07026, lr:9.41e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.079, tt:2633.778\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00004, loss_test:0.07531, lr:9.41e-03, fs:0.78788 (r=0.788,p=0.788),  time:36.084, tt:2670.192\n",
      "Ep:74, loss:0.00004, loss_test:0.06272, lr:9.41e-03, fs:0.87831 (r=0.838,p=0.922),  time:36.099, tt:2707.391\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00004, loss_test:0.06605, lr:9.41e-03, fs:0.83060 (r=0.768,p=0.905),  time:36.119, tt:2745.070\n",
      "Ep:76, loss:0.00003, loss_test:0.07024, lr:9.41e-03, fs:0.84211 (r=0.808,p=0.879),  time:36.153, tt:2783.770\n",
      "Ep:77, loss:0.00003, loss_test:0.06500, lr:9.41e-03, fs:0.84783 (r=0.788,p=0.918),  time:36.182, tt:2822.229\n",
      "Ep:78, loss:0.00003, loss_test:0.06709, lr:9.41e-03, fs:0.82609 (r=0.768,p=0.894),  time:36.198, tt:2859.673\n",
      "Ep:79, loss:0.00003, loss_test:0.06732, lr:9.41e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.217, tt:2897.384\n",
      "Ep:80, loss:0.00003, loss_test:0.06672, lr:9.41e-03, fs:0.82609 (r=0.768,p=0.894),  time:36.239, tt:2935.375\n",
      "Ep:81, loss:0.00003, loss_test:0.06921, lr:9.41e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.267, tt:2973.886\n",
      "Ep:82, loss:0.00003, loss_test:0.06307, lr:9.41e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.308, tt:3013.549\n",
      "Ep:83, loss:0.00003, loss_test:0.06272, lr:9.41e-03, fs:0.88298 (r=0.838,p=0.933),  time:36.336, tt:3052.216\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00003, loss_test:0.07214, lr:9.41e-03, fs:0.80851 (r=0.768,p=0.854),  time:36.372, tt:3091.578\n",
      "Ep:85, loss:0.00003, loss_test:0.06578, lr:9.41e-03, fs:0.83871 (r=0.788,p=0.897),  time:36.398, tt:3130.194\n",
      "Ep:86, loss:0.00003, loss_test:0.06440, lr:9.41e-03, fs:0.87234 (r=0.828,p=0.921),  time:36.417, tt:3168.316\n",
      "Ep:87, loss:0.00003, loss_test:0.07348, lr:9.41e-03, fs:0.79581 (r=0.768,p=0.826),  time:36.440, tt:3206.722\n",
      "Ep:88, loss:0.00003, loss_test:0.06943, lr:9.41e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.454, tt:3244.417\n",
      "Ep:89, loss:0.00003, loss_test:0.06202, lr:9.41e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.482, tt:3283.414\n",
      "Ep:90, loss:0.00003, loss_test:0.07336, lr:9.41e-03, fs:0.81081 (r=0.758,p=0.872),  time:36.506, tt:3322.017\n",
      "Ep:91, loss:0.00003, loss_test:0.06270, lr:9.41e-03, fs:0.86772 (r=0.828,p=0.911),  time:36.515, tt:3359.416\n",
      "Ep:92, loss:0.00003, loss_test:0.06349, lr:9.41e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.514, tt:3395.832\n",
      "Ep:93, loss:0.00002, loss_test:0.07247, lr:9.41e-03, fs:0.83060 (r=0.768,p=0.905),  time:36.522, tt:3433.022\n",
      "Ep:94, loss:0.00002, loss_test:0.06232, lr:9.41e-03, fs:0.86772 (r=0.828,p=0.911),  time:36.570, tt:3474.158\n",
      "Ep:95, loss:0.00002, loss_test:0.07411, lr:9.32e-03, fs:0.81967 (r=0.758,p=0.893),  time:36.585, tt:3512.121\n",
      "Ep:96, loss:0.00002, loss_test:0.06508, lr:9.23e-03, fs:0.83060 (r=0.768,p=0.905),  time:36.596, tt:3549.851\n",
      "Ep:97, loss:0.00002, loss_test:0.06524, lr:9.14e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.605, tt:3587.312\n",
      "Ep:98, loss:0.00002, loss_test:0.06796, lr:9.04e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.605, tt:3623.900\n",
      "Ep:99, loss:0.00002, loss_test:0.06444, lr:8.95e-03, fs:0.85561 (r=0.808,p=0.909),  time:36.615, tt:3661.466\n",
      "Ep:100, loss:0.00002, loss_test:0.07210, lr:8.86e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.639, tt:3700.514\n",
      "Ep:101, loss:0.00002, loss_test:0.06493, lr:8.78e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.656, tt:3738.931\n",
      "Ep:102, loss:0.00002, loss_test:0.06689, lr:8.69e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.664, tt:3776.386\n",
      "Ep:103, loss:0.00002, loss_test:0.06867, lr:8.60e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.667, tt:3813.363\n",
      "Ep:104, loss:0.00002, loss_test:0.06551, lr:8.51e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.683, tt:3851.689\n",
      "Ep:105, loss:0.00002, loss_test:0.06874, lr:8.43e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.694, tt:3889.587\n",
      "Ep:106, loss:0.00002, loss_test:0.06476, lr:8.35e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.707, tt:3927.667\n",
      "Ep:107, loss:0.00002, loss_test:0.07224, lr:8.26e-03, fs:0.82162 (r=0.768,p=0.884),  time:36.717, tt:3965.426\n",
      "Ep:108, loss:0.00002, loss_test:0.06586, lr:8.18e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.733, tt:4003.862\n",
      "Ep:109, loss:0.00002, loss_test:0.06786, lr:8.10e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.732, tt:4040.524\n",
      "Ep:110, loss:0.00002, loss_test:0.06871, lr:8.02e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.750, tt:4079.195\n",
      "Ep:111, loss:0.00002, loss_test:0.06520, lr:7.94e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.756, tt:4116.703\n",
      "Ep:112, loss:0.00002, loss_test:0.07205, lr:7.86e-03, fs:0.83060 (r=0.768,p=0.905),  time:36.780, tt:4156.175\n",
      "Ep:113, loss:0.00002, loss_test:0.06592, lr:7.78e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.786, tt:4193.586\n",
      "Ep:114, loss:0.00002, loss_test:0.07089, lr:7.70e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.794, tt:4231.252\n",
      "Ep:115, loss:0.00002, loss_test:0.06802, lr:7.62e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.811, tt:4270.082\n",
      "Ep:116, loss:0.00001, loss_test:0.07189, lr:7.55e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.816, tt:4307.506\n",
      "Ep:117, loss:0.00002, loss_test:0.06850, lr:7.47e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.827, tt:4345.601\n",
      "Ep:118, loss:0.00001, loss_test:0.06836, lr:7.40e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.842, tt:4384.240\n",
      "Ep:119, loss:0.00001, loss_test:0.07175, lr:7.32e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.844, tt:4421.292\n",
      "Ep:120, loss:0.00001, loss_test:0.06532, lr:7.25e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.853, tt:4459.215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:121, loss:0.00001, loss_test:0.07455, lr:7.18e-03, fs:0.82022 (r=0.737,p=0.924),  time:36.869, tt:4497.987\n",
      "Ep:122, loss:0.00001, loss_test:0.06414, lr:7.11e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.880, tt:4536.203\n",
      "Ep:123, loss:0.00001, loss_test:0.07564, lr:7.03e-03, fs:0.79545 (r=0.707,p=0.909),  time:36.907, tt:4576.513\n",
      "Ep:124, loss:0.00001, loss_test:0.06583, lr:6.96e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.910, tt:4613.765\n",
      "Ep:125, loss:0.00001, loss_test:0.07356, lr:6.89e-03, fs:0.81564 (r=0.737,p=0.912),  time:36.910, tt:4650.624\n",
      "Ep:126, loss:0.00001, loss_test:0.06640, lr:6.83e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.915, tt:4688.205\n",
      "Ep:127, loss:0.00001, loss_test:0.07318, lr:6.76e-03, fs:0.82682 (r=0.747,p=0.925),  time:36.925, tt:4726.395\n",
      "Ep:128, loss:0.00001, loss_test:0.06849, lr:6.69e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.925, tt:4763.338\n",
      "Ep:129, loss:0.00001, loss_test:0.07241, lr:6.62e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.937, tt:4801.786\n",
      "Ep:130, loss:0.00001, loss_test:0.06774, lr:6.56e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.940, tt:4839.133\n",
      "Ep:131, loss:0.00001, loss_test:0.07175, lr:6.49e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.997, tt:4883.664\n",
      "Ep:132, loss:0.00001, loss_test:0.06896, lr:6.43e-03, fs:0.83978 (r=0.768,p=0.927),  time:37.001, tt:4921.187\n",
      "Ep:133, loss:0.00001, loss_test:0.07109, lr:6.36e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.995, tt:4957.281\n",
      "Ep:134, loss:0.00001, loss_test:0.06819, lr:6.30e-03, fs:0.83978 (r=0.768,p=0.927),  time:37.007, tt:4995.928\n",
      "Ep:135, loss:0.00001, loss_test:0.07247, lr:6.24e-03, fs:0.82682 (r=0.747,p=0.925),  time:37.017, tt:5034.362\n",
      "Ep:136, loss:0.00001, loss_test:0.06933, lr:6.17e-03, fs:0.83978 (r=0.768,p=0.927),  time:37.013, tt:5070.822\n",
      "Ep:137, loss:0.00001, loss_test:0.07216, lr:6.11e-03, fs:0.83978 (r=0.768,p=0.927),  time:37.016, tt:5108.237\n",
      "Ep:138, loss:0.00001, loss_test:0.06912, lr:6.05e-03, fs:0.83978 (r=0.768,p=0.927),  time:37.025, tt:5146.440\n",
      "Ep:139, loss:0.00001, loss_test:0.07271, lr:5.99e-03, fs:0.82222 (r=0.747,p=0.914),  time:37.027, tt:5183.800\n",
      "Ep:140, loss:0.00001, loss_test:0.07011, lr:5.93e-03, fs:0.84444 (r=0.768,p=0.938),  time:37.023, tt:5220.222\n",
      "Ep:141, loss:0.00001, loss_test:0.07186, lr:5.87e-03, fs:0.83516 (r=0.768,p=0.916),  time:37.011, tt:5255.529\n",
      "Ep:142, loss:0.00001, loss_test:0.07016, lr:5.81e-03, fs:0.84444 (r=0.768,p=0.938),  time:37.013, tt:5292.908\n",
      "Ep:143, loss:0.00001, loss_test:0.07312, lr:5.75e-03, fs:0.82022 (r=0.737,p=0.924),  time:37.015, tt:5330.132\n",
      "Ep:144, loss:0.00001, loss_test:0.06969, lr:5.70e-03, fs:0.84444 (r=0.768,p=0.938),  time:37.016, tt:5367.312\n",
      "Ep:145, loss:0.00001, loss_test:0.07425, lr:5.64e-03, fs:0.81356 (r=0.727,p=0.923),  time:37.015, tt:5404.255\n",
      "Ep:146, loss:0.00001, loss_test:0.06931, lr:5.58e-03, fs:0.84444 (r=0.768,p=0.938),  time:37.011, tt:5440.641\n",
      "Ep:147, loss:0.00001, loss_test:0.07327, lr:5.53e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.015, tt:5478.157\n",
      "Ep:148, loss:0.00001, loss_test:0.06930, lr:5.47e-03, fs:0.84444 (r=0.768,p=0.938),  time:37.021, tt:5516.144\n",
      "Ep:149, loss:0.00001, loss_test:0.07353, lr:5.42e-03, fs:0.81564 (r=0.737,p=0.912),  time:37.024, tt:5553.576\n",
      "Ep:150, loss:0.00001, loss_test:0.06902, lr:5.36e-03, fs:0.84916 (r=0.768,p=0.950),  time:37.024, tt:5590.675\n",
      "Ep:151, loss:0.00001, loss_test:0.07435, lr:5.31e-03, fs:0.79769 (r=0.697,p=0.932),  time:37.026, tt:5627.926\n",
      "Ep:152, loss:0.00001, loss_test:0.06864, lr:5.26e-03, fs:0.84916 (r=0.768,p=0.950),  time:37.033, tt:5666.060\n",
      "Ep:153, loss:0.00001, loss_test:0.07607, lr:5.20e-03, fs:0.79769 (r=0.697,p=0.932),  time:37.056, tt:5706.599\n",
      "Ep:154, loss:0.00001, loss_test:0.07112, lr:5.15e-03, fs:0.84916 (r=0.768,p=0.950),  time:37.098, tt:5750.199\n",
      "Ep:155, loss:0.00001, loss_test:0.07191, lr:5.10e-03, fs:0.82955 (r=0.737,p=0.948),  time:37.098, tt:5787.226\n",
      "Ep:156, loss:0.00001, loss_test:0.07188, lr:5.05e-03, fs:0.84444 (r=0.768,p=0.938),  time:37.105, tt:5825.421\n",
      "Ep:157, loss:0.00001, loss_test:0.07065, lr:5.00e-03, fs:0.84916 (r=0.768,p=0.950),  time:37.121, tt:5865.092\n",
      "Ep:158, loss:0.00001, loss_test:0.07400, lr:4.95e-03, fs:0.80460 (r=0.707,p=0.933),  time:37.127, tt:5903.163\n",
      "Ep:159, loss:0.00001, loss_test:0.06960, lr:4.90e-03, fs:0.84916 (r=0.768,p=0.950),  time:37.127, tt:5940.383\n",
      "Ep:160, loss:0.00001, loss_test:0.07458, lr:4.85e-03, fs:0.80702 (r=0.697,p=0.958),  time:37.135, tt:5978.763\n",
      "Ep:161, loss:0.00001, loss_test:0.07037, lr:4.80e-03, fs:0.84916 (r=0.768,p=0.950),  time:37.138, tt:6016.290\n",
      "Ep:162, loss:0.00001, loss_test:0.07181, lr:4.75e-03, fs:0.82955 (r=0.737,p=0.948),  time:37.139, tt:6053.597\n",
      "Ep:163, loss:0.00001, loss_test:0.07237, lr:4.71e-03, fs:0.82955 (r=0.737,p=0.948),  time:37.137, tt:6090.540\n",
      "Ep:164, loss:0.00001, loss_test:0.07063, lr:4.66e-03, fs:0.84916 (r=0.768,p=0.950),  time:37.143, tt:6128.660\n",
      "Ep:165, loss:0.00001, loss_test:0.07336, lr:4.61e-03, fs:0.82081 (r=0.717,p=0.959),  time:37.147, tt:6166.387\n",
      "Ep:166, loss:0.00001, loss_test:0.07053, lr:4.57e-03, fs:0.84916 (r=0.768,p=0.950),  time:37.154, tt:6204.674\n",
      "Ep:167, loss:0.00001, loss_test:0.07192, lr:4.52e-03, fs:0.82955 (r=0.737,p=0.948),  time:37.159, tt:6242.630\n",
      "Ep:168, loss:0.00001, loss_test:0.07057, lr:4.48e-03, fs:0.84916 (r=0.768,p=0.950),  time:37.166, tt:6281.082\n",
      "Ep:169, loss:0.00001, loss_test:0.07164, lr:4.43e-03, fs:0.84916 (r=0.768,p=0.950),  time:37.158, tt:6316.871\n",
      "Ep:170, loss:0.00001, loss_test:0.07088, lr:4.39e-03, fs:0.84916 (r=0.768,p=0.950),  time:37.166, tt:6355.439\n",
      "Ep:171, loss:0.00001, loss_test:0.07140, lr:4.34e-03, fs:0.84916 (r=0.768,p=0.950),  time:37.165, tt:6392.333\n",
      "Ep:172, loss:0.00001, loss_test:0.07200, lr:4.30e-03, fs:0.83616 (r=0.747,p=0.949),  time:37.162, tt:6429.029\n",
      "Ep:173, loss:0.00001, loss_test:0.07072, lr:4.26e-03, fs:0.84270 (r=0.758,p=0.949),  time:37.154, tt:6464.742\n",
      "Ep:174, loss:0.00001, loss_test:0.07324, lr:4.21e-03, fs:0.80925 (r=0.707,p=0.946),  time:37.152, tt:6501.654\n",
      "Ep:175, loss:0.00001, loss_test:0.07179, lr:4.17e-03, fs:0.83616 (r=0.747,p=0.949),  time:37.158, tt:6539.801\n",
      "Ep:176, loss:0.00001, loss_test:0.07194, lr:4.13e-03, fs:0.82286 (r=0.727,p=0.947),  time:37.157, tt:6576.812\n",
      "Ep:177, loss:0.00001, loss_test:0.07196, lr:4.09e-03, fs:0.82955 (r=0.737,p=0.948),  time:37.169, tt:6616.162\n",
      "Ep:178, loss:0.00001, loss_test:0.07232, lr:4.05e-03, fs:0.82955 (r=0.737,p=0.948),  time:37.166, tt:6652.758\n",
      "Ep:179, loss:0.00001, loss_test:0.07151, lr:4.01e-03, fs:0.82286 (r=0.727,p=0.947),  time:37.178, tt:6692.024\n",
      "Ep:180, loss:0.00001, loss_test:0.07224, lr:3.97e-03, fs:0.82955 (r=0.737,p=0.948),  time:37.177, tt:6729.066\n",
      "Ep:181, loss:0.00001, loss_test:0.07306, lr:3.93e-03, fs:0.80925 (r=0.707,p=0.946),  time:37.183, tt:6767.221\n",
      "Ep:182, loss:0.00001, loss_test:0.07093, lr:3.89e-03, fs:0.84916 (r=0.768,p=0.950),  time:37.186, tt:6804.955\n",
      "Ep:183, loss:0.00001, loss_test:0.07306, lr:3.85e-03, fs:0.80925 (r=0.707,p=0.946),  time:37.193, tt:6843.562\n",
      "Ep:184, loss:0.00001, loss_test:0.07143, lr:3.81e-03, fs:0.83616 (r=0.747,p=0.949),  time:37.199, tt:6881.796\n",
      "Ep:185, loss:0.00001, loss_test:0.07225, lr:3.77e-03, fs:0.80925 (r=0.707,p=0.946),  time:37.202, tt:6919.519\n",
      "Ep:186, loss:0.00001, loss_test:0.07175, lr:3.73e-03, fs:0.82955 (r=0.737,p=0.948),  time:37.199, tt:6956.267\n",
      "Ep:187, loss:0.00001, loss_test:0.07220, lr:3.70e-03, fs:0.82286 (r=0.727,p=0.947),  time:37.206, tt:6994.687\n",
      "Ep:188, loss:0.00001, loss_test:0.07228, lr:3.66e-03, fs:0.80233 (r=0.697,p=0.945),  time:37.212, tt:7033.112\n",
      "Ep:189, loss:0.00001, loss_test:0.07102, lr:3.62e-03, fs:0.84916 (r=0.768,p=0.950),  time:37.221, tt:7072.024\n",
      "Ep:190, loss:0.00001, loss_test:0.07343, lr:3.59e-03, fs:0.80702 (r=0.697,p=0.958),  time:37.219, tt:7108.821\n",
      "Ep:191, loss:0.00001, loss_test:0.07138, lr:3.55e-03, fs:0.82955 (r=0.737,p=0.948),  time:37.217, tt:7145.669\n",
      "Ep:192, loss:0.00001, loss_test:0.07313, lr:3.52e-03, fs:0.80233 (r=0.697,p=0.945),  time:37.220, tt:7183.388\n",
      "Ep:193, loss:0.00001, loss_test:0.07347, lr:3.48e-03, fs:0.80702 (r=0.697,p=0.958),  time:37.227, tt:7221.944\n",
      "Ep:194, loss:0.00001, loss_test:0.07015, lr:3.45e-03, fs:0.84916 (r=0.768,p=0.950),  time:37.232, tt:7260.291\n",
      "Ep:195, loss:0.00001, loss_test:0.07321, lr:3.41e-03, fs:0.80233 (r=0.697,p=0.945),  time:37.248, tt:7300.528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:196, loss:0.00001, loss_test:0.07152, lr:3.38e-03, fs:0.83616 (r=0.747,p=0.949),  time:37.252, tt:7338.726\n",
      "Ep:197, loss:0.00001, loss_test:0.07156, lr:3.34e-03, fs:0.82286 (r=0.727,p=0.947),  time:37.254, tt:7376.388\n",
      "Ep:198, loss:0.00001, loss_test:0.07190, lr:3.31e-03, fs:0.82286 (r=0.727,p=0.947),  time:37.258, tt:7414.331\n",
      "Ep:199, loss:0.00001, loss_test:0.07176, lr:3.28e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.266, tt:7453.150\n",
      "Ep:200, loss:0.00001, loss_test:0.07144, lr:3.24e-03, fs:0.82955 (r=0.737,p=0.948),  time:37.285, tt:7494.383\n",
      "Ep:201, loss:0.00001, loss_test:0.07134, lr:3.21e-03, fs:0.82955 (r=0.737,p=0.948),  time:37.295, tt:7533.641\n",
      "Ep:202, loss:0.00001, loss_test:0.07250, lr:3.18e-03, fs:0.80233 (r=0.697,p=0.945),  time:37.301, tt:7572.077\n",
      "Ep:203, loss:0.00001, loss_test:0.07227, lr:3.15e-03, fs:0.82286 (r=0.727,p=0.947),  time:37.290, tt:7607.132\n",
      "Ep:204, loss:0.00001, loss_test:0.07172, lr:3.12e-03, fs:0.82286 (r=0.727,p=0.947),  time:37.287, tt:7643.775\n",
      "Ep:205, loss:0.00001, loss_test:0.07218, lr:3.09e-03, fs:0.80925 (r=0.707,p=0.946),  time:37.202, tt:7663.566\n",
      "Ep:206, loss:0.00001, loss_test:0.07099, lr:3.05e-03, fs:0.83616 (r=0.747,p=0.949),  time:37.160, tt:7692.097\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14494, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.632, tt:30.632\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14407, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.681, tt:67.361\n",
      "Ep:2, loss:0.00028, loss_test:0.14241, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.249, tt:105.748\n",
      "Ep:3, loss:0.00028, loss_test:0.13947, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.343, tt:141.371\n",
      "Ep:4, loss:0.00027, loss_test:0.13426, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:36.017, tt:180.087\n",
      "Ep:5, loss:0.00026, loss_test:0.12485, lr:1.00e-02, fs:0.67883 (r=0.939,p=0.531),  time:35.822, tt:214.934\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.11279, lr:1.00e-02, fs:0.68996 (r=0.798,p=0.608),  time:35.905, tt:251.338\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.10750, lr:1.00e-02, fs:0.68627 (r=0.707,p=0.667),  time:35.987, tt:287.897\n",
      "Ep:8, loss:0.00022, loss_test:0.10441, lr:1.00e-02, fs:0.72973 (r=0.818,p=0.659),  time:36.055, tt:324.499\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.10275, lr:1.00e-02, fs:0.75745 (r=0.899,p=0.654),  time:36.383, tt:363.828\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.09777, lr:1.00e-02, fs:0.76190 (r=0.808,p=0.721),  time:36.633, tt:402.968\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.09516, lr:1.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:36.655, tt:439.864\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.09385, lr:1.00e-02, fs:0.78222 (r=0.889,p=0.698),  time:36.635, tt:476.252\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.09126, lr:1.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:36.786, tt:515.001\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.08970, lr:1.00e-02, fs:0.79621 (r=0.848,p=0.750),  time:36.886, tt:553.294\n",
      "Ep:15, loss:0.00017, loss_test:0.08806, lr:1.00e-02, fs:0.79621 (r=0.848,p=0.750),  time:36.986, tt:591.778\n",
      "Ep:16, loss:0.00016, loss_test:0.08733, lr:1.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:37.008, tt:629.131\n",
      "Ep:17, loss:0.00015, loss_test:0.08581, lr:1.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:37.026, tt:666.477\n",
      "Ep:18, loss:0.00015, loss_test:0.08473, lr:1.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:37.099, tt:704.881\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.08313, lr:1.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:37.129, tt:742.579\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.08171, lr:1.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:37.184, tt:780.875\n",
      "Ep:21, loss:0.00013, loss_test:0.08122, lr:1.00e-02, fs:0.83810 (r=0.889,p=0.793),  time:37.252, tt:819.538\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00013, loss_test:0.08003, lr:1.00e-02, fs:0.84906 (r=0.909,p=0.796),  time:37.245, tt:856.629\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.07967, lr:1.00e-02, fs:0.85167 (r=0.899,p=0.809),  time:37.296, tt:895.092\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00012, loss_test:0.07869, lr:1.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:37.345, tt:933.627\n",
      "Ep:25, loss:0.00011, loss_test:0.07726, lr:1.00e-02, fs:0.84762 (r=0.899,p=0.802),  time:37.458, tt:973.898\n",
      "Ep:26, loss:0.00011, loss_test:0.07710, lr:1.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:37.438, tt:1010.831\n",
      "Ep:27, loss:0.00010, loss_test:0.07454, lr:1.00e-02, fs:0.87850 (r=0.949,p=0.817),  time:37.487, tt:1049.634\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00010, loss_test:0.07440, lr:1.00e-02, fs:0.85149 (r=0.869,p=0.835),  time:37.655, tt:1092.009\n",
      "Ep:29, loss:0.00010, loss_test:0.07236, lr:1.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:37.648, tt:1129.437\n",
      "Ep:30, loss:0.00009, loss_test:0.07049, lr:1.00e-02, fs:0.88571 (r=0.939,p=0.838),  time:37.682, tt:1168.129\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00009, loss_test:0.07229, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:37.733, tt:1207.464\n",
      "Ep:32, loss:0.00009, loss_test:0.06871, lr:1.00e-02, fs:0.88235 (r=0.909,p=0.857),  time:37.915, tt:1251.185\n",
      "Ep:33, loss:0.00008, loss_test:0.07247, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:37.926, tt:1289.499\n",
      "Ep:34, loss:0.00008, loss_test:0.06622, lr:1.00e-02, fs:0.91346 (r=0.960,p=0.872),  time:37.941, tt:1327.931\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00008, loss_test:0.07081, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:37.977, tt:1367.189\n",
      "Ep:36, loss:0.00007, loss_test:0.06431, lr:1.00e-02, fs:0.89855 (r=0.939,p=0.861),  time:37.993, tt:1405.748\n",
      "Ep:37, loss:0.00007, loss_test:0.06750, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:37.961, tt:1442.531\n",
      "Ep:38, loss:0.00007, loss_test:0.06874, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:37.971, tt:1480.867\n",
      "Ep:39, loss:0.00006, loss_test:0.06319, lr:1.00e-02, fs:0.88660 (r=0.869,p=0.905),  time:37.946, tt:1517.825\n",
      "Ep:40, loss:0.00006, loss_test:0.07037, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:37.869, tt:1552.610\n",
      "Ep:41, loss:0.00006, loss_test:0.06085, lr:1.00e-02, fs:0.90547 (r=0.919,p=0.892),  time:37.845, tt:1589.481\n",
      "Ep:42, loss:0.00006, loss_test:0.06816, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:37.833, tt:1626.817\n",
      "Ep:43, loss:0.00006, loss_test:0.06013, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:37.842, tt:1665.035\n",
      "Ep:44, loss:0.00005, loss_test:0.06283, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:37.811, tt:1701.511\n",
      "Ep:45, loss:0.00005, loss_test:0.06368, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:37.804, tt:1738.990\n",
      "Ep:46, loss:0.00005, loss_test:0.05855, lr:9.90e-03, fs:0.86316 (r=0.828,p=0.901),  time:37.895, tt:1781.088\n",
      "Ep:47, loss:0.00005, loss_test:0.06475, lr:9.80e-03, fs:0.85106 (r=0.808,p=0.899),  time:37.888, tt:1818.627\n",
      "Ep:48, loss:0.00004, loss_test:0.05809, lr:9.70e-03, fs:0.86911 (r=0.838,p=0.902),  time:37.861, tt:1855.194\n",
      "Ep:49, loss:0.00004, loss_test:0.06639, lr:9.61e-03, fs:0.84492 (r=0.798,p=0.898),  time:37.934, tt:1896.705\n",
      "Ep:50, loss:0.00004, loss_test:0.05725, lr:9.51e-03, fs:0.86772 (r=0.828,p=0.911),  time:37.954, tt:1935.656\n",
      "Ep:51, loss:0.00004, loss_test:0.06419, lr:9.41e-03, fs:0.84946 (r=0.798,p=0.908),  time:37.930, tt:1972.379\n",
      "Ep:52, loss:0.00004, loss_test:0.06101, lr:9.32e-03, fs:0.86170 (r=0.818,p=0.910),  time:37.935, tt:2010.550\n",
      "Ep:53, loss:0.00004, loss_test:0.05805, lr:9.23e-03, fs:0.86170 (r=0.818,p=0.910),  time:37.924, tt:2047.889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:54, loss:0.00003, loss_test:0.05998, lr:9.14e-03, fs:0.82418 (r=0.758,p=0.904),  time:37.927, tt:2085.969\n",
      "Ep:55, loss:0.00003, loss_test:0.06075, lr:9.04e-03, fs:0.84324 (r=0.788,p=0.907),  time:37.934, tt:2124.300\n",
      "Ep:56, loss:0.00003, loss_test:0.05795, lr:8.95e-03, fs:0.86170 (r=0.818,p=0.910),  time:37.932, tt:2162.119\n",
      "Ep:57, loss:0.00003, loss_test:0.06231, lr:8.86e-03, fs:0.81768 (r=0.747,p=0.902),  time:37.908, tt:2198.662\n",
      "Ep:58, loss:0.00003, loss_test:0.05770, lr:8.78e-03, fs:0.83696 (r=0.778,p=0.906),  time:37.891, tt:2235.562\n",
      "Ep:59, loss:0.00003, loss_test:0.05821, lr:8.69e-03, fs:0.85561 (r=0.808,p=0.909),  time:37.901, tt:2274.070\n",
      "Ep:60, loss:0.00003, loss_test:0.05885, lr:8.60e-03, fs:0.86631 (r=0.818,p=0.920),  time:37.919, tt:2313.069\n",
      "Ep:61, loss:0.00003, loss_test:0.05949, lr:8.51e-03, fs:0.84153 (r=0.778,p=0.917),  time:37.940, tt:2352.260\n",
      "Ep:62, loss:0.00003, loss_test:0.05913, lr:8.43e-03, fs:0.85561 (r=0.808,p=0.909),  time:37.917, tt:2388.799\n",
      "Ep:63, loss:0.00003, loss_test:0.05917, lr:8.35e-03, fs:0.82222 (r=0.747,p=0.914),  time:37.899, tt:2425.514\n",
      "Ep:64, loss:0.00002, loss_test:0.06021, lr:8.26e-03, fs:0.85870 (r=0.798,p=0.929),  time:37.882, tt:2462.338\n",
      "Ep:65, loss:0.00002, loss_test:0.05844, lr:8.18e-03, fs:0.82418 (r=0.758,p=0.904),  time:37.877, tt:2499.905\n",
      "Ep:66, loss:0.00002, loss_test:0.05979, lr:8.10e-03, fs:0.86631 (r=0.818,p=0.920),  time:37.906, tt:2539.733\n",
      "Ep:67, loss:0.00002, loss_test:0.05996, lr:8.02e-03, fs:0.83333 (r=0.758,p=0.926),  time:37.914, tt:2578.134\n",
      "Ep:68, loss:0.00002, loss_test:0.06024, lr:7.94e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.923, tt:2616.717\n",
      "Ep:69, loss:0.00002, loss_test:0.06137, lr:7.86e-03, fs:0.83333 (r=0.758,p=0.926),  time:37.914, tt:2653.969\n",
      "Ep:70, loss:0.00002, loss_test:0.06085, lr:7.78e-03, fs:0.83333 (r=0.758,p=0.926),  time:37.896, tt:2690.611\n",
      "Ep:71, loss:0.00002, loss_test:0.06082, lr:7.70e-03, fs:0.83333 (r=0.758,p=0.926),  time:37.897, tt:2728.554\n",
      "Ep:72, loss:0.00002, loss_test:0.06061, lr:7.62e-03, fs:0.82682 (r=0.747,p=0.925),  time:37.913, tt:2767.684\n",
      "Ep:73, loss:0.00002, loss_test:0.06173, lr:7.55e-03, fs:0.83799 (r=0.758,p=0.938),  time:37.954, tt:2808.575\n",
      "Ep:74, loss:0.00002, loss_test:0.06076, lr:7.47e-03, fs:0.86339 (r=0.798,p=0.940),  time:37.955, tt:2846.630\n",
      "Ep:75, loss:0.00002, loss_test:0.06439, lr:7.40e-03, fs:0.82682 (r=0.747,p=0.925),  time:37.965, tt:2885.346\n",
      "Ep:76, loss:0.00002, loss_test:0.06267, lr:7.32e-03, fs:0.83799 (r=0.758,p=0.938),  time:37.969, tt:2923.600\n",
      "Ep:77, loss:0.00002, loss_test:0.06076, lr:7.25e-03, fs:0.82682 (r=0.747,p=0.925),  time:37.980, tt:2962.417\n",
      "Ep:78, loss:0.00002, loss_test:0.06319, lr:7.18e-03, fs:0.86813 (r=0.798,p=0.952),  time:37.998, tt:3001.849\n",
      "Ep:79, loss:0.00002, loss_test:0.06491, lr:7.11e-03, fs:0.83146 (r=0.747,p=0.937),  time:38.004, tt:3040.334\n",
      "Ep:80, loss:0.00002, loss_test:0.06160, lr:7.03e-03, fs:0.88043 (r=0.818,p=0.953),  time:38.012, tt:3079.002\n",
      "Ep:81, loss:0.00002, loss_test:0.06351, lr:6.96e-03, fs:0.83146 (r=0.747,p=0.937),  time:38.032, tt:3118.654\n",
      "Ep:82, loss:0.00001, loss_test:0.06133, lr:6.89e-03, fs:0.88649 (r=0.828,p=0.953),  time:38.035, tt:3156.934\n",
      "Ep:83, loss:0.00001, loss_test:0.06384, lr:6.83e-03, fs:0.83146 (r=0.747,p=0.937),  time:38.032, tt:3194.657\n",
      "Ep:84, loss:0.00001, loss_test:0.06338, lr:6.76e-03, fs:0.84916 (r=0.768,p=0.950),  time:38.029, tt:3232.489\n",
      "Ep:85, loss:0.00001, loss_test:0.06416, lr:6.69e-03, fs:0.83616 (r=0.747,p=0.949),  time:38.049, tt:3272.186\n",
      "Ep:86, loss:0.00001, loss_test:0.06366, lr:6.62e-03, fs:0.86813 (r=0.798,p=0.952),  time:38.062, tt:3311.401\n",
      "Ep:87, loss:0.00001, loss_test:0.06506, lr:6.56e-03, fs:0.83616 (r=0.747,p=0.949),  time:38.060, tt:3349.320\n",
      "Ep:88, loss:0.00001, loss_test:0.06387, lr:6.49e-03, fs:0.88043 (r=0.818,p=0.953),  time:38.051, tt:3386.545\n",
      "Ep:89, loss:0.00001, loss_test:0.06645, lr:6.43e-03, fs:0.83616 (r=0.747,p=0.949),  time:38.036, tt:3423.230\n",
      "Ep:90, loss:0.00001, loss_test:0.06408, lr:6.36e-03, fs:0.84270 (r=0.758,p=0.949),  time:38.036, tt:3461.271\n",
      "Ep:91, loss:0.00001, loss_test:0.06580, lr:6.30e-03, fs:0.83616 (r=0.747,p=0.949),  time:38.014, tt:3497.247\n",
      "Ep:92, loss:0.00001, loss_test:0.06547, lr:6.24e-03, fs:0.84270 (r=0.758,p=0.949),  time:38.018, tt:3535.691\n",
      "Ep:93, loss:0.00001, loss_test:0.06468, lr:6.17e-03, fs:0.83616 (r=0.747,p=0.949),  time:38.020, tt:3573.886\n",
      "Ep:94, loss:0.00001, loss_test:0.06676, lr:6.11e-03, fs:0.83616 (r=0.747,p=0.949),  time:37.998, tt:3609.829\n",
      "Ep:95, loss:0.00001, loss_test:0.06545, lr:6.05e-03, fs:0.84270 (r=0.758,p=0.949),  time:37.989, tt:3646.932\n",
      "Ep:96, loss:0.00001, loss_test:0.06690, lr:5.99e-03, fs:0.83616 (r=0.747,p=0.949),  time:37.991, tt:3685.091\n",
      "Ep:97, loss:0.00001, loss_test:0.06676, lr:5.93e-03, fs:0.84270 (r=0.758,p=0.949),  time:37.973, tt:3721.367\n",
      "Ep:98, loss:0.00001, loss_test:0.06692, lr:5.87e-03, fs:0.84091 (r=0.747,p=0.961),  time:37.986, tt:3760.582\n",
      "Ep:99, loss:0.00001, loss_test:0.06629, lr:5.81e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.986, tt:3798.629\n",
      "Ep:100, loss:0.00001, loss_test:0.06879, lr:5.75e-03, fs:0.84091 (r=0.747,p=0.961),  time:37.991, tt:3837.128\n",
      "Ep:101, loss:0.00001, loss_test:0.06681, lr:5.70e-03, fs:0.84746 (r=0.758,p=0.962),  time:37.985, tt:3874.427\n",
      "Ep:102, loss:0.00001, loss_test:0.06680, lr:5.64e-03, fs:0.84746 (r=0.758,p=0.962),  time:37.995, tt:3913.502\n",
      "Ep:103, loss:0.00001, loss_test:0.06889, lr:5.58e-03, fs:0.84746 (r=0.758,p=0.962),  time:37.984, tt:3950.326\n",
      "Ep:104, loss:0.00001, loss_test:0.06923, lr:5.53e-03, fs:0.84091 (r=0.747,p=0.961),  time:38.024, tt:3992.569\n",
      "Ep:105, loss:0.00001, loss_test:0.06798, lr:5.47e-03, fs:0.84746 (r=0.758,p=0.962),  time:38.033, tt:4031.472\n",
      "Ep:106, loss:0.00001, loss_test:0.06899, lr:5.42e-03, fs:0.84746 (r=0.758,p=0.962),  time:38.028, tt:4068.983\n",
      "Ep:107, loss:0.00001, loss_test:0.06915, lr:5.36e-03, fs:0.84091 (r=0.747,p=0.961),  time:38.032, tt:4107.437\n",
      "Ep:108, loss:0.00001, loss_test:0.06923, lr:5.31e-03, fs:0.84746 (r=0.758,p=0.962),  time:38.042, tt:4146.536\n",
      "Ep:109, loss:0.00001, loss_test:0.07068, lr:5.26e-03, fs:0.83429 (r=0.737,p=0.961),  time:38.032, tt:4183.570\n",
      "Ep:110, loss:0.00001, loss_test:0.06976, lr:5.20e-03, fs:0.84746 (r=0.758,p=0.962),  time:38.052, tt:4223.717\n",
      "Ep:111, loss:0.00001, loss_test:0.06931, lr:5.15e-03, fs:0.84746 (r=0.758,p=0.962),  time:38.044, tt:4260.950\n",
      "Ep:112, loss:0.00001, loss_test:0.07060, lr:5.10e-03, fs:0.84091 (r=0.747,p=0.961),  time:38.051, tt:4299.710\n",
      "Ep:113, loss:0.00001, loss_test:0.06976, lr:5.05e-03, fs:0.84746 (r=0.758,p=0.962),  time:38.065, tt:4339.369\n",
      "Ep:114, loss:0.00001, loss_test:0.07085, lr:5.00e-03, fs:0.84091 (r=0.747,p=0.961),  time:38.076, tt:4378.757\n",
      "Ep:115, loss:0.00001, loss_test:0.06984, lr:4.95e-03, fs:0.84746 (r=0.758,p=0.962),  time:38.078, tt:4417.041\n",
      "Ep:116, loss:0.00001, loss_test:0.07054, lr:4.90e-03, fs:0.84746 (r=0.758,p=0.962),  time:38.079, tt:4455.209\n",
      "Ep:117, loss:0.00001, loss_test:0.07087, lr:4.85e-03, fs:0.84746 (r=0.758,p=0.962),  time:38.073, tt:4492.644\n",
      "Ep:118, loss:0.00001, loss_test:0.07040, lr:4.80e-03, fs:0.84746 (r=0.758,p=0.962),  time:38.059, tt:4529.027\n",
      "Ep:119, loss:0.00001, loss_test:0.06981, lr:4.75e-03, fs:0.84746 (r=0.758,p=0.962),  time:38.049, tt:4565.855\n",
      "Ep:120, loss:0.00001, loss_test:0.07093, lr:4.71e-03, fs:0.84091 (r=0.747,p=0.961),  time:38.050, tt:4604.034\n",
      "Ep:121, loss:0.00001, loss_test:0.07152, lr:4.66e-03, fs:0.84091 (r=0.747,p=0.961),  time:38.058, tt:4643.053\n",
      "Ep:122, loss:0.00001, loss_test:0.07145, lr:4.61e-03, fs:0.84091 (r=0.747,p=0.961),  time:38.067, tt:4682.301\n",
      "Ep:123, loss:0.00001, loss_test:0.07163, lr:4.57e-03, fs:0.82759 (r=0.727,p=0.960),  time:38.076, tt:4721.408\n",
      "Ep:124, loss:0.00001, loss_test:0.07074, lr:4.52e-03, fs:0.84746 (r=0.758,p=0.962),  time:38.081, tt:4760.118\n",
      "Ep:125, loss:0.00001, loss_test:0.07081, lr:4.48e-03, fs:0.84746 (r=0.758,p=0.962),  time:38.087, tt:4798.927\n",
      "Ep:126, loss:0.00001, loss_test:0.07023, lr:4.43e-03, fs:0.84746 (r=0.758,p=0.962),  time:38.092, tt:4837.623\n",
      "Ep:127, loss:0.00001, loss_test:0.07098, lr:4.39e-03, fs:0.84091 (r=0.747,p=0.961),  time:38.084, tt:4874.802\n",
      "Ep:128, loss:0.00001, loss_test:0.07131, lr:4.34e-03, fs:0.84091 (r=0.747,p=0.961),  time:38.086, tt:4913.101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:129, loss:0.00001, loss_test:0.07129, lr:4.30e-03, fs:0.84091 (r=0.747,p=0.961),  time:38.082, tt:4950.664\n",
      "Ep:130, loss:0.00001, loss_test:0.07097, lr:4.26e-03, fs:0.84091 (r=0.747,p=0.961),  time:38.075, tt:4987.871\n",
      "Ep:131, loss:0.00001, loss_test:0.07170, lr:4.21e-03, fs:0.84091 (r=0.747,p=0.961),  time:38.087, tt:5027.426\n",
      "Ep:132, loss:0.00000, loss_test:0.07011, lr:4.17e-03, fs:0.84091 (r=0.747,p=0.961),  time:38.085, tt:5065.297\n",
      "Ep:133, loss:0.00000, loss_test:0.07151, lr:4.13e-03, fs:0.84091 (r=0.747,p=0.961),  time:38.074, tt:5101.909\n",
      "Ep:134, loss:0.00000, loss_test:0.07249, lr:4.09e-03, fs:0.83429 (r=0.737,p=0.961),  time:38.069, tt:5139.365\n",
      "Ep:135, loss:0.00000, loss_test:0.07054, lr:4.05e-03, fs:0.84091 (r=0.747,p=0.961),  time:38.063, tt:5176.613\n",
      "Ep:136, loss:0.00000, loss_test:0.07128, lr:4.01e-03, fs:0.84091 (r=0.747,p=0.961),  time:38.054, tt:5213.416\n",
      "Ep:137, loss:0.00000, loss_test:0.07265, lr:3.97e-03, fs:0.83429 (r=0.737,p=0.961),  time:38.053, tt:5251.328\n",
      "Ep:138, loss:0.00000, loss_test:0.07161, lr:3.93e-03, fs:0.84091 (r=0.747,p=0.961),  time:38.056, tt:5289.759\n",
      "Ep:139, loss:0.00000, loss_test:0.07138, lr:3.89e-03, fs:0.83429 (r=0.737,p=0.961),  time:38.059, tt:5328.282\n",
      "Ep:140, loss:0.00000, loss_test:0.07207, lr:3.85e-03, fs:0.84091 (r=0.747,p=0.961),  time:38.058, tt:5366.181\n",
      "Ep:141, loss:0.00000, loss_test:0.07156, lr:3.81e-03, fs:0.83429 (r=0.737,p=0.961),  time:38.046, tt:5402.501\n",
      "Ep:142, loss:0.00000, loss_test:0.07137, lr:3.77e-03, fs:0.83429 (r=0.737,p=0.961),  time:38.037, tt:5439.284\n",
      "Ep:143, loss:0.00000, loss_test:0.07152, lr:3.73e-03, fs:0.82759 (r=0.727,p=0.960),  time:38.035, tt:5476.991\n",
      "Ep:144, loss:0.00000, loss_test:0.07136, lr:3.70e-03, fs:0.83429 (r=0.737,p=0.961),  time:38.043, tt:5516.250\n",
      "Ep:145, loss:0.00000, loss_test:0.07179, lr:3.66e-03, fs:0.83429 (r=0.737,p=0.961),  time:38.048, tt:5554.962\n",
      "Ep:146, loss:0.00000, loss_test:0.07276, lr:3.62e-03, fs:0.82081 (r=0.717,p=0.959),  time:38.043, tt:5592.317\n",
      "Ep:147, loss:0.00000, loss_test:0.07166, lr:3.59e-03, fs:0.83429 (r=0.737,p=0.961),  time:38.049, tt:5631.315\n",
      "Ep:148, loss:0.00000, loss_test:0.07213, lr:3.55e-03, fs:0.82081 (r=0.717,p=0.959),  time:38.057, tt:5670.431\n",
      "Ep:149, loss:0.00000, loss_test:0.07298, lr:3.52e-03, fs:0.82081 (r=0.717,p=0.959),  time:38.057, tt:5708.566\n",
      "Ep:150, loss:0.00000, loss_test:0.07187, lr:3.48e-03, fs:0.83429 (r=0.737,p=0.961),  time:38.061, tt:5747.189\n",
      "Ep:151, loss:0.00000, loss_test:0.07173, lr:3.45e-03, fs:0.81395 (r=0.707,p=0.959),  time:38.057, tt:5784.641\n",
      "Ep:152, loss:0.00000, loss_test:0.07202, lr:3.41e-03, fs:0.83429 (r=0.737,p=0.961),  time:38.054, tt:5822.232\n",
      "Ep:153, loss:0.00000, loss_test:0.07197, lr:3.38e-03, fs:0.82081 (r=0.717,p=0.959),  time:38.058, tt:5860.915\n",
      "Ep:154, loss:0.00000, loss_test:0.07171, lr:3.34e-03, fs:0.83429 (r=0.737,p=0.961),  time:38.051, tt:5897.909\n",
      "Ep:155, loss:0.00000, loss_test:0.07335, lr:3.31e-03, fs:0.80702 (r=0.697,p=0.958),  time:38.047, tt:5935.356\n",
      "Ep:156, loss:0.00000, loss_test:0.07280, lr:3.28e-03, fs:0.80000 (r=0.687,p=0.958),  time:38.041, tt:5972.496\n",
      "Ep:157, loss:0.00000, loss_test:0.07184, lr:3.24e-03, fs:0.82081 (r=0.717,p=0.959),  time:38.032, tt:6009.095\n",
      "Ep:158, loss:0.00000, loss_test:0.07172, lr:3.21e-03, fs:0.81395 (r=0.707,p=0.959),  time:38.037, tt:6047.810\n",
      "Ep:159, loss:0.00000, loss_test:0.07341, lr:3.18e-03, fs:0.82081 (r=0.717,p=0.959),  time:38.028, tt:6084.501\n",
      "Ep:160, loss:0.00000, loss_test:0.07225, lr:3.15e-03, fs:0.80702 (r=0.697,p=0.958),  time:38.020, tt:6121.180\n",
      "Ep:161, loss:0.00000, loss_test:0.07188, lr:3.12e-03, fs:0.82081 (r=0.717,p=0.959),  time:38.016, tt:6158.526\n",
      "Ep:162, loss:0.00000, loss_test:0.07240, lr:3.09e-03, fs:0.82081 (r=0.717,p=0.959),  time:38.007, tt:6195.212\n",
      "Ep:163, loss:0.00000, loss_test:0.07298, lr:3.05e-03, fs:0.78571 (r=0.667,p=0.957),  time:37.998, tt:6231.750\n",
      "Ep:164, loss:0.00000, loss_test:0.07264, lr:3.02e-03, fs:0.80702 (r=0.697,p=0.958),  time:38.001, tt:6270.185\n",
      "Ep:165, loss:0.00000, loss_test:0.07250, lr:2.99e-03, fs:0.81395 (r=0.707,p=0.959),  time:37.999, tt:6307.756\n",
      "Ep:166, loss:0.00000, loss_test:0.07262, lr:2.96e-03, fs:0.80000 (r=0.687,p=0.958),  time:37.991, tt:6344.470\n",
      "Ep:167, loss:0.00000, loss_test:0.07215, lr:2.93e-03, fs:0.81395 (r=0.707,p=0.959),  time:37.986, tt:6381.689\n",
      "Ep:168, loss:0.00000, loss_test:0.07201, lr:2.90e-03, fs:0.79290 (r=0.677,p=0.957),  time:37.976, tt:6417.864\n",
      "Ep:169, loss:0.00000, loss_test:0.07290, lr:2.88e-03, fs:0.79290 (r=0.677,p=0.957),  time:37.960, tt:6453.139\n",
      "Ep:170, loss:0.00000, loss_test:0.07295, lr:2.85e-03, fs:0.79290 (r=0.677,p=0.957),  time:37.953, tt:6489.937\n",
      "Ep:171, loss:0.00000, loss_test:0.07259, lr:2.82e-03, fs:0.79290 (r=0.677,p=0.957),  time:37.945, tt:6526.551\n",
      "Ep:172, loss:0.00000, loss_test:0.07248, lr:2.79e-03, fs:0.79290 (r=0.677,p=0.957),  time:37.934, tt:6562.578\n",
      "Ep:173, loss:0.00000, loss_test:0.07258, lr:2.76e-03, fs:0.81395 (r=0.707,p=0.959),  time:37.934, tt:6600.521\n",
      "Ep:174, loss:0.00000, loss_test:0.07270, lr:2.73e-03, fs:0.77844 (r=0.657,p=0.956),  time:37.919, tt:6635.752\n",
      "Ep:175, loss:0.00000, loss_test:0.07254, lr:2.71e-03, fs:0.78571 (r=0.667,p=0.957),  time:37.909, tt:6671.954\n",
      "Ep:176, loss:0.00000, loss_test:0.07203, lr:2.68e-03, fs:0.81395 (r=0.707,p=0.959),  time:37.906, tt:6709.368\n",
      "Ep:177, loss:0.00000, loss_test:0.07238, lr:2.65e-03, fs:0.78571 (r=0.667,p=0.957),  time:37.902, tt:6746.546\n",
      "Ep:178, loss:0.00000, loss_test:0.07266, lr:2.63e-03, fs:0.78571 (r=0.667,p=0.957),  time:37.902, tt:6784.395\n",
      "Ep:179, loss:0.00000, loss_test:0.07261, lr:2.60e-03, fs:0.80702 (r=0.697,p=0.958),  time:37.897, tt:6821.464\n",
      "Ep:180, loss:0.00000, loss_test:0.07279, lr:2.57e-03, fs:0.80702 (r=0.697,p=0.958),  time:37.897, tt:6859.268\n",
      "Ep:181, loss:0.00000, loss_test:0.07248, lr:2.55e-03, fs:0.78571 (r=0.667,p=0.957),  time:37.905, tt:6898.783\n",
      "Ep:182, loss:0.00000, loss_test:0.07282, lr:2.52e-03, fs:0.78571 (r=0.667,p=0.957),  time:37.900, tt:6935.623\n",
      "Ep:183, loss:0.00000, loss_test:0.07222, lr:2.50e-03, fs:0.78571 (r=0.667,p=0.957),  time:37.900, tt:6973.579\n",
      "Ep:184, loss:0.00000, loss_test:0.07239, lr:2.47e-03, fs:0.80000 (r=0.687,p=0.958),  time:37.890, tt:7009.630\n",
      "Ep:185, loss:0.00000, loss_test:0.07267, lr:2.45e-03, fs:0.78571 (r=0.667,p=0.957),  time:37.909, tt:7050.993\n",
      "Ep:186, loss:0.00000, loss_test:0.07259, lr:2.42e-03, fs:0.77844 (r=0.657,p=0.956),  time:37.898, tt:7087.004\n",
      "Ep:187, loss:0.00000, loss_test:0.07212, lr:2.40e-03, fs:0.78571 (r=0.667,p=0.957),  time:37.898, tt:7124.767\n",
      "Ep:188, loss:0.00000, loss_test:0.07268, lr:2.38e-03, fs:0.78571 (r=0.667,p=0.957),  time:37.889, tt:7161.053\n",
      "Ep:189, loss:0.00000, loss_test:0.07271, lr:2.35e-03, fs:0.77844 (r=0.657,p=0.956),  time:37.887, tt:7198.548\n",
      "Ep:190, loss:0.00000, loss_test:0.07193, lr:2.33e-03, fs:0.81395 (r=0.707,p=0.959),  time:37.876, tt:7234.352\n",
      "Ep:191, loss:0.00000, loss_test:0.07250, lr:2.31e-03, fs:0.78571 (r=0.667,p=0.957),  time:37.866, tt:7270.360\n",
      "Ep:192, loss:0.00000, loss_test:0.07363, lr:2.28e-03, fs:0.77844 (r=0.657,p=0.956),  time:37.866, tt:7308.064\n",
      "Ep:193, loss:0.00000, loss_test:0.07341, lr:2.26e-03, fs:0.77844 (r=0.657,p=0.956),  time:37.867, tt:7346.157\n",
      "Ep:194, loss:0.00000, loss_test:0.07241, lr:2.24e-03, fs:0.78571 (r=0.667,p=0.957),  time:37.857, tt:7382.180\n",
      "Ep:195, loss:0.00000, loss_test:0.07233, lr:2.21e-03, fs:0.77844 (r=0.657,p=0.956),  time:37.850, tt:7418.664\n",
      "Ep:196, loss:0.00000, loss_test:0.07262, lr:2.19e-03, fs:0.78571 (r=0.667,p=0.957),  time:37.841, tt:7454.615\n",
      "Ep:197, loss:0.00000, loss_test:0.07280, lr:2.17e-03, fs:0.78571 (r=0.667,p=0.957),  time:37.839, tt:7492.061\n",
      "Ep:198, loss:0.00000, loss_test:0.07253, lr:2.15e-03, fs:0.77844 (r=0.657,p=0.956),  time:37.835, tt:7529.253\n",
      "Ep:199, loss:0.00000, loss_test:0.07268, lr:2.13e-03, fs:0.77844 (r=0.657,p=0.956),  time:37.829, tt:7565.840\n",
      "Ep:200, loss:0.00000, loss_test:0.07275, lr:2.11e-03, fs:0.78571 (r=0.667,p=0.957),  time:37.827, tt:7603.186\n",
      "Ep:201, loss:0.00000, loss_test:0.07267, lr:2.08e-03, fs:0.77844 (r=0.657,p=0.956),  time:37.827, tt:7641.073\n",
      "Ep:202, loss:0.00000, loss_test:0.07279, lr:2.06e-03, fs:0.77844 (r=0.657,p=0.956),  time:37.833, tt:7680.185\n",
      "Ep:203, loss:0.00000, loss_test:0.07262, lr:2.04e-03, fs:0.77844 (r=0.657,p=0.956),  time:37.831, tt:7717.525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:204, loss:0.00000, loss_test:0.07245, lr:2.02e-03, fs:0.77844 (r=0.657,p=0.956),  time:37.828, tt:7754.764\n",
      "Ep:205, loss:0.00000, loss_test:0.07260, lr:2.00e-03, fs:0.77844 (r=0.657,p=0.956),  time:37.722, tt:7770.825\n",
      "Ep:206, loss:0.00000, loss_test:0.07247, lr:1.98e-03, fs:0.77844 (r=0.657,p=0.956),  time:37.609, tt:7785.128\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00081, loss_test:0.02192, lr:1.00e-02, fs:0.59908 (r=0.747,p=0.500),  time:641.824, tt:641.824\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00060, loss_test:0.01982, lr:1.00e-02, fs:0.60377 (r=0.736,p=0.512),  time:654.771, tt:1309.542\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00053, loss_test:0.01821, lr:1.00e-02, fs:0.67299 (r=0.816,p=0.573),  time:655.288, tt:1965.865\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00048, loss_test:0.01706, lr:1.00e-02, fs:0.70588 (r=0.828,p=0.615),  time:655.609, tt:2622.437\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00044, loss_test:0.01612, lr:1.00e-02, fs:0.72727 (r=0.828,p=0.649),  time:656.341, tt:3281.703\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00040, loss_test:0.01521, lr:1.00e-02, fs:0.77895 (r=0.851,p=0.718),  time:655.962, tt:3935.774\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00036, loss_test:0.01457, lr:1.00e-02, fs:0.78723 (r=0.851,p=0.733),  time:653.947, tt:4577.626\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00033, loss_test:0.01418, lr:1.00e-02, fs:0.80874 (r=0.851,p=0.771),  time:653.751, tt:5230.011\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00030, loss_test:0.01386, lr:1.00e-02, fs:0.80874 (r=0.851,p=0.771),  time:653.761, tt:5883.852\n",
      "Ep:9, loss:0.00027, loss_test:0.01393, lr:1.00e-02, fs:0.83616 (r=0.851,p=0.822),  time:654.313, tt:6543.134\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00025, loss_test:0.01393, lr:1.00e-02, fs:0.84091 (r=0.851,p=0.831),  time:653.652, tt:7190.171\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00023, loss_test:0.01401, lr:1.00e-02, fs:0.84524 (r=0.816,p=0.877),  time:653.506, tt:7842.068\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.01417, lr:1.00e-02, fs:0.83636 (r=0.793,p=0.885),  time:653.354, tt:8493.596\n",
      "Ep:13, loss:0.00019, loss_test:0.01436, lr:1.00e-02, fs:0.81481 (r=0.759,p=0.880),  time:652.983, tt:9141.769\n",
      "Ep:14, loss:0.00018, loss_test:0.01463, lr:1.00e-02, fs:0.81761 (r=0.747,p=0.903),  time:652.628, tt:9789.422\n",
      "Ep:15, loss:0.00017, loss_test:0.01496, lr:1.00e-02, fs:0.82051 (r=0.736,p=0.928),  time:652.497, tt:10439.956\n",
      "Ep:16, loss:0.00015, loss_test:0.01525, lr:1.00e-02, fs:0.82051 (r=0.736,p=0.928),  time:652.429, tt:11091.292\n",
      "Ep:17, loss:0.00014, loss_test:0.01560, lr:1.00e-02, fs:0.82581 (r=0.736,p=0.941),  time:652.176, tt:11739.172\n",
      "Ep:18, loss:0.00013, loss_test:0.01604, lr:1.00e-02, fs:0.82581 (r=0.736,p=0.941),  time:652.058, tt:12389.108\n",
      "Ep:19, loss:0.00013, loss_test:0.01635, lr:1.00e-02, fs:0.82581 (r=0.736,p=0.941),  time:652.060, tt:13041.202\n",
      "Ep:20, loss:0.00012, loss_test:0.01678, lr:1.00e-02, fs:0.82581 (r=0.736,p=0.941),  time:651.793, tt:13687.645\n",
      "Ep:21, loss:0.00011, loss_test:0.01721, lr:1.00e-02, fs:0.82581 (r=0.736,p=0.941),  time:651.874, tt:14341.235\n",
      "Ep:22, loss:0.00010, loss_test:0.01741, lr:1.00e-02, fs:0.83117 (r=0.736,p=0.955),  time:651.976, tt:14995.456\n",
      "Ep:23, loss:0.00010, loss_test:0.01806, lr:9.90e-03, fs:0.83117 (r=0.736,p=0.955),  time:652.088, tt:15650.110\n",
      "Ep:24, loss:0.00009, loss_test:0.01826, lr:9.80e-03, fs:0.83117 (r=0.736,p=0.955),  time:652.258, tt:16306.449\n",
      "Ep:25, loss:0.00009, loss_test:0.01867, lr:9.70e-03, fs:0.83660 (r=0.736,p=0.970),  time:652.402, tt:16962.444\n",
      "Ep:26, loss:0.00008, loss_test:0.01894, lr:9.61e-03, fs:0.83660 (r=0.736,p=0.970),  time:652.584, tt:17619.757\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00080, loss_test:0.02287, lr:1.00e-02, fs:0.61033 (r=0.747,p=0.516),  time:656.296, tt:656.296\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00060, loss_test:0.01973, lr:1.00e-02, fs:0.62559 (r=0.759,p=0.532),  time:667.901, tt:1335.802\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00053, loss_test:0.01752, lr:1.00e-02, fs:0.69565 (r=0.828,p=0.600),  time:669.357, tt:2008.071\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00046, loss_test:0.01596, lr:1.00e-02, fs:0.71287 (r=0.828,p=0.626),  time:670.754, tt:2683.014\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00041, loss_test:0.01456, lr:1.00e-02, fs:0.76923 (r=0.862,p=0.694),  time:669.754, tt:3348.771\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00036, loss_test:0.01368, lr:1.00e-02, fs:0.80423 (r=0.874,p=0.745),  time:669.814, tt:4018.881\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00032, loss_test:0.01314, lr:1.00e-02, fs:0.83060 (r=0.874,p=0.792),  time:669.176, tt:4684.229\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00029, loss_test:0.01271, lr:1.00e-02, fs:0.83978 (r=0.874,p=0.809),  time:669.111, tt:5352.888\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00026, loss_test:0.01251, lr:1.00e-02, fs:0.87356 (r=0.874,p=0.874),  time:669.349, tt:6024.142\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00024, loss_test:0.01253, lr:1.00e-02, fs:0.87861 (r=0.874,p=0.884),  time:670.744, tt:6707.441\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.01253, lr:1.00e-02, fs:0.88235 (r=0.862,p=0.904),  time:670.370, tt:7374.071\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.01253, lr:1.00e-02, fs:0.88757 (r=0.862,p=0.915),  time:670.699, tt:8048.384\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.01262, lr:1.00e-02, fs:0.88757 (r=0.862,p=0.915),  time:670.780, tt:8720.135\n",
      "Ep:13, loss:0.00017, loss_test:0.01295, lr:1.00e-02, fs:0.89820 (r=0.862,p=0.938),  time:671.149, tt:9396.086\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00015, loss_test:0.01318, lr:1.00e-02, fs:0.89157 (r=0.851,p=0.937),  time:670.731, tt:10060.967\n",
      "Ep:15, loss:0.00014, loss_test:0.01337, lr:1.00e-02, fs:0.89697 (r=0.851,p=0.949),  time:670.328, tt:10725.249\n",
      "Ep:16, loss:0.00013, loss_test:0.01374, lr:1.00e-02, fs:0.89697 (r=0.851,p=0.949),  time:670.295, tt:11395.020\n",
      "Ep:17, loss:0.00012, loss_test:0.01406, lr:1.00e-02, fs:0.90244 (r=0.851,p=0.961),  time:670.277, tt:12064.989\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00011, loss_test:0.01428, lr:1.00e-02, fs:0.90244 (r=0.851,p=0.961),  time:670.591, tt:12741.221\n",
      "Ep:19, loss:0.00011, loss_test:0.01466, lr:1.00e-02, fs:0.90683 (r=0.839,p=0.986),  time:670.352, tt:13407.041\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00010, loss_test:0.01496, lr:1.00e-02, fs:0.90683 (r=0.839,p=0.986),  time:670.308, tt:14076.458\n",
      "Ep:21, loss:0.00009, loss_test:0.01533, lr:1.00e-02, fs:0.89308 (r=0.816,p=0.986),  time:670.399, tt:14748.778\n",
      "Ep:22, loss:0.00009, loss_test:0.01559, lr:1.00e-02, fs:0.89308 (r=0.816,p=0.986),  time:670.592, tt:15423.626\n",
      "Ep:23, loss:0.00008, loss_test:0.01601, lr:1.00e-02, fs:0.89308 (r=0.816,p=0.986),  time:670.006, tt:16080.153\n",
      "Ep:24, loss:0.00008, loss_test:0.01620, lr:1.00e-02, fs:0.89308 (r=0.816,p=0.986),  time:669.969, tt:16749.235\n",
      "Ep:25, loss:0.00007, loss_test:0.01647, lr:1.00e-02, fs:0.89308 (r=0.816,p=0.986),  time:669.274, tt:17401.131\n",
      "Ep:26, loss:0.00007, loss_test:0.01689, lr:1.00e-02, fs:0.89308 (r=0.816,p=0.986),  time:668.017, tt:18036.467\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00074, loss_test:0.02097, lr:1.00e-02, fs:0.61864 (r=0.839,p=0.490),  time:686.876, tt:686.876\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00059, loss_test:0.01967, lr:1.00e-02, fs:0.65471 (r=0.839,p=0.537),  time:692.593, tt:1385.186\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00054, loss_test:0.01872, lr:1.00e-02, fs:0.65741 (r=0.816,p=0.550),  time:694.127, tt:2082.382\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00050, loss_test:0.01793, lr:1.00e-02, fs:0.68932 (r=0.816,p=0.597),  time:693.187, tt:2772.747\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00047, loss_test:0.01735, lr:1.00e-02, fs:0.70707 (r=0.805,p=0.631),  time:693.129, tt:3465.646\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00044, loss_test:0.01696, lr:1.00e-02, fs:0.71875 (r=0.793,p=0.657),  time:693.947, tt:4163.679\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00042, loss_test:0.01662, lr:1.00e-02, fs:0.72826 (r=0.770,p=0.691),  time:694.726, tt:4863.083\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00039, loss_test:0.01620, lr:1.00e-02, fs:0.74317 (r=0.782,p=0.708),  time:694.441, tt:5555.528\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00037, loss_test:0.01586, lr:1.00e-02, fs:0.75556 (r=0.782,p=0.731),  time:694.269, tt:6248.420\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00035, loss_test:0.01565, lr:1.00e-02, fs:0.76301 (r=0.759,p=0.767),  time:694.490, tt:6944.902\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00033, loss_test:0.01537, lr:1.00e-02, fs:0.76744 (r=0.759,p=0.776),  time:694.452, tt:7638.972\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00031, loss_test:0.01523, lr:1.00e-02, fs:0.77647 (r=0.759,p=0.795),  time:695.158, tt:8341.893\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00030, loss_test:0.01513, lr:1.00e-02, fs:0.75449 (r=0.724,p=0.787),  time:695.407, tt:9040.296\n",
      "Ep:13, loss:0.00028, loss_test:0.01496, lr:1.00e-02, fs:0.75449 (r=0.724,p=0.787),  time:694.997, tt:9729.957\n",
      "Ep:14, loss:0.00027, loss_test:0.01485, lr:1.00e-02, fs:0.75904 (r=0.724,p=0.797),  time:695.175, tt:10427.619\n",
      "Ep:15, loss:0.00025, loss_test:0.01484, lr:1.00e-02, fs:0.74074 (r=0.690,p=0.800),  time:694.947, tt:11119.159\n",
      "Ep:16, loss:0.00024, loss_test:0.01473, lr:1.00e-02, fs:0.73750 (r=0.678,p=0.808),  time:695.107, tt:11816.822\n",
      "Ep:17, loss:0.00023, loss_test:0.01465, lr:1.00e-02, fs:0.74684 (r=0.678,p=0.831),  time:695.225, tt:12514.048\n",
      "Ep:18, loss:0.00022, loss_test:0.01462, lr:1.00e-02, fs:0.76129 (r=0.678,p=0.868),  time:695.620, tt:13216.780\n",
      "Ep:19, loss:0.00020, loss_test:0.01461, lr:1.00e-02, fs:0.76129 (r=0.678,p=0.868),  time:695.861, tt:13917.224\n",
      "Ep:20, loss:0.00019, loss_test:0.01466, lr:1.00e-02, fs:0.77124 (r=0.678,p=0.894),  time:696.125, tt:14618.622\n",
      "Ep:21, loss:0.00019, loss_test:0.01463, lr:1.00e-02, fs:0.77632 (r=0.678,p=0.908),  time:696.488, tt:15322.742\n",
      "Ep:22, loss:0.00018, loss_test:0.01461, lr:1.00e-02, fs:0.78146 (r=0.678,p=0.922),  time:696.059, tt:16009.355\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00017, loss_test:0.01477, lr:1.00e-02, fs:0.78667 (r=0.678,p=0.937),  time:696.144, tt:16707.454\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00016, loss_test:0.01484, lr:1.00e-02, fs:0.79195 (r=0.678,p=0.952),  time:696.115, tt:17402.876\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00015, loss_test:0.01482, lr:1.00e-02, fs:0.79195 (r=0.678,p=0.952),  time:695.503, tt:18083.091\n",
      "Ep:26, loss:0.00014, loss_test:0.01494, lr:1.00e-02, fs:0.79195 (r=0.678,p=0.952),  time:695.354, tt:18774.557\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00075, loss_test:0.02066, lr:1.00e-02, fs:0.64228 (r=0.908,p=0.497),  time:694.313, tt:694.313\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00062, loss_test:0.01996, lr:1.00e-02, fs:0.61111 (r=0.759,p=0.512),  time:696.547, tt:1393.094\n",
      "Ep:2, loss:0.00058, loss_test:0.01927, lr:1.00e-02, fs:0.62857 (r=0.759,p=0.537),  time:695.639, tt:2086.918\n",
      "Ep:3, loss:0.00055, loss_test:0.01869, lr:1.00e-02, fs:0.66351 (r=0.805,p=0.565),  time:696.432, tt:2785.729\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00053, loss_test:0.01816, lr:1.00e-02, fs:0.69194 (r=0.839,p=0.589),  time:697.772, tt:3488.860\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00051, loss_test:0.01764, lr:1.00e-02, fs:0.70874 (r=0.839,p=0.613),  time:707.320, tt:4243.922\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00049, loss_test:0.01711, lr:1.00e-02, fs:0.71569 (r=0.839,p=0.624),  time:705.221, tt:4936.548\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00047, loss_test:0.01663, lr:1.00e-02, fs:0.72637 (r=0.839,p=0.640),  time:703.814, tt:5630.511\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00045, loss_test:0.01623, lr:1.00e-02, fs:0.74490 (r=0.839,p=0.670),  time:703.352, tt:6330.167\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00044, loss_test:0.01586, lr:1.00e-02, fs:0.77487 (r=0.851,p=0.712),  time:702.249, tt:7022.490\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00042, loss_test:0.01550, lr:1.00e-02, fs:0.78125 (r=0.862,p=0.714),  time:702.755, tt:7730.310\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00041, loss_test:0.01519, lr:1.00e-02, fs:0.77720 (r=0.862,p=0.708),  time:702.364, tt:8428.374\n",
      "Ep:12, loss:0.00040, loss_test:0.01490, lr:1.00e-02, fs:0.77720 (r=0.862,p=0.708),  time:702.946, tt:9138.299\n",
      "Ep:13, loss:0.00038, loss_test:0.01463, lr:1.00e-02, fs:0.76842 (r=0.839,p=0.709),  time:702.536, tt:9835.508\n",
      "Ep:14, loss:0.00037, loss_test:0.01436, lr:1.00e-02, fs:0.78947 (r=0.862,p=0.728),  time:702.476, tt:10537.143\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00036, loss_test:0.01415, lr:1.00e-02, fs:0.80423 (r=0.874,p=0.745),  time:702.369, tt:11237.909\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00035, loss_test:0.01394, lr:1.00e-02, fs:0.80423 (r=0.874,p=0.745),  time:702.877, tt:11948.905\n",
      "Ep:17, loss:0.00034, loss_test:0.01371, lr:1.00e-02, fs:0.81481 (r=0.885,p=0.755),  time:702.532, tt:12645.583\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00033, loss_test:0.01354, lr:1.00e-02, fs:0.81283 (r=0.874,p=0.760),  time:702.268, tt:13343.092\n",
      "Ep:19, loss:0.00032, loss_test:0.01341, lr:1.00e-02, fs:0.82609 (r=0.874,p=0.784),  time:702.356, tt:14047.127\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00031, loss_test:0.01322, lr:1.00e-02, fs:0.82609 (r=0.874,p=0.784),  time:702.470, tt:14751.867\n",
      "Ep:21, loss:0.00030, loss_test:0.01311, lr:1.00e-02, fs:0.82222 (r=0.851,p=0.796),  time:702.137, tt:15447.022\n",
      "Ep:22, loss:0.00029, loss_test:0.01297, lr:1.00e-02, fs:0.83146 (r=0.851,p=0.813),  time:701.895, tt:16143.580\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00028, loss_test:0.01284, lr:1.00e-02, fs:0.83146 (r=0.851,p=0.813),  time:701.823, tt:16843.758\n",
      "Ep:24, loss:0.00027, loss_test:0.01270, lr:1.00e-02, fs:0.83616 (r=0.851,p=0.822),  time:701.549, tt:17538.714\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00026, loss_test:0.01253, lr:1.00e-02, fs:0.84091 (r=0.851,p=0.831),  time:701.951, tt:18250.738\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00026, loss_test:0.01242, lr:1.00e-02, fs:0.84571 (r=0.851,p=0.841),  time:702.067, tt:18955.812\n",
      "##########Best model found so far##########\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00077, loss_test:0.02053, lr:1.00e-02, fs:0.63598 (r=0.874,p=0.500),  time:611.788, tt:611.788\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00061, loss_test:0.01998, lr:1.00e-02, fs:0.63393 (r=0.816,p=0.518),  time:602.289, tt:1204.578\n",
      "Ep:2, loss:0.00056, loss_test:0.01915, lr:1.00e-02, fs:0.67890 (r=0.851,p=0.565),  time:599.543, tt:1798.629\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00052, loss_test:0.01841, lr:1.00e-02, fs:0.68571 (r=0.828,p=0.585),  time:598.837, tt:2395.347\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00049, loss_test:0.01768, lr:1.00e-02, fs:0.71921 (r=0.839,p=0.629),  time:598.257, tt:2991.283\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00046, loss_test:0.01715, lr:1.00e-02, fs:0.73000 (r=0.839,p=0.646),  time:596.487, tt:3578.925\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00044, loss_test:0.01665, lr:1.00e-02, fs:0.73737 (r=0.839,p=0.658),  time:596.503, tt:4175.524\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00042, loss_test:0.01623, lr:1.00e-02, fs:0.74227 (r=0.828,p=0.673),  time:596.829, tt:4774.635\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00040, loss_test:0.01586, lr:1.00e-02, fs:0.75789 (r=0.828,p=0.699),  time:596.128, tt:5365.148\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00038, loss_test:0.01554, lr:1.00e-02, fs:0.79348 (r=0.839,p=0.753),  time:596.195, tt:5961.946\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00036, loss_test:0.01516, lr:1.00e-02, fs:0.79781 (r=0.839,p=0.760),  time:596.632, tt:6562.955\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00034, loss_test:0.01499, lr:1.00e-02, fs:0.79121 (r=0.828,p=0.758),  time:597.327, tt:7167.923\n",
      "Ep:12, loss:0.00032, loss_test:0.01482, lr:1.00e-02, fs:0.81111 (r=0.839,p=0.785),  time:596.829, tt:7758.777\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00031, loss_test:0.01457, lr:1.00e-02, fs:0.81564 (r=0.839,p=0.793),  time:596.811, tt:8355.351\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00030, loss_test:0.01449, lr:1.00e-02, fs:0.81143 (r=0.816,p=0.807),  time:596.442, tt:8946.633\n",
      "Ep:15, loss:0.00028, loss_test:0.01433, lr:1.00e-02, fs:0.81818 (r=0.828,p=0.809),  time:596.278, tt:9540.443\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00027, loss_test:0.01426, lr:1.00e-02, fs:0.82081 (r=0.816,p=0.826),  time:596.242, tt:10136.117\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00026, loss_test:0.01414, lr:1.00e-02, fs:0.83041 (r=0.816,p=0.845),  time:595.990, tt:10727.826\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00024, loss_test:0.01407, lr:1.00e-02, fs:0.82353 (r=0.805,p=0.843),  time:595.857, tt:11321.281\n",
      "Ep:19, loss:0.00023, loss_test:0.01400, lr:1.00e-02, fs:0.82840 (r=0.805,p=0.854),  time:595.630, tt:11912.595\n",
      "Ep:20, loss:0.00022, loss_test:0.01402, lr:1.00e-02, fs:0.84337 (r=0.805,p=0.886),  time:595.696, tt:12509.614\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00021, loss_test:0.01397, lr:1.00e-02, fs:0.83636 (r=0.793,p=0.885),  time:595.421, tt:13099.264\n",
      "Ep:22, loss:0.00020, loss_test:0.01391, lr:1.00e-02, fs:0.83636 (r=0.793,p=0.885),  time:595.411, tt:13694.452\n",
      "Ep:23, loss:0.00020, loss_test:0.01388, lr:1.00e-02, fs:0.83951 (r=0.782,p=0.907),  time:592.635, tt:14223.242\n",
      "Ep:24, loss:0.00019, loss_test:0.01381, lr:1.00e-02, fs:0.83230 (r=0.770,p=0.905),  time:589.992, tt:14749.802\n",
      "Ep:25, loss:0.00018, loss_test:0.01383, lr:1.00e-02, fs:0.81761 (r=0.747,p=0.903),  time:587.774, tt:15282.134\n",
      "Ep:26, loss:0.00017, loss_test:0.01382, lr:1.00e-02, fs:0.80769 (r=0.724,p=0.913),  time:585.764, tt:15815.625\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00096, loss_test:0.02639, lr:1.00e-02, fs:0.59729 (r=0.759,p=0.493),  time:587.910, tt:587.910\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00066, loss_test:0.02152, lr:1.00e-02, fs:0.59908 (r=0.747,p=0.500),  time:595.614, tt:1191.227\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00055, loss_test:0.01896, lr:1.00e-02, fs:0.65438 (r=0.816,p=0.546),  time:597.341, tt:1792.022\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00047, loss_test:0.01729, lr:1.00e-02, fs:0.69194 (r=0.839,p=0.589),  time:598.116, tt:2392.465\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00041, loss_test:0.01611, lr:1.00e-02, fs:0.71642 (r=0.828,p=0.632),  time:598.576, tt:2992.878\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00035, loss_test:0.01492, lr:1.00e-02, fs:0.74490 (r=0.839,p=0.670),  time:598.462, tt:3590.772\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00030, loss_test:0.01410, lr:1.00e-02, fs:0.79167 (r=0.874,p=0.724),  time:597.717, tt:4184.018\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00026, loss_test:0.01329, lr:1.00e-02, fs:0.81522 (r=0.862,p=0.773),  time:598.765, tt:4790.122\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.01296, lr:1.00e-02, fs:0.83333 (r=0.862,p=0.806),  time:597.903, tt:5381.124\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00019, loss_test:0.01296, lr:1.00e-02, fs:0.84270 (r=0.862,p=0.824),  time:598.453, tt:5984.533\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00016, loss_test:0.01269, lr:1.00e-02, fs:0.84746 (r=0.862,p=0.833),  time:598.359, tt:6581.949\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00014, loss_test:0.01290, lr:1.00e-02, fs:0.85057 (r=0.851,p=0.851),  time:598.523, tt:7182.278\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00012, loss_test:0.01264, lr:1.00e-02, fs:0.86550 (r=0.851,p=0.881),  time:598.466, tt:7780.056\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00010, loss_test:0.01291, lr:1.00e-02, fs:0.87952 (r=0.839,p=0.924),  time:598.401, tt:8377.612\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00009, loss_test:0.01284, lr:1.00e-02, fs:0.89024 (r=0.839,p=0.948),  time:598.820, tt:8982.306\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00008, loss_test:0.01327, lr:1.00e-02, fs:0.87654 (r=0.816,p=0.947),  time:598.374, tt:9573.984\n",
      "Ep:16, loss:0.00007, loss_test:0.01351, lr:1.00e-02, fs:0.88199 (r=0.816,p=0.959),  time:598.522, tt:10174.871\n",
      "Ep:17, loss:0.00006, loss_test:0.01388, lr:1.00e-02, fs:0.88750 (r=0.816,p=0.973),  time:598.441, tt:10771.946\n",
      "Ep:18, loss:0.00006, loss_test:0.01410, lr:1.00e-02, fs:0.88750 (r=0.816,p=0.973),  time:598.609, tt:11373.578\n",
      "Ep:19, loss:0.00005, loss_test:0.01424, lr:1.00e-02, fs:0.88750 (r=0.816,p=0.973),  time:595.521, tt:11910.422\n",
      "Ep:20, loss:0.00005, loss_test:0.01437, lr:1.00e-02, fs:0.88750 (r=0.816,p=0.973),  time:589.598, tt:12381.568\n",
      "Ep:21, loss:0.00004, loss_test:0.01466, lr:1.00e-02, fs:0.88750 (r=0.816,p=0.973),  time:583.186, tt:12830.085\n",
      "Ep:22, loss:0.00004, loss_test:0.01515, lr:1.00e-02, fs:0.89308 (r=0.816,p=0.986),  time:575.873, tt:13245.089\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00004, loss_test:0.01513, lr:1.00e-02, fs:0.88750 (r=0.816,p=0.973),  time:564.939, tt:13558.537\n",
      "Ep:24, loss:0.00003, loss_test:0.01556, lr:1.00e-02, fs:0.89308 (r=0.816,p=0.986),  time:551.706, tt:13792.653\n",
      "Ep:25, loss:0.00003, loss_test:0.01572, lr:1.00e-02, fs:0.89308 (r=0.816,p=0.986),  time:539.532, tt:14027.843\n",
      "Ep:26, loss:0.00003, loss_test:0.01599, lr:1.00e-02, fs:0.89308 (r=0.816,p=0.986),  time:526.661, tt:14219.845\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00070, loss_test:0.01970, lr:1.00e-02, fs:0.61611 (r=0.747,p=0.524),  time:711.248, tt:711.248\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.01770, lr:1.00e-02, fs:0.67593 (r=0.839,p=0.566),  time:685.604, tt:1371.208\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00049, loss_test:0.01642, lr:1.00e-02, fs:0.71845 (r=0.851,p=0.622),  time:679.194, tt:2037.583\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00044, loss_test:0.01557, lr:1.00e-02, fs:0.75510 (r=0.851,p=0.679),  time:678.765, tt:2715.058\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00040, loss_test:0.01482, lr:1.00e-02, fs:0.77720 (r=0.862,p=0.708),  time:677.183, tt:3385.917\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00037, loss_test:0.01424, lr:1.00e-02, fs:0.80214 (r=0.862,p=0.750),  time:674.131, tt:4044.788\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00034, loss_test:0.01368, lr:1.00e-02, fs:0.83696 (r=0.885,p=0.794),  time:674.264, tt:4719.845\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00031, loss_test:0.01323, lr:1.00e-02, fs:0.86188 (r=0.897,p=0.830),  time:674.725, tt:5397.802\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00029, loss_test:0.01288, lr:1.00e-02, fs:0.86857 (r=0.874,p=0.864),  time:674.688, tt:6072.189\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00027, loss_test:0.01257, lr:1.00e-02, fs:0.86857 (r=0.874,p=0.864),  time:679.538, tt:6795.376\n",
      "Ep:10, loss:0.00025, loss_test:0.01247, lr:1.00e-02, fs:0.86705 (r=0.862,p=0.872),  time:687.495, tt:7562.440\n",
      "Ep:11, loss:0.00023, loss_test:0.01227, lr:1.00e-02, fs:0.87719 (r=0.862,p=0.893),  time:693.475, tt:8321.699\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.01222, lr:1.00e-02, fs:0.87574 (r=0.851,p=0.902),  time:698.687, tt:9082.936\n",
      "Ep:13, loss:0.00020, loss_test:0.01204, lr:1.00e-02, fs:0.87273 (r=0.828,p=0.923),  time:703.126, tt:9843.766\n",
      "Ep:14, loss:0.00019, loss_test:0.01194, lr:1.00e-02, fs:0.86585 (r=0.816,p=0.922),  time:706.712, tt:10600.677\n",
      "Ep:15, loss:0.00017, loss_test:0.01206, lr:1.00e-02, fs:0.82278 (r=0.747,p=0.915),  time:709.712, tt:11355.384\n",
      "Ep:16, loss:0.00016, loss_test:0.01194, lr:1.00e-02, fs:0.82051 (r=0.736,p=0.928),  time:712.199, tt:12107.379\n",
      "Ep:17, loss:0.00015, loss_test:0.01219, lr:1.00e-02, fs:0.81046 (r=0.713,p=0.939),  time:714.270, tt:12856.862\n",
      "Ep:18, loss:0.00014, loss_test:0.01211, lr:1.00e-02, fs:0.81046 (r=0.713,p=0.939),  time:716.174, tt:13607.316\n",
      "Ep:19, loss:0.00013, loss_test:0.01212, lr:1.00e-02, fs:0.81046 (r=0.713,p=0.939),  time:718.023, tt:14360.453\n",
      "Ep:20, loss:0.00013, loss_test:0.01222, lr:1.00e-02, fs:0.81579 (r=0.713,p=0.954),  time:720.208, tt:15124.369\n",
      "Ep:21, loss:0.00012, loss_test:0.01230, lr:1.00e-02, fs:0.81579 (r=0.713,p=0.954),  time:721.460, tt:15872.126\n",
      "Ep:22, loss:0.00011, loss_test:0.01239, lr:1.00e-02, fs:0.81579 (r=0.713,p=0.954),  time:723.199, tt:16633.579\n",
      "Ep:23, loss:0.00011, loss_test:0.01246, lr:9.90e-03, fs:0.82119 (r=0.713,p=0.969),  time:724.986, tt:17399.674\n",
      "Ep:24, loss:0.00010, loss_test:0.01243, lr:9.80e-03, fs:0.82119 (r=0.713,p=0.969),  time:726.119, tt:18152.979\n",
      "Ep:25, loss:0.00009, loss_test:0.01263, lr:9.70e-03, fs:0.82119 (r=0.713,p=0.969),  time:727.003, tt:18902.069\n",
      "Ep:26, loss:0.00009, loss_test:0.01274, lr:9.61e-03, fs:0.82119 (r=0.713,p=0.969),  time:727.392, tt:19639.596\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 20000: \n",
      "Ep:0, loss:0.00001, loss_test:0.14318, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:42.695, tt:42.695\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00001, loss_test:0.14165, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:44.903, tt:89.806\n",
      "Ep:2, loss:0.00001, loss_test:0.13894, lr:1.00e-02, fs:0.66142 (r=0.966,p=0.503),  time:46.830, tt:140.490\n",
      "Ep:3, loss:0.00001, loss_test:0.13422, lr:1.00e-02, fs:0.62447 (r=0.851,p=0.493),  time:47.478, tt:189.913\n",
      "Ep:4, loss:0.00001, loss_test:0.12946, lr:1.00e-02, fs:0.59406 (r=0.690,p=0.522),  time:47.807, tt:239.036\n",
      "Ep:5, loss:0.00001, loss_test:0.12863, lr:1.00e-02, fs:0.60355 (r=0.586,p=0.622),  time:48.096, tt:288.575\n",
      "Ep:6, loss:0.00001, loss_test:0.12861, lr:1.00e-02, fs:0.61728 (r=0.575,p=0.667),  time:48.142, tt:336.991\n",
      "Ep:7, loss:0.00001, loss_test:0.12498, lr:1.00e-02, fs:0.61714 (r=0.621,p=0.614),  time:48.468, tt:387.742\n",
      "Ep:8, loss:0.00001, loss_test:0.12219, lr:1.00e-02, fs:0.61364 (r=0.621,p=0.607),  time:48.559, tt:437.026\n",
      "Ep:9, loss:0.00001, loss_test:0.11854, lr:1.00e-02, fs:0.63855 (r=0.609,p=0.671),  time:48.739, tt:487.393\n",
      "Ep:10, loss:0.00001, loss_test:0.11457, lr:1.00e-02, fs:0.64198 (r=0.598,p=0.693),  time:48.805, tt:536.856\n",
      "Ep:11, loss:0.00001, loss_test:0.11063, lr:1.00e-02, fs:0.64671 (r=0.621,p=0.675),  time:48.908, tt:586.898\n",
      "Ep:12, loss:0.00001, loss_test:0.10675, lr:9.90e-03, fs:0.66272 (r=0.644,p=0.683),  time:49.009, tt:637.118\n",
      "Ep:13, loss:0.00001, loss_test:0.10341, lr:9.80e-03, fs:0.69136 (r=0.644,p=0.747),  time:48.999, tt:685.981\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00001, loss_test:0.09987, lr:9.80e-03, fs:0.70238 (r=0.678,p=0.728),  time:49.449, tt:741.742\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00001, loss_test:0.09662, lr:9.80e-03, fs:0.70238 (r=0.678,p=0.728),  time:49.275, tt:788.399\n",
      "Ep:16, loss:0.00001, loss_test:0.09374, lr:9.80e-03, fs:0.74847 (r=0.701,p=0.803),  time:49.296, tt:838.034\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00001, loss_test:0.09162, lr:9.80e-03, fs:0.77844 (r=0.747,p=0.812),  time:49.279, tt:887.017\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00001, loss_test:0.08930, lr:9.80e-03, fs:0.78824 (r=0.770,p=0.807),  time:49.233, tt:935.435\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00001, loss_test:0.08695, lr:9.80e-03, fs:0.80240 (r=0.770,p=0.838),  time:49.193, tt:983.863\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00001, loss_test:0.08510, lr:9.80e-03, fs:0.80952 (r=0.782,p=0.840),  time:49.185, tt:1032.886\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00001, loss_test:0.08314, lr:9.80e-03, fs:0.81657 (r=0.793,p=0.841),  time:49.109, tt:1080.390\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00001, loss_test:0.08123, lr:9.80e-03, fs:0.81437 (r=0.782,p=0.850),  time:49.071, tt:1128.634\n",
      "Ep:23, loss:0.00001, loss_test:0.07951, lr:9.80e-03, fs:0.82143 (r=0.793,p=0.852),  time:49.118, tt:1178.823\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00001, loss_test:0.07760, lr:9.80e-03, fs:0.82927 (r=0.782,p=0.883),  time:49.124, tt:1228.096\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00001, loss_test:0.07520, lr:9.80e-03, fs:0.85030 (r=0.816,p=0.887),  time:49.091, tt:1276.378\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00001, loss_test:0.07360, lr:9.80e-03, fs:0.84848 (r=0.805,p=0.897),  time:49.078, tt:1325.113\n",
      "Ep:27, loss:0.00001, loss_test:0.07192, lr:9.80e-03, fs:0.86228 (r=0.828,p=0.900),  time:49.060, tt:1373.676\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00001, loss_test:0.07089, lr:9.80e-03, fs:0.86905 (r=0.839,p=0.901),  time:49.035, tt:1422.023\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00000, loss_test:0.06977, lr:9.80e-03, fs:0.86905 (r=0.839,p=0.901),  time:49.048, tt:1471.438\n",
      "Ep:30, loss:0.00000, loss_test:0.06819, lr:9.80e-03, fs:0.87425 (r=0.839,p=0.912),  time:49.048, tt:1520.487\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00000, loss_test:0.06746, lr:9.80e-03, fs:0.87425 (r=0.839,p=0.912),  time:48.980, tt:1567.351\n",
      "Ep:32, loss:0.00000, loss_test:0.06611, lr:9.80e-03, fs:0.87273 (r=0.828,p=0.923),  time:49.070, tt:1619.322\n",
      "Ep:33, loss:0.00000, loss_test:0.06537, lr:9.80e-03, fs:0.87805 (r=0.828,p=0.935),  time:49.044, tt:1667.511\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00000, loss_test:0.06447, lr:9.80e-03, fs:0.87117 (r=0.816,p=0.934),  time:48.958, tt:1713.529\n",
      "Ep:35, loss:0.00000, loss_test:0.06429, lr:9.80e-03, fs:0.88199 (r=0.816,p=0.959),  time:48.927, tt:1761.355\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00000, loss_test:0.06379, lr:9.80e-03, fs:0.88199 (r=0.816,p=0.959),  time:48.923, tt:1810.169\n",
      "Ep:37, loss:0.00000, loss_test:0.06378, lr:9.80e-03, fs:0.88199 (r=0.816,p=0.959),  time:48.971, tt:1860.908\n",
      "Ep:38, loss:0.00000, loss_test:0.06317, lr:9.80e-03, fs:0.88199 (r=0.816,p=0.959),  time:49.006, tt:1911.251\n",
      "Ep:39, loss:0.00000, loss_test:0.06330, lr:9.80e-03, fs:0.88750 (r=0.816,p=0.973),  time:49.000, tt:1960.018\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00000, loss_test:0.06233, lr:9.80e-03, fs:0.88750 (r=0.816,p=0.973),  time:48.971, tt:2007.793\n",
      "Ep:41, loss:0.00000, loss_test:0.06267, lr:9.80e-03, fs:0.88750 (r=0.816,p=0.973),  time:48.974, tt:2056.925\n",
      "Ep:42, loss:0.00000, loss_test:0.06139, lr:9.80e-03, fs:0.88750 (r=0.816,p=0.973),  time:48.928, tt:2103.888\n",
      "Ep:43, loss:0.00000, loss_test:0.06133, lr:9.80e-03, fs:0.88750 (r=0.816,p=0.973),  time:48.893, tt:2151.277\n",
      "Ep:44, loss:0.00000, loss_test:0.06060, lr:9.80e-03, fs:0.89308 (r=0.816,p=0.986),  time:48.907, tt:2200.820\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00000, loss_test:0.06144, lr:9.80e-03, fs:0.89308 (r=0.816,p=0.986),  time:48.913, tt:2250.017\n",
      "Ep:46, loss:0.00000, loss_test:0.05915, lr:9.80e-03, fs:0.89308 (r=0.816,p=0.986),  time:48.887, tt:2297.692\n",
      "Ep:47, loss:0.00000, loss_test:0.06127, lr:9.80e-03, fs:0.89308 (r=0.816,p=0.986),  time:48.920, tt:2348.148\n",
      "Ep:48, loss:0.00000, loss_test:0.05876, lr:9.80e-03, fs:0.89308 (r=0.816,p=0.986),  time:48.911, tt:2396.648\n",
      "Ep:49, loss:0.00000, loss_test:0.06002, lr:9.80e-03, fs:0.89308 (r=0.816,p=0.986),  time:48.911, tt:2445.539\n",
      "Ep:50, loss:0.00000, loss_test:0.05979, lr:9.80e-03, fs:0.89308 (r=0.816,p=0.986),  time:48.953, tt:2496.618\n",
      "Ep:51, loss:0.00000, loss_test:0.05866, lr:9.80e-03, fs:0.89308 (r=0.816,p=0.986),  time:48.903, tt:2542.981\n",
      "Ep:52, loss:0.00000, loss_test:0.05932, lr:9.80e-03, fs:0.89308 (r=0.816,p=0.986),  time:48.888, tt:2591.052\n",
      "Ep:53, loss:0.00000, loss_test:0.05832, lr:9.80e-03, fs:0.89308 (r=0.816,p=0.986),  time:48.914, tt:2641.350\n",
      "Ep:54, loss:0.00000, loss_test:0.05853, lr:9.80e-03, fs:0.89873 (r=0.816,p=1.000),  time:48.921, tt:2690.642\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00000, loss_test:0.05777, lr:9.80e-03, fs:0.89308 (r=0.816,p=0.986),  time:48.937, tt:2740.476\n",
      "Ep:56, loss:0.00000, loss_test:0.05936, lr:9.80e-03, fs:0.89308 (r=0.816,p=0.986),  time:48.913, tt:2788.065\n",
      "Ep:57, loss:0.00000, loss_test:0.05872, lr:9.80e-03, fs:0.89873 (r=0.816,p=1.000),  time:48.912, tt:2836.916\n",
      "Ep:58, loss:0.00000, loss_test:0.05709, lr:9.80e-03, fs:0.89873 (r=0.816,p=1.000),  time:48.921, tt:2886.320\n",
      "Ep:59, loss:0.00000, loss_test:0.05958, lr:9.80e-03, fs:0.89873 (r=0.816,p=1.000),  time:48.932, tt:2935.910\n",
      "Ep:60, loss:0.00000, loss_test:0.05745, lr:9.80e-03, fs:0.89873 (r=0.816,p=1.000),  time:48.917, tt:2983.909\n",
      "Ep:61, loss:0.00000, loss_test:0.05847, lr:9.80e-03, fs:0.89873 (r=0.816,p=1.000),  time:48.921, tt:3033.085\n",
      "Ep:62, loss:0.00000, loss_test:0.05786, lr:9.80e-03, fs:0.89873 (r=0.816,p=1.000),  time:48.911, tt:3081.423\n",
      "Ep:63, loss:0.00000, loss_test:0.05838, lr:9.80e-03, fs:0.89873 (r=0.816,p=1.000),  time:48.886, tt:3128.704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00000, loss_test:0.06041, lr:9.80e-03, fs:0.89873 (r=0.816,p=1.000),  time:48.840, tt:3174.604\n",
      "Ep:65, loss:0.00000, loss_test:0.05866, lr:9.80e-03, fs:0.89873 (r=0.816,p=1.000),  time:48.815, tt:3221.814\n",
      "Ep:66, loss:0.00000, loss_test:0.05898, lr:9.70e-03, fs:0.89873 (r=0.816,p=1.000),  time:48.838, tt:3272.157\n",
      "Ep:67, loss:0.00000, loss_test:0.05911, lr:9.61e-03, fs:0.89873 (r=0.816,p=1.000),  time:48.827, tt:3320.252\n",
      "Ep:68, loss:0.00000, loss_test:0.05896, lr:9.51e-03, fs:0.89873 (r=0.816,p=1.000),  time:48.841, tt:3370.002\n",
      "Ep:69, loss:0.00000, loss_test:0.06058, lr:9.41e-03, fs:0.89873 (r=0.816,p=1.000),  time:48.866, tt:3420.606\n",
      "Ep:70, loss:0.00000, loss_test:0.05907, lr:9.32e-03, fs:0.89873 (r=0.816,p=1.000),  time:48.847, tt:3468.162\n",
      "Ep:71, loss:0.00000, loss_test:0.06109, lr:9.23e-03, fs:0.89873 (r=0.816,p=1.000),  time:48.839, tt:3516.395\n",
      "Ep:72, loss:0.00000, loss_test:0.05942, lr:9.14e-03, fs:0.89873 (r=0.816,p=1.000),  time:48.835, tt:3564.959\n",
      "Ep:73, loss:0.00000, loss_test:0.06030, lr:9.04e-03, fs:0.89873 (r=0.816,p=1.000),  time:48.829, tt:3613.370\n",
      "Ep:74, loss:0.00000, loss_test:0.06054, lr:8.95e-03, fs:0.89873 (r=0.816,p=1.000),  time:48.813, tt:3660.968\n",
      "Ep:75, loss:0.00000, loss_test:0.06036, lr:8.86e-03, fs:0.89873 (r=0.816,p=1.000),  time:48.805, tt:3709.188\n",
      "Ep:76, loss:0.00000, loss_test:0.06150, lr:8.78e-03, fs:0.89873 (r=0.816,p=1.000),  time:48.786, tt:3756.543\n",
      "Ep:77, loss:0.00000, loss_test:0.06022, lr:8.69e-03, fs:0.89873 (r=0.816,p=1.000),  time:48.776, tt:3804.557\n",
      "Ep:78, loss:0.00000, loss_test:0.06171, lr:8.60e-03, fs:0.89873 (r=0.816,p=1.000),  time:48.776, tt:3853.286\n",
      "Ep:79, loss:0.00000, loss_test:0.06127, lr:8.51e-03, fs:0.89873 (r=0.816,p=1.000),  time:48.741, tt:3899.268\n",
      "Ep:80, loss:0.00000, loss_test:0.06114, lr:8.43e-03, fs:0.85526 (r=0.747,p=1.000),  time:48.724, tt:3946.682\n",
      "Ep:81, loss:0.00000, loss_test:0.06210, lr:8.35e-03, fs:0.83221 (r=0.713,p=1.000),  time:48.716, tt:3994.697\n",
      "Ep:82, loss:0.00000, loss_test:0.06141, lr:8.26e-03, fs:0.85526 (r=0.747,p=1.000),  time:48.715, tt:4043.380\n",
      "Ep:83, loss:0.00000, loss_test:0.06257, lr:8.18e-03, fs:0.81633 (r=0.690,p=1.000),  time:48.738, tt:4093.993\n",
      "Ep:84, loss:0.00000, loss_test:0.06173, lr:8.10e-03, fs:0.81633 (r=0.690,p=1.000),  time:48.728, tt:4141.840\n",
      "Ep:85, loss:0.00000, loss_test:0.06302, lr:8.02e-03, fs:0.80822 (r=0.678,p=1.000),  time:48.715, tt:4189.447\n",
      "Ep:86, loss:0.00000, loss_test:0.06200, lr:7.94e-03, fs:0.80822 (r=0.678,p=1.000),  time:48.711, tt:4237.892\n",
      "Ep:87, loss:0.00000, loss_test:0.06356, lr:7.86e-03, fs:0.80822 (r=0.678,p=1.000),  time:48.698, tt:4285.433\n",
      "Ep:88, loss:0.00000, loss_test:0.06325, lr:7.78e-03, fs:0.80822 (r=0.678,p=1.000),  time:48.704, tt:4334.645\n",
      "Ep:89, loss:0.00000, loss_test:0.06335, lr:7.70e-03, fs:0.80822 (r=0.678,p=1.000),  time:48.670, tt:4380.316\n",
      "Ep:90, loss:0.00000, loss_test:0.06363, lr:7.62e-03, fs:0.80822 (r=0.678,p=1.000),  time:48.617, tt:4424.119\n",
      "Ep:91, loss:0.00000, loss_test:0.06396, lr:7.55e-03, fs:0.80822 (r=0.678,p=1.000),  time:48.562, tt:4467.726\n",
      "Ep:92, loss:0.00000, loss_test:0.06401, lr:7.47e-03, fs:0.80822 (r=0.678,p=1.000),  time:48.500, tt:4510.526\n",
      "Ep:93, loss:0.00000, loss_test:0.06404, lr:7.40e-03, fs:0.80822 (r=0.678,p=1.000),  time:48.434, tt:4552.793\n",
      "Ep:94, loss:0.00000, loss_test:0.06490, lr:7.32e-03, fs:0.80822 (r=0.678,p=1.000),  time:48.374, tt:4595.485\n",
      "Ep:95, loss:0.00000, loss_test:0.06489, lr:7.25e-03, fs:0.80822 (r=0.678,p=1.000),  time:48.308, tt:4637.608\n",
      "Ep:96, loss:0.00000, loss_test:0.06538, lr:7.18e-03, fs:0.80822 (r=0.678,p=1.000),  time:48.273, tt:4682.527\n",
      "Ep:97, loss:0.00000, loss_test:0.06488, lr:7.11e-03, fs:0.80822 (r=0.678,p=1.000),  time:48.220, tt:4725.579\n",
      "Ep:98, loss:0.00000, loss_test:0.06616, lr:7.03e-03, fs:0.80822 (r=0.678,p=1.000),  time:48.166, tt:4768.402\n",
      "Ep:99, loss:0.00000, loss_test:0.06528, lr:6.96e-03, fs:0.80822 (r=0.678,p=1.000),  time:48.114, tt:4811.449\n",
      "Ep:100, loss:0.00000, loss_test:0.06635, lr:6.89e-03, fs:0.80822 (r=0.678,p=1.000),  time:48.071, tt:4855.146\n",
      "Ep:101, loss:0.00000, loss_test:0.06589, lr:6.83e-03, fs:0.80822 (r=0.678,p=1.000),  time:48.011, tt:4897.076\n",
      "Ep:102, loss:0.00000, loss_test:0.06649, lr:6.76e-03, fs:0.80822 (r=0.678,p=1.000),  time:48.000, tt:4944.031\n",
      "Ep:103, loss:0.00000, loss_test:0.06627, lr:6.69e-03, fs:0.80822 (r=0.678,p=1.000),  time:47.902, tt:4981.802\n",
      "Ep:104, loss:0.00000, loss_test:0.06672, lr:6.62e-03, fs:0.80822 (r=0.678,p=1.000),  time:47.777, tt:5016.581\n",
      "Ep:105, loss:0.00000, loss_test:0.06640, lr:6.56e-03, fs:0.80822 (r=0.678,p=1.000),  time:47.634, tt:5049.256\n",
      "Ep:106, loss:0.00000, loss_test:0.06692, lr:6.49e-03, fs:0.80822 (r=0.678,p=1.000),  time:47.446, tt:5076.714\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=20000 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 20000: \n",
      "Ep:0, loss:0.00001, loss_test:0.14496, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.738, tt:33.738\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00001, loss_test:0.14377, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.358, tt:80.716\n",
      "Ep:2, loss:0.00001, loss_test:0.14160, lr:1.00e-02, fs:0.67704 (r=1.000,p=0.512),  time:42.921, tt:128.763\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00001, loss_test:0.13799, lr:1.00e-02, fs:0.62185 (r=0.851,p=0.490),  time:43.551, tt:174.206\n",
      "Ep:4, loss:0.00001, loss_test:0.13511, lr:1.00e-02, fs:0.61111 (r=0.759,p=0.512),  time:44.294, tt:221.469\n",
      "Ep:5, loss:0.00001, loss_test:0.13537, lr:1.00e-02, fs:0.61140 (r=0.678,p=0.557),  time:45.219, tt:271.312\n",
      "Ep:6, loss:0.00001, loss_test:0.13627, lr:1.00e-02, fs:0.61290 (r=0.655,p=0.576),  time:45.535, tt:318.744\n",
      "Ep:7, loss:0.00001, loss_test:0.13257, lr:1.00e-02, fs:0.59783 (r=0.632,p=0.567),  time:47.031, tt:376.246\n",
      "Ep:8, loss:0.00001, loss_test:0.12770, lr:1.00e-02, fs:0.59574 (r=0.644,p=0.554),  time:47.282, tt:425.538\n",
      "Ep:9, loss:0.00001, loss_test:0.12318, lr:1.00e-02, fs:0.61957 (r=0.655,p=0.588),  time:47.180, tt:471.797\n",
      "Ep:10, loss:0.00001, loss_test:0.11992, lr:1.00e-02, fs:0.63584 (r=0.632,p=0.640),  time:47.132, tt:518.456\n",
      "Ep:11, loss:0.00001, loss_test:0.11643, lr:1.00e-02, fs:0.63095 (r=0.609,p=0.654),  time:47.048, tt:564.575\n",
      "Ep:12, loss:0.00001, loss_test:0.11198, lr:1.00e-02, fs:0.65537 (r=0.667,p=0.644),  time:47.113, tt:612.466\n",
      "Ep:13, loss:0.00001, loss_test:0.10790, lr:1.00e-02, fs:0.65517 (r=0.655,p=0.655),  time:47.217, tt:661.033\n",
      "Ep:14, loss:0.00001, loss_test:0.10409, lr:9.90e-03, fs:0.66258 (r=0.621,p=0.711),  time:47.291, tt:709.362\n",
      "Ep:15, loss:0.00001, loss_test:0.10044, lr:9.80e-03, fs:0.73256 (r=0.724,p=0.741),  time:47.284, tt:756.542\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00001, loss_test:0.09737, lr:9.80e-03, fs:0.76836 (r=0.782,p=0.756),  time:47.232, tt:802.940\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00001, loss_test:0.09406, lr:9.80e-03, fs:0.76364 (r=0.724,p=0.808),  time:47.232, tt:850.174\n",
      "Ep:18, loss:0.00001, loss_test:0.09081, lr:9.80e-03, fs:0.77844 (r=0.747,p=0.812),  time:47.281, tt:898.346\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00001, loss_test:0.08825, lr:9.80e-03, fs:0.79762 (r=0.770,p=0.827),  time:47.264, tt:945.282\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00001, loss_test:0.08631, lr:9.80e-03, fs:0.78788 (r=0.747,p=0.833),  time:47.283, tt:992.949\n",
      "Ep:21, loss:0.00001, loss_test:0.08326, lr:9.80e-03, fs:0.80952 (r=0.782,p=0.840),  time:47.288, tt:1040.344\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00001, loss_test:0.08187, lr:9.80e-03, fs:0.79503 (r=0.736,p=0.865),  time:47.371, tt:1089.530\n",
      "Ep:23, loss:0.00001, loss_test:0.08032, lr:9.80e-03, fs:0.84524 (r=0.816,p=0.877),  time:47.371, tt:1136.914\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00001, loss_test:0.07926, lr:9.80e-03, fs:0.82927 (r=0.782,p=0.883),  time:47.444, tt:1186.093\n",
      "Ep:25, loss:0.00001, loss_test:0.07777, lr:9.80e-03, fs:0.82927 (r=0.782,p=0.883),  time:47.400, tt:1232.396\n",
      "Ep:26, loss:0.00001, loss_test:0.07743, lr:9.80e-03, fs:0.81481 (r=0.759,p=0.880),  time:47.434, tt:1280.729\n",
      "Ep:27, loss:0.00001, loss_test:0.07575, lr:9.80e-03, fs:0.80745 (r=0.747,p=0.878),  time:47.441, tt:1328.356\n",
      "Ep:28, loss:0.00001, loss_test:0.07555, lr:9.80e-03, fs:0.80000 (r=0.736,p=0.877),  time:47.426, tt:1375.362\n",
      "Ep:29, loss:0.00001, loss_test:0.07418, lr:9.80e-03, fs:0.80000 (r=0.736,p=0.877),  time:47.393, tt:1421.778\n",
      "Ep:30, loss:0.00001, loss_test:0.07386, lr:9.80e-03, fs:0.80503 (r=0.736,p=0.889),  time:47.361, tt:1468.184\n",
      "Ep:31, loss:0.00000, loss_test:0.07272, lr:9.80e-03, fs:0.80745 (r=0.747,p=0.878),  time:47.403, tt:1516.903\n",
      "Ep:32, loss:0.00000, loss_test:0.07201, lr:9.80e-03, fs:0.80745 (r=0.747,p=0.878),  time:47.378, tt:1563.481\n",
      "Ep:33, loss:0.00000, loss_test:0.07157, lr:9.80e-03, fs:0.81250 (r=0.747,p=0.890),  time:47.433, tt:1612.729\n",
      "Ep:34, loss:0.00000, loss_test:0.07133, lr:9.80e-03, fs:0.80503 (r=0.736,p=0.889),  time:47.411, tt:1659.383\n",
      "Ep:35, loss:0.00000, loss_test:0.07165, lr:9.70e-03, fs:0.80503 (r=0.736,p=0.889),  time:47.409, tt:1706.715\n",
      "Ep:36, loss:0.00000, loss_test:0.07137, lr:9.61e-03, fs:0.81013 (r=0.736,p=0.901),  time:47.408, tt:1754.082\n",
      "Ep:37, loss:0.00000, loss_test:0.07160, lr:9.51e-03, fs:0.81013 (r=0.736,p=0.901),  time:47.436, tt:1802.578\n",
      "Ep:38, loss:0.00000, loss_test:0.07263, lr:9.41e-03, fs:0.81013 (r=0.736,p=0.901),  time:47.451, tt:1850.585\n",
      "Ep:39, loss:0.00000, loss_test:0.07232, lr:9.32e-03, fs:0.81013 (r=0.736,p=0.901),  time:47.481, tt:1899.240\n",
      "Ep:40, loss:0.00000, loss_test:0.07255, lr:9.23e-03, fs:0.81013 (r=0.736,p=0.901),  time:47.477, tt:1946.547\n",
      "Ep:41, loss:0.00000, loss_test:0.07340, lr:9.14e-03, fs:0.81529 (r=0.736,p=0.914),  time:47.483, tt:1994.294\n",
      "Ep:42, loss:0.00000, loss_test:0.07248, lr:9.04e-03, fs:0.80769 (r=0.724,p=0.913),  time:47.493, tt:2042.188\n",
      "Ep:43, loss:0.00000, loss_test:0.07253, lr:8.95e-03, fs:0.81013 (r=0.736,p=0.901),  time:47.456, tt:2088.063\n",
      "Ep:44, loss:0.00000, loss_test:0.07207, lr:8.86e-03, fs:0.81529 (r=0.736,p=0.914),  time:47.449, tt:2135.224\n",
      "Ep:45, loss:0.00000, loss_test:0.07369, lr:8.78e-03, fs:0.82581 (r=0.736,p=0.941),  time:47.374, tt:2179.222\n",
      "Ep:46, loss:0.00000, loss_test:0.07220, lr:8.69e-03, fs:0.82581 (r=0.736,p=0.941),  time:47.304, tt:2223.290\n",
      "Ep:47, loss:0.00000, loss_test:0.07466, lr:8.60e-03, fs:0.81818 (r=0.724,p=0.940),  time:47.265, tt:2268.734\n",
      "Ep:48, loss:0.00000, loss_test:0.07315, lr:8.51e-03, fs:0.82581 (r=0.736,p=0.941),  time:47.199, tt:2312.761\n",
      "Ep:49, loss:0.00000, loss_test:0.07540, lr:8.43e-03, fs:0.83117 (r=0.736,p=0.955),  time:47.186, tt:2359.276\n",
      "Ep:50, loss:0.00000, loss_test:0.07419, lr:8.35e-03, fs:0.82353 (r=0.724,p=0.955),  time:47.212, tt:2407.791\n",
      "Ep:51, loss:0.00000, loss_test:0.07612, lr:8.26e-03, fs:0.82353 (r=0.724,p=0.955),  time:47.211, tt:2454.991\n",
      "Ep:52, loss:0.00000, loss_test:0.07577, lr:8.18e-03, fs:0.81579 (r=0.713,p=0.954),  time:47.242, tt:2503.830\n",
      "Ep:53, loss:0.00000, loss_test:0.07522, lr:8.10e-03, fs:0.81579 (r=0.713,p=0.954),  time:47.272, tt:2552.682\n",
      "Ep:54, loss:0.00000, loss_test:0.07640, lr:8.02e-03, fs:0.81579 (r=0.713,p=0.954),  time:47.291, tt:2601.033\n",
      "Ep:55, loss:0.00000, loss_test:0.07604, lr:7.94e-03, fs:0.81579 (r=0.713,p=0.954),  time:47.272, tt:2647.248\n",
      "Ep:56, loss:0.00000, loss_test:0.07581, lr:7.86e-03, fs:0.81333 (r=0.701,p=0.968),  time:47.287, tt:2695.376\n",
      "Ep:57, loss:0.00000, loss_test:0.07725, lr:7.78e-03, fs:0.82119 (r=0.713,p=0.969),  time:47.288, tt:2742.731\n",
      "Ep:58, loss:0.00000, loss_test:0.07634, lr:7.70e-03, fs:0.82119 (r=0.713,p=0.969),  time:47.303, tt:2790.890\n",
      "Ep:59, loss:0.00000, loss_test:0.07695, lr:7.62e-03, fs:0.81333 (r=0.701,p=0.968),  time:47.287, tt:2837.197\n",
      "Ep:60, loss:0.00000, loss_test:0.07714, lr:7.55e-03, fs:0.82119 (r=0.713,p=0.969),  time:47.296, tt:2885.076\n",
      "Ep:61, loss:0.00000, loss_test:0.07639, lr:7.47e-03, fs:0.81333 (r=0.701,p=0.968),  time:47.319, tt:2933.779\n",
      "Ep:62, loss:0.00000, loss_test:0.07735, lr:7.40e-03, fs:0.81333 (r=0.701,p=0.968),  time:47.343, tt:2982.614\n",
      "Ep:63, loss:0.00000, loss_test:0.07716, lr:7.32e-03, fs:0.81333 (r=0.701,p=0.968),  time:47.383, tt:3032.498\n",
      "Ep:64, loss:0.00000, loss_test:0.07754, lr:7.25e-03, fs:0.81333 (r=0.701,p=0.968),  time:47.396, tt:3080.770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:65, loss:0.00000, loss_test:0.07788, lr:7.18e-03, fs:0.81333 (r=0.701,p=0.968),  time:47.413, tt:3129.285\n",
      "Ep:66, loss:0.00000, loss_test:0.07833, lr:7.11e-03, fs:0.81879 (r=0.701,p=0.984),  time:47.411, tt:3176.555\n",
      "Ep:67, loss:0.00000, loss_test:0.07821, lr:7.03e-03, fs:0.81333 (r=0.701,p=0.968),  time:47.422, tt:3224.700\n",
      "Ep:68, loss:0.00000, loss_test:0.07890, lr:6.96e-03, fs:0.81879 (r=0.701,p=0.984),  time:47.444, tt:3273.635\n",
      "Ep:69, loss:0.00000, loss_test:0.07876, lr:6.89e-03, fs:0.81879 (r=0.701,p=0.984),  time:47.454, tt:3321.774\n",
      "Ep:70, loss:0.00000, loss_test:0.07919, lr:6.83e-03, fs:0.81081 (r=0.690,p=0.984),  time:47.482, tt:3371.249\n",
      "Ep:71, loss:0.00000, loss_test:0.07954, lr:6.76e-03, fs:0.81879 (r=0.701,p=0.984),  time:47.500, tt:3420.032\n",
      "Ep:72, loss:0.00000, loss_test:0.07950, lr:6.69e-03, fs:0.81081 (r=0.690,p=0.984),  time:47.520, tt:3468.927\n",
      "Ep:73, loss:0.00000, loss_test:0.08098, lr:6.62e-03, fs:0.81081 (r=0.690,p=0.984),  time:47.519, tt:3516.393\n",
      "Ep:74, loss:0.00000, loss_test:0.07949, lr:6.56e-03, fs:0.81879 (r=0.701,p=0.984),  time:47.512, tt:3563.405\n",
      "Ep:75, loss:0.00000, loss_test:0.08155, lr:6.49e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.516, tt:3611.236\n",
      "Ep:76, loss:0.00000, loss_test:0.08001, lr:6.43e-03, fs:0.81081 (r=0.690,p=0.984),  time:47.560, tt:3662.139\n",
      "Ep:77, loss:0.00000, loss_test:0.08140, lr:6.36e-03, fs:0.81081 (r=0.690,p=0.984),  time:47.586, tt:3711.682\n",
      "Ep:78, loss:0.00000, loss_test:0.08086, lr:6.30e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.616, tt:3761.648\n",
      "Ep:79, loss:0.00000, loss_test:0.08061, lr:6.24e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.640, tt:3811.231\n",
      "Ep:80, loss:0.00000, loss_test:0.08181, lr:6.17e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.656, tt:3860.154\n",
      "Ep:81, loss:0.00000, loss_test:0.08053, lr:6.11e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.679, tt:3909.672\n",
      "Ep:82, loss:0.00000, loss_test:0.08162, lr:6.05e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.709, tt:3959.840\n",
      "Ep:83, loss:0.00000, loss_test:0.08135, lr:5.99e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.747, tt:4010.780\n",
      "Ep:84, loss:0.00000, loss_test:0.08192, lr:5.93e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.768, tt:4060.287\n",
      "Ep:85, loss:0.00000, loss_test:0.08168, lr:5.87e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.772, tt:4108.428\n",
      "Ep:86, loss:0.00000, loss_test:0.08210, lr:5.81e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.792, tt:4157.942\n",
      "Ep:87, loss:0.00000, loss_test:0.08202, lr:5.75e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.793, tt:4205.778\n",
      "Ep:88, loss:0.00000, loss_test:0.08201, lr:5.70e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.808, tt:4254.922\n",
      "Ep:89, loss:0.00000, loss_test:0.08240, lr:5.64e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.826, tt:4304.349\n",
      "Ep:90, loss:0.00000, loss_test:0.08213, lr:5.58e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.832, tt:4352.708\n",
      "Ep:91, loss:0.00000, loss_test:0.08280, lr:5.53e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.876, tt:4404.580\n",
      "Ep:92, loss:0.00000, loss_test:0.08215, lr:5.47e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.923, tt:4456.808\n",
      "Ep:93, loss:0.00000, loss_test:0.08303, lr:5.42e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.924, tt:4504.853\n",
      "Ep:94, loss:0.00000, loss_test:0.08172, lr:5.36e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.941, tt:4554.348\n",
      "Ep:95, loss:0.00000, loss_test:0.08303, lr:5.31e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.947, tt:4602.873\n",
      "Ep:96, loss:0.00000, loss_test:0.08177, lr:5.26e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.967, tt:4652.803\n",
      "Ep:97, loss:0.00000, loss_test:0.08278, lr:5.20e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.927, tt:4696.803\n",
      "Ep:98, loss:0.00000, loss_test:0.08214, lr:5.15e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.884, tt:4740.505\n",
      "Ep:99, loss:0.00000, loss_test:0.08228, lr:5.10e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.842, tt:4784.237\n",
      "Ep:100, loss:0.00000, loss_test:0.08240, lr:5.05e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.828, tt:4830.640\n",
      "Ep:101, loss:0.00000, loss_test:0.08239, lr:5.00e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.803, tt:4875.927\n",
      "Ep:102, loss:0.00000, loss_test:0.08253, lr:4.95e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.765, tt:4919.751\n",
      "Ep:103, loss:0.00000, loss_test:0.08242, lr:4.90e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.679, tt:4958.641\n",
      "Ep:104, loss:0.00000, loss_test:0.08251, lr:4.85e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.670, tt:5005.378\n",
      "Ep:105, loss:0.00000, loss_test:0.08247, lr:4.80e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.681, tt:5054.181\n",
      "Ep:106, loss:0.00000, loss_test:0.08257, lr:4.75e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.642, tt:5097.704\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=20000 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 26722 Test samples: 198\n",
      "Train positive samples: 13361 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00328, loss_test:0.10617, lr:4.00e-03, fs:0.71220 (r=0.737,p=0.689),  time:548.263, tt:548.263\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00234, loss_test:0.09182, lr:4.00e-03, fs:0.77320 (r=0.758,p=0.789),  time:564.804, tt:1129.608\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00172, loss_test:0.08837, lr:4.00e-03, fs:0.75000 (r=0.667,p=0.857),  time:570.302, tt:1710.905\n",
      "Ep:3, loss:0.00125, loss_test:0.08809, lr:4.00e-03, fs:0.73054 (r=0.616,p=0.897),  time:573.915, tt:2295.660\n",
      "Ep:4, loss:0.00089, loss_test:0.08920, lr:4.00e-03, fs:0.71166 (r=0.586,p=0.906),  time:574.393, tt:2871.967\n",
      "Ep:5, loss:0.00059, loss_test:0.09244, lr:4.00e-03, fs:0.69620 (r=0.556,p=0.932),  time:575.550, tt:3453.297\n",
      "Ep:6, loss:0.00038, loss_test:0.09658, lr:4.00e-03, fs:0.70064 (r=0.556,p=0.948),  time:576.113, tt:4032.792\n",
      "Ep:7, loss:0.00024, loss_test:0.09740, lr:4.00e-03, fs:0.68387 (r=0.535,p=0.946),  time:577.336, tt:4618.690\n",
      "Ep:8, loss:0.00016, loss_test:0.10515, lr:4.00e-03, fs:0.68831 (r=0.535,p=0.964),  time:578.814, tt:5209.326\n",
      "Ep:9, loss:0.00012, loss_test:0.11028, lr:4.00e-03, fs:0.69281 (r=0.535,p=0.981),  time:579.041, tt:5790.408\n",
      "Ep:10, loss:0.00009, loss_test:0.11026, lr:4.00e-03, fs:0.69737 (r=0.535,p=1.000),  time:576.998, tt:6346.975\n",
      "Ep:11, loss:0.00007, loss_test:0.11302, lr:4.00e-03, fs:0.65306 (r=0.485,p=1.000),  time:572.696, tt:6872.347\n",
      "Ep:12, loss:0.00005, loss_test:0.11587, lr:4.00e-03, fs:0.65306 (r=0.485,p=1.000),  time:568.189, tt:7386.453\n",
      "Ep:13, loss:0.00004, loss_test:0.11755, lr:3.96e-03, fs:0.65306 (r=0.485,p=1.000),  time:565.013, tt:7910.182\n",
      "Ep:14, loss:0.00003, loss_test:0.11871, lr:3.92e-03, fs:0.65306 (r=0.485,p=1.000),  time:561.991, tt:8429.869\n",
      "Ep:15, loss:0.00003, loss_test:0.11798, lr:3.88e-03, fs:0.65306 (r=0.485,p=1.000),  time:559.472, tt:8951.551\n",
      "Ep:16, loss:0.00002, loss_test:0.11721, lr:3.84e-03, fs:0.65306 (r=0.485,p=1.000),  time:556.955, tt:9468.237\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,17,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 3200 Test samples: 198\n",
      "Train positive samples: 1600 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14504, lr:4.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:52.487, tt:52.487\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14397, lr:4.00e-03, fs:0.66892 (r=1.000,p=0.503),  time:63.446, tt:126.892\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00055, loss_test:0.14188, lr:4.00e-03, fs:0.66667 (r=0.990,p=0.503),  time:70.990, tt:212.969\n",
      "Ep:3, loss:0.00053, loss_test:0.13829, lr:4.00e-03, fs:0.66667 (r=0.970,p=0.508),  time:73.127, tt:292.507\n",
      "Ep:4, loss:0.00050, loss_test:0.13287, lr:4.00e-03, fs:0.64032 (r=0.818,p=0.526),  time:74.723, tt:373.615\n",
      "Ep:5, loss:0.00046, loss_test:0.12827, lr:4.00e-03, fs:0.58291 (r=0.586,p=0.580),  time:75.983, tt:455.898\n",
      "Ep:6, loss:0.00044, loss_test:0.12412, lr:4.00e-03, fs:0.59794 (r=0.586,p=0.611),  time:77.524, tt:542.671\n",
      "Ep:7, loss:0.00042, loss_test:0.12136, lr:4.00e-03, fs:0.65421 (r=0.707,p=0.609),  time:78.273, tt:626.182\n",
      "Ep:8, loss:0.00040, loss_test:0.11910, lr:4.00e-03, fs:0.64550 (r=0.616,p=0.678),  time:78.571, tt:707.139\n",
      "Ep:9, loss:0.00038, loss_test:0.11677, lr:4.00e-03, fs:0.64171 (r=0.606,p=0.682),  time:78.906, tt:789.061\n",
      "Ep:10, loss:0.00036, loss_test:0.11394, lr:4.00e-03, fs:0.65263 (r=0.626,p=0.681),  time:79.497, tt:874.464\n",
      "Ep:11, loss:0.00035, loss_test:0.11276, lr:4.00e-03, fs:0.65537 (r=0.586,p=0.744),  time:79.870, tt:958.443\n",
      "Ep:12, loss:0.00033, loss_test:0.11046, lr:4.00e-03, fs:0.68817 (r=0.646,p=0.736),  time:80.140, tt:1041.818\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00031, loss_test:0.10896, lr:4.00e-03, fs:0.65537 (r=0.586,p=0.744),  time:80.304, tt:1124.251\n",
      "Ep:14, loss:0.00030, loss_test:0.10836, lr:4.00e-03, fs:0.67416 (r=0.606,p=0.759),  time:80.539, tt:1208.082\n",
      "Ep:15, loss:0.00029, loss_test:0.10701, lr:4.00e-03, fs:0.67778 (r=0.616,p=0.753),  time:80.752, tt:1292.033\n",
      "Ep:16, loss:0.00027, loss_test:0.10584, lr:4.00e-03, fs:0.68156 (r=0.616,p=0.762),  time:80.819, tt:1373.916\n",
      "Ep:17, loss:0.00026, loss_test:0.10330, lr:4.00e-03, fs:0.71739 (r=0.667,p=0.776),  time:80.895, tt:1456.107\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00025, loss_test:0.10360, lr:4.00e-03, fs:0.67429 (r=0.596,p=0.776),  time:80.520, tt:1529.883\n",
      "Ep:19, loss:0.00024, loss_test:0.10043, lr:4.00e-03, fs:0.73514 (r=0.687,p=0.791),  time:80.357, tt:1607.138\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00023, loss_test:0.10189, lr:4.00e-03, fs:0.66667 (r=0.566,p=0.812),  time:80.446, tt:1689.363\n",
      "Ep:21, loss:0.00022, loss_test:0.09811, lr:4.00e-03, fs:0.70391 (r=0.636,p=0.787),  time:80.886, tt:1779.495\n",
      "Ep:22, loss:0.00021, loss_test:0.09957, lr:4.00e-03, fs:0.68235 (r=0.586,p=0.817),  time:80.937, tt:1861.559\n",
      "Ep:23, loss:0.00020, loss_test:0.10098, lr:4.00e-03, fs:0.66265 (r=0.556,p=0.821),  time:81.022, tt:1944.533\n",
      "Ep:24, loss:0.00019, loss_test:0.09559, lr:4.00e-03, fs:0.71508 (r=0.646,p=0.800),  time:81.093, tt:2027.327\n",
      "Ep:25, loss:0.00018, loss_test:0.09881, lr:4.00e-03, fs:0.66667 (r=0.545,p=0.857),  time:81.123, tt:2109.210\n",
      "Ep:26, loss:0.00017, loss_test:0.09660, lr:4.00e-03, fs:0.74286 (r=0.657,p=0.855),  time:81.244, tt:2193.590\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00016, loss_test:0.09492, lr:4.00e-03, fs:0.74419 (r=0.646,p=0.877),  time:81.270, tt:2275.550\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00015, loss_test:0.09610, lr:4.00e-03, fs:0.69880 (r=0.586,p=0.866),  time:81.124, tt:2352.606\n",
      "Ep:29, loss:0.00014, loss_test:0.09458, lr:4.00e-03, fs:0.72515 (r=0.626,p=0.861),  time:81.263, tt:2437.878\n",
      "Ep:30, loss:0.00014, loss_test:0.09065, lr:4.00e-03, fs:0.72515 (r=0.626,p=0.861),  time:81.420, tt:2524.033\n",
      "Ep:31, loss:0.00013, loss_test:0.09620, lr:4.00e-03, fs:0.67073 (r=0.556,p=0.846),  time:81.604, tt:2611.328\n",
      "Ep:32, loss:0.00012, loss_test:0.09816, lr:4.00e-03, fs:0.67485 (r=0.556,p=0.859),  time:81.627, tt:2693.692\n",
      "Ep:33, loss:0.00011, loss_test:0.09357, lr:4.00e-03, fs:0.67073 (r=0.556,p=0.846),  time:81.650, tt:2776.092\n",
      "Ep:34, loss:0.00011, loss_test:0.09411, lr:4.00e-03, fs:0.68293 (r=0.566,p=0.862),  time:81.746, tt:2861.115\n",
      "Ep:35, loss:0.00010, loss_test:0.09928, lr:4.00e-03, fs:0.67500 (r=0.545,p=0.885),  time:81.827, tt:2945.778\n",
      "Ep:36, loss:0.00010, loss_test:0.09658, lr:4.00e-03, fs:0.67485 (r=0.556,p=0.859),  time:81.944, tt:3031.934\n",
      "Ep:37, loss:0.00009, loss_test:0.09147, lr:4.00e-03, fs:0.69091 (r=0.576,p=0.864),  time:81.996, tt:3115.845\n",
      "Ep:38, loss:0.00009, loss_test:0.09963, lr:4.00e-03, fs:0.67081 (r=0.545,p=0.871),  time:81.980, tt:3197.237\n",
      "Ep:39, loss:0.00008, loss_test:0.09755, lr:3.96e-03, fs:0.68323 (r=0.556,p=0.887),  time:82.032, tt:3281.280\n",
      "Ep:40, loss:0.00008, loss_test:0.10121, lr:3.92e-03, fs:0.68750 (r=0.556,p=0.902),  time:81.992, tt:3361.665\n",
      "Ep:41, loss:0.00007, loss_test:0.09978, lr:3.88e-03, fs:0.67925 (r=0.545,p=0.900),  time:82.088, tt:3447.713\n",
      "Ep:42, loss:0.00007, loss_test:0.10334, lr:3.84e-03, fs:0.68354 (r=0.545,p=0.915),  time:82.133, tt:3531.724\n",
      "Ep:43, loss:0.00006, loss_test:0.09964, lr:3.80e-03, fs:0.67500 (r=0.545,p=0.885),  time:82.178, tt:3615.819\n",
      "Ep:44, loss:0.00006, loss_test:0.10121, lr:3.77e-03, fs:0.68354 (r=0.545,p=0.915),  time:82.225, tt:3700.106\n",
      "Ep:45, loss:0.00005, loss_test:0.10527, lr:3.73e-03, fs:0.69231 (r=0.545,p=0.947),  time:82.243, tt:3783.188\n",
      "Ep:46, loss:0.00005, loss_test:0.10375, lr:3.69e-03, fs:0.69231 (r=0.545,p=0.947),  time:82.239, tt:3865.232\n",
      "Ep:47, loss:0.00005, loss_test:0.10221, lr:3.65e-03, fs:0.69231 (r=0.545,p=0.947),  time:82.278, tt:3949.332\n",
      "Ep:48, loss:0.00004, loss_test:0.10787, lr:3.62e-03, fs:0.69231 (r=0.545,p=0.947),  time:82.345, tt:4034.910\n",
      "Ep:49, loss:0.00004, loss_test:0.10417, lr:3.58e-03, fs:0.69231 (r=0.545,p=0.947),  time:82.394, tt:4119.699\n",
      "Ep:50, loss:0.00004, loss_test:0.10583, lr:3.55e-03, fs:0.69677 (r=0.545,p=0.964),  time:82.371, tt:4200.917\n",
      "Ep:51, loss:0.00004, loss_test:0.11044, lr:3.51e-03, fs:0.70130 (r=0.545,p=0.982),  time:82.410, tt:4285.300\n",
      "Ep:52, loss:0.00003, loss_test:0.10575, lr:3.47e-03, fs:0.69231 (r=0.545,p=0.947),  time:82.498, tt:4372.388\n",
      "Ep:53, loss:0.00003, loss_test:0.11345, lr:3.44e-03, fs:0.65772 (r=0.495,p=0.980),  time:82.538, tt:4457.062\n",
      "Ep:54, loss:0.00003, loss_test:0.10601, lr:3.41e-03, fs:0.69677 (r=0.545,p=0.964),  time:82.523, tt:4538.762\n",
      "Ep:55, loss:0.00003, loss_test:0.10833, lr:3.37e-03, fs:0.69677 (r=0.545,p=0.964),  time:82.413, tt:4615.129\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"5-5\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,56,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00410, loss_test:0.11140, lr:4.00e-03, fs:0.65922 (r=0.596,p=0.738),  time:727.323, tt:727.323\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00278, loss_test:0.09944, lr:4.00e-03, fs:0.75000 (r=0.667,p=0.857),  time:740.395, tt:1480.790\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00197, loss_test:0.09703, lr:4.00e-03, fs:0.72941 (r=0.626,p=0.873),  time:746.675, tt:2240.024\n",
      "Ep:3, loss:0.00135, loss_test:0.09626, lr:4.00e-03, fs:0.73171 (r=0.606,p=0.923),  time:749.975, tt:2999.900\n",
      "Ep:4, loss:0.00091, loss_test:0.10498, lr:4.00e-03, fs:0.68790 (r=0.545,p=0.931),  time:750.127, tt:3750.635\n",
      "Ep:5, loss:0.00063, loss_test:0.10521, lr:4.00e-03, fs:0.68387 (r=0.535,p=0.946),  time:749.178, tt:4495.070\n",
      "Ep:6, loss:0.00044, loss_test:0.10701, lr:4.00e-03, fs:0.67974 (r=0.525,p=0.963),  time:746.857, tt:5227.998\n",
      "Ep:7, loss:0.00032, loss_test:0.11242, lr:4.00e-03, fs:0.62585 (r=0.465,p=0.958),  time:745.577, tt:5964.618\n",
      "Ep:8, loss:0.00024, loss_test:0.11813, lr:4.00e-03, fs:0.62585 (r=0.465,p=0.958),  time:744.327, tt:6698.945\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1f730233e1d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;31m#loss.backward(retain_graph=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_number=\"5-5\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,16,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00368, loss_test:0.10239, lr:1.00e-02, fs:0.75000 (r=0.697,p=0.812),  time:715.111, tt:715.111\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00187, loss_test:0.09365, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:736.376, tt:1472.752\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00098, loss_test:0.09677, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:738.349, tt:2215.048\n",
      "Ep:3, loss:0.00053, loss_test:0.11592, lr:1.00e-02, fs:0.67949 (r=0.535,p=0.930),  time:742.035, tt:2968.138\n",
      "Ep:4, loss:0.00024, loss_test:0.12462, lr:1.00e-02, fs:0.68831 (r=0.535,p=0.964),  time:742.608, tt:3713.042\n",
      "Ep:5, loss:0.00012, loss_test:0.12945, lr:1.00e-02, fs:0.68874 (r=0.525,p=1.000),  time:744.628, tt:4467.768\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2968fe5e98e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;31m#forward_backward positive batch sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, feature)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/graph.py\u001b[0m in \u001b[0;36mupdate_all\u001b[0;34m(self, message_func, reduce_func, apply_node_func)\u001b[0m\n\u001b[1;32m   3236\u001b[0m                                           \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3237\u001b[0m                                           apply_func=apply_node_func)\n\u001b[0;32m-> 3238\u001b[0;31m             \u001b[0mRuntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3240\u001b[0m     def prop_nodes(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/runtime/runtime.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(prog)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mexe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# prog.pprint_exe(exe)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mexe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/runtime/ir/executor.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1198\u001b[0m         self.ret.data = F.copy_reduce(\n\u001b[1;32m   1199\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             out_map)\n\u001b[0m\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mcopy_reduce\u001b[0;34m(reducer, graph, target, in_data, out_size, in_map, out_map)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 out_map=(None, None)):\n\u001b[1;32m    432\u001b[0m     \u001b[0mout_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCopyReduce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, reducer, graph, target, in_data, out_data, out_size, in_map, out_map)\u001b[0m\n\u001b[1;32m    389\u001b[0m         K.copy_reduce(\n\u001b[1;32m    390\u001b[0m             \u001b[0mreducer\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreducer\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'sum'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             graph, target, in_data_nd, out_data_nd, in_map[0], out_map[0])\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0;31m# normalize if mean reducer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# NOTE(zihao): this is a temporary hack and we should have better solution in the future.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/kernel.py\u001b[0m in \u001b[0;36mcopy_reduce\u001b[0;34m(reducer, G, target, X, out, X_rows, out_rows)\u001b[0m\n\u001b[1;32m    370\u001b[0m     _CAPI_DGLKernelCopyReduce(\n\u001b[1;32m    371\u001b[0m         \u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         X, out, X_rows, out_rows)\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;31m# pylint: disable=invalid-name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/_ffi/_ctypes/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    188\u001b[0m         check_call(_LIB.DGLFuncCall(\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             ctypes.byref(ret_val), ctypes.byref(ret_tcode)))\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_number=\"5-5\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,16,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,16,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00362, loss_test:0.10727, lr:1.00e-02, fs:0.68293 (r=0.566,p=0.862),  time:740.293, tt:740.293\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00177, loss_test:0.10497, lr:1.00e-02, fs:0.68712 (r=0.566,p=0.875),  time:739.951, tt:1479.901\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00095, loss_test:0.11587, lr:1.00e-02, fs:0.70370 (r=0.576,p=0.905),  time:744.633, tt:2233.899\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00049, loss_test:0.12468, lr:1.00e-02, fs:0.57143 (r=0.404,p=0.976),  time:748.571, tt:2994.286\n",
      "Ep:4, loss:0.00026, loss_test:0.13509, lr:1.00e-02, fs:0.57143 (r=0.404,p=0.976),  time:752.008, tt:3760.041\n",
      "Ep:5, loss:0.00014, loss_test:0.13500, lr:1.00e-02, fs:0.52941 (r=0.364,p=0.973),  time:752.261, tt:4513.568\n",
      "Ep:6, loss:0.00008, loss_test:0.14089, lr:1.00e-02, fs:0.55474 (r=0.384,p=1.000),  time:750.932, tt:5256.527\n",
      "Ep:7, loss:0.00005, loss_test:0.14309, lr:1.00e-02, fs:0.47692 (r=0.313,p=1.000),  time:749.228, tt:5993.826\n",
      "Ep:8, loss:0.00003, loss_test:0.14348, lr:1.00e-02, fs:0.55474 (r=0.384,p=1.000),  time:748.227, tt:6734.046\n",
      "Ep:9, loss:0.00002, loss_test:0.14244, lr:1.00e-02, fs:0.55072 (r=0.384,p=0.974),  time:747.330, tt:7473.300\n",
      "Ep:10, loss:0.00002, loss_test:0.14147, lr:1.00e-02, fs:0.55474 (r=0.384,p=1.000),  time:746.431, tt:8210.736\n",
      "Ep:11, loss:0.00001, loss_test:0.14284, lr:1.00e-02, fs:0.55474 (r=0.384,p=1.000),  time:746.753, tt:8961.033\n",
      "Ep:12, loss:0.00001, loss_test:0.14118, lr:1.00e-02, fs:0.55474 (r=0.384,p=1.000),  time:748.145, tt:9725.889\n",
      "Ep:13, loss:0.00001, loss_test:0.14165, lr:1.00e-02, fs:0.55474 (r=0.384,p=1.000),  time:748.129, tt:10473.806\n",
      "Ep:14, loss:0.00001, loss_test:0.14176, lr:9.90e-03, fs:0.55474 (r=0.384,p=1.000),  time:749.001, tt:11235.021\n",
      "Ep:15, loss:0.00001, loss_test:0.14111, lr:9.80e-03, fs:0.54676 (r=0.384,p=0.950),  time:748.813, tt:11981.016\n",
      "Ep:16, loss:0.00001, loss_test:0.14305, lr:9.70e-03, fs:0.54676 (r=0.384,p=0.950),  time:749.661, tt:12744.242\n",
      "Ep:17, loss:0.00001, loss_test:0.14004, lr:9.61e-03, fs:0.54676 (r=0.384,p=0.950),  time:750.222, tt:13504.001\n",
      "Ep:18, loss:0.00001, loss_test:0.13970, lr:9.51e-03, fs:0.54676 (r=0.384,p=0.950),  time:750.750, tt:14264.243\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8ca8a6ef5fd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m66\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;31m#forward_backward positive batch sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, feature)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/graph.py\u001b[0m in \u001b[0;36mupdate_all\u001b[0;34m(self, message_func, reduce_func, apply_node_func)\u001b[0m\n\u001b[1;32m   3236\u001b[0m                                           \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3237\u001b[0m                                           apply_func=apply_node_func)\n\u001b[0;32m-> 3238\u001b[0;31m             \u001b[0mRuntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3240\u001b[0m     def prop_nodes(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/runtime/runtime.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(prog)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mexe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# prog.pprint_exe(exe)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mexe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/runtime/ir/executor.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1198\u001b[0m         self.ret.data = F.copy_reduce(\n\u001b[1;32m   1199\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             out_map)\n\u001b[0m\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mcopy_reduce\u001b[0;34m(reducer, graph, target, in_data, out_size, in_map, out_map)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 out_map=(None, None)):\n\u001b[1;32m    432\u001b[0m     \u001b[0mout_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCopyReduce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, reducer, graph, target, in_data, out_data, out_size, in_map, out_map)\u001b[0m\n\u001b[1;32m    389\u001b[0m         K.copy_reduce(\n\u001b[1;32m    390\u001b[0m             \u001b[0mreducer\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreducer\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'sum'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             graph, target, in_data_nd, out_data_nd, in_map[0], out_map[0])\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0;31m# normalize if mean reducer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# NOTE(zihao): this is a temporary hack and we should have better solution in the future.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/kernel.py\u001b[0m in \u001b[0;36mcopy_reduce\u001b[0;34m(reducer, G, target, X, out, X_rows, out_rows)\u001b[0m\n\u001b[1;32m    370\u001b[0m     _CAPI_DGLKernelCopyReduce(\n\u001b[1;32m    371\u001b[0m         \u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         X, out, X_rows, out_rows)\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;31m# pylint: disable=invalid-name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/_ffi/_ctypes/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    188\u001b[0m         check_call(_LIB.DGLFuncCall(\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             ctypes.byref(ret_val), ctypes.byref(ret_tcode)))\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,66,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,66,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14812, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.372, tt:13.372\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14801, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.800, tt:33.601\n",
      "Ep:2, loss:0.00004, loss_test:0.14784, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:18.045, tt:54.136\n",
      "Ep:3, loss:0.00004, loss_test:0.14757, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:18.572, tt:74.287\n",
      "Ep:4, loss:0.00004, loss_test:0.14714, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:19.063, tt:95.313\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.14652, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:19.171, tt:115.027\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.14566, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:19.390, tt:135.733\n",
      "Ep:7, loss:0.00004, loss_test:0.14461, lr:1.00e-02, fs:0.65278 (r=0.949,p=0.497),  time:19.461, tt:155.692\n",
      "Ep:8, loss:0.00004, loss_test:0.14365, lr:1.00e-02, fs:0.65480 (r=0.929,p=0.505),  time:19.482, tt:175.335\n",
      "Ep:9, loss:0.00003, loss_test:0.14264, lr:1.00e-02, fs:0.63035 (r=0.818,p=0.513),  time:19.319, tt:193.194\n",
      "Ep:10, loss:0.00003, loss_test:0.14242, lr:1.00e-02, fs:0.58515 (r=0.677,p=0.515),  time:19.399, tt:213.394\n",
      "Ep:11, loss:0.00003, loss_test:0.14471, lr:1.00e-02, fs:0.52792 (r=0.525,p=0.531),  time:19.400, tt:232.800\n",
      "Ep:12, loss:0.00003, loss_test:0.14807, lr:1.00e-02, fs:0.51934 (r=0.475,p=0.573),  time:19.495, tt:253.440\n",
      "Ep:13, loss:0.00003, loss_test:0.14796, lr:1.00e-02, fs:0.53763 (r=0.505,p=0.575),  time:19.523, tt:273.323\n",
      "Ep:14, loss:0.00003, loss_test:0.14467, lr:1.00e-02, fs:0.53465 (r=0.545,p=0.524),  time:19.479, tt:292.181\n",
      "Ep:15, loss:0.00003, loss_test:0.14177, lr:1.00e-02, fs:0.59361 (r=0.657,p=0.542),  time:19.424, tt:310.791\n",
      "Ep:16, loss:0.00003, loss_test:0.13992, lr:1.00e-02, fs:0.61261 (r=0.687,p=0.553),  time:19.414, tt:330.040\n",
      "Ep:17, loss:0.00003, loss_test:0.13894, lr:9.90e-03, fs:0.59434 (r=0.636,p=0.558),  time:19.428, tt:349.708\n",
      "Ep:18, loss:0.00003, loss_test:0.13890, lr:9.80e-03, fs:0.56281 (r=0.566,p=0.560),  time:19.466, tt:369.851\n",
      "Ep:19, loss:0.00003, loss_test:0.13896, lr:9.70e-03, fs:0.55026 (r=0.525,p=0.578),  time:19.447, tt:388.944\n",
      "Ep:20, loss:0.00003, loss_test:0.13769, lr:9.61e-03, fs:0.56085 (r=0.535,p=0.589),  time:19.379, tt:406.956\n",
      "Ep:21, loss:0.00003, loss_test:0.13601, lr:9.51e-03, fs:0.55838 (r=0.556,p=0.561),  time:19.355, tt:425.800\n",
      "Ep:22, loss:0.00003, loss_test:0.13486, lr:9.41e-03, fs:0.59512 (r=0.616,p=0.575),  time:19.384, tt:445.829\n",
      "Ep:23, loss:0.00003, loss_test:0.13425, lr:9.32e-03, fs:0.60577 (r=0.636,p=0.578),  time:19.376, tt:465.028\n",
      "Ep:24, loss:0.00002, loss_test:0.13378, lr:9.23e-03, fs:0.57576 (r=0.576,p=0.576),  time:19.388, tt:484.691\n",
      "Ep:25, loss:0.00002, loss_test:0.13340, lr:9.14e-03, fs:0.57754 (r=0.545,p=0.614),  time:19.341, tt:502.854\n",
      "Ep:26, loss:0.00002, loss_test:0.13277, lr:9.04e-03, fs:0.57297 (r=0.535,p=0.616),  time:19.373, tt:523.073\n",
      "Ep:27, loss:0.00002, loss_test:0.13138, lr:8.95e-03, fs:0.57297 (r=0.535,p=0.616),  time:19.377, tt:542.564\n",
      "Ep:28, loss:0.00002, loss_test:0.13011, lr:8.86e-03, fs:0.58947 (r=0.566,p=0.615),  time:19.359, tt:561.425\n",
      "Ep:29, loss:0.00002, loss_test:0.12942, lr:8.78e-03, fs:0.59067 (r=0.576,p=0.606),  time:19.370, tt:581.112\n",
      "Ep:30, loss:0.00002, loss_test:0.12928, lr:8.69e-03, fs:0.59686 (r=0.576,p=0.620),  time:19.463, tt:603.368\n",
      "Ep:31, loss:0.00002, loss_test:0.12941, lr:8.60e-03, fs:0.59259 (r=0.566,p=0.622),  time:19.513, tt:624.428\n",
      "Ep:32, loss:0.00002, loss_test:0.12940, lr:8.51e-03, fs:0.59783 (r=0.556,p=0.647),  time:19.506, tt:643.707\n",
      "Ep:33, loss:0.00002, loss_test:0.12902, lr:8.43e-03, fs:0.58696 (r=0.545,p=0.635),  time:19.510, tt:663.339\n",
      "Ep:34, loss:0.00002, loss_test:0.12838, lr:8.35e-03, fs:0.58378 (r=0.545,p=0.628),  time:19.459, tt:681.060\n",
      "Ep:35, loss:0.00002, loss_test:0.12776, lr:8.26e-03, fs:0.57297 (r=0.535,p=0.616),  time:19.411, tt:698.795\n",
      "Ep:36, loss:0.00002, loss_test:0.12735, lr:8.18e-03, fs:0.56522 (r=0.525,p=0.612),  time:19.422, tt:718.627\n",
      "Ep:37, loss:0.00002, loss_test:0.12694, lr:8.10e-03, fs:0.54237 (r=0.485,p=0.615),  time:19.434, tt:738.502\n",
      "Ep:38, loss:0.00002, loss_test:0.12632, lr:8.02e-03, fs:0.54444 (r=0.495,p=0.605),  time:19.453, tt:758.650\n",
      "Ep:39, loss:0.00002, loss_test:0.12568, lr:7.94e-03, fs:0.55249 (r=0.505,p=0.610),  time:19.443, tt:777.705\n",
      "Ep:40, loss:0.00002, loss_test:0.12500, lr:7.86e-03, fs:0.53631 (r=0.485,p=0.600),  time:19.424, tt:796.380\n",
      "Ep:41, loss:0.00002, loss_test:0.12455, lr:7.78e-03, fs:0.54237 (r=0.485,p=0.615),  time:19.425, tt:815.870\n",
      "Ep:42, loss:0.00002, loss_test:0.12431, lr:7.70e-03, fs:0.54023 (r=0.475,p=0.627),  time:19.422, tt:835.164\n",
      "Ep:43, loss:0.00002, loss_test:0.12385, lr:7.62e-03, fs:0.54023 (r=0.475,p=0.627),  time:19.465, tt:856.480\n",
      "Ep:44, loss:0.00002, loss_test:0.12318, lr:7.55e-03, fs:0.53409 (r=0.475,p=0.610),  time:19.459, tt:875.636\n",
      "Ep:45, loss:0.00002, loss_test:0.12282, lr:7.47e-03, fs:0.53107 (r=0.475,p=0.603),  time:19.466, tt:895.440\n",
      "Ep:46, loss:0.00002, loss_test:0.12268, lr:7.40e-03, fs:0.54335 (r=0.475,p=0.635),  time:19.469, tt:915.032\n",
      "Ep:47, loss:0.00002, loss_test:0.12245, lr:7.32e-03, fs:0.54335 (r=0.475,p=0.635),  time:19.479, tt:935.003\n",
      "Ep:48, loss:0.00002, loss_test:0.12199, lr:7.25e-03, fs:0.54857 (r=0.485,p=0.632),  time:19.461, tt:953.570\n",
      "Ep:49, loss:0.00002, loss_test:0.12169, lr:7.18e-03, fs:0.55866 (r=0.505,p=0.625),  time:19.441, tt:972.038\n",
      "Ep:50, loss:0.00002, loss_test:0.12204, lr:7.11e-03, fs:0.53801 (r=0.465,p=0.639),  time:19.505, tt:994.752\n",
      "Ep:51, loss:0.00002, loss_test:0.12236, lr:7.03e-03, fs:0.54438 (r=0.465,p=0.657),  time:19.517, tt:1014.870\n",
      "Ep:52, loss:0.00002, loss_test:0.12208, lr:6.96e-03, fs:0.54762 (r=0.465,p=0.667),  time:19.492, tt:1033.064\n",
      "Ep:53, loss:0.00001, loss_test:0.12150, lr:6.89e-03, fs:0.54651 (r=0.475,p=0.644),  time:19.482, tt:1052.047\n",
      "Ep:54, loss:0.00001, loss_test:0.12151, lr:6.83e-03, fs:0.55294 (r=0.475,p=0.662),  time:19.487, tt:1071.774\n",
      "Ep:55, loss:0.00001, loss_test:0.12198, lr:6.76e-03, fs:0.54762 (r=0.465,p=0.667),  time:19.464, tt:1090.002\n",
      "Ep:56, loss:0.00001, loss_test:0.12160, lr:6.69e-03, fs:0.53571 (r=0.455,p=0.652),  time:19.526, tt:1112.992\n",
      "Ep:57, loss:0.00001, loss_test:0.12096, lr:6.62e-03, fs:0.53254 (r=0.455,p=0.643),  time:19.515, tt:1131.852\n",
      "Ep:58, loss:0.00001, loss_test:0.12117, lr:6.56e-03, fs:0.53571 (r=0.455,p=0.652),  time:19.506, tt:1150.860\n",
      "Ep:59, loss:0.00001, loss_test:0.12087, lr:6.49e-03, fs:0.54217 (r=0.455,p=0.672),  time:19.463, tt:1167.755\n",
      "Ep:60, loss:0.00001, loss_test:0.11991, lr:6.43e-03, fs:0.55621 (r=0.475,p=0.671),  time:19.460, tt:1187.064\n",
      "Ep:61, loss:0.00001, loss_test:0.12035, lr:6.36e-03, fs:0.53988 (r=0.444,p=0.688),  time:19.457, tt:1206.304\n",
      "Ep:62, loss:0.00001, loss_test:0.12024, lr:6.30e-03, fs:0.54878 (r=0.455,p=0.692),  time:19.430, tt:1224.102\n",
      "Ep:63, loss:0.00001, loss_test:0.11914, lr:6.24e-03, fs:0.58824 (r=0.505,p=0.704),  time:19.399, tt:1241.525\n",
      "Ep:64, loss:0.00001, loss_test:0.11998, lr:6.17e-03, fs:0.54878 (r=0.455,p=0.692),  time:19.379, tt:1259.636\n",
      "Ep:65, loss:0.00001, loss_test:0.11977, lr:6.11e-03, fs:0.55215 (r=0.455,p=0.703),  time:19.370, tt:1278.391\n",
      "Ep:66, loss:0.00001, loss_test:0.11877, lr:6.05e-03, fs:0.57143 (r=0.485,p=0.696),  time:19.357, tt:1296.935\n",
      "Ep:67, loss:0.00001, loss_test:0.12017, lr:5.99e-03, fs:0.55556 (r=0.455,p=0.714),  time:19.344, tt:1315.394\n",
      "Ep:68, loss:0.00001, loss_test:0.11977, lr:5.93e-03, fs:0.54878 (r=0.455,p=0.692),  time:19.346, tt:1334.901\n",
      "Ep:69, loss:0.00001, loss_test:0.11857, lr:5.87e-03, fs:0.56805 (r=0.485,p=0.686),  time:19.331, tt:1353.200\n",
      "Ep:70, loss:0.00001, loss_test:0.11938, lr:5.81e-03, fs:0.54878 (r=0.455,p=0.692),  time:19.346, tt:1373.567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:71, loss:0.00001, loss_test:0.11970, lr:5.75e-03, fs:0.55901 (r=0.455,p=0.726),  time:19.336, tt:1392.182\n",
      "Ep:72, loss:0.00001, loss_test:0.11856, lr:5.70e-03, fs:0.54878 (r=0.455,p=0.692),  time:19.328, tt:1410.924\n",
      "Ep:73, loss:0.00001, loss_test:0.11770, lr:5.64e-03, fs:0.55090 (r=0.465,p=0.676),  time:19.327, tt:1430.191\n",
      "Ep:74, loss:0.00001, loss_test:0.11861, lr:5.58e-03, fs:0.55556 (r=0.455,p=0.714),  time:19.323, tt:1449.226\n",
      "Ep:75, loss:0.00001, loss_test:0.11882, lr:5.53e-03, fs:0.55901 (r=0.455,p=0.726),  time:19.325, tt:1468.672\n",
      "Ep:76, loss:0.00001, loss_test:0.11781, lr:5.47e-03, fs:0.56098 (r=0.465,p=0.708),  time:19.292, tt:1485.511\n",
      "Ep:77, loss:0.00001, loss_test:0.11730, lr:5.42e-03, fs:0.56098 (r=0.465,p=0.708),  time:19.291, tt:1504.674\n",
      "Ep:78, loss:0.00001, loss_test:0.11799, lr:5.36e-03, fs:0.55215 (r=0.455,p=0.703),  time:19.281, tt:1523.225\n",
      "Ep:79, loss:0.00001, loss_test:0.11824, lr:5.31e-03, fs:0.55000 (r=0.444,p=0.721),  time:19.263, tt:1541.037\n",
      "Ep:80, loss:0.00001, loss_test:0.11753, lr:5.26e-03, fs:0.56970 (r=0.475,p=0.712),  time:19.259, tt:1559.968\n",
      "Ep:81, loss:0.00001, loss_test:0.11757, lr:5.20e-03, fs:0.55215 (r=0.455,p=0.703),  time:19.249, tt:1578.399\n",
      "Ep:82, loss:0.00001, loss_test:0.11776, lr:5.15e-03, fs:0.55346 (r=0.444,p=0.733),  time:19.240, tt:1596.914\n",
      "Ep:83, loss:0.00001, loss_test:0.11691, lr:5.10e-03, fs:0.56442 (r=0.465,p=0.719),  time:19.222, tt:1614.653\n",
      "Ep:84, loss:0.00001, loss_test:0.11702, lr:5.05e-03, fs:0.55901 (r=0.455,p=0.726),  time:19.227, tt:1634.272\n",
      "Ep:85, loss:0.00001, loss_test:0.11685, lr:5.00e-03, fs:0.57317 (r=0.475,p=0.723),  time:19.224, tt:1653.303\n",
      "Ep:86, loss:0.00001, loss_test:0.11731, lr:4.95e-03, fs:0.56250 (r=0.455,p=0.738),  time:19.208, tt:1671.109\n",
      "Ep:87, loss:0.00001, loss_test:0.11659, lr:4.90e-03, fs:0.58537 (r=0.485,p=0.738),  time:19.221, tt:1691.488\n",
      "Ep:88, loss:0.00001, loss_test:0.11673, lr:4.85e-03, fs:0.58025 (r=0.475,p=0.746),  time:19.219, tt:1710.531\n",
      "Ep:89, loss:0.00001, loss_test:0.11672, lr:4.80e-03, fs:0.58025 (r=0.475,p=0.746),  time:19.263, tt:1733.641\n",
      "Ep:90, loss:0.00001, loss_test:0.11641, lr:4.75e-03, fs:0.58537 (r=0.485,p=0.738),  time:19.255, tt:1752.188\n",
      "Ep:91, loss:0.00001, loss_test:0.11727, lr:4.71e-03, fs:0.57143 (r=0.465,p=0.742),  time:19.250, tt:1771.016\n",
      "Ep:92, loss:0.00001, loss_test:0.11698, lr:4.66e-03, fs:0.56790 (r=0.465,p=0.730),  time:19.241, tt:1789.416\n",
      "Ep:93, loss:0.00001, loss_test:0.11607, lr:4.61e-03, fs:0.58537 (r=0.485,p=0.738),  time:19.233, tt:1807.872\n",
      "Ep:94, loss:0.00001, loss_test:0.11689, lr:4.57e-03, fs:0.55000 (r=0.444,p=0.721),  time:19.238, tt:1827.631\n",
      "Ep:95, loss:0.00001, loss_test:0.11689, lr:4.52e-03, fs:0.53503 (r=0.424,p=0.724),  time:19.240, tt:1847.009\n",
      "Ep:96, loss:0.00001, loss_test:0.11591, lr:4.48e-03, fs:0.57669 (r=0.475,p=0.734),  time:19.238, tt:1866.044\n",
      "Ep:97, loss:0.00001, loss_test:0.11604, lr:4.43e-03, fs:0.57669 (r=0.475,p=0.734),  time:19.233, tt:1884.845\n",
      "Ep:98, loss:0.00001, loss_test:0.11669, lr:4.39e-03, fs:0.54088 (r=0.434,p=0.717),  time:19.216, tt:1902.341\n",
      "Ep:99, loss:0.00001, loss_test:0.11636, lr:4.34e-03, fs:0.55000 (r=0.444,p=0.721),  time:19.223, tt:1922.321\n",
      "Ep:100, loss:0.00001, loss_test:0.11551, lr:4.30e-03, fs:0.55901 (r=0.455,p=0.726),  time:19.214, tt:1940.594\n",
      "Ep:101, loss:0.00001, loss_test:0.11574, lr:4.26e-03, fs:0.56790 (r=0.465,p=0.730),  time:19.207, tt:1959.121\n",
      "Ep:102, loss:0.00001, loss_test:0.11641, lr:4.21e-03, fs:0.55346 (r=0.444,p=0.733),  time:19.209, tt:1978.557\n",
      "Ep:103, loss:0.00001, loss_test:0.11596, lr:4.17e-03, fs:0.56250 (r=0.455,p=0.738),  time:19.196, tt:1996.385\n",
      "Ep:104, loss:0.00001, loss_test:0.11499, lr:4.13e-03, fs:0.57669 (r=0.475,p=0.734),  time:19.191, tt:2015.072\n",
      "Ep:105, loss:0.00001, loss_test:0.11609, lr:4.09e-03, fs:0.54777 (r=0.434,p=0.741),  time:19.188, tt:2033.955\n",
      "Ep:106, loss:0.00001, loss_test:0.11621, lr:4.05e-03, fs:0.53846 (r=0.424,p=0.737),  time:19.179, tt:2052.105\n",
      "Ep:107, loss:0.00001, loss_test:0.11512, lr:4.01e-03, fs:0.56604 (r=0.455,p=0.750),  time:19.175, tt:2070.940\n",
      "Ep:108, loss:0.00001, loss_test:0.11468, lr:3.97e-03, fs:0.56604 (r=0.455,p=0.750),  time:19.171, tt:2089.604\n",
      "Ep:109, loss:0.00001, loss_test:0.11577, lr:3.93e-03, fs:0.53846 (r=0.424,p=0.737),  time:19.164, tt:2108.059\n",
      "Ep:110, loss:0.00001, loss_test:0.11545, lr:3.89e-03, fs:0.54777 (r=0.434,p=0.741),  time:19.160, tt:2126.792\n",
      "Ep:111, loss:0.00001, loss_test:0.11421, lr:3.85e-03, fs:0.55696 (r=0.444,p=0.746),  time:19.145, tt:2144.236\n",
      "Ep:112, loss:0.00001, loss_test:0.11448, lr:3.81e-03, fs:0.55696 (r=0.444,p=0.746),  time:19.141, tt:2162.891\n",
      "Ep:113, loss:0.00001, loss_test:0.11515, lr:3.77e-03, fs:0.55696 (r=0.444,p=0.746),  time:19.111, tt:2178.657\n",
      "Ep:114, loss:0.00001, loss_test:0.11482, lr:3.73e-03, fs:0.55696 (r=0.444,p=0.746),  time:19.110, tt:2197.632\n",
      "Ep:115, loss:0.00001, loss_test:0.11377, lr:3.70e-03, fs:0.56604 (r=0.455,p=0.750),  time:19.103, tt:2215.891\n",
      "Ep:116, loss:0.00001, loss_test:0.11375, lr:3.66e-03, fs:0.55696 (r=0.444,p=0.746),  time:19.109, tt:2235.793\n",
      "Ep:117, loss:0.00001, loss_test:0.11384, lr:3.62e-03, fs:0.55696 (r=0.444,p=0.746),  time:19.104, tt:2254.242\n",
      "Ep:118, loss:0.00001, loss_test:0.11373, lr:3.59e-03, fs:0.55696 (r=0.444,p=0.746),  time:19.096, tt:2272.401\n",
      "Ep:119, loss:0.00001, loss_test:0.11390, lr:3.55e-03, fs:0.55696 (r=0.444,p=0.746),  time:19.091, tt:2290.861\n",
      "Ep:120, loss:0.00001, loss_test:0.11393, lr:3.52e-03, fs:0.55696 (r=0.444,p=0.746),  time:19.085, tt:2309.260\n",
      "Ep:121, loss:0.00001, loss_test:0.11311, lr:3.48e-03, fs:0.56604 (r=0.455,p=0.750),  time:19.070, tt:2326.544\n",
      "Ep:122, loss:0.00001, loss_test:0.11388, lr:3.45e-03, fs:0.55696 (r=0.444,p=0.746),  time:19.072, tt:2345.819\n",
      "Ep:123, loss:0.00001, loss_test:0.11377, lr:3.41e-03, fs:0.56051 (r=0.444,p=0.759),  time:19.067, tt:2364.364\n",
      "Ep:124, loss:0.00001, loss_test:0.11300, lr:3.38e-03, fs:0.55696 (r=0.444,p=0.746),  time:19.063, tt:2382.904\n",
      "Ep:125, loss:0.00001, loss_test:0.11251, lr:3.34e-03, fs:0.56604 (r=0.455,p=0.750),  time:19.064, tt:2402.045\n",
      "Ep:126, loss:0.00001, loss_test:0.11367, lr:3.31e-03, fs:0.56051 (r=0.444,p=0.759),  time:19.070, tt:2421.911\n",
      "Ep:127, loss:0.00001, loss_test:0.11418, lr:3.28e-03, fs:0.56051 (r=0.444,p=0.759),  time:19.068, tt:2440.735\n",
      "Ep:128, loss:0.00001, loss_test:0.11350, lr:3.24e-03, fs:0.56051 (r=0.444,p=0.759),  time:19.075, tt:2460.733\n",
      "Ep:129, loss:0.00001, loss_test:0.11254, lr:3.21e-03, fs:0.56604 (r=0.455,p=0.750),  time:19.084, tt:2480.980\n",
      "Ep:130, loss:0.00001, loss_test:0.11314, lr:3.18e-03, fs:0.56051 (r=0.444,p=0.759),  time:19.089, tt:2500.595\n",
      "Ep:131, loss:0.00001, loss_test:0.11382, lr:3.15e-03, fs:0.56410 (r=0.444,p=0.772),  time:19.102, tt:2521.418\n",
      "Ep:132, loss:0.00001, loss_test:0.11365, lr:3.12e-03, fs:0.56410 (r=0.444,p=0.772),  time:19.103, tt:2540.744\n",
      "Ep:133, loss:0.00001, loss_test:0.11291, lr:3.09e-03, fs:0.56962 (r=0.455,p=0.763),  time:19.103, tt:2559.815\n",
      "Ep:134, loss:0.00001, loss_test:0.11285, lr:3.05e-03, fs:0.56962 (r=0.455,p=0.763),  time:19.096, tt:2577.902\n",
      "Ep:135, loss:0.00001, loss_test:0.11347, lr:3.02e-03, fs:0.56774 (r=0.444,p=0.786),  time:19.099, tt:2597.512\n",
      "Ep:136, loss:0.00001, loss_test:0.11328, lr:2.99e-03, fs:0.56774 (r=0.444,p=0.786),  time:19.104, tt:2617.191\n",
      "Ep:137, loss:0.00001, loss_test:0.11266, lr:2.96e-03, fs:0.56962 (r=0.455,p=0.763),  time:19.095, tt:2635.111\n",
      "Ep:138, loss:0.00001, loss_test:0.11264, lr:2.93e-03, fs:0.57325 (r=0.455,p=0.776),  time:19.097, tt:2654.421\n",
      "Ep:139, loss:0.00001, loss_test:0.11302, lr:2.90e-03, fs:0.56774 (r=0.444,p=0.786),  time:19.100, tt:2673.995\n",
      "Ep:140, loss:0.00001, loss_test:0.11260, lr:2.88e-03, fs:0.55844 (r=0.434,p=0.782),  time:19.105, tt:2693.769\n",
      "Ep:141, loss:0.00001, loss_test:0.11205, lr:2.85e-03, fs:0.56774 (r=0.444,p=0.786),  time:19.106, tt:2713.108\n",
      "Ep:142, loss:0.00001, loss_test:0.11318, lr:2.82e-03, fs:0.56209 (r=0.434,p=0.796),  time:19.098, tt:2730.961\n",
      "Ep:143, loss:0.00001, loss_test:0.11355, lr:2.79e-03, fs:0.54305 (r=0.414,p=0.788),  time:19.100, tt:2750.449\n",
      "Ep:144, loss:0.00001, loss_test:0.11287, lr:2.76e-03, fs:0.56209 (r=0.434,p=0.796),  time:19.103, tt:2769.900\n",
      "Ep:145, loss:0.00001, loss_test:0.11191, lr:2.73e-03, fs:0.56774 (r=0.444,p=0.786),  time:19.108, tt:2789.810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:146, loss:0.00001, loss_test:0.11261, lr:2.71e-03, fs:0.55844 (r=0.434,p=0.782),  time:19.112, tt:2809.457\n",
      "Ep:147, loss:0.00001, loss_test:0.11325, lr:2.68e-03, fs:0.55263 (r=0.424,p=0.792),  time:19.115, tt:2829.048\n",
      "Ep:148, loss:0.00001, loss_test:0.11293, lr:2.65e-03, fs:0.53947 (r=0.414,p=0.774),  time:19.119, tt:2848.656\n",
      "Ep:149, loss:0.00001, loss_test:0.11230, lr:2.63e-03, fs:0.54902 (r=0.424,p=0.778),  time:19.137, tt:2870.548\n",
      "Ep:150, loss:0.00001, loss_test:0.11231, lr:2.60e-03, fs:0.54902 (r=0.424,p=0.778),  time:19.131, tt:2888.710\n",
      "Ep:151, loss:0.00001, loss_test:0.11249, lr:2.57e-03, fs:0.54902 (r=0.424,p=0.778),  time:19.131, tt:2907.884\n",
      "Ep:152, loss:0.00001, loss_test:0.11220, lr:2.55e-03, fs:0.54902 (r=0.424,p=0.778),  time:19.127, tt:2926.435\n",
      "Ep:153, loss:0.00001, loss_test:0.11178, lr:2.52e-03, fs:0.54902 (r=0.424,p=0.778),  time:19.124, tt:2945.125\n",
      "Ep:154, loss:0.00001, loss_test:0.11259, lr:2.50e-03, fs:0.53333 (r=0.404,p=0.784),  time:19.115, tt:2962.848\n",
      "Ep:155, loss:0.00001, loss_test:0.11282, lr:2.47e-03, fs:0.53333 (r=0.404,p=0.784),  time:19.112, tt:2981.403\n",
      "Ep:156, loss:0.00001, loss_test:0.11201, lr:2.45e-03, fs:0.54305 (r=0.414,p=0.788),  time:19.112, tt:3000.590\n",
      "Ep:157, loss:0.00001, loss_test:0.11151, lr:2.42e-03, fs:0.55263 (r=0.424,p=0.792),  time:19.103, tt:3018.261\n",
      "Ep:158, loss:0.00001, loss_test:0.11225, lr:2.40e-03, fs:0.54305 (r=0.414,p=0.788),  time:19.103, tt:3037.419\n",
      "Ep:159, loss:0.00001, loss_test:0.11247, lr:2.38e-03, fs:0.54305 (r=0.414,p=0.788),  time:19.102, tt:3056.255\n",
      "Ep:160, loss:0.00001, loss_test:0.11208, lr:2.35e-03, fs:0.54305 (r=0.414,p=0.788),  time:19.106, tt:3076.141\n",
      "Ep:161, loss:0.00001, loss_test:0.11167, lr:2.33e-03, fs:0.54305 (r=0.414,p=0.788),  time:19.103, tt:3094.661\n",
      "Ep:162, loss:0.00001, loss_test:0.11228, lr:2.31e-03, fs:0.54305 (r=0.414,p=0.788),  time:19.091, tt:3111.867\n",
      "Ep:163, loss:0.00001, loss_test:0.11208, lr:2.28e-03, fs:0.54305 (r=0.414,p=0.788),  time:19.093, tt:3131.294\n",
      "Ep:164, loss:0.00001, loss_test:0.11124, lr:2.26e-03, fs:0.55263 (r=0.424,p=0.792),  time:19.091, tt:3150.088\n",
      "Ep:165, loss:0.00001, loss_test:0.11182, lr:2.24e-03, fs:0.54305 (r=0.414,p=0.788),  time:19.090, tt:3168.899\n",
      "Ep:166, loss:0.00001, loss_test:0.11222, lr:2.21e-03, fs:0.54305 (r=0.414,p=0.788),  time:19.094, tt:3188.706\n",
      "Ep:167, loss:0.00000, loss_test:0.11171, lr:2.19e-03, fs:0.54305 (r=0.414,p=0.788),  time:19.088, tt:3206.770\n",
      "Ep:168, loss:0.00000, loss_test:0.11135, lr:2.17e-03, fs:0.54305 (r=0.414,p=0.788),  time:19.088, tt:3225.881\n",
      "Ep:169, loss:0.00000, loss_test:0.11227, lr:2.15e-03, fs:0.53333 (r=0.404,p=0.784),  time:19.068, tt:3241.643\n",
      "Ep:170, loss:0.00000, loss_test:0.11239, lr:2.13e-03, fs:0.53333 (r=0.404,p=0.784),  time:19.063, tt:3259.730\n",
      "Ep:171, loss:0.00000, loss_test:0.11166, lr:2.11e-03, fs:0.54305 (r=0.414,p=0.788),  time:19.058, tt:3277.932\n",
      "Ep:172, loss:0.00000, loss_test:0.11081, lr:2.08e-03, fs:0.55263 (r=0.424,p=0.792),  time:19.047, tt:3295.140\n",
      "Ep:173, loss:0.00000, loss_test:0.11155, lr:2.06e-03, fs:0.54305 (r=0.414,p=0.788),  time:19.045, tt:3313.863\n",
      "Ep:174, loss:0.00000, loss_test:0.11221, lr:2.04e-03, fs:0.53333 (r=0.404,p=0.784),  time:19.041, tt:3332.186\n",
      "Ep:175, loss:0.00000, loss_test:0.11199, lr:2.02e-03, fs:0.53333 (r=0.404,p=0.784),  time:19.037, tt:3350.455\n",
      "Ep:176, loss:0.00000, loss_test:0.11110, lr:2.00e-03, fs:0.54305 (r=0.414,p=0.788),  time:19.033, tt:3368.914\n",
      "Ep:177, loss:0.00000, loss_test:0.11151, lr:1.98e-03, fs:0.54305 (r=0.414,p=0.788),  time:19.036, tt:3388.345\n",
      "Ep:178, loss:0.00000, loss_test:0.11191, lr:1.96e-03, fs:0.53333 (r=0.404,p=0.784),  time:19.029, tt:3406.120\n",
      "Ep:179, loss:0.00000, loss_test:0.11182, lr:1.94e-03, fs:0.53333 (r=0.404,p=0.784),  time:19.026, tt:3424.763\n",
      "Ep:180, loss:0.00000, loss_test:0.11166, lr:1.92e-03, fs:0.54305 (r=0.414,p=0.788),  time:19.022, tt:3442.939\n",
      "Ep:181, loss:0.00000, loss_test:0.11170, lr:1.90e-03, fs:0.53333 (r=0.404,p=0.784),  time:19.016, tt:3460.885\n",
      "Ep:182, loss:0.00000, loss_test:0.11156, lr:1.89e-03, fs:0.53333 (r=0.404,p=0.784),  time:19.008, tt:3478.504\n",
      "Ep:183, loss:0.00000, loss_test:0.11165, lr:1.87e-03, fs:0.53333 (r=0.404,p=0.784),  time:19.012, tt:3498.201\n",
      "Ep:184, loss:0.00000, loss_test:0.11177, lr:1.85e-03, fs:0.53333 (r=0.404,p=0.784),  time:19.009, tt:3516.589\n",
      "Ep:185, loss:0.00000, loss_test:0.11170, lr:1.83e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.010, tt:3535.865\n",
      "Ep:186, loss:0.00000, loss_test:0.11144, lr:1.81e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.015, tt:3555.741\n",
      "Ep:187, loss:0.00000, loss_test:0.11168, lr:1.79e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.018, tt:3575.316\n",
      "Ep:188, loss:0.00000, loss_test:0.11171, lr:1.78e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.027, tt:3596.059\n",
      "Ep:189, loss:0.00000, loss_test:0.11133, lr:1.76e-03, fs:0.53333 (r=0.404,p=0.784),  time:19.038, tt:3617.190\n",
      "Ep:190, loss:0.00000, loss_test:0.11161, lr:1.74e-03, fs:0.53333 (r=0.404,p=0.784),  time:19.035, tt:3635.644\n",
      "Ep:191, loss:0.00000, loss_test:0.11175, lr:1.72e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.033, tt:3654.427\n",
      "Ep:192, loss:0.00000, loss_test:0.11154, lr:1.71e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.034, tt:3673.634\n",
      "Ep:193, loss:0.00000, loss_test:0.11141, lr:1.69e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.043, tt:3694.265\n",
      "Ep:194, loss:0.00000, loss_test:0.11193, lr:1.67e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.046, tt:3713.920\n",
      "Ep:195, loss:0.00000, loss_test:0.11198, lr:1.65e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.053, tt:3734.320\n",
      "Ep:196, loss:0.00000, loss_test:0.11140, lr:1.64e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.054, tt:3753.544\n",
      "Ep:197, loss:0.00000, loss_test:0.11160, lr:1.62e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.057, tt:3773.278\n",
      "Ep:198, loss:0.00000, loss_test:0.11202, lr:1.61e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.065, tt:3793.886\n",
      "Ep:199, loss:0.00000, loss_test:0.11197, lr:1.59e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.072, tt:3814.336\n",
      "Ep:200, loss:0.00000, loss_test:0.11166, lr:1.57e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.077, tt:3834.434\n",
      "Ep:201, loss:0.00000, loss_test:0.11176, lr:1.56e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.090, tt:3856.089\n",
      "Ep:202, loss:0.00000, loss_test:0.11133, lr:1.54e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.098, tt:3876.819\n",
      "Ep:203, loss:0.00000, loss_test:0.11130, lr:1.53e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.108, tt:3898.111\n",
      "Ep:204, loss:0.00000, loss_test:0.11176, lr:1.51e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.117, tt:3919.000\n",
      "Ep:205, loss:0.00000, loss_test:0.11165, lr:1.50e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.123, tt:3939.279\n",
      "Ep:206, loss:0.00000, loss_test:0.11152, lr:1.48e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.123, tt:3958.546\n",
      "Ep:207, loss:0.00000, loss_test:0.11170, lr:1.47e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.136, tt:3980.281\n",
      "Ep:208, loss:0.00000, loss_test:0.11152, lr:1.45e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.144, tt:4001.103\n",
      "Ep:209, loss:0.00000, loss_test:0.11123, lr:1.44e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.154, tt:4022.244\n",
      "Ep:210, loss:0.00000, loss_test:0.11166, lr:1.42e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.159, tt:4042.595\n",
      "Ep:211, loss:0.00000, loss_test:0.11142, lr:1.41e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.163, tt:4062.514\n",
      "Ep:212, loss:0.00000, loss_test:0.11139, lr:1.39e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.169, tt:4082.997\n",
      "Ep:213, loss:0.00000, loss_test:0.11138, lr:1.38e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.179, tt:4104.236\n",
      "Ep:214, loss:0.00000, loss_test:0.11116, lr:1.37e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.211, tt:4130.383\n",
      "Ep:215, loss:0.00000, loss_test:0.11151, lr:1.35e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.214, tt:4150.249\n",
      "Ep:216, loss:0.00000, loss_test:0.11142, lr:1.34e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.219, tt:4170.424\n",
      "Ep:217, loss:0.00000, loss_test:0.11127, lr:1.33e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.217, tt:4189.256\n",
      "Ep:218, loss:0.00000, loss_test:0.11155, lr:1.31e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.221, tt:4209.375\n",
      "Ep:219, loss:0.00000, loss_test:0.11132, lr:1.30e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.224, tt:4229.263\n",
      "Ep:220, loss:0.00000, loss_test:0.11084, lr:1.29e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.235, tt:4250.829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:221, loss:0.00000, loss_test:0.11140, lr:1.27e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.232, tt:4269.591\n",
      "Ep:222, loss:0.00000, loss_test:0.11166, lr:1.26e-03, fs:0.52703 (r=0.394,p=0.796),  time:19.231, tt:4288.609\n",
      "Ep:223, loss:0.00000, loss_test:0.11137, lr:1.25e-03, fs:0.54667 (r=0.414,p=0.804),  time:19.229, tt:4307.377\n",
      "Ep:224, loss:0.00000, loss_test:0.11118, lr:1.24e-03, fs:0.54667 (r=0.414,p=0.804),  time:19.234, tt:4327.631\n",
      "Ep:225, loss:0.00000, loss_test:0.11134, lr:1.22e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.237, tt:4347.581\n",
      "Ep:226, loss:0.00000, loss_test:0.11117, lr:1.21e-03, fs:0.53691 (r=0.404,p=0.800),  time:19.240, tt:4367.487\n",
      "Ep:227, loss:0.00000, loss_test:0.11113, lr:1.20e-03, fs:0.54667 (r=0.414,p=0.804),  time:19.241, tt:4387.050\n",
      "Ep:228, loss:0.00000, loss_test:0.11142, lr:1.19e-03, fs:0.54667 (r=0.414,p=0.804),  time:19.242, tt:4406.372\n",
      "Ep:229, loss:0.00000, loss_test:0.11143, lr:1.18e-03, fs:0.54667 (r=0.414,p=0.804),  time:19.245, tt:4426.429\n",
      "Ep:230, loss:0.00000, loss_test:0.11145, lr:1.16e-03, fs:0.54667 (r=0.414,p=0.804),  time:19.245, tt:4445.513\n",
      "Ep:231, loss:0.00000, loss_test:0.11151, lr:1.15e-03, fs:0.54667 (r=0.414,p=0.804),  time:19.246, tt:4465.098\n",
      "Ep:232, loss:0.00000, loss_test:0.11120, lr:1.14e-03, fs:0.54667 (r=0.414,p=0.804),  time:19.251, tt:4485.484\n",
      "Ep:233, loss:0.00000, loss_test:0.11123, lr:1.13e-03, fs:0.54667 (r=0.414,p=0.804),  time:19.253, tt:4505.127\n",
      "Ep:234, loss:0.00000, loss_test:0.11139, lr:1.12e-03, fs:0.54667 (r=0.414,p=0.804),  time:19.254, tt:4524.714\n",
      "Ep:235, loss:0.00000, loss_test:0.11124, lr:1.11e-03, fs:0.54667 (r=0.414,p=0.804),  time:19.256, tt:4544.299\n",
      "Ep:236, loss:0.00000, loss_test:0.11141, lr:1.10e-03, fs:0.54667 (r=0.414,p=0.804),  time:19.254, tt:4563.235\n",
      "Ep:237, loss:0.00000, loss_test:0.11120, lr:1.08e-03, fs:0.54667 (r=0.414,p=0.804),  time:19.256, tt:4582.922\n",
      "Ep:238, loss:0.00000, loss_test:0.11108, lr:1.07e-03, fs:0.54667 (r=0.414,p=0.804),  time:19.257, tt:4602.541\n",
      "Ep:239, loss:0.00000, loss_test:0.11162, lr:1.06e-03, fs:0.54054 (r=0.404,p=0.816),  time:19.257, tt:4621.796\n",
      "Ep:240, loss:0.00000, loss_test:0.11162, lr:1.05e-03, fs:0.54054 (r=0.404,p=0.816),  time:19.260, tt:4641.721\n",
      "Ep:241, loss:0.00000, loss_test:0.11113, lr:1.04e-03, fs:0.54667 (r=0.414,p=0.804),  time:19.259, tt:4660.788\n",
      "Ep:242, loss:0.00000, loss_test:0.11081, lr:1.03e-03, fs:0.55629 (r=0.424,p=0.808),  time:19.261, tt:4680.511\n",
      "Ep:243, loss:0.00000, loss_test:0.11148, lr:1.02e-03, fs:0.54054 (r=0.404,p=0.816),  time:19.265, tt:4700.782\n",
      "Ep:244, loss:0.00000, loss_test:0.11169, lr:1.01e-03, fs:0.53061 (r=0.394,p=0.812),  time:19.268, tt:4720.737\n",
      "Ep:245, loss:0.00000, loss_test:0.11143, lr:1.00e-03, fs:0.54054 (r=0.404,p=0.816),  time:19.273, tt:4741.095\n",
      "Ep:246, loss:0.00000, loss_test:0.11090, lr:9.91e-04, fs:0.55629 (r=0.424,p=0.808),  time:19.280, tt:4762.044\n",
      "Ep:247, loss:0.00000, loss_test:0.11105, lr:9.81e-04, fs:0.55034 (r=0.414,p=0.820),  time:19.285, tt:4782.579\n",
      "Ep:248, loss:0.00000, loss_test:0.11139, lr:9.71e-04, fs:0.54054 (r=0.404,p=0.816),  time:19.286, tt:4802.133\n",
      "Ep:249, loss:0.00000, loss_test:0.11130, lr:9.62e-04, fs:0.54054 (r=0.404,p=0.816),  time:19.290, tt:4822.543\n",
      "Ep:250, loss:0.00000, loss_test:0.11090, lr:9.52e-04, fs:0.55629 (r=0.424,p=0.808),  time:19.289, tt:4841.616\n",
      "Ep:251, loss:0.00000, loss_test:0.11087, lr:9.42e-04, fs:0.55629 (r=0.424,p=0.808),  time:19.292, tt:4861.504\n",
      "Ep:252, loss:0.00000, loss_test:0.11154, lr:9.33e-04, fs:0.54054 (r=0.404,p=0.816),  time:19.299, tt:4882.752\n",
      "Ep:253, loss:0.00000, loss_test:0.11178, lr:9.24e-04, fs:0.53061 (r=0.394,p=0.812),  time:19.305, tt:4903.389\n",
      "Ep:254, loss:0.00000, loss_test:0.11151, lr:9.14e-04, fs:0.53061 (r=0.394,p=0.812),  time:19.311, tt:4924.365\n",
      "Ep:255, loss:0.00000, loss_test:0.11092, lr:9.05e-04, fs:0.56000 (r=0.424,p=0.824),  time:19.316, tt:4944.844\n",
      "Ep:256, loss:0.00000, loss_test:0.11087, lr:8.96e-04, fs:0.56000 (r=0.424,p=0.824),  time:19.319, tt:4965.086\n",
      "Ep:257, loss:0.00000, loss_test:0.11125, lr:8.87e-04, fs:0.54054 (r=0.404,p=0.816),  time:19.323, tt:4985.345\n",
      "Ep:258, loss:0.00000, loss_test:0.11133, lr:8.78e-04, fs:0.54422 (r=0.404,p=0.833),  time:19.327, tt:5005.680\n",
      "Ep:259, loss:0.00000, loss_test:0.11107, lr:8.70e-04, fs:0.56000 (r=0.424,p=0.824),  time:19.329, tt:5025.573\n",
      "Ep:260, loss:0.00000, loss_test:0.11074, lr:8.61e-04, fs:0.56000 (r=0.424,p=0.824),  time:19.331, tt:5045.460\n",
      "Ep:261, loss:0.00000, loss_test:0.11097, lr:8.52e-04, fs:0.56000 (r=0.424,p=0.824),  time:19.330, tt:5064.562\n",
      "Ep:262, loss:0.00000, loss_test:0.11114, lr:8.44e-04, fs:0.55405 (r=0.414,p=0.837),  time:19.328, tt:5083.374\n",
      "Ep:263, loss:0.00000, loss_test:0.11101, lr:8.35e-04, fs:0.56000 (r=0.424,p=0.824),  time:19.329, tt:5102.969\n",
      "Ep:264, loss:0.00000, loss_test:0.11070, lr:8.27e-04, fs:0.56000 (r=0.424,p=0.824),  time:19.329, tt:5122.085\n",
      "Ep:265, loss:0.00000, loss_test:0.11099, lr:8.19e-04, fs:0.56000 (r=0.424,p=0.824),  time:19.331, tt:5142.004\n",
      "Ep:266, loss:0.00000, loss_test:0.11120, lr:8.11e-04, fs:0.55405 (r=0.414,p=0.837),  time:19.330, tt:5161.078\n",
      "Ep:267, loss:0.00000, loss_test:0.11111, lr:8.02e-04, fs:0.56000 (r=0.424,p=0.824),  time:19.334, tt:5181.620\n",
      "Ep:268, loss:0.00000, loss_test:0.11096, lr:7.94e-04, fs:0.56000 (r=0.424,p=0.824),  time:19.336, tt:5201.279\n",
      "Ep:269, loss:0.00000, loss_test:0.11111, lr:7.87e-04, fs:0.55405 (r=0.414,p=0.837),  time:19.339, tt:5221.629\n",
      "Ep:270, loss:0.00000, loss_test:0.11104, lr:7.79e-04, fs:0.56000 (r=0.424,p=0.824),  time:19.337, tt:5240.380\n",
      "Ep:271, loss:0.00000, loss_test:0.11096, lr:7.71e-04, fs:0.56000 (r=0.424,p=0.824),  time:19.342, tt:5260.975\n",
      "Ep:272, loss:0.00000, loss_test:0.11127, lr:7.63e-04, fs:0.55405 (r=0.414,p=0.837),  time:19.346, tt:5281.351\n",
      "Ep:273, loss:0.00000, loss_test:0.11120, lr:7.56e-04, fs:0.55405 (r=0.414,p=0.837),  time:19.340, tt:5299.158\n",
      "Ep:274, loss:0.00000, loss_test:0.11081, lr:7.48e-04, fs:0.56376 (r=0.424,p=0.840),  time:19.343, tt:5319.326\n",
      "Ep:275, loss:0.00000, loss_test:0.11080, lr:7.40e-04, fs:0.56376 (r=0.424,p=0.840),  time:19.341, tt:5338.180\n",
      "Ep:276, loss:0.00000, loss_test:0.11102, lr:7.33e-04, fs:0.55405 (r=0.414,p=0.837),  time:19.345, tt:5358.484\n",
      "Ep:277, loss:0.00000, loss_test:0.11096, lr:7.26e-04, fs:0.55405 (r=0.414,p=0.837),  time:19.350, tt:5379.374\n",
      "Ep:278, loss:0.00000, loss_test:0.11087, lr:7.18e-04, fs:0.56000 (r=0.424,p=0.824),  time:19.354, tt:5399.808\n",
      "Ep:279, loss:0.00000, loss_test:0.11105, lr:7.11e-04, fs:0.56376 (r=0.424,p=0.840),  time:19.357, tt:5419.840\n",
      "Ep:280, loss:0.00000, loss_test:0.11106, lr:7.04e-04, fs:0.56376 (r=0.424,p=0.840),  time:19.357, tt:5439.384\n",
      "Ep:281, loss:0.00000, loss_test:0.11100, lr:6.97e-04, fs:0.56376 (r=0.424,p=0.840),  time:19.362, tt:5460.086\n",
      "Ep:282, loss:0.00000, loss_test:0.11087, lr:6.90e-04, fs:0.56376 (r=0.424,p=0.840),  time:19.365, tt:5480.238\n",
      "Ep:283, loss:0.00000, loss_test:0.11092, lr:6.83e-04, fs:0.56376 (r=0.424,p=0.840),  time:19.365, tt:5499.662\n",
      "Ep:284, loss:0.00000, loss_test:0.11097, lr:6.76e-04, fs:0.56376 (r=0.424,p=0.840),  time:19.369, tt:5520.248\n",
      "Ep:285, loss:0.00000, loss_test:0.11091, lr:6.70e-04, fs:0.56376 (r=0.424,p=0.840),  time:19.367, tt:5538.928\n",
      "Ep:286, loss:0.00000, loss_test:0.11092, lr:6.63e-04, fs:0.56376 (r=0.424,p=0.840),  time:19.366, tt:5557.994\n",
      "Ep:287, loss:0.00000, loss_test:0.11079, lr:6.56e-04, fs:0.56376 (r=0.424,p=0.840),  time:19.363, tt:5576.501\n",
      "Ep:288, loss:0.00000, loss_test:0.11080, lr:6.50e-04, fs:0.56376 (r=0.424,p=0.840),  time:19.361, tt:5595.323\n",
      "Ep:289, loss:0.00000, loss_test:0.11077, lr:6.43e-04, fs:0.56376 (r=0.424,p=0.840),  time:19.362, tt:5614.983\n",
      "Ep:290, loss:0.00000, loss_test:0.11078, lr:6.37e-04, fs:0.56376 (r=0.424,p=0.840),  time:19.365, tt:5635.130\n",
      "Ep:291, loss:0.00000, loss_test:0.11092, lr:6.30e-04, fs:0.56376 (r=0.424,p=0.840),  time:19.363, tt:5653.962\n",
      "Ep:292, loss:0.00000, loss_test:0.11079, lr:6.24e-04, fs:0.56376 (r=0.424,p=0.840),  time:19.363, tt:5673.348\n",
      "Ep:293, loss:0.00000, loss_test:0.11083, lr:6.18e-04, fs:0.56376 (r=0.424,p=0.840),  time:19.373, tt:5695.604\n",
      "Ep:294, loss:0.00000, loss_test:0.11094, lr:6.12e-04, fs:0.56376 (r=0.424,p=0.840),  time:19.375, tt:5715.771\n",
      "Ep:295, loss:0.00000, loss_test:0.11081, lr:6.06e-04, fs:0.56376 (r=0.424,p=0.840),  time:19.370, tt:5733.569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.15370, lr:1.00e-02, fs:0.62143 (r=0.879,p=0.481),  time:9.960, tt:9.960\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.15391, lr:1.00e-02, fs:0.62366 (r=0.879,p=0.483),  time:12.620, tt:25.241\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.15399, lr:1.00e-02, fs:0.60223 (r=0.818,p=0.476),  time:14.307, tt:42.922\n",
      "Ep:3, loss:0.00004, loss_test:0.15429, lr:1.00e-02, fs:0.59459 (r=0.778,p=0.481),  time:15.476, tt:61.905\n",
      "Ep:4, loss:0.00003, loss_test:0.15470, lr:1.00e-02, fs:0.58300 (r=0.727,p=0.486),  time:15.934, tt:79.672\n",
      "Ep:5, loss:0.00003, loss_test:0.15581, lr:1.00e-02, fs:0.56897 (r=0.667,p=0.496),  time:16.447, tt:98.680\n",
      "Ep:6, loss:0.00003, loss_test:0.15697, lr:1.00e-02, fs:0.56388 (r=0.646,p=0.500),  time:16.749, tt:117.245\n",
      "Ep:7, loss:0.00003, loss_test:0.15833, lr:1.00e-02, fs:0.56872 (r=0.606,p=0.536),  time:17.002, tt:136.020\n",
      "Ep:8, loss:0.00003, loss_test:0.15914, lr:1.00e-02, fs:0.53731 (r=0.545,p=0.529),  time:17.175, tt:154.579\n",
      "Ep:9, loss:0.00003, loss_test:0.15871, lr:1.00e-02, fs:0.50761 (r=0.505,p=0.510),  time:17.203, tt:172.034\n",
      "Ep:10, loss:0.00003, loss_test:0.15688, lr:1.00e-02, fs:0.52217 (r=0.535,p=0.510),  time:17.203, tt:189.237\n",
      "Ep:11, loss:0.00003, loss_test:0.15496, lr:1.00e-02, fs:0.53846 (r=0.566,p=0.514),  time:17.238, tt:206.859\n",
      "Ep:12, loss:0.00003, loss_test:0.15363, lr:1.00e-02, fs:0.54545 (r=0.576,p=0.518),  time:17.296, tt:224.846\n",
      "Ep:13, loss:0.00003, loss_test:0.15313, lr:9.90e-03, fs:0.52885 (r=0.556,p=0.505),  time:17.354, tt:242.961\n",
      "Ep:14, loss:0.00003, loss_test:0.15303, lr:9.80e-03, fs:0.52174 (r=0.545,p=0.500),  time:17.413, tt:261.196\n",
      "Ep:15, loss:0.00003, loss_test:0.15313, lr:9.70e-03, fs:0.50980 (r=0.525,p=0.495),  time:17.400, tt:278.401\n",
      "Ep:16, loss:0.00003, loss_test:0.15312, lr:9.61e-03, fs:0.51961 (r=0.535,p=0.505),  time:17.355, tt:295.029\n",
      "Ep:17, loss:0.00003, loss_test:0.15236, lr:9.51e-03, fs:0.53202 (r=0.545,p=0.519),  time:17.333, tt:311.992\n",
      "Ep:18, loss:0.00003, loss_test:0.15144, lr:9.41e-03, fs:0.53202 (r=0.545,p=0.519),  time:17.377, tt:330.163\n",
      "Ep:19, loss:0.00003, loss_test:0.15074, lr:9.32e-03, fs:0.53465 (r=0.545,p=0.524),  time:17.407, tt:348.138\n",
      "Ep:20, loss:0.00003, loss_test:0.15037, lr:9.23e-03, fs:0.53731 (r=0.545,p=0.529),  time:17.383, tt:365.040\n",
      "Ep:21, loss:0.00003, loss_test:0.15037, lr:9.14e-03, fs:0.53731 (r=0.545,p=0.529),  time:17.367, tt:382.070\n",
      "Ep:22, loss:0.00003, loss_test:0.14993, lr:9.04e-03, fs:0.53000 (r=0.535,p=0.525),  time:17.352, tt:399.101\n",
      "Ep:23, loss:0.00003, loss_test:0.14917, lr:8.95e-03, fs:0.53266 (r=0.535,p=0.530),  time:17.279, tt:414.700\n",
      "Ep:24, loss:0.00003, loss_test:0.14855, lr:8.86e-03, fs:0.53535 (r=0.535,p=0.535),  time:17.195, tt:429.867\n",
      "Ep:25, loss:0.00003, loss_test:0.14809, lr:8.78e-03, fs:0.54000 (r=0.545,p=0.535),  time:17.280, tt:449.282\n",
      "Ep:26, loss:0.00002, loss_test:0.14805, lr:8.69e-03, fs:0.54271 (r=0.545,p=0.540),  time:17.264, tt:466.122\n",
      "Ep:27, loss:0.00002, loss_test:0.14820, lr:8.60e-03, fs:0.55838 (r=0.556,p=0.561),  time:17.200, tt:481.610\n",
      "Ep:28, loss:0.00002, loss_test:0.14791, lr:8.51e-03, fs:0.53125 (r=0.515,p=0.548),  time:17.179, tt:498.204\n",
      "Ep:29, loss:0.00002, loss_test:0.14711, lr:8.43e-03, fs:0.53886 (r=0.525,p=0.553),  time:17.153, tt:514.602\n",
      "Ep:30, loss:0.00002, loss_test:0.14596, lr:8.35e-03, fs:0.55102 (r=0.545,p=0.557),  time:17.155, tt:531.805\n",
      "Ep:31, loss:0.00002, loss_test:0.14503, lr:8.26e-03, fs:0.56410 (r=0.556,p=0.573),  time:17.114, tt:547.645\n",
      "Ep:32, loss:0.00002, loss_test:0.14443, lr:8.18e-03, fs:0.56410 (r=0.556,p=0.573),  time:17.051, tt:562.684\n",
      "Ep:33, loss:0.00002, loss_test:0.14426, lr:8.10e-03, fs:0.55208 (r=0.535,p=0.570),  time:17.005, tt:578.183\n",
      "Ep:34, loss:0.00002, loss_test:0.14429, lr:8.02e-03, fs:0.54450 (r=0.525,p=0.565),  time:16.979, tt:594.279\n",
      "Ep:35, loss:0.00002, loss_test:0.14441, lr:7.94e-03, fs:0.53476 (r=0.505,p=0.568),  time:16.966, tt:610.786\n",
      "Ep:36, loss:0.00002, loss_test:0.14428, lr:7.86e-03, fs:0.53476 (r=0.505,p=0.568),  time:16.903, tt:625.426\n",
      "Ep:37, loss:0.00002, loss_test:0.14386, lr:7.78e-03, fs:0.52406 (r=0.495,p=0.557),  time:16.911, tt:642.619\n",
      "Ep:38, loss:0.00002, loss_test:0.14318, lr:7.70e-03, fs:0.49451 (r=0.455,p=0.542),  time:16.902, tt:659.193\n",
      "Ep:39, loss:0.00002, loss_test:0.14236, lr:7.62e-03, fs:0.51087 (r=0.475,p=0.553),  time:16.897, tt:675.884\n",
      "Ep:40, loss:0.00002, loss_test:0.14163, lr:7.55e-03, fs:0.51892 (r=0.485,p=0.558),  time:16.876, tt:691.915\n",
      "Ep:41, loss:0.00002, loss_test:0.14145, lr:7.47e-03, fs:0.52973 (r=0.495,p=0.570),  time:16.829, tt:706.822\n",
      "Ep:42, loss:0.00002, loss_test:0.14164, lr:7.40e-03, fs:0.51366 (r=0.475,p=0.560),  time:16.806, tt:722.645\n",
      "Ep:43, loss:0.00002, loss_test:0.14196, lr:7.32e-03, fs:0.50829 (r=0.465,p=0.561),  time:16.783, tt:738.447\n",
      "Ep:44, loss:0.00002, loss_test:0.14182, lr:7.25e-03, fs:0.50829 (r=0.465,p=0.561),  time:16.767, tt:754.522\n",
      "Ep:45, loss:0.00002, loss_test:0.14126, lr:7.18e-03, fs:0.51111 (r=0.465,p=0.568),  time:16.751, tt:770.549\n",
      "Ep:46, loss:0.00002, loss_test:0.14064, lr:7.11e-03, fs:0.50000 (r=0.455,p=0.556),  time:16.721, tt:785.891\n",
      "Ep:47, loss:0.00002, loss_test:0.14051, lr:7.03e-03, fs:0.50000 (r=0.455,p=0.556),  time:16.703, tt:801.735\n",
      "Ep:48, loss:0.00002, loss_test:0.14086, lr:6.96e-03, fs:0.49162 (r=0.444,p=0.550),  time:16.686, tt:817.596\n",
      "Ep:49, loss:0.00002, loss_test:0.14130, lr:6.89e-03, fs:0.48315 (r=0.434,p=0.544),  time:16.670, tt:833.519\n",
      "Ep:50, loss:0.00002, loss_test:0.14163, lr:6.83e-03, fs:0.48864 (r=0.434,p=0.558),  time:16.681, tt:850.714\n",
      "Ep:51, loss:0.00002, loss_test:0.14160, lr:6.76e-03, fs:0.49718 (r=0.444,p=0.564),  time:16.651, tt:865.857\n",
      "Ep:52, loss:0.00002, loss_test:0.14136, lr:6.69e-03, fs:0.49438 (r=0.444,p=0.557),  time:16.634, tt:881.625\n",
      "Ep:53, loss:0.00002, loss_test:0.14123, lr:6.62e-03, fs:0.49438 (r=0.444,p=0.557),  time:16.644, tt:898.773\n",
      "Ep:54, loss:0.00002, loss_test:0.14121, lr:6.56e-03, fs:0.49438 (r=0.444,p=0.557),  time:16.632, tt:914.772\n",
      "Ep:55, loss:0.00002, loss_test:0.14131, lr:6.49e-03, fs:0.49438 (r=0.444,p=0.557),  time:16.602, tt:929.713\n",
      "Ep:56, loss:0.00002, loss_test:0.14138, lr:6.43e-03, fs:0.49438 (r=0.444,p=0.557),  time:16.627, tt:947.745\n",
      "Ep:57, loss:0.00002, loss_test:0.14143, lr:6.36e-03, fs:0.50000 (r=0.455,p=0.556),  time:16.647, tt:965.509\n",
      "Ep:58, loss:0.00002, loss_test:0.14158, lr:6.30e-03, fs:0.49438 (r=0.444,p=0.557),  time:16.673, tt:983.732\n",
      "Ep:59, loss:0.00002, loss_test:0.14153, lr:6.24e-03, fs:0.50000 (r=0.455,p=0.556),  time:16.696, tt:1001.779\n",
      "Ep:60, loss:0.00002, loss_test:0.14136, lr:6.17e-03, fs:0.50000 (r=0.455,p=0.556),  time:16.693, tt:1018.278\n",
      "Ep:61, loss:0.00002, loss_test:0.14115, lr:6.11e-03, fs:0.50000 (r=0.455,p=0.556),  time:16.708, tt:1035.906\n",
      "Ep:62, loss:0.00002, loss_test:0.14113, lr:6.05e-03, fs:0.49162 (r=0.444,p=0.550),  time:16.726, tt:1053.710\n",
      "Ep:63, loss:0.00002, loss_test:0.14101, lr:5.99e-03, fs:0.50000 (r=0.455,p=0.556),  time:16.733, tt:1070.886\n",
      "Ep:64, loss:0.00002, loss_test:0.14087, lr:5.93e-03, fs:0.49451 (r=0.455,p=0.542),  time:16.752, tt:1088.854\n",
      "Ep:65, loss:0.00002, loss_test:0.14086, lr:5.87e-03, fs:0.49451 (r=0.455,p=0.542),  time:16.748, tt:1105.342\n",
      "Ep:66, loss:0.00002, loss_test:0.14116, lr:5.81e-03, fs:0.49724 (r=0.455,p=0.549),  time:16.744, tt:1121.865\n",
      "Ep:67, loss:0.00001, loss_test:0.14130, lr:5.75e-03, fs:0.48889 (r=0.444,p=0.543),  time:16.759, tt:1139.645\n",
      "Ep:68, loss:0.00001, loss_test:0.14106, lr:5.70e-03, fs:0.49724 (r=0.455,p=0.549),  time:16.766, tt:1156.873\n",
      "Ep:69, loss:0.00001, loss_test:0.14076, lr:5.64e-03, fs:0.49724 (r=0.455,p=0.549),  time:16.794, tt:1175.581\n",
      "Ep:70, loss:0.00001, loss_test:0.14077, lr:5.58e-03, fs:0.49724 (r=0.455,p=0.549),  time:16.805, tt:1193.148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:71, loss:0.00001, loss_test:0.14104, lr:5.53e-03, fs:0.49724 (r=0.455,p=0.549),  time:16.829, tt:1211.703\n",
      "Ep:72, loss:0.00001, loss_test:0.14120, lr:5.47e-03, fs:0.49724 (r=0.455,p=0.549),  time:16.851, tt:1230.097\n",
      "Ep:73, loss:0.00001, loss_test:0.14093, lr:5.42e-03, fs:0.49724 (r=0.455,p=0.549),  time:16.869, tt:1248.286\n",
      "Ep:74, loss:0.00001, loss_test:0.14076, lr:5.36e-03, fs:0.48889 (r=0.444,p=0.543),  time:16.867, tt:1265.036\n",
      "Ep:75, loss:0.00001, loss_test:0.14091, lr:5.31e-03, fs:0.48889 (r=0.444,p=0.543),  time:16.871, tt:1282.204\n",
      "Ep:76, loss:0.00001, loss_test:0.14053, lr:5.26e-03, fs:0.49724 (r=0.455,p=0.549),  time:16.897, tt:1301.061\n",
      "Ep:77, loss:0.00001, loss_test:0.14026, lr:5.20e-03, fs:0.49724 (r=0.455,p=0.549),  time:16.918, tt:1319.595\n",
      "Ep:78, loss:0.00001, loss_test:0.14012, lr:5.15e-03, fs:0.50000 (r=0.455,p=0.556),  time:16.921, tt:1336.746\n",
      "Ep:79, loss:0.00001, loss_test:0.14013, lr:5.10e-03, fs:0.50000 (r=0.455,p=0.556),  time:16.938, tt:1355.037\n",
      "Ep:80, loss:0.00001, loss_test:0.14017, lr:5.05e-03, fs:0.50829 (r=0.465,p=0.561),  time:16.944, tt:1372.480\n",
      "Ep:81, loss:0.00001, loss_test:0.13998, lr:5.00e-03, fs:0.50829 (r=0.465,p=0.561),  time:16.952, tt:1390.030\n",
      "Ep:82, loss:0.00001, loss_test:0.13987, lr:4.95e-03, fs:0.50000 (r=0.455,p=0.556),  time:16.960, tt:1407.722\n",
      "Ep:83, loss:0.00001, loss_test:0.13972, lr:4.90e-03, fs:0.50000 (r=0.455,p=0.556),  time:16.976, tt:1426.000\n",
      "Ep:84, loss:0.00001, loss_test:0.13995, lr:4.85e-03, fs:0.50279 (r=0.455,p=0.562),  time:16.976, tt:1442.935\n",
      "Ep:85, loss:0.00001, loss_test:0.13978, lr:4.80e-03, fs:0.50279 (r=0.455,p=0.562),  time:16.981, tt:1460.360\n",
      "Ep:86, loss:0.00001, loss_test:0.13940, lr:4.75e-03, fs:0.50279 (r=0.455,p=0.562),  time:16.988, tt:1477.928\n",
      "Ep:87, loss:0.00001, loss_test:0.13929, lr:4.71e-03, fs:0.50279 (r=0.455,p=0.562),  time:16.985, tt:1494.693\n",
      "Ep:88, loss:0.00001, loss_test:0.13945, lr:4.66e-03, fs:0.50279 (r=0.455,p=0.562),  time:16.993, tt:1512.353\n",
      "Ep:89, loss:0.00001, loss_test:0.13935, lr:4.61e-03, fs:0.50562 (r=0.455,p=0.570),  time:17.012, tt:1531.073\n",
      "Ep:90, loss:0.00001, loss_test:0.13934, lr:4.57e-03, fs:0.50562 (r=0.455,p=0.570),  time:17.027, tt:1549.482\n",
      "Ep:91, loss:0.00001, loss_test:0.13909, lr:4.52e-03, fs:0.49438 (r=0.444,p=0.557),  time:17.051, tt:1568.732\n",
      "Ep:92, loss:0.00001, loss_test:0.13917, lr:4.48e-03, fs:0.50562 (r=0.455,p=0.570),  time:17.069, tt:1587.416\n",
      "Ep:93, loss:0.00001, loss_test:0.13919, lr:4.43e-03, fs:0.50562 (r=0.455,p=0.570),  time:17.081, tt:1605.588\n",
      "Ep:94, loss:0.00001, loss_test:0.13871, lr:4.39e-03, fs:0.51397 (r=0.465,p=0.575),  time:17.084, tt:1623.003\n",
      "Ep:95, loss:0.00001, loss_test:0.13873, lr:4.34e-03, fs:0.51111 (r=0.465,p=0.568),  time:17.088, tt:1640.422\n",
      "Ep:96, loss:0.00001, loss_test:0.13868, lr:4.30e-03, fs:0.51934 (r=0.475,p=0.573),  time:17.090, tt:1657.778\n",
      "Ep:97, loss:0.00001, loss_test:0.13898, lr:4.26e-03, fs:0.52514 (r=0.475,p=0.588),  time:17.087, tt:1674.570\n",
      "Ep:98, loss:0.00001, loss_test:0.13891, lr:4.21e-03, fs:0.52222 (r=0.475,p=0.580),  time:17.108, tt:1693.705\n",
      "Ep:99, loss:0.00001, loss_test:0.13843, lr:4.17e-03, fs:0.52222 (r=0.475,p=0.580),  time:17.121, tt:1712.069\n",
      "Ep:100, loss:0.00001, loss_test:0.13863, lr:4.13e-03, fs:0.52222 (r=0.475,p=0.580),  time:17.123, tt:1729.412\n",
      "Ep:101, loss:0.00001, loss_test:0.13907, lr:4.09e-03, fs:0.52514 (r=0.475,p=0.588),  time:17.133, tt:1747.527\n",
      "Ep:102, loss:0.00001, loss_test:0.13880, lr:4.05e-03, fs:0.54945 (r=0.505,p=0.602),  time:17.144, tt:1765.782\n",
      "Ep:103, loss:0.00001, loss_test:0.13869, lr:4.01e-03, fs:0.53333 (r=0.485,p=0.593),  time:17.146, tt:1783.209\n",
      "Ep:104, loss:0.00001, loss_test:0.13833, lr:3.97e-03, fs:0.54144 (r=0.495,p=0.598),  time:17.157, tt:1801.500\n",
      "Ep:105, loss:0.00001, loss_test:0.13830, lr:3.93e-03, fs:0.55738 (r=0.515,p=0.607),  time:17.162, tt:1819.167\n",
      "Ep:106, loss:0.00001, loss_test:0.13914, lr:3.89e-03, fs:0.53714 (r=0.475,p=0.618),  time:17.169, tt:1837.131\n",
      "Ep:107, loss:0.00001, loss_test:0.13908, lr:3.85e-03, fs:0.54545 (r=0.485,p=0.623),  time:17.178, tt:1855.189\n",
      "Ep:108, loss:0.00001, loss_test:0.13840, lr:3.81e-03, fs:0.55738 (r=0.515,p=0.607),  time:17.179, tt:1872.520\n",
      "Ep:109, loss:0.00001, loss_test:0.13782, lr:3.77e-03, fs:0.55738 (r=0.515,p=0.607),  time:17.181, tt:1889.950\n",
      "Ep:110, loss:0.00001, loss_test:0.13828, lr:3.73e-03, fs:0.54545 (r=0.485,p=0.623),  time:17.189, tt:1907.945\n",
      "Ep:111, loss:0.00001, loss_test:0.13873, lr:3.70e-03, fs:0.55367 (r=0.495,p=0.628),  time:17.196, tt:1925.905\n",
      "Ep:112, loss:0.00001, loss_test:0.13847, lr:3.66e-03, fs:0.56354 (r=0.515,p=0.622),  time:17.199, tt:1943.456\n",
      "Ep:113, loss:0.00001, loss_test:0.13802, lr:3.62e-03, fs:0.56831 (r=0.525,p=0.619),  time:17.210, tt:1961.926\n",
      "Ep:114, loss:0.00001, loss_test:0.13785, lr:3.59e-03, fs:0.56180 (r=0.505,p=0.633),  time:17.214, tt:1979.568\n",
      "Ep:115, loss:0.00001, loss_test:0.13799, lr:3.55e-03, fs:0.56180 (r=0.505,p=0.633),  time:17.223, tt:1997.914\n",
      "Ep:116, loss:0.00001, loss_test:0.13803, lr:3.52e-03, fs:0.57923 (r=0.535,p=0.631),  time:17.237, tt:2016.749\n",
      "Ep:117, loss:0.00001, loss_test:0.13811, lr:3.48e-03, fs:0.57143 (r=0.525,p=0.627),  time:17.243, tt:2034.632\n",
      "Ep:118, loss:0.00001, loss_test:0.13783, lr:3.45e-03, fs:0.56180 (r=0.505,p=0.633),  time:17.240, tt:2051.604\n",
      "Ep:119, loss:0.00001, loss_test:0.13718, lr:3.41e-03, fs:0.57459 (r=0.525,p=0.634),  time:17.246, tt:2069.520\n",
      "Ep:120, loss:0.00001, loss_test:0.13714, lr:3.38e-03, fs:0.60215 (r=0.566,p=0.644),  time:17.261, tt:2088.575\n",
      "Ep:121, loss:0.00001, loss_test:0.13796, lr:3.34e-03, fs:0.57459 (r=0.525,p=0.634),  time:17.259, tt:2105.542\n",
      "Ep:122, loss:0.00001, loss_test:0.13828, lr:3.31e-03, fs:0.58101 (r=0.525,p=0.650),  time:17.263, tt:2123.310\n",
      "Ep:123, loss:0.00001, loss_test:0.13789, lr:3.28e-03, fs:0.58101 (r=0.525,p=0.650),  time:17.263, tt:2140.585\n",
      "Ep:124, loss:0.00001, loss_test:0.13714, lr:3.24e-03, fs:0.60963 (r=0.576,p=0.648),  time:17.253, tt:2156.675\n",
      "Ep:125, loss:0.00001, loss_test:0.13686, lr:3.21e-03, fs:0.60963 (r=0.576,p=0.648),  time:17.259, tt:2174.627\n",
      "Ep:126, loss:0.00001, loss_test:0.13730, lr:3.18e-03, fs:0.60870 (r=0.566,p=0.659),  time:17.265, tt:2192.681\n",
      "Ep:127, loss:0.00001, loss_test:0.13765, lr:3.15e-03, fs:0.60870 (r=0.566,p=0.659),  time:17.269, tt:2210.407\n",
      "Ep:128, loss:0.00001, loss_test:0.13753, lr:3.12e-03, fs:0.60638 (r=0.576,p=0.640),  time:17.280, tt:2229.178\n",
      "Ep:129, loss:0.00001, loss_test:0.13708, lr:3.09e-03, fs:0.60638 (r=0.576,p=0.640),  time:17.292, tt:2248.001\n",
      "Ep:130, loss:0.00001, loss_test:0.13676, lr:3.05e-03, fs:0.61622 (r=0.576,p=0.663),  time:17.306, tt:2267.096\n",
      "Ep:131, loss:0.00001, loss_test:0.13677, lr:3.02e-03, fs:0.61622 (r=0.576,p=0.663),  time:17.315, tt:2285.551\n",
      "Ep:132, loss:0.00001, loss_test:0.13683, lr:2.99e-03, fs:0.61376 (r=0.586,p=0.644),  time:17.329, tt:2304.769\n",
      "Ep:133, loss:0.00001, loss_test:0.13711, lr:2.96e-03, fs:0.61622 (r=0.576,p=0.663),  time:17.337, tt:2323.100\n",
      "Ep:134, loss:0.00001, loss_test:0.13679, lr:2.93e-03, fs:0.61622 (r=0.576,p=0.663),  time:17.346, tt:2341.743\n",
      "Ep:135, loss:0.00001, loss_test:0.13641, lr:2.90e-03, fs:0.61376 (r=0.586,p=0.644),  time:17.359, tt:2360.778\n",
      "Ep:136, loss:0.00001, loss_test:0.13668, lr:2.88e-03, fs:0.61290 (r=0.576,p=0.655),  time:17.365, tt:2379.049\n",
      "Ep:137, loss:0.00001, loss_test:0.13676, lr:2.85e-03, fs:0.61622 (r=0.576,p=0.663),  time:17.377, tt:2398.064\n",
      "Ep:138, loss:0.00001, loss_test:0.13645, lr:2.82e-03, fs:0.61702 (r=0.586,p=0.652),  time:17.394, tt:2417.739\n",
      "Ep:139, loss:0.00001, loss_test:0.13626, lr:2.79e-03, fs:0.62366 (r=0.586,p=0.667),  time:17.401, tt:2436.206\n",
      "Ep:140, loss:0.00001, loss_test:0.13645, lr:2.76e-03, fs:0.61622 (r=0.576,p=0.663),  time:17.402, tt:2453.646\n",
      "Ep:141, loss:0.00001, loss_test:0.13640, lr:2.73e-03, fs:0.61622 (r=0.576,p=0.663),  time:17.409, tt:2472.045\n",
      "Ep:142, loss:0.00001, loss_test:0.13607, lr:2.71e-03, fs:0.61702 (r=0.586,p=0.652),  time:17.419, tt:2490.918\n",
      "Ep:143, loss:0.00001, loss_test:0.13620, lr:2.68e-03, fs:0.61957 (r=0.576,p=0.671),  time:17.429, tt:2509.738\n",
      "Ep:144, loss:0.00001, loss_test:0.13630, lr:2.65e-03, fs:0.61622 (r=0.576,p=0.663),  time:17.438, tt:2528.501\n",
      "Ep:145, loss:0.00001, loss_test:0.13606, lr:2.63e-03, fs:0.62105 (r=0.596,p=0.648),  time:17.449, tt:2547.589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:146, loss:0.00001, loss_test:0.13643, lr:2.60e-03, fs:0.61957 (r=0.576,p=0.671),  time:17.456, tt:2565.960\n",
      "Ep:147, loss:0.00001, loss_test:0.13639, lr:2.57e-03, fs:0.61957 (r=0.576,p=0.671),  time:17.471, tt:2585.753\n",
      "Ep:148, loss:0.00001, loss_test:0.13600, lr:2.55e-03, fs:0.61376 (r=0.586,p=0.644),  time:17.482, tt:2604.835\n",
      "Ep:149, loss:0.00001, loss_test:0.13572, lr:2.52e-03, fs:0.62105 (r=0.596,p=0.648),  time:17.496, tt:2624.333\n",
      "Ep:150, loss:0.00001, loss_test:0.13593, lr:2.50e-03, fs:0.62703 (r=0.586,p=0.674),  time:17.509, tt:2643.820\n",
      "##########Best model found so far##########\n",
      "Ep:151, loss:0.00001, loss_test:0.13593, lr:2.50e-03, fs:0.62703 (r=0.586,p=0.674),  time:17.519, tt:2662.918\n",
      "Ep:152, loss:0.00001, loss_test:0.13548, lr:2.50e-03, fs:0.62766 (r=0.596,p=0.663),  time:17.528, tt:2681.725\n",
      "##########Best model found so far##########\n",
      "Ep:153, loss:0.00001, loss_test:0.13553, lr:2.50e-03, fs:0.63492 (r=0.606,p=0.667),  time:17.544, tt:2701.799\n",
      "##########Best model found so far##########\n",
      "Ep:154, loss:0.00001, loss_test:0.13591, lr:2.50e-03, fs:0.62703 (r=0.586,p=0.674),  time:17.559, tt:2721.607\n",
      "Ep:155, loss:0.00001, loss_test:0.13590, lr:2.50e-03, fs:0.62703 (r=0.586,p=0.674),  time:17.564, tt:2739.978\n",
      "Ep:156, loss:0.00001, loss_test:0.13549, lr:2.50e-03, fs:0.62434 (r=0.596,p=0.656),  time:17.576, tt:2759.388\n",
      "Ep:157, loss:0.00001, loss_test:0.13549, lr:2.50e-03, fs:0.62766 (r=0.596,p=0.663),  time:17.583, tt:2778.151\n",
      "Ep:158, loss:0.00001, loss_test:0.13558, lr:2.50e-03, fs:0.62366 (r=0.586,p=0.667),  time:17.589, tt:2796.710\n",
      "Ep:159, loss:0.00001, loss_test:0.13543, lr:2.50e-03, fs:0.63102 (r=0.596,p=0.670),  time:17.598, tt:2815.606\n",
      "Ep:160, loss:0.00001, loss_test:0.13534, lr:2.50e-03, fs:0.62766 (r=0.596,p=0.663),  time:17.607, tt:2834.720\n",
      "Ep:161, loss:0.00001, loss_test:0.13538, lr:2.50e-03, fs:0.63441 (r=0.596,p=0.678),  time:17.619, tt:2854.340\n",
      "Ep:162, loss:0.00001, loss_test:0.13522, lr:2.50e-03, fs:0.63441 (r=0.596,p=0.678),  time:17.629, tt:2873.575\n",
      "Ep:163, loss:0.00001, loss_test:0.13498, lr:2.50e-03, fs:0.63830 (r=0.606,p=0.674),  time:17.645, tt:2893.792\n",
      "##########Best model found so far##########\n",
      "Ep:164, loss:0.00001, loss_test:0.13538, lr:2.50e-03, fs:0.63441 (r=0.596,p=0.678),  time:17.657, tt:2913.431\n",
      "Ep:165, loss:0.00001, loss_test:0.13531, lr:2.50e-03, fs:0.64171 (r=0.606,p=0.682),  time:17.664, tt:2932.165\n",
      "##########Best model found so far##########\n",
      "Ep:166, loss:0.00001, loss_test:0.13488, lr:2.50e-03, fs:0.64550 (r=0.616,p=0.678),  time:17.675, tt:2951.681\n",
      "##########Best model found so far##########\n",
      "Ep:167, loss:0.00001, loss_test:0.13507, lr:2.50e-03, fs:0.64171 (r=0.606,p=0.682),  time:17.687, tt:2971.446\n",
      "Ep:168, loss:0.00001, loss_test:0.13534, lr:2.50e-03, fs:0.64550 (r=0.616,p=0.678),  time:17.700, tt:2991.337\n",
      "Ep:169, loss:0.00001, loss_test:0.13509, lr:2.50e-03, fs:0.64921 (r=0.626,p=0.674),  time:17.718, tt:3012.028\n",
      "##########Best model found so far##########\n",
      "Ep:170, loss:0.00001, loss_test:0.13484, lr:2.50e-03, fs:0.64550 (r=0.616,p=0.678),  time:17.726, tt:3031.185\n",
      "Ep:171, loss:0.00001, loss_test:0.13449, lr:2.50e-03, fs:0.65263 (r=0.626,p=0.681),  time:17.737, tt:3050.848\n",
      "##########Best model found so far##########\n",
      "Ep:172, loss:0.00001, loss_test:0.13473, lr:2.50e-03, fs:0.64921 (r=0.626,p=0.674),  time:17.741, tt:3069.268\n",
      "Ep:173, loss:0.00001, loss_test:0.13519, lr:2.50e-03, fs:0.65263 (r=0.626,p=0.681),  time:17.755, tt:3089.419\n",
      "Ep:174, loss:0.00001, loss_test:0.13506, lr:2.50e-03, fs:0.65608 (r=0.626,p=0.689),  time:17.766, tt:3109.079\n",
      "##########Best model found so far##########\n",
      "Ep:175, loss:0.00001, loss_test:0.13455, lr:2.50e-03, fs:0.65263 (r=0.626,p=0.681),  time:17.774, tt:3128.201\n",
      "Ep:176, loss:0.00001, loss_test:0.13432, lr:2.50e-03, fs:0.64921 (r=0.626,p=0.674),  time:17.785, tt:3148.012\n",
      "Ep:177, loss:0.00001, loss_test:0.13479, lr:2.50e-03, fs:0.65608 (r=0.626,p=0.689),  time:17.796, tt:3167.721\n",
      "Ep:178, loss:0.00001, loss_test:0.13485, lr:2.50e-03, fs:0.65608 (r=0.626,p=0.689),  time:17.804, tt:3186.887\n",
      "Ep:179, loss:0.00001, loss_test:0.13436, lr:2.50e-03, fs:0.64921 (r=0.626,p=0.674),  time:17.812, tt:3206.178\n",
      "Ep:180, loss:0.00001, loss_test:0.13410, lr:2.50e-03, fs:0.64921 (r=0.626,p=0.674),  time:17.821, tt:3225.606\n",
      "Ep:181, loss:0.00001, loss_test:0.13454, lr:2.50e-03, fs:0.65263 (r=0.626,p=0.681),  time:17.828, tt:3244.662\n",
      "Ep:182, loss:0.00001, loss_test:0.13475, lr:2.50e-03, fs:0.65263 (r=0.626,p=0.681),  time:17.836, tt:3264.008\n",
      "Ep:183, loss:0.00001, loss_test:0.13445, lr:2.50e-03, fs:0.64921 (r=0.626,p=0.674),  time:17.844, tt:3283.296\n",
      "Ep:184, loss:0.00001, loss_test:0.13399, lr:2.50e-03, fs:0.64921 (r=0.626,p=0.674),  time:17.852, tt:3302.613\n",
      "Ep:185, loss:0.00001, loss_test:0.13411, lr:2.50e-03, fs:0.64921 (r=0.626,p=0.674),  time:17.866, tt:3323.027\n",
      "Ep:186, loss:0.00001, loss_test:0.13444, lr:2.47e-03, fs:0.65957 (r=0.626,p=0.697),  time:17.877, tt:3343.076\n",
      "##########Best model found so far##########\n",
      "Ep:187, loss:0.00001, loss_test:0.13426, lr:2.47e-03, fs:0.65957 (r=0.626,p=0.697),  time:17.885, tt:3362.430\n",
      "Ep:188, loss:0.00001, loss_test:0.13393, lr:2.47e-03, fs:0.65263 (r=0.626,p=0.681),  time:17.892, tt:3381.564\n",
      "Ep:189, loss:0.00001, loss_test:0.13409, lr:2.47e-03, fs:0.64921 (r=0.626,p=0.674),  time:17.902, tt:3401.371\n",
      "Ep:190, loss:0.00001, loss_test:0.13421, lr:2.47e-03, fs:0.65957 (r=0.626,p=0.697),  time:17.906, tt:3420.046\n",
      "Ep:191, loss:0.00001, loss_test:0.13404, lr:2.47e-03, fs:0.65608 (r=0.626,p=0.689),  time:17.915, tt:3439.705\n",
      "Ep:192, loss:0.00001, loss_test:0.13369, lr:2.47e-03, fs:0.64583 (r=0.626,p=0.667),  time:17.928, tt:3460.082\n",
      "Ep:193, loss:0.00001, loss_test:0.13399, lr:2.47e-03, fs:0.65957 (r=0.626,p=0.697),  time:17.941, tt:3480.552\n",
      "Ep:194, loss:0.00001, loss_test:0.13420, lr:2.47e-03, fs:0.65957 (r=0.626,p=0.697),  time:17.948, tt:3499.844\n",
      "Ep:195, loss:0.00001, loss_test:0.13382, lr:2.47e-03, fs:0.65263 (r=0.626,p=0.681),  time:17.955, tt:3519.179\n",
      "Ep:196, loss:0.00001, loss_test:0.13350, lr:2.47e-03, fs:0.65263 (r=0.626,p=0.681),  time:17.962, tt:3538.547\n",
      "Ep:197, loss:0.00001, loss_test:0.13375, lr:2.47e-03, fs:0.65957 (r=0.626,p=0.697),  time:17.972, tt:3558.498\n",
      "Ep:198, loss:0.00001, loss_test:0.13420, lr:2.45e-03, fs:0.65957 (r=0.626,p=0.697),  time:17.976, tt:3577.320\n",
      "Ep:199, loss:0.00001, loss_test:0.13393, lr:2.42e-03, fs:0.65263 (r=0.626,p=0.681),  time:17.983, tt:3596.524\n",
      "Ep:200, loss:0.00001, loss_test:0.13324, lr:2.40e-03, fs:0.65263 (r=0.626,p=0.681),  time:17.988, tt:3615.523\n",
      "Ep:201, loss:0.00001, loss_test:0.13350, lr:2.38e-03, fs:0.65263 (r=0.626,p=0.681),  time:17.986, tt:3633.206\n",
      "Ep:202, loss:0.00001, loss_test:0.13382, lr:2.35e-03, fs:0.65608 (r=0.626,p=0.689),  time:17.988, tt:3651.549\n",
      "Ep:203, loss:0.00001, loss_test:0.13361, lr:2.33e-03, fs:0.65263 (r=0.626,p=0.681),  time:17.991, tt:3670.071\n",
      "Ep:204, loss:0.00001, loss_test:0.13337, lr:2.31e-03, fs:0.65608 (r=0.626,p=0.689),  time:17.990, tt:3688.006\n",
      "Ep:205, loss:0.00001, loss_test:0.13336, lr:2.28e-03, fs:0.65608 (r=0.626,p=0.689),  time:17.990, tt:3705.850\n",
      "Ep:206, loss:0.00001, loss_test:0.13334, lr:2.26e-03, fs:0.65263 (r=0.626,p=0.681),  time:17.992, tt:3724.421\n",
      "Ep:207, loss:0.00001, loss_test:0.13352, lr:2.24e-03, fs:0.65608 (r=0.626,p=0.689),  time:17.994, tt:3742.737\n",
      "Ep:208, loss:0.00001, loss_test:0.13338, lr:2.21e-03, fs:0.65608 (r=0.626,p=0.689),  time:17.999, tt:3761.856\n",
      "Ep:209, loss:0.00001, loss_test:0.13314, lr:2.19e-03, fs:0.65608 (r=0.626,p=0.689),  time:18.003, tt:3780.603\n",
      "Ep:210, loss:0.00001, loss_test:0.13321, lr:2.17e-03, fs:0.65608 (r=0.626,p=0.689),  time:18.001, tt:3798.252\n",
      "Ep:211, loss:0.00001, loss_test:0.13338, lr:2.15e-03, fs:0.65608 (r=0.626,p=0.689),  time:18.003, tt:3816.735\n",
      "Ep:212, loss:0.00001, loss_test:0.13333, lr:2.13e-03, fs:0.65608 (r=0.626,p=0.689),  time:18.005, tt:3835.095\n",
      "Ep:213, loss:0.00001, loss_test:0.13321, lr:2.11e-03, fs:0.65608 (r=0.626,p=0.689),  time:18.009, tt:3853.818\n",
      "Ep:214, loss:0.00001, loss_test:0.13330, lr:2.08e-03, fs:0.65608 (r=0.626,p=0.689),  time:18.013, tt:3872.821\n",
      "Ep:215, loss:0.00001, loss_test:0.13318, lr:2.06e-03, fs:0.65957 (r=0.626,p=0.697),  time:18.014, tt:3890.991\n",
      "Ep:216, loss:0.00001, loss_test:0.13309, lr:2.04e-03, fs:0.65608 (r=0.626,p=0.689),  time:18.012, tt:3908.586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:217, loss:0.00001, loss_test:0.13322, lr:2.02e-03, fs:0.65608 (r=0.626,p=0.689),  time:18.009, tt:3926.041\n",
      "Ep:218, loss:0.00001, loss_test:0.13306, lr:2.00e-03, fs:0.65608 (r=0.626,p=0.689),  time:18.006, tt:3943.412\n",
      "Ep:219, loss:0.00001, loss_test:0.13307, lr:1.98e-03, fs:0.65608 (r=0.626,p=0.689),  time:18.009, tt:3962.066\n",
      "Ep:220, loss:0.00001, loss_test:0.13313, lr:1.96e-03, fs:0.65957 (r=0.626,p=0.697),  time:18.009, tt:3980.084\n",
      "Ep:221, loss:0.00001, loss_test:0.13319, lr:1.94e-03, fs:0.65957 (r=0.626,p=0.697),  time:18.016, tt:3999.451\n",
      "Ep:222, loss:0.00001, loss_test:0.13308, lr:1.92e-03, fs:0.65608 (r=0.626,p=0.689),  time:18.018, tt:4017.950\n",
      "Ep:223, loss:0.00001, loss_test:0.13316, lr:1.90e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.023, tt:4037.068\n",
      "##########Best model found so far##########\n",
      "Ep:224, loss:0.00001, loss_test:0.13293, lr:1.90e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.018, tt:4054.150\n",
      "Ep:225, loss:0.00001, loss_test:0.13288, lr:1.90e-03, fs:0.65957 (r=0.626,p=0.697),  time:18.016, tt:4071.546\n",
      "Ep:226, loss:0.00001, loss_test:0.13296, lr:1.90e-03, fs:0.65957 (r=0.626,p=0.697),  time:18.018, tt:4090.146\n",
      "Ep:227, loss:0.00001, loss_test:0.13304, lr:1.90e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.022, tt:4108.959\n",
      "Ep:228, loss:0.00001, loss_test:0.13309, lr:1.90e-03, fs:0.66667 (r=0.626,p=0.713),  time:18.023, tt:4127.174\n",
      "##########Best model found so far##########\n",
      "Ep:229, loss:0.00001, loss_test:0.13312, lr:1.90e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.024, tt:4145.467\n",
      "Ep:230, loss:0.00001, loss_test:0.13296, lr:1.90e-03, fs:0.65957 (r=0.626,p=0.697),  time:18.027, tt:4164.283\n",
      "Ep:231, loss:0.00001, loss_test:0.13309, lr:1.90e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.031, tt:4183.131\n",
      "Ep:232, loss:0.00001, loss_test:0.13300, lr:1.90e-03, fs:0.66667 (r=0.626,p=0.713),  time:18.027, tt:4200.334\n",
      "Ep:233, loss:0.00001, loss_test:0.13296, lr:1.90e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.030, tt:4219.014\n",
      "Ep:234, loss:0.00001, loss_test:0.13297, lr:1.90e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.033, tt:4237.817\n",
      "Ep:235, loss:0.00001, loss_test:0.13280, lr:1.90e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.041, tt:4257.572\n",
      "Ep:236, loss:0.00001, loss_test:0.13272, lr:1.90e-03, fs:0.66667 (r=0.626,p=0.713),  time:18.041, tt:4275.811\n",
      "Ep:237, loss:0.00001, loss_test:0.13287, lr:1.90e-03, fs:0.66667 (r=0.626,p=0.713),  time:18.042, tt:4293.998\n",
      "Ep:238, loss:0.00001, loss_test:0.13315, lr:1.90e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.043, tt:4312.383\n",
      "Ep:239, loss:0.00001, loss_test:0.13289, lr:1.90e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.048, tt:4331.514\n",
      "Ep:240, loss:0.00001, loss_test:0.13242, lr:1.89e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.053, tt:4350.865\n",
      "Ep:241, loss:0.00001, loss_test:0.13252, lr:1.87e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.056, tt:4369.495\n",
      "Ep:242, loss:0.00001, loss_test:0.13290, lr:1.85e-03, fs:0.66667 (r=0.626,p=0.713),  time:18.057, tt:4387.822\n",
      "Ep:243, loss:0.00001, loss_test:0.13301, lr:1.83e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.057, tt:4405.986\n",
      "Ep:244, loss:0.00001, loss_test:0.13282, lr:1.81e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.060, tt:4424.678\n",
      "Ep:245, loss:0.00001, loss_test:0.13255, lr:1.79e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.064, tt:4443.805\n",
      "Ep:246, loss:0.00001, loss_test:0.13233, lr:1.78e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.062, tt:4461.342\n",
      "Ep:247, loss:0.00001, loss_test:0.13233, lr:1.76e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.065, tt:4480.173\n",
      "Ep:248, loss:0.00001, loss_test:0.13248, lr:1.74e-03, fs:0.65957 (r=0.626,p=0.697),  time:18.067, tt:4498.713\n",
      "Ep:249, loss:0.00001, loss_test:0.13248, lr:1.72e-03, fs:0.65957 (r=0.626,p=0.697),  time:18.069, tt:4517.331\n",
      "Ep:250, loss:0.00001, loss_test:0.13249, lr:1.71e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.070, tt:4535.626\n",
      "Ep:251, loss:0.00001, loss_test:0.13249, lr:1.69e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.071, tt:4553.950\n",
      "Ep:252, loss:0.00001, loss_test:0.13243, lr:1.67e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.074, tt:4572.801\n",
      "Ep:253, loss:0.00001, loss_test:0.13253, lr:1.65e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.073, tt:4590.528\n",
      "Ep:254, loss:0.00001, loss_test:0.13253, lr:1.64e-03, fs:0.66667 (r=0.626,p=0.713),  time:18.072, tt:4608.466\n",
      "Ep:255, loss:0.00001, loss_test:0.13256, lr:1.62e-03, fs:0.66667 (r=0.626,p=0.713),  time:18.075, tt:4627.165\n",
      "Ep:256, loss:0.00001, loss_test:0.13261, lr:1.61e-03, fs:0.66667 (r=0.626,p=0.713),  time:18.076, tt:4645.457\n",
      "Ep:257, loss:0.00001, loss_test:0.13230, lr:1.59e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.073, tt:4662.727\n",
      "Ep:258, loss:0.00001, loss_test:0.13225, lr:1.57e-03, fs:0.66667 (r=0.626,p=0.713),  time:18.074, tt:4681.167\n",
      "Ep:259, loss:0.00001, loss_test:0.13246, lr:1.56e-03, fs:0.65957 (r=0.626,p=0.697),  time:18.074, tt:4699.229\n",
      "Ep:260, loss:0.00001, loss_test:0.13248, lr:1.54e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.075, tt:4717.684\n",
      "Ep:261, loss:0.00001, loss_test:0.13232, lr:1.53e-03, fs:0.66667 (r=0.626,p=0.713),  time:18.079, tt:4736.666\n",
      "Ep:262, loss:0.00001, loss_test:0.13240, lr:1.51e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.081, tt:4755.330\n",
      "Ep:263, loss:0.00001, loss_test:0.13252, lr:1.50e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.081, tt:4773.389\n",
      "Ep:264, loss:0.00001, loss_test:0.13246, lr:1.48e-03, fs:0.66667 (r=0.626,p=0.713),  time:18.080, tt:4791.325\n",
      "Ep:265, loss:0.00001, loss_test:0.13263, lr:1.47e-03, fs:0.66667 (r=0.626,p=0.713),  time:18.079, tt:4809.122\n",
      "Ep:266, loss:0.00001, loss_test:0.13264, lr:1.45e-03, fs:0.66667 (r=0.626,p=0.713),  time:18.080, tt:4827.442\n",
      "Ep:267, loss:0.00001, loss_test:0.13241, lr:1.44e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.081, tt:4845.815\n",
      "Ep:268, loss:0.00001, loss_test:0.13244, lr:1.42e-03, fs:0.66667 (r=0.626,p=0.713),  time:18.079, tt:4863.358\n",
      "Ep:269, loss:0.00001, loss_test:0.13252, lr:1.41e-03, fs:0.66667 (r=0.626,p=0.713),  time:18.078, tt:4881.061\n",
      "Ep:270, loss:0.00001, loss_test:0.13247, lr:1.39e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.073, tt:4897.808\n",
      "Ep:271, loss:0.00001, loss_test:0.13250, lr:1.38e-03, fs:0.66667 (r=0.626,p=0.713),  time:18.072, tt:4915.655\n",
      "Ep:272, loss:0.00001, loss_test:0.13256, lr:1.37e-03, fs:0.67027 (r=0.626,p=0.721),  time:18.076, tt:4934.718\n",
      "##########Best model found so far##########\n",
      "Ep:273, loss:0.00001, loss_test:0.13254, lr:1.37e-03, fs:0.67027 (r=0.626,p=0.721),  time:18.076, tt:4952.931\n",
      "Ep:274, loss:0.00001, loss_test:0.13238, lr:1.37e-03, fs:0.66667 (r=0.626,p=0.713),  time:18.087, tt:4973.832\n",
      "Ep:275, loss:0.00001, loss_test:0.13236, lr:1.37e-03, fs:0.67027 (r=0.626,p=0.721),  time:18.087, tt:4991.964\n",
      "Ep:276, loss:0.00001, loss_test:0.13254, lr:1.37e-03, fs:0.67027 (r=0.626,p=0.721),  time:18.094, tt:5011.911\n",
      "Ep:277, loss:0.00001, loss_test:0.13255, lr:1.37e-03, fs:0.67027 (r=0.626,p=0.721),  time:18.093, tt:5029.994\n",
      "Ep:278, loss:0.00001, loss_test:0.13229, lr:1.37e-03, fs:0.67027 (r=0.626,p=0.721),  time:18.095, tt:5048.537\n",
      "Ep:279, loss:0.00001, loss_test:0.13234, lr:1.37e-03, fs:0.67027 (r=0.626,p=0.721),  time:18.099, tt:5067.659\n",
      "Ep:280, loss:0.00001, loss_test:0.13260, lr:1.37e-03, fs:0.67027 (r=0.626,p=0.721),  time:18.102, tt:5086.598\n",
      "Ep:281, loss:0.00001, loss_test:0.13244, lr:1.37e-03, fs:0.67027 (r=0.626,p=0.721),  time:18.100, tt:5104.204\n",
      "Ep:282, loss:0.00001, loss_test:0.13218, lr:1.37e-03, fs:0.67027 (r=0.626,p=0.721),  time:18.099, tt:5122.139\n",
      "Ep:283, loss:0.00001, loss_test:0.13236, lr:1.37e-03, fs:0.67027 (r=0.626,p=0.721),  time:18.098, tt:5139.922\n",
      "Ep:284, loss:0.00001, loss_test:0.13266, lr:1.35e-03, fs:0.66667 (r=0.616,p=0.726),  time:18.098, tt:5157.980\n",
      "Ep:285, loss:0.00001, loss_test:0.13248, lr:1.34e-03, fs:0.66667 (r=0.616,p=0.726),  time:18.100, tt:5176.703\n",
      "Ep:286, loss:0.00001, loss_test:0.13209, lr:1.33e-03, fs:0.67027 (r=0.626,p=0.721),  time:18.105, tt:5196.114\n",
      "Ep:287, loss:0.00001, loss_test:0.13217, lr:1.31e-03, fs:0.67391 (r=0.626,p=0.729),  time:18.106, tt:5214.401\n",
      "##########Best model found so far##########\n",
      "Ep:288, loss:0.00001, loss_test:0.13244, lr:1.31e-03, fs:0.66667 (r=0.616,p=0.726),  time:18.109, tt:5233.436\n",
      "Ep:289, loss:0.00001, loss_test:0.13259, lr:1.31e-03, fs:0.66667 (r=0.616,p=0.726),  time:18.112, tt:5252.467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:290, loss:0.00001, loss_test:0.13227, lr:1.31e-03, fs:0.66667 (r=0.616,p=0.726),  time:18.114, tt:5271.078\n",
      "Ep:291, loss:0.00001, loss_test:0.13195, lr:1.31e-03, fs:0.67027 (r=0.626,p=0.721),  time:18.117, tt:5290.113\n",
      "Ep:292, loss:0.00001, loss_test:0.13201, lr:1.31e-03, fs:0.67391 (r=0.626,p=0.729),  time:18.118, tt:5308.711\n",
      "Ep:293, loss:0.00001, loss_test:0.13237, lr:1.31e-03, fs:0.66667 (r=0.616,p=0.726),  time:18.116, tt:5326.046\n",
      "Ep:294, loss:0.00001, loss_test:0.13243, lr:1.31e-03, fs:0.66667 (r=0.616,p=0.726),  time:18.112, tt:5343.089\n",
      "Ep:295, loss:0.00001, loss_test:0.13224, lr:1.31e-03, fs:0.66667 (r=0.616,p=0.726),  time:18.107, tt:5359.794\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,1,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.11667, lr:1.00e-02, fs:0.70400 (r=0.889,p=0.583),  time:10.797, tt:10.797\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.11636, lr:1.00e-02, fs:0.70120 (r=0.889,p=0.579),  time:12.666, tt:25.333\n",
      "Ep:2, loss:0.00004, loss_test:0.11596, lr:1.00e-02, fs:0.70400 (r=0.889,p=0.583),  time:14.728, tt:44.185\n",
      "Ep:3, loss:0.00004, loss_test:0.11555, lr:1.00e-02, fs:0.70161 (r=0.879,p=0.584),  time:15.672, tt:62.688\n",
      "Ep:4, loss:0.00004, loss_test:0.11524, lr:1.00e-02, fs:0.69355 (r=0.869,p=0.577),  time:16.112, tt:80.558\n",
      "Ep:5, loss:0.00004, loss_test:0.11493, lr:1.00e-02, fs:0.69636 (r=0.869,p=0.581),  time:16.324, tt:97.945\n",
      "Ep:6, loss:0.00004, loss_test:0.11461, lr:1.00e-02, fs:0.69919 (r=0.869,p=0.585),  time:16.557, tt:115.899\n",
      "Ep:7, loss:0.00004, loss_test:0.11436, lr:1.00e-02, fs:0.70204 (r=0.869,p=0.589),  time:16.747, tt:133.980\n",
      "Ep:8, loss:0.00004, loss_test:0.11407, lr:1.00e-02, fs:0.70492 (r=0.869,p=0.593),  time:16.949, tt:152.540\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.11375, lr:1.00e-02, fs:0.70492 (r=0.869,p=0.593),  time:17.083, tt:170.833\n",
      "Ep:10, loss:0.00004, loss_test:0.11339, lr:1.00e-02, fs:0.70492 (r=0.869,p=0.593),  time:17.207, tt:189.281\n",
      "Ep:11, loss:0.00004, loss_test:0.11303, lr:1.00e-02, fs:0.70782 (r=0.869,p=0.597),  time:17.294, tt:207.534\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.11269, lr:1.00e-02, fs:0.71074 (r=0.869,p=0.601),  time:17.397, tt:226.162\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.11235, lr:1.00e-02, fs:0.70833 (r=0.859,p=0.603),  time:17.387, tt:243.424\n",
      "Ep:14, loss:0.00004, loss_test:0.11203, lr:1.00e-02, fs:0.70833 (r=0.859,p=0.603),  time:17.419, tt:261.282\n",
      "Ep:15, loss:0.00004, loss_test:0.11167, lr:1.00e-02, fs:0.70833 (r=0.859,p=0.603),  time:17.483, tt:279.723\n",
      "Ep:16, loss:0.00004, loss_test:0.11127, lr:1.00e-02, fs:0.70833 (r=0.859,p=0.603),  time:17.554, tt:298.425\n",
      "Ep:17, loss:0.00004, loss_test:0.11083, lr:1.00e-02, fs:0.71369 (r=0.869,p=0.606),  time:17.657, tt:317.827\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.11035, lr:1.00e-02, fs:0.71369 (r=0.869,p=0.606),  time:17.722, tt:336.726\n",
      "Ep:19, loss:0.00004, loss_test:0.10988, lr:1.00e-02, fs:0.71369 (r=0.869,p=0.606),  time:17.805, tt:356.095\n",
      "Ep:20, loss:0.00004, loss_test:0.10943, lr:1.00e-02, fs:0.71369 (r=0.869,p=0.606),  time:17.865, tt:375.167\n",
      "Ep:21, loss:0.00004, loss_test:0.10904, lr:1.00e-02, fs:0.71369 (r=0.869,p=0.606),  time:17.882, tt:393.410\n",
      "Ep:22, loss:0.00004, loss_test:0.10872, lr:1.00e-02, fs:0.71901 (r=0.879,p=0.608),  time:17.915, tt:412.041\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00004, loss_test:0.10842, lr:1.00e-02, fs:0.71901 (r=0.879,p=0.608),  time:17.996, tt:431.900\n",
      "Ep:24, loss:0.00004, loss_test:0.10814, lr:1.00e-02, fs:0.71901 (r=0.879,p=0.608),  time:18.030, tt:450.759\n",
      "Ep:25, loss:0.00004, loss_test:0.10782, lr:1.00e-02, fs:0.71901 (r=0.879,p=0.608),  time:18.056, tt:469.469\n",
      "Ep:26, loss:0.00004, loss_test:0.10742, lr:1.00e-02, fs:0.71605 (r=0.879,p=0.604),  time:18.077, tt:488.083\n",
      "Ep:27, loss:0.00004, loss_test:0.10693, lr:1.00e-02, fs:0.71605 (r=0.879,p=0.604),  time:18.101, tt:506.824\n",
      "Ep:28, loss:0.00004, loss_test:0.10640, lr:1.00e-02, fs:0.71901 (r=0.879,p=0.608),  time:18.168, tt:526.879\n",
      "Ep:29, loss:0.00003, loss_test:0.10584, lr:1.00e-02, fs:0.72199 (r=0.879,p=0.613),  time:18.204, tt:546.109\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.10526, lr:1.00e-02, fs:0.72500 (r=0.879,p=0.617),  time:18.262, tt:566.110\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.10473, lr:1.00e-02, fs:0.73418 (r=0.879,p=0.630),  time:18.289, tt:585.249\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.10421, lr:1.00e-02, fs:0.73418 (r=0.879,p=0.630),  time:18.301, tt:603.939\n",
      "Ep:33, loss:0.00003, loss_test:0.10368, lr:1.00e-02, fs:0.73109 (r=0.879,p=0.626),  time:18.302, tt:622.273\n",
      "Ep:34, loss:0.00003, loss_test:0.10314, lr:1.00e-02, fs:0.73109 (r=0.879,p=0.626),  time:18.294, tt:640.303\n",
      "Ep:35, loss:0.00003, loss_test:0.10257, lr:1.00e-02, fs:0.73109 (r=0.879,p=0.626),  time:18.313, tt:659.281\n",
      "Ep:36, loss:0.00003, loss_test:0.10199, lr:1.00e-02, fs:0.73109 (r=0.879,p=0.626),  time:18.299, tt:677.048\n",
      "Ep:37, loss:0.00003, loss_test:0.10135, lr:1.00e-02, fs:0.73109 (r=0.879,p=0.626),  time:18.310, tt:695.780\n",
      "Ep:38, loss:0.00003, loss_test:0.10066, lr:1.00e-02, fs:0.73109 (r=0.879,p=0.626),  time:18.289, tt:713.282\n",
      "Ep:39, loss:0.00003, loss_test:0.10003, lr:1.00e-02, fs:0.73109 (r=0.879,p=0.626),  time:18.294, tt:731.769\n",
      "Ep:40, loss:0.00003, loss_test:0.09938, lr:1.00e-02, fs:0.73109 (r=0.879,p=0.626),  time:18.297, tt:750.162\n",
      "Ep:41, loss:0.00003, loss_test:0.09879, lr:1.00e-02, fs:0.74043 (r=0.879,p=0.640),  time:18.304, tt:768.769\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.09820, lr:1.00e-02, fs:0.74043 (r=0.879,p=0.640),  time:18.308, tt:787.227\n",
      "Ep:43, loss:0.00003, loss_test:0.09757, lr:1.00e-02, fs:0.74359 (r=0.879,p=0.644),  time:18.315, tt:805.838\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00003, loss_test:0.09693, lr:1.00e-02, fs:0.74894 (r=0.889,p=0.647),  time:18.349, tt:825.719\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00003, loss_test:0.09624, lr:1.00e-02, fs:0.75745 (r=0.899,p=0.654),  time:18.372, tt:845.098\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00003, loss_test:0.09548, lr:1.00e-02, fs:0.75745 (r=0.899,p=0.654),  time:18.405, tt:865.030\n",
      "Ep:47, loss:0.00003, loss_test:0.09470, lr:1.00e-02, fs:0.76068 (r=0.899,p=0.659),  time:18.435, tt:884.857\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00003, loss_test:0.09397, lr:1.00e-02, fs:0.77056 (r=0.899,p=0.674),  time:18.457, tt:904.374\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00003, loss_test:0.09328, lr:1.00e-02, fs:0.76856 (r=0.889,p=0.677),  time:18.486, tt:924.324\n",
      "Ep:50, loss:0.00003, loss_test:0.09251, lr:1.00e-02, fs:0.75771 (r=0.869,p=0.672),  time:18.509, tt:943.970\n",
      "Ep:51, loss:0.00003, loss_test:0.09183, lr:1.00e-02, fs:0.76316 (r=0.879,p=0.674),  time:18.529, tt:963.534\n",
      "Ep:52, loss:0.00003, loss_test:0.09133, lr:1.00e-02, fs:0.75983 (r=0.879,p=0.669),  time:18.542, tt:982.719\n",
      "Ep:53, loss:0.00003, loss_test:0.09079, lr:1.00e-02, fs:0.74561 (r=0.859,p=0.659),  time:18.545, tt:1001.404\n",
      "Ep:54, loss:0.00003, loss_test:0.09048, lr:1.00e-02, fs:0.74561 (r=0.859,p=0.659),  time:18.590, tt:1022.432\n",
      "Ep:55, loss:0.00003, loss_test:0.09016, lr:1.00e-02, fs:0.74890 (r=0.859,p=0.664),  time:18.609, tt:1042.090\n",
      "Ep:56, loss:0.00003, loss_test:0.08995, lr:1.00e-02, fs:0.75221 (r=0.859,p=0.669),  time:18.621, tt:1061.423\n",
      "Ep:57, loss:0.00003, loss_test:0.08974, lr:1.00e-02, fs:0.75676 (r=0.848,p=0.683),  time:18.618, tt:1079.824\n",
      "Ep:58, loss:0.00003, loss_test:0.08939, lr:1.00e-02, fs:0.76018 (r=0.848,p=0.689),  time:18.608, tt:1097.872\n",
      "Ep:59, loss:0.00003, loss_test:0.08898, lr:1.00e-02, fs:0.76577 (r=0.859,p=0.691),  time:18.618, tt:1117.110\n",
      "Ep:60, loss:0.00003, loss_test:0.08851, lr:9.90e-03, fs:0.76577 (r=0.859,p=0.691),  time:18.640, tt:1137.058\n",
      "Ep:61, loss:0.00003, loss_test:0.08795, lr:9.80e-03, fs:0.76233 (r=0.859,p=0.685),  time:18.644, tt:1155.933\n",
      "Ep:62, loss:0.00003, loss_test:0.08734, lr:9.70e-03, fs:0.77130 (r=0.869,p=0.694),  time:18.649, tt:1174.886\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00002, loss_test:0.08670, lr:9.70e-03, fs:0.76786 (r=0.869,p=0.688),  time:18.654, tt:1193.860\n",
      "Ep:64, loss:0.00002, loss_test:0.08608, lr:9.70e-03, fs:0.76786 (r=0.869,p=0.688),  time:18.659, tt:1212.804\n",
      "Ep:65, loss:0.00002, loss_test:0.08549, lr:9.70e-03, fs:0.75893 (r=0.859,p=0.680),  time:18.654, tt:1231.136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:66, loss:0.00002, loss_test:0.08484, lr:9.70e-03, fs:0.75893 (r=0.859,p=0.680),  time:18.648, tt:1249.443\n",
      "Ep:67, loss:0.00002, loss_test:0.08415, lr:9.70e-03, fs:0.76233 (r=0.859,p=0.685),  time:18.653, tt:1268.400\n",
      "Ep:68, loss:0.00002, loss_test:0.08342, lr:9.70e-03, fs:0.76923 (r=0.859,p=0.697),  time:18.646, tt:1286.605\n",
      "Ep:69, loss:0.00002, loss_test:0.08280, lr:9.70e-03, fs:0.77626 (r=0.859,p=0.708),  time:18.632, tt:1304.272\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00002, loss_test:0.08232, lr:9.70e-03, fs:0.78182 (r=0.869,p=0.711),  time:18.624, tt:1322.326\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00002, loss_test:0.08186, lr:9.70e-03, fs:0.78182 (r=0.869,p=0.711),  time:18.627, tt:1341.177\n",
      "Ep:72, loss:0.00002, loss_test:0.08130, lr:9.70e-03, fs:0.78182 (r=0.869,p=0.711),  time:18.634, tt:1360.261\n",
      "Ep:73, loss:0.00002, loss_test:0.08074, lr:9.70e-03, fs:0.78539 (r=0.869,p=0.717),  time:18.642, tt:1379.476\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00002, loss_test:0.07994, lr:9.70e-03, fs:0.77828 (r=0.869,p=0.705),  time:18.642, tt:1398.141\n",
      "Ep:75, loss:0.00002, loss_test:0.07914, lr:9.70e-03, fs:0.79091 (r=0.879,p=0.719),  time:18.638, tt:1416.505\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00002, loss_test:0.07830, lr:9.70e-03, fs:0.79091 (r=0.879,p=0.719),  time:18.637, tt:1435.019\n",
      "Ep:77, loss:0.00002, loss_test:0.07686, lr:9.70e-03, fs:0.79817 (r=0.879,p=0.731),  time:18.637, tt:1453.680\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00002, loss_test:0.07579, lr:9.70e-03, fs:0.81081 (r=0.909,p=0.732),  time:18.648, tt:1473.202\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00002, loss_test:0.07428, lr:9.70e-03, fs:0.81279 (r=0.899,p=0.742),  time:18.659, tt:1492.744\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00002, loss_test:0.07324, lr:9.70e-03, fs:0.82569 (r=0.909,p=0.756),  time:18.653, tt:1510.907\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00002, loss_test:0.07232, lr:9.70e-03, fs:0.83105 (r=0.919,p=0.758),  time:18.663, tt:1530.402\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00002, loss_test:0.07150, lr:9.70e-03, fs:0.83871 (r=0.919,p=0.771),  time:18.671, tt:1549.670\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00002, loss_test:0.07033, lr:9.70e-03, fs:0.83871 (r=0.919,p=0.771),  time:18.672, tt:1568.406\n",
      "Ep:84, loss:0.00002, loss_test:0.06903, lr:9.70e-03, fs:0.83333 (r=0.909,p=0.769),  time:18.715, tt:1590.805\n",
      "Ep:85, loss:0.00002, loss_test:0.06763, lr:9.70e-03, fs:0.83178 (r=0.899,p=0.774),  time:18.718, tt:1609.712\n",
      "Ep:86, loss:0.00002, loss_test:0.06677, lr:9.70e-03, fs:0.82791 (r=0.899,p=0.767),  time:18.715, tt:1628.196\n",
      "Ep:87, loss:0.00002, loss_test:0.06591, lr:9.70e-03, fs:0.83178 (r=0.899,p=0.774),  time:18.728, tt:1648.066\n",
      "Ep:88, loss:0.00002, loss_test:0.06582, lr:9.70e-03, fs:0.81651 (r=0.899,p=0.748),  time:18.721, tt:1666.175\n",
      "Ep:89, loss:0.00001, loss_test:0.06476, lr:9.70e-03, fs:0.83178 (r=0.899,p=0.774),  time:18.720, tt:1684.814\n",
      "Ep:90, loss:0.00001, loss_test:0.06427, lr:9.70e-03, fs:0.82569 (r=0.909,p=0.756),  time:18.732, tt:1704.594\n",
      "Ep:91, loss:0.00001, loss_test:0.06357, lr:9.70e-03, fs:0.84762 (r=0.899,p=0.802),  time:18.734, tt:1723.564\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00001, loss_test:0.06342, lr:9.70e-03, fs:0.82407 (r=0.899,p=0.761),  time:18.737, tt:1742.512\n",
      "Ep:93, loss:0.00001, loss_test:0.06227, lr:9.70e-03, fs:0.85308 (r=0.909,p=0.804),  time:18.743, tt:1761.821\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00001, loss_test:0.06176, lr:9.70e-03, fs:0.84906 (r=0.909,p=0.796),  time:18.751, tt:1781.330\n",
      "Ep:95, loss:0.00001, loss_test:0.06143, lr:9.70e-03, fs:0.84906 (r=0.909,p=0.796),  time:18.758, tt:1800.783\n",
      "Ep:96, loss:0.00001, loss_test:0.06075, lr:9.70e-03, fs:0.86124 (r=0.909,p=0.818),  time:18.766, tt:1820.314\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00001, loss_test:0.06018, lr:9.70e-03, fs:0.84651 (r=0.919,p=0.784),  time:18.772, tt:1839.684\n",
      "Ep:98, loss:0.00001, loss_test:0.06033, lr:9.70e-03, fs:0.86538 (r=0.909,p=0.826),  time:18.776, tt:1858.838\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00001, loss_test:0.05961, lr:9.70e-03, fs:0.85047 (r=0.919,p=0.791),  time:18.769, tt:1876.942\n",
      "Ep:100, loss:0.00001, loss_test:0.05868, lr:9.70e-03, fs:0.87923 (r=0.919,p=0.843),  time:18.758, tt:1894.558\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00001, loss_test:0.05781, lr:9.70e-03, fs:0.87081 (r=0.919,p=0.827),  time:18.756, tt:1913.128\n",
      "Ep:102, loss:0.00001, loss_test:0.05662, lr:9.70e-03, fs:0.85849 (r=0.919,p=0.805),  time:18.759, tt:1932.143\n",
      "Ep:103, loss:0.00001, loss_test:0.05691, lr:9.70e-03, fs:0.87379 (r=0.909,p=0.841),  time:18.755, tt:1950.531\n",
      "Ep:104, loss:0.00001, loss_test:0.05779, lr:9.70e-03, fs:0.86385 (r=0.929,p=0.807),  time:18.754, tt:1969.143\n",
      "Ep:105, loss:0.00001, loss_test:0.05724, lr:9.70e-03, fs:0.86275 (r=0.889,p=0.838),  time:18.745, tt:1986.931\n",
      "Ep:106, loss:0.00001, loss_test:0.05552, lr:9.70e-03, fs:0.86792 (r=0.929,p=0.814),  time:18.745, tt:2005.723\n",
      "Ep:107, loss:0.00001, loss_test:0.05438, lr:9.70e-03, fs:0.87619 (r=0.929,p=0.829),  time:18.738, tt:2023.758\n",
      "Ep:108, loss:0.00001, loss_test:0.05487, lr:9.70e-03, fs:0.85854 (r=0.889,p=0.830),  time:18.726, tt:2041.114\n",
      "Ep:109, loss:0.00001, loss_test:0.05678, lr:9.70e-03, fs:0.85981 (r=0.929,p=0.800),  time:18.726, tt:2059.885\n",
      "Ep:110, loss:0.00001, loss_test:0.05615, lr:9.70e-03, fs:0.87310 (r=0.869,p=0.878),  time:18.725, tt:2078.499\n",
      "Ep:111, loss:0.00001, loss_test:0.05532, lr:9.70e-03, fs:0.88462 (r=0.929,p=0.844),  time:18.727, tt:2097.414\n",
      "##########Best model found so far##########\n",
      "Ep:112, loss:0.00001, loss_test:0.05341, lr:9.70e-03, fs:0.87255 (r=0.899,p=0.848),  time:18.710, tt:2114.188\n",
      "Ep:113, loss:0.00001, loss_test:0.05320, lr:9.70e-03, fs:0.87685 (r=0.899,p=0.856),  time:18.705, tt:2132.385\n",
      "Ep:114, loss:0.00001, loss_test:0.05447, lr:9.70e-03, fs:0.87204 (r=0.929,p=0.821),  time:18.708, tt:2151.395\n",
      "Ep:115, loss:0.00001, loss_test:0.05534, lr:9.70e-03, fs:0.87629 (r=0.859,p=0.895),  time:18.707, tt:2169.955\n",
      "Ep:116, loss:0.00001, loss_test:0.05568, lr:9.70e-03, fs:0.87619 (r=0.929,p=0.829),  time:18.699, tt:2187.803\n",
      "Ep:117, loss:0.00001, loss_test:0.06106, lr:9.70e-03, fs:0.86792 (r=0.929,p=0.814),  time:18.719, tt:2208.835\n",
      "Ep:118, loss:0.00001, loss_test:0.06313, lr:9.70e-03, fs:0.81592 (r=0.828,p=0.804),  time:18.722, tt:2227.867\n",
      "Ep:119, loss:0.00001, loss_test:0.05656, lr:9.70e-03, fs:0.86667 (r=0.919,p=0.820),  time:18.713, tt:2245.605\n",
      "Ep:120, loss:0.00001, loss_test:0.06220, lr:9.70e-03, fs:0.89320 (r=0.929,p=0.860),  time:18.716, tt:2264.653\n",
      "##########Best model found so far##########\n",
      "Ep:121, loss:0.00001, loss_test:0.05741, lr:9.70e-03, fs:0.88557 (r=0.899,p=0.873),  time:18.726, tt:2284.547\n",
      "Ep:122, loss:0.00001, loss_test:0.05555, lr:9.70e-03, fs:0.87685 (r=0.899,p=0.856),  time:18.723, tt:2302.956\n",
      "Ep:123, loss:0.00001, loss_test:0.05558, lr:9.70e-03, fs:0.88462 (r=0.929,p=0.844),  time:18.724, tt:2321.736\n",
      "Ep:124, loss:0.00001, loss_test:0.05610, lr:9.70e-03, fs:0.89756 (r=0.929,p=0.868),  time:18.723, tt:2340.329\n",
      "##########Best model found so far##########\n",
      "Ep:125, loss:0.00001, loss_test:0.05432, lr:9.70e-03, fs:0.89756 (r=0.929,p=0.868),  time:18.711, tt:2357.539\n",
      "Ep:126, loss:0.00001, loss_test:0.05766, lr:9.70e-03, fs:0.88000 (r=0.889,p=0.871),  time:18.695, tt:2374.322\n",
      "Ep:127, loss:0.00001, loss_test:0.05392, lr:9.70e-03, fs:0.88038 (r=0.929,p=0.836),  time:18.685, tt:2391.725\n",
      "Ep:128, loss:0.00001, loss_test:0.05231, lr:9.70e-03, fs:0.90640 (r=0.929,p=0.885),  time:18.668, tt:2408.120\n",
      "##########Best model found so far##########\n",
      "Ep:129, loss:0.00001, loss_test:0.05169, lr:9.70e-03, fs:0.91542 (r=0.929,p=0.902),  time:18.646, tt:2423.990\n",
      "##########Best model found so far##########\n",
      "Ep:130, loss:0.00001, loss_test:0.05569, lr:9.70e-03, fs:0.87379 (r=0.909,p=0.841),  time:18.629, tt:2440.335\n",
      "Ep:131, loss:0.00001, loss_test:0.05232, lr:9.70e-03, fs:0.88557 (r=0.899,p=0.873),  time:18.611, tt:2456.629\n",
      "Ep:132, loss:0.00001, loss_test:0.05112, lr:9.70e-03, fs:0.90256 (r=0.889,p=0.917),  time:18.598, tt:2473.497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00001, loss_test:0.05162, lr:9.70e-03, fs:0.90640 (r=0.929,p=0.885),  time:18.600, tt:2492.445\n",
      "Ep:134, loss:0.00001, loss_test:0.05370, lr:9.70e-03, fs:0.89655 (r=0.919,p=0.875),  time:18.593, tt:2510.069\n",
      "Ep:135, loss:0.00001, loss_test:0.05558, lr:9.70e-03, fs:0.89109 (r=0.909,p=0.874),  time:18.599, tt:2529.532\n",
      "Ep:136, loss:0.00001, loss_test:0.05262, lr:9.70e-03, fs:0.91089 (r=0.929,p=0.893),  time:18.594, tt:2547.382\n",
      "Ep:137, loss:0.00001, loss_test:0.05299, lr:9.70e-03, fs:0.92462 (r=0.929,p=0.920),  time:18.579, tt:2563.901\n",
      "##########Best model found so far##########\n",
      "Ep:138, loss:0.00001, loss_test:0.05083, lr:9.70e-03, fs:0.90196 (r=0.929,p=0.876),  time:18.564, tt:2580.358\n",
      "Ep:139, loss:0.00001, loss_test:0.05188, lr:9.70e-03, fs:0.91000 (r=0.919,p=0.901),  time:18.552, tt:2597.296\n",
      "Ep:140, loss:0.00001, loss_test:0.05229, lr:9.70e-03, fs:0.90640 (r=0.929,p=0.885),  time:18.538, tt:2613.816\n",
      "Ep:141, loss:0.00001, loss_test:0.05213, lr:9.70e-03, fs:0.90640 (r=0.929,p=0.885),  time:18.523, tt:2630.201\n",
      "Ep:142, loss:0.00001, loss_test:0.05088, lr:9.70e-03, fs:0.90722 (r=0.889,p=0.926),  time:18.494, tt:2644.645\n",
      "Ep:143, loss:0.00001, loss_test:0.05120, lr:9.70e-03, fs:0.91837 (r=0.909,p=0.928),  time:18.469, tt:2659.564\n",
      "Ep:144, loss:0.00001, loss_test:0.05031, lr:9.70e-03, fs:0.91542 (r=0.929,p=0.902),  time:18.449, tt:2675.112\n",
      "Ep:145, loss:0.00000, loss_test:0.04948, lr:9.70e-03, fs:0.91542 (r=0.929,p=0.902),  time:18.436, tt:2691.615\n",
      "Ep:146, loss:0.00000, loss_test:0.04974, lr:9.70e-03, fs:0.91089 (r=0.929,p=0.893),  time:18.421, tt:2707.891\n",
      "Ep:147, loss:0.00000, loss_test:0.05065, lr:9.70e-03, fs:0.92632 (r=0.889,p=0.967),  time:18.402, tt:2723.510\n",
      "##########Best model found so far##########\n",
      "Ep:148, loss:0.00000, loss_test:0.05014, lr:9.70e-03, fs:0.92000 (r=0.929,p=0.911),  time:18.386, tt:2739.487\n",
      "Ep:149, loss:0.00000, loss_test:0.04980, lr:9.70e-03, fs:0.92462 (r=0.929,p=0.920),  time:18.373, tt:2755.891\n",
      "Ep:150, loss:0.00000, loss_test:0.04980, lr:9.70e-03, fs:0.90452 (r=0.909,p=0.900),  time:18.354, tt:2771.407\n",
      "Ep:151, loss:0.00000, loss_test:0.04940, lr:9.70e-03, fs:0.92462 (r=0.929,p=0.920),  time:18.342, tt:2788.002\n",
      "Ep:152, loss:0.00000, loss_test:0.05033, lr:9.70e-03, fs:0.92462 (r=0.929,p=0.920),  time:18.314, tt:2802.116\n",
      "Ep:153, loss:0.00000, loss_test:0.04979, lr:9.70e-03, fs:0.92462 (r=0.929,p=0.920),  time:18.306, tt:2819.061\n",
      "Ep:154, loss:0.00000, loss_test:0.05013, lr:9.70e-03, fs:0.93401 (r=0.929,p=0.939),  time:18.292, tt:2835.224\n",
      "##########Best model found so far##########\n",
      "Ep:155, loss:0.00000, loss_test:0.04833, lr:9.70e-03, fs:0.93401 (r=0.929,p=0.939),  time:18.279, tt:2851.479\n",
      "Ep:156, loss:0.00000, loss_test:0.04948, lr:9.70e-03, fs:0.92462 (r=0.929,p=0.920),  time:18.263, tt:2867.216\n",
      "Ep:157, loss:0.00000, loss_test:0.04934, lr:9.70e-03, fs:0.94845 (r=0.929,p=0.968),  time:18.248, tt:2883.148\n",
      "##########Best model found so far##########\n",
      "Ep:158, loss:0.00000, loss_test:0.04998, lr:9.70e-03, fs:0.92000 (r=0.929,p=0.911),  time:18.228, tt:2898.249\n",
      "Ep:159, loss:0.00000, loss_test:0.04899, lr:9.70e-03, fs:0.93750 (r=0.909,p=0.968),  time:18.207, tt:2913.059\n",
      "Ep:160, loss:0.00000, loss_test:0.04945, lr:9.70e-03, fs:0.92929 (r=0.929,p=0.929),  time:18.193, tt:2929.129\n",
      "Ep:161, loss:0.00000, loss_test:0.04948, lr:9.70e-03, fs:0.94241 (r=0.909,p=0.978),  time:18.186, tt:2946.157\n",
      "Ep:162, loss:0.00000, loss_test:0.04856, lr:9.70e-03, fs:0.93878 (r=0.929,p=0.948),  time:18.175, tt:2962.593\n",
      "Ep:163, loss:0.00000, loss_test:0.04881, lr:9.70e-03, fs:0.92929 (r=0.929,p=0.929),  time:18.167, tt:2979.448\n",
      "Ep:164, loss:0.00000, loss_test:0.05164, lr:9.70e-03, fs:0.91979 (r=0.869,p=0.977),  time:18.150, tt:2994.787\n",
      "Ep:165, loss:0.00000, loss_test:0.05072, lr:9.70e-03, fs:0.92929 (r=0.929,p=0.929),  time:18.139, tt:3010.998\n",
      "Ep:166, loss:0.00000, loss_test:0.05195, lr:9.70e-03, fs:0.93122 (r=0.889,p=0.978),  time:18.125, tt:3026.886\n",
      "Ep:167, loss:0.00000, loss_test:0.05124, lr:9.70e-03, fs:0.95337 (r=0.929,p=0.979),  time:18.120, tt:3044.222\n",
      "##########Best model found so far##########\n",
      "Ep:168, loss:0.00000, loss_test:0.04977, lr:9.70e-03, fs:0.94301 (r=0.919,p=0.968),  time:18.107, tt:3060.106\n",
      "Ep:169, loss:0.00000, loss_test:0.05099, lr:9.70e-03, fs:0.95337 (r=0.929,p=0.979),  time:18.092, tt:3075.594\n",
      "Ep:170, loss:0.00000, loss_test:0.04926, lr:9.70e-03, fs:0.95288 (r=0.919,p=0.989),  time:18.088, tt:3093.030\n",
      "Ep:171, loss:0.00000, loss_test:0.04904, lr:9.70e-03, fs:0.94792 (r=0.919,p=0.978),  time:18.083, tt:3110.202\n",
      "Ep:172, loss:0.00000, loss_test:0.04979, lr:9.70e-03, fs:0.94737 (r=0.909,p=0.989),  time:18.079, tt:3127.610\n",
      "Ep:173, loss:0.00000, loss_test:0.05103, lr:9.70e-03, fs:0.95288 (r=0.919,p=0.989),  time:18.073, tt:3144.640\n",
      "Ep:174, loss:0.00000, loss_test:0.04954, lr:9.70e-03, fs:0.92553 (r=0.879,p=0.978),  time:18.066, tt:3161.552\n",
      "Ep:175, loss:0.00000, loss_test:0.05102, lr:9.70e-03, fs:0.95337 (r=0.929,p=0.979),  time:18.060, tt:3178.601\n",
      "Ep:176, loss:0.00000, loss_test:0.05170, lr:9.70e-03, fs:0.92473 (r=0.869,p=0.989),  time:18.060, tt:3196.574\n",
      "Ep:177, loss:0.00000, loss_test:0.05039, lr:9.70e-03, fs:0.95337 (r=0.929,p=0.979),  time:18.057, tt:3214.102\n",
      "Ep:178, loss:0.00000, loss_test:0.05548, lr:9.70e-03, fs:0.92473 (r=0.869,p=0.989),  time:18.049, tt:3230.721\n",
      "Ep:179, loss:0.00000, loss_test:0.04991, lr:9.61e-03, fs:0.93048 (r=0.879,p=0.989),  time:18.044, tt:3247.832\n",
      "Ep:180, loss:0.00000, loss_test:0.04972, lr:9.51e-03, fs:0.95337 (r=0.929,p=0.979),  time:18.044, tt:3266.005\n",
      "Ep:181, loss:0.00000, loss_test:0.05229, lr:9.41e-03, fs:0.92473 (r=0.869,p=0.989),  time:18.034, tt:3282.166\n",
      "Ep:182, loss:0.00000, loss_test:0.05223, lr:9.32e-03, fs:0.95833 (r=0.929,p=0.989),  time:18.026, tt:3298.666\n",
      "##########Best model found so far##########\n",
      "Ep:183, loss:0.00000, loss_test:0.04983, lr:9.32e-03, fs:0.95833 (r=0.929,p=0.989),  time:18.023, tt:3316.231\n",
      "Ep:184, loss:0.00000, loss_test:0.05062, lr:9.32e-03, fs:0.92473 (r=0.869,p=0.989),  time:18.021, tt:3333.808\n",
      "Ep:185, loss:0.00000, loss_test:0.04936, lr:9.32e-03, fs:0.95337 (r=0.929,p=0.979),  time:18.014, tt:3350.648\n",
      "Ep:186, loss:0.00000, loss_test:0.04964, lr:9.32e-03, fs:0.94737 (r=0.909,p=0.989),  time:18.008, tt:3367.472\n",
      "Ep:187, loss:0.00000, loss_test:0.04976, lr:9.32e-03, fs:0.94180 (r=0.899,p=0.989),  time:17.998, tt:3383.573\n",
      "Ep:188, loss:0.00000, loss_test:0.04913, lr:9.32e-03, fs:0.95833 (r=0.929,p=0.989),  time:17.990, tt:3400.063\n",
      "Ep:189, loss:0.00000, loss_test:0.04712, lr:9.32e-03, fs:0.94737 (r=0.909,p=0.989),  time:17.978, tt:3415.862\n",
      "Ep:190, loss:0.00000, loss_test:0.04963, lr:9.32e-03, fs:0.94737 (r=0.909,p=0.989),  time:17.975, tt:3433.166\n",
      "Ep:191, loss:0.00000, loss_test:0.04879, lr:9.32e-03, fs:0.94180 (r=0.899,p=0.989),  time:17.972, tt:3450.663\n",
      "Ep:192, loss:0.00000, loss_test:0.04950, lr:9.32e-03, fs:0.95833 (r=0.929,p=0.989),  time:17.974, tt:3468.906\n",
      "Ep:193, loss:0.00000, loss_test:0.05220, lr:9.32e-03, fs:0.94118 (r=0.889,p=1.000),  time:17.975, tt:3487.204\n",
      "Ep:194, loss:0.00000, loss_test:0.04835, lr:9.23e-03, fs:0.92473 (r=0.869,p=0.989),  time:17.981, tt:3506.379\n",
      "Ep:195, loss:0.00000, loss_test:0.04904, lr:9.14e-03, fs:0.95833 (r=0.929,p=0.989),  time:18.013, tt:3530.502\n",
      "Ep:196, loss:0.00000, loss_test:0.05161, lr:9.04e-03, fs:0.95789 (r=0.919,p=1.000),  time:18.023, tt:3550.534\n",
      "Ep:197, loss:0.00000, loss_test:0.04758, lr:8.95e-03, fs:0.95238 (r=0.909,p=1.000),  time:18.036, tt:3571.086\n",
      "Ep:198, loss:0.00000, loss_test:0.04829, lr:8.86e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.040, tt:3589.972\n",
      "##########Best model found so far##########\n",
      "Ep:199, loss:0.00000, loss_test:0.05203, lr:8.86e-03, fs:0.93548 (r=0.879,p=1.000),  time:18.043, tt:3608.689\n",
      "Ep:200, loss:0.00000, loss_test:0.04903, lr:8.86e-03, fs:0.94681 (r=0.899,p=1.000),  time:18.052, tt:3628.507\n",
      "Ep:201, loss:0.00000, loss_test:0.04887, lr:8.86e-03, fs:0.95238 (r=0.909,p=1.000),  time:18.058, tt:3647.635\n",
      "Ep:202, loss:0.00000, loss_test:0.05193, lr:8.86e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.065, tt:3667.294\n",
      "Ep:203, loss:0.00000, loss_test:0.04779, lr:8.86e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.068, tt:3685.939\n",
      "Ep:204, loss:0.00000, loss_test:0.04939, lr:8.86e-03, fs:0.91803 (r=0.848,p=1.000),  time:18.076, tt:3705.651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:205, loss:0.00000, loss_test:0.05141, lr:8.86e-03, fs:0.94681 (r=0.899,p=1.000),  time:18.082, tt:3724.944\n",
      "Ep:206, loss:0.00000, loss_test:0.05073, lr:8.86e-03, fs:0.92473 (r=0.869,p=0.989),  time:18.090, tt:3744.718\n",
      "Ep:207, loss:0.00000, loss_test:0.04998, lr:8.86e-03, fs:0.95833 (r=0.929,p=0.989),  time:18.097, tt:3764.239\n",
      "Ep:208, loss:0.00000, loss_test:0.05776, lr:8.86e-03, fs:0.87500 (r=0.778,p=1.000),  time:18.103, tt:3783.532\n",
      "Ep:209, loss:0.00000, loss_test:0.05403, lr:8.86e-03, fs:0.93617 (r=0.889,p=0.989),  time:18.108, tt:3802.605\n",
      "Ep:210, loss:0.00000, loss_test:0.05058, lr:8.78e-03, fs:0.95288 (r=0.919,p=0.989),  time:18.107, tt:3820.669\n",
      "Ep:211, loss:0.00000, loss_test:0.05683, lr:8.69e-03, fs:0.92391 (r=0.859,p=1.000),  time:18.113, tt:3839.945\n",
      "Ep:212, loss:0.00000, loss_test:0.05277, lr:8.60e-03, fs:0.95833 (r=0.929,p=0.989),  time:18.122, tt:3860.009\n",
      "Ep:213, loss:0.00000, loss_test:0.05499, lr:8.51e-03, fs:0.93548 (r=0.879,p=1.000),  time:18.131, tt:3880.043\n",
      "Ep:214, loss:0.00000, loss_test:0.05289, lr:8.43e-03, fs:0.92391 (r=0.859,p=1.000),  time:18.137, tt:3899.382\n",
      "Ep:215, loss:0.00000, loss_test:0.05041, lr:8.35e-03, fs:0.92973 (r=0.869,p=1.000),  time:18.140, tt:3918.309\n",
      "Ep:216, loss:0.00000, loss_test:0.05019, lr:8.26e-03, fs:0.95833 (r=0.929,p=0.989),  time:18.146, tt:3937.612\n",
      "Ep:217, loss:0.00000, loss_test:0.05577, lr:8.18e-03, fs:0.93548 (r=0.879,p=1.000),  time:18.151, tt:3956.811\n",
      "Ep:218, loss:0.00000, loss_test:0.05245, lr:8.10e-03, fs:0.94118 (r=0.889,p=1.000),  time:18.155, tt:3975.923\n",
      "Ep:219, loss:0.00000, loss_test:0.05060, lr:8.02e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.164, tt:3996.048\n",
      "Ep:220, loss:0.00000, loss_test:0.05164, lr:7.94e-03, fs:0.94118 (r=0.889,p=1.000),  time:18.171, tt:4015.825\n",
      "Ep:221, loss:0.00000, loss_test:0.05199, lr:7.86e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.179, tt:4035.638\n",
      "Ep:222, loss:0.00000, loss_test:0.05066, lr:7.78e-03, fs:0.94681 (r=0.899,p=1.000),  time:18.183, tt:4054.771\n",
      "Ep:223, loss:0.00000, loss_test:0.05082, lr:7.70e-03, fs:0.92973 (r=0.869,p=1.000),  time:18.189, tt:4074.270\n",
      "Ep:224, loss:0.00000, loss_test:0.05107, lr:7.62e-03, fs:0.94118 (r=0.889,p=1.000),  time:18.196, tt:4094.119\n",
      "Ep:225, loss:0.00000, loss_test:0.04940, lr:7.55e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.198, tt:4112.655\n",
      "Ep:226, loss:0.00000, loss_test:0.05128, lr:7.47e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.194, tt:4130.120\n",
      "Ep:227, loss:0.00000, loss_test:0.05143, lr:7.40e-03, fs:0.94118 (r=0.889,p=1.000),  time:18.200, tt:4149.565\n",
      "Ep:228, loss:0.00000, loss_test:0.05062, lr:7.32e-03, fs:0.94681 (r=0.899,p=1.000),  time:18.204, tt:4168.675\n",
      "Ep:229, loss:0.00000, loss_test:0.05191, lr:7.25e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.206, tt:4187.390\n",
      "Ep:230, loss:0.00000, loss_test:0.05190, lr:7.18e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.208, tt:4205.961\n",
      "Ep:231, loss:0.00000, loss_test:0.05029, lr:7.11e-03, fs:0.95238 (r=0.909,p=1.000),  time:18.211, tt:4225.010\n",
      "Ep:232, loss:0.00000, loss_test:0.05142, lr:7.03e-03, fs:0.93548 (r=0.879,p=1.000),  time:18.210, tt:4243.003\n",
      "Ep:233, loss:0.00000, loss_test:0.05271, lr:6.96e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.216, tt:4262.502\n",
      "Ep:234, loss:0.00000, loss_test:0.05191, lr:6.89e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.216, tt:4280.710\n",
      "Ep:235, loss:0.00000, loss_test:0.05215, lr:6.83e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.219, tt:4299.674\n",
      "Ep:236, loss:0.00000, loss_test:0.05289, lr:6.76e-03, fs:0.94118 (r=0.889,p=1.000),  time:18.226, tt:4319.482\n",
      "Ep:237, loss:0.00000, loss_test:0.05230, lr:6.69e-03, fs:0.94681 (r=0.899,p=1.000),  time:18.229, tt:4338.479\n",
      "Ep:238, loss:0.00000, loss_test:0.05120, lr:6.62e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.230, tt:4357.090\n",
      "Ep:239, loss:0.00000, loss_test:0.05115, lr:6.56e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.229, tt:4375.036\n",
      "Ep:240, loss:0.00000, loss_test:0.05215, lr:6.49e-03, fs:0.95238 (r=0.909,p=1.000),  time:18.232, tt:4393.826\n",
      "Ep:241, loss:0.00000, loss_test:0.05236, lr:6.43e-03, fs:0.95789 (r=0.919,p=1.000),  time:18.238, tt:4413.597\n",
      "Ep:242, loss:0.00000, loss_test:0.05226, lr:6.36e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.245, tt:4433.482\n",
      "Ep:243, loss:0.00000, loss_test:0.05243, lr:6.30e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.251, tt:4453.197\n",
      "Ep:244, loss:0.00000, loss_test:0.05265, lr:6.24e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.254, tt:4472.310\n",
      "Ep:245, loss:0.00000, loss_test:0.05210, lr:6.17e-03, fs:0.95238 (r=0.909,p=1.000),  time:18.257, tt:4491.197\n",
      "Ep:246, loss:0.00000, loss_test:0.05268, lr:6.11e-03, fs:0.95789 (r=0.919,p=1.000),  time:18.261, tt:4510.521\n",
      "Ep:247, loss:0.00000, loss_test:0.05262, lr:6.05e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.263, tt:4529.256\n",
      "Ep:248, loss:0.00000, loss_test:0.05199, lr:5.99e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.266, tt:4548.288\n",
      "Ep:249, loss:0.00000, loss_test:0.05133, lr:5.93e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.270, tt:4567.403\n",
      "Ep:250, loss:0.00000, loss_test:0.05143, lr:5.87e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.270, tt:4585.832\n",
      "Ep:251, loss:0.00000, loss_test:0.05265, lr:5.81e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.271, tt:4604.221\n",
      "Ep:252, loss:0.00000, loss_test:0.05256, lr:5.75e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.275, tt:4623.490\n",
      "Ep:253, loss:0.00000, loss_test:0.05226, lr:5.70e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.275, tt:4641.759\n",
      "Ep:254, loss:0.00000, loss_test:0.05292, lr:5.64e-03, fs:0.95789 (r=0.919,p=1.000),  time:18.278, tt:4660.819\n",
      "Ep:255, loss:0.00000, loss_test:0.05226, lr:5.58e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.279, tt:4679.539\n",
      "Ep:256, loss:0.00000, loss_test:0.05233, lr:5.53e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.282, tt:4698.441\n",
      "Ep:257, loss:0.00000, loss_test:0.05287, lr:5.47e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.284, tt:4717.226\n",
      "Ep:258, loss:0.00000, loss_test:0.05278, lr:5.42e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.285, tt:4735.707\n",
      "Ep:259, loss:0.00000, loss_test:0.05238, lr:5.36e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.287, tt:4754.592\n",
      "Ep:260, loss:0.00000, loss_test:0.05226, lr:5.31e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.291, tt:4773.919\n",
      "Ep:261, loss:0.00000, loss_test:0.05224, lr:5.26e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.292, tt:4792.510\n",
      "Ep:262, loss:0.00000, loss_test:0.05252, lr:5.20e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.297, tt:4812.142\n",
      "Ep:263, loss:0.00000, loss_test:0.05280, lr:5.15e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.300, tt:4831.117\n",
      "Ep:264, loss:0.00000, loss_test:0.05329, lr:5.10e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.300, tt:4849.408\n",
      "Ep:265, loss:0.00000, loss_test:0.05237, lr:5.05e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.299, tt:4867.655\n",
      "Ep:266, loss:0.00000, loss_test:0.05234, lr:5.00e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.305, tt:4887.542\n",
      "Ep:267, loss:0.00000, loss_test:0.05250, lr:4.95e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.308, tt:4906.622\n",
      "Ep:268, loss:0.00000, loss_test:0.05242, lr:4.90e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.311, tt:4925.762\n",
      "Ep:269, loss:0.00000, loss_test:0.05322, lr:4.85e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.313, tt:4944.385\n",
      "Ep:270, loss:0.00000, loss_test:0.05279, lr:4.80e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.315, tt:4963.426\n",
      "Ep:271, loss:0.00000, loss_test:0.05223, lr:4.75e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.319, tt:4982.818\n",
      "Ep:272, loss:0.00000, loss_test:0.05338, lr:4.71e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.322, tt:5001.858\n",
      "Ep:273, loss:0.00000, loss_test:0.05292, lr:4.66e-03, fs:0.95789 (r=0.919,p=1.000),  time:18.324, tt:5020.800\n",
      "Ep:274, loss:0.00000, loss_test:0.05225, lr:4.61e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.323, tt:5038.936\n",
      "Ep:275, loss:0.00000, loss_test:0.05394, lr:4.57e-03, fs:0.95238 (r=0.909,p=1.000),  time:18.319, tt:5055.944\n",
      "Ep:276, loss:0.00000, loss_test:0.05385, lr:4.52e-03, fs:0.95789 (r=0.919,p=1.000),  time:18.318, tt:5074.119\n",
      "Ep:277, loss:0.00000, loss_test:0.05273, lr:4.48e-03, fs:0.95238 (r=0.909,p=1.000),  time:18.320, tt:5092.837\n",
      "Ep:278, loss:0.00000, loss_test:0.05334, lr:4.43e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.321, tt:5111.536\n",
      "Ep:279, loss:0.00000, loss_test:0.05405, lr:4.39e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.323, tt:5130.327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:280, loss:0.00000, loss_test:0.05335, lr:4.34e-03, fs:0.95789 (r=0.919,p=1.000),  time:18.327, tt:5149.830\n",
      "Ep:281, loss:0.00000, loss_test:0.05288, lr:4.30e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.328, tt:5168.404\n",
      "Ep:282, loss:0.00000, loss_test:0.05336, lr:4.26e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.327, tt:5186.614\n",
      "Ep:283, loss:0.00000, loss_test:0.05349, lr:4.21e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.328, tt:5205.182\n",
      "Ep:284, loss:0.00000, loss_test:0.05289, lr:4.17e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.341, tt:5227.084\n",
      "Ep:285, loss:0.00000, loss_test:0.05334, lr:4.13e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.340, tt:5245.124\n",
      "Ep:286, loss:0.00000, loss_test:0.05349, lr:4.09e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.346, tt:5265.435\n",
      "Ep:287, loss:0.00000, loss_test:0.05330, lr:4.05e-03, fs:0.95238 (r=0.909,p=1.000),  time:18.350, tt:5284.697\n",
      "Ep:288, loss:0.00000, loss_test:0.05301, lr:4.01e-03, fs:0.95238 (r=0.909,p=1.000),  time:18.352, tt:5303.698\n",
      "Ep:289, loss:0.00000, loss_test:0.05333, lr:3.97e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.353, tt:5322.234\n",
      "Ep:290, loss:0.00000, loss_test:0.05306, lr:3.93e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.355, tt:5341.358\n",
      "Ep:291, loss:0.00000, loss_test:0.05293, lr:3.89e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.360, tt:5360.973\n",
      "Ep:292, loss:0.00000, loss_test:0.05318, lr:3.85e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.364, tt:5380.729\n",
      "Ep:293, loss:0.00000, loss_test:0.05308, lr:3.81e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.366, tt:5399.503\n",
      "Ep:294, loss:0.00000, loss_test:0.05274, lr:3.77e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.366, tt:5417.947\n",
      "Ep:295, loss:0.00000, loss_test:0.05287, lr:3.73e-03, fs:0.96335 (r=0.929,p=1.000),  time:18.348, tt:5431.129\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14236, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.135, tt:12.135\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14204, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.957, tt:27.914\n",
      "Ep:2, loss:0.00004, loss_test:0.14155, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.208, tt:42.623\n",
      "Ep:3, loss:0.00004, loss_test:0.14088, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:14.431, tt:57.722\n",
      "Ep:4, loss:0.00004, loss_test:0.14003, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:14.643, tt:73.216\n",
      "Ep:5, loss:0.00004, loss_test:0.13896, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:14.887, tt:89.323\n",
      "Ep:6, loss:0.00004, loss_test:0.13762, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:15.062, tt:105.434\n",
      "Ep:7, loss:0.00004, loss_test:0.13592, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:15.261, tt:122.088\n",
      "Ep:8, loss:0.00004, loss_test:0.13378, lr:1.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:15.297, tt:137.677\n",
      "Ep:9, loss:0.00004, loss_test:0.13110, lr:1.00e-02, fs:0.67128 (r=0.980,p=0.511),  time:15.324, tt:153.241\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.12768, lr:1.00e-02, fs:0.65714 (r=0.929,p=0.508),  time:15.371, tt:169.081\n",
      "Ep:11, loss:0.00004, loss_test:0.12346, lr:1.00e-02, fs:0.66171 (r=0.899,p=0.524),  time:15.368, tt:184.411\n",
      "Ep:12, loss:0.00004, loss_test:0.11860, lr:1.00e-02, fs:0.68526 (r=0.869,p=0.566),  time:15.462, tt:201.006\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.11448, lr:1.00e-02, fs:0.69198 (r=0.828,p=0.594),  time:15.531, tt:217.431\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.11145, lr:1.00e-02, fs:0.69091 (r=0.768,p=0.628),  time:15.534, tt:233.009\n",
      "Ep:15, loss:0.00003, loss_test:0.11025, lr:1.00e-02, fs:0.67619 (r=0.717,p=0.640),  time:15.589, tt:249.417\n",
      "Ep:16, loss:0.00003, loss_test:0.10999, lr:1.00e-02, fs:0.69608 (r=0.717,p=0.676),  time:15.585, tt:264.948\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.10974, lr:1.00e-02, fs:0.69697 (r=0.697,p=0.697),  time:15.589, tt:280.593\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.10927, lr:1.00e-02, fs:0.68020 (r=0.677,p=0.684),  time:15.607, tt:296.528\n",
      "Ep:19, loss:0.00003, loss_test:0.10855, lr:1.00e-02, fs:0.67677 (r=0.677,p=0.677),  time:15.627, tt:312.540\n",
      "Ep:20, loss:0.00003, loss_test:0.10752, lr:1.00e-02, fs:0.69565 (r=0.727,p=0.667),  time:15.687, tt:329.434\n",
      "Ep:21, loss:0.00003, loss_test:0.10646, lr:1.00e-02, fs:0.70755 (r=0.758,p=0.664),  time:15.716, tt:345.758\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.10512, lr:1.00e-02, fs:0.71028 (r=0.768,p=0.661),  time:15.761, tt:362.498\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.10360, lr:1.00e-02, fs:0.72381 (r=0.768,p=0.685),  time:15.789, tt:378.928\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.10211, lr:1.00e-02, fs:0.71717 (r=0.717,p=0.717),  time:15.806, tt:395.143\n",
      "Ep:25, loss:0.00003, loss_test:0.10074, lr:1.00e-02, fs:0.72539 (r=0.707,p=0.745),  time:15.814, tt:411.154\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.09961, lr:1.00e-02, fs:0.72251 (r=0.697,p=0.750),  time:15.807, tt:426.783\n",
      "Ep:27, loss:0.00003, loss_test:0.09838, lr:1.00e-02, fs:0.71875 (r=0.697,p=0.742),  time:15.770, tt:441.559\n",
      "Ep:28, loss:0.00003, loss_test:0.09726, lr:1.00e-02, fs:0.73096 (r=0.727,p=0.735),  time:15.772, tt:457.388\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.09624, lr:1.00e-02, fs:0.73892 (r=0.758,p=0.721),  time:15.791, tt:473.736\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.09514, lr:1.00e-02, fs:0.73892 (r=0.758,p=0.721),  time:15.803, tt:489.884\n",
      "Ep:31, loss:0.00003, loss_test:0.09393, lr:1.00e-02, fs:0.74000 (r=0.747,p=0.733),  time:15.819, tt:506.219\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.09288, lr:1.00e-02, fs:0.74872 (r=0.737,p=0.760),  time:15.800, tt:521.388\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.09215, lr:1.00e-02, fs:0.74737 (r=0.717,p=0.780),  time:15.760, tt:535.852\n",
      "Ep:34, loss:0.00003, loss_test:0.09141, lr:1.00e-02, fs:0.76042 (r=0.737,p=0.785),  time:15.733, tt:550.660\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.09064, lr:1.00e-02, fs:0.77083 (r=0.747,p=0.796),  time:15.742, tt:566.704\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.08969, lr:1.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:15.742, tt:582.464\n",
      "Ep:37, loss:0.00003, loss_test:0.08873, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:15.698, tt:596.542\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.08784, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:15.676, tt:611.383\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.08712, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:15.655, tt:626.216\n",
      "Ep:40, loss:0.00002, loss_test:0.08638, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:15.650, tt:641.664\n",
      "Ep:41, loss:0.00002, loss_test:0.08566, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:15.680, tt:658.547\n",
      "Ep:42, loss:0.00002, loss_test:0.08497, lr:1.00e-02, fs:0.77320 (r=0.758,p=0.789),  time:15.662, tt:673.478\n",
      "Ep:43, loss:0.00002, loss_test:0.08427, lr:1.00e-02, fs:0.77083 (r=0.747,p=0.796),  time:15.723, tt:691.833\n",
      "Ep:44, loss:0.00002, loss_test:0.08360, lr:1.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:15.706, tt:706.760\n",
      "Ep:45, loss:0.00002, loss_test:0.08290, lr:1.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:15.687, tt:721.583\n",
      "Ep:46, loss:0.00002, loss_test:0.08217, lr:1.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:15.696, tt:737.735\n",
      "Ep:47, loss:0.00002, loss_test:0.08149, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:15.703, tt:753.738\n",
      "Ep:48, loss:0.00002, loss_test:0.08091, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:15.681, tt:768.354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:49, loss:0.00002, loss_test:0.08039, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:15.659, tt:782.975\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.07984, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:15.687, tt:800.029\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.07926, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:15.696, tt:816.208\n",
      "Ep:52, loss:0.00002, loss_test:0.07872, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:15.704, tt:832.313\n",
      "Ep:53, loss:0.00002, loss_test:0.07813, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:15.702, tt:847.884\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.07756, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:15.695, tt:863.232\n",
      "Ep:55, loss:0.00002, loss_test:0.07708, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:15.714, tt:879.991\n",
      "Ep:56, loss:0.00002, loss_test:0.07662, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:15.689, tt:894.299\n",
      "Ep:57, loss:0.00002, loss_test:0.07620, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:15.675, tt:909.178\n",
      "Ep:58, loss:0.00002, loss_test:0.07581, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:15.673, tt:924.697\n",
      "Ep:59, loss:0.00002, loss_test:0.07538, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:15.661, tt:939.649\n",
      "Ep:60, loss:0.00002, loss_test:0.07493, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:15.664, tt:955.528\n",
      "Ep:61, loss:0.00002, loss_test:0.07452, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:15.649, tt:970.219\n",
      "Ep:62, loss:0.00002, loss_test:0.07415, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:15.656, tt:986.325\n",
      "Ep:63, loss:0.00002, loss_test:0.07384, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:15.653, tt:1001.802\n",
      "Ep:64, loss:0.00002, loss_test:0.07355, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:15.652, tt:1017.406\n",
      "Ep:65, loss:0.00002, loss_test:0.07323, lr:9.90e-03, fs:0.80612 (r=0.798,p=0.814),  time:15.641, tt:1032.322\n",
      "Ep:66, loss:0.00002, loss_test:0.07285, lr:9.80e-03, fs:0.80203 (r=0.798,p=0.806),  time:15.654, tt:1048.785\n",
      "Ep:67, loss:0.00002, loss_test:0.07241, lr:9.70e-03, fs:0.81407 (r=0.818,p=0.810),  time:15.650, tt:1064.192\n",
      "Ep:68, loss:0.00002, loss_test:0.07201, lr:9.61e-03, fs:0.81407 (r=0.818,p=0.810),  time:15.648, tt:1079.679\n",
      "Ep:69, loss:0.00002, loss_test:0.07163, lr:9.51e-03, fs:0.81407 (r=0.818,p=0.810),  time:15.643, tt:1095.017\n",
      "Ep:70, loss:0.00002, loss_test:0.07130, lr:9.41e-03, fs:0.81818 (r=0.818,p=0.818),  time:15.627, tt:1109.498\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00002, loss_test:0.07096, lr:9.41e-03, fs:0.81818 (r=0.818,p=0.818),  time:15.623, tt:1124.851\n",
      "Ep:72, loss:0.00002, loss_test:0.07068, lr:9.41e-03, fs:0.82234 (r=0.818,p=0.827),  time:15.614, tt:1139.789\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00002, loss_test:0.07039, lr:9.41e-03, fs:0.82234 (r=0.818,p=0.827),  time:15.610, tt:1155.143\n",
      "Ep:74, loss:0.00002, loss_test:0.07008, lr:9.41e-03, fs:0.82828 (r=0.828,p=0.828),  time:15.594, tt:1169.566\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00002, loss_test:0.06985, lr:9.41e-03, fs:0.82051 (r=0.808,p=0.833),  time:15.593, tt:1185.049\n",
      "Ep:76, loss:0.00002, loss_test:0.06961, lr:9.41e-03, fs:0.82474 (r=0.808,p=0.842),  time:15.582, tt:1199.793\n",
      "Ep:77, loss:0.00002, loss_test:0.06935, lr:9.41e-03, fs:0.82474 (r=0.808,p=0.842),  time:15.559, tt:1213.581\n",
      "Ep:78, loss:0.00002, loss_test:0.06907, lr:9.41e-03, fs:0.83077 (r=0.818,p=0.844),  time:15.548, tt:1228.261\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00002, loss_test:0.06885, lr:9.41e-03, fs:0.83077 (r=0.818,p=0.844),  time:15.549, tt:1243.892\n",
      "Ep:80, loss:0.00002, loss_test:0.06860, lr:9.41e-03, fs:0.83077 (r=0.818,p=0.844),  time:15.542, tt:1258.879\n",
      "Ep:81, loss:0.00001, loss_test:0.06832, lr:9.41e-03, fs:0.83673 (r=0.828,p=0.845),  time:15.542, tt:1274.433\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.06809, lr:9.41e-03, fs:0.83673 (r=0.828,p=0.845),  time:15.535, tt:1289.398\n",
      "Ep:83, loss:0.00001, loss_test:0.06784, lr:9.41e-03, fs:0.83673 (r=0.828,p=0.845),  time:15.522, tt:1303.849\n",
      "Ep:84, loss:0.00001, loss_test:0.06754, lr:9.41e-03, fs:0.83673 (r=0.828,p=0.845),  time:15.515, tt:1318.816\n",
      "Ep:85, loss:0.00001, loss_test:0.06727, lr:9.41e-03, fs:0.83673 (r=0.828,p=0.845),  time:15.506, tt:1333.511\n",
      "Ep:86, loss:0.00001, loss_test:0.06699, lr:9.41e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.493, tt:1347.886\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00001, loss_test:0.06660, lr:9.41e-03, fs:0.86000 (r=0.869,p=0.851),  time:15.493, tt:1363.385\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00001, loss_test:0.06621, lr:9.41e-03, fs:0.86567 (r=0.879,p=0.853),  time:15.472, tt:1377.008\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00001, loss_test:0.06586, lr:9.41e-03, fs:0.87685 (r=0.899,p=0.856),  time:15.448, tt:1390.287\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00001, loss_test:0.06558, lr:9.41e-03, fs:0.87685 (r=0.899,p=0.856),  time:15.432, tt:1404.274\n",
      "Ep:91, loss:0.00001, loss_test:0.06532, lr:9.41e-03, fs:0.87685 (r=0.899,p=0.856),  time:15.422, tt:1418.837\n",
      "Ep:92, loss:0.00001, loss_test:0.06506, lr:9.41e-03, fs:0.88235 (r=0.909,p=0.857),  time:15.400, tt:1432.219\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00001, loss_test:0.06488, lr:9.41e-03, fs:0.88235 (r=0.909,p=0.857),  time:15.385, tt:1446.182\n",
      "Ep:94, loss:0.00001, loss_test:0.06474, lr:9.41e-03, fs:0.87685 (r=0.899,p=0.856),  time:15.371, tt:1460.249\n",
      "Ep:95, loss:0.00001, loss_test:0.06458, lr:9.41e-03, fs:0.87685 (r=0.899,p=0.856),  time:15.372, tt:1475.665\n",
      "Ep:96, loss:0.00001, loss_test:0.06446, lr:9.41e-03, fs:0.86567 (r=0.879,p=0.853),  time:15.352, tt:1489.172\n",
      "Ep:97, loss:0.00001, loss_test:0.06434, lr:9.41e-03, fs:0.86567 (r=0.879,p=0.853),  time:15.341, tt:1503.391\n",
      "Ep:98, loss:0.00001, loss_test:0.06419, lr:9.41e-03, fs:0.86567 (r=0.879,p=0.853),  time:15.330, tt:1517.690\n",
      "Ep:99, loss:0.00001, loss_test:0.06395, lr:9.41e-03, fs:0.87129 (r=0.889,p=0.854),  time:15.322, tt:1532.161\n",
      "Ep:100, loss:0.00001, loss_test:0.06378, lr:9.41e-03, fs:0.87129 (r=0.889,p=0.854),  time:15.339, tt:1549.283\n",
      "Ep:101, loss:0.00001, loss_test:0.06361, lr:9.41e-03, fs:0.86567 (r=0.879,p=0.853),  time:15.320, tt:1562.618\n",
      "Ep:102, loss:0.00001, loss_test:0.06340, lr:9.41e-03, fs:0.86000 (r=0.869,p=0.851),  time:15.306, tt:1576.541\n",
      "Ep:103, loss:0.00001, loss_test:0.06316, lr:9.41e-03, fs:0.85427 (r=0.859,p=0.850),  time:15.300, tt:1591.250\n",
      "Ep:104, loss:0.00001, loss_test:0.06302, lr:9.32e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.306, tt:1607.166\n",
      "Ep:105, loss:0.00001, loss_test:0.06283, lr:9.23e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.297, tt:1621.482\n",
      "Ep:106, loss:0.00001, loss_test:0.06256, lr:9.14e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.302, tt:1637.340\n",
      "Ep:107, loss:0.00001, loss_test:0.06246, lr:9.04e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.295, tt:1651.862\n",
      "Ep:108, loss:0.00001, loss_test:0.06237, lr:8.95e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.288, tt:1666.445\n",
      "Ep:109, loss:0.00001, loss_test:0.06219, lr:8.86e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.293, tt:1682.283\n",
      "Ep:110, loss:0.00001, loss_test:0.06206, lr:8.78e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.289, tt:1697.043\n",
      "Ep:111, loss:0.00001, loss_test:0.06189, lr:8.69e-03, fs:0.84103 (r=0.828,p=0.854),  time:15.279, tt:1711.266\n",
      "Ep:112, loss:0.00001, loss_test:0.06156, lr:8.60e-03, fs:0.84694 (r=0.838,p=0.856),  time:15.273, tt:1725.866\n",
      "Ep:113, loss:0.00001, loss_test:0.06137, lr:8.51e-03, fs:0.84103 (r=0.828,p=0.854),  time:15.260, tt:1739.588\n",
      "Ep:114, loss:0.00001, loss_test:0.06120, lr:8.43e-03, fs:0.84103 (r=0.828,p=0.854),  time:15.260, tt:1754.909\n",
      "Ep:115, loss:0.00001, loss_test:0.06106, lr:8.35e-03, fs:0.84103 (r=0.828,p=0.854),  time:15.251, tt:1769.076\n",
      "Ep:116, loss:0.00001, loss_test:0.06099, lr:8.26e-03, fs:0.84536 (r=0.828,p=0.863),  time:15.237, tt:1782.775\n",
      "Ep:117, loss:0.00001, loss_test:0.06093, lr:8.18e-03, fs:0.84974 (r=0.828,p=0.872),  time:15.234, tt:1797.574\n",
      "Ep:118, loss:0.00001, loss_test:0.06086, lr:8.10e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.234, tt:1812.808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:119, loss:0.00001, loss_test:0.06075, lr:8.02e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.234, tt:1828.046\n",
      "Ep:120, loss:0.00001, loss_test:0.06062, lr:7.94e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.218, tt:1841.409\n",
      "Ep:121, loss:0.00001, loss_test:0.06041, lr:7.86e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.218, tt:1856.655\n",
      "Ep:122, loss:0.00001, loss_test:0.06032, lr:7.78e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.215, tt:1871.446\n",
      "Ep:123, loss:0.00001, loss_test:0.06018, lr:7.70e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.201, tt:1884.870\n",
      "Ep:124, loss:0.00001, loss_test:0.06000, lr:7.62e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.194, tt:1899.193\n",
      "Ep:125, loss:0.00001, loss_test:0.05987, lr:7.55e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.198, tt:1914.936\n",
      "Ep:126, loss:0.00001, loss_test:0.05972, lr:7.47e-03, fs:0.84375 (r=0.818,p=0.871),  time:15.200, tt:1930.420\n",
      "Ep:127, loss:0.00001, loss_test:0.05956, lr:7.40e-03, fs:0.85263 (r=0.818,p=0.890),  time:15.196, tt:1945.076\n",
      "Ep:128, loss:0.00001, loss_test:0.05944, lr:7.32e-03, fs:0.84656 (r=0.808,p=0.889),  time:15.196, tt:1960.319\n",
      "Ep:129, loss:0.00001, loss_test:0.05933, lr:7.25e-03, fs:0.84656 (r=0.808,p=0.889),  time:15.192, tt:1974.914\n",
      "Ep:130, loss:0.00001, loss_test:0.05921, lr:7.18e-03, fs:0.84656 (r=0.808,p=0.889),  time:15.192, tt:1990.161\n",
      "Ep:131, loss:0.00001, loss_test:0.05912, lr:7.11e-03, fs:0.84043 (r=0.798,p=0.888),  time:15.193, tt:2005.436\n",
      "Ep:132, loss:0.00001, loss_test:0.05899, lr:7.03e-03, fs:0.84656 (r=0.808,p=0.889),  time:15.198, tt:2021.296\n",
      "Ep:133, loss:0.00001, loss_test:0.05882, lr:6.96e-03, fs:0.84656 (r=0.808,p=0.889),  time:15.200, tt:2036.848\n",
      "Ep:134, loss:0.00001, loss_test:0.05867, lr:6.89e-03, fs:0.84656 (r=0.808,p=0.889),  time:15.207, tt:2052.968\n",
      "Ep:135, loss:0.00001, loss_test:0.05855, lr:6.83e-03, fs:0.84656 (r=0.808,p=0.889),  time:15.222, tt:2070.150\n",
      "Ep:136, loss:0.00001, loss_test:0.05847, lr:6.76e-03, fs:0.84656 (r=0.808,p=0.889),  time:15.227, tt:2086.106\n",
      "Ep:137, loss:0.00001, loss_test:0.05838, lr:6.69e-03, fs:0.84656 (r=0.808,p=0.889),  time:15.226, tt:2101.213\n",
      "Ep:138, loss:0.00001, loss_test:0.05833, lr:6.62e-03, fs:0.84656 (r=0.808,p=0.889),  time:15.227, tt:2116.556\n",
      "Ep:139, loss:0.00001, loss_test:0.05830, lr:6.56e-03, fs:0.84043 (r=0.798,p=0.888),  time:15.235, tt:2132.959\n",
      "Ep:140, loss:0.00001, loss_test:0.05819, lr:6.49e-03, fs:0.84043 (r=0.798,p=0.888),  time:15.237, tt:2148.388\n",
      "Ep:141, loss:0.00001, loss_test:0.05808, lr:6.43e-03, fs:0.84043 (r=0.798,p=0.888),  time:15.234, tt:2163.171\n",
      "Ep:142, loss:0.00001, loss_test:0.05805, lr:6.36e-03, fs:0.83422 (r=0.788,p=0.886),  time:15.228, tt:2177.654\n",
      "Ep:143, loss:0.00001, loss_test:0.05792, lr:6.30e-03, fs:0.83871 (r=0.788,p=0.897),  time:15.224, tt:2192.210\n",
      "Ep:144, loss:0.00001, loss_test:0.05778, lr:6.24e-03, fs:0.83422 (r=0.788,p=0.886),  time:15.234, tt:2208.941\n",
      "Ep:145, loss:0.00001, loss_test:0.05780, lr:6.17e-03, fs:0.83696 (r=0.778,p=0.906),  time:15.233, tt:2224.001\n",
      "Ep:146, loss:0.00001, loss_test:0.05775, lr:6.11e-03, fs:0.84153 (r=0.778,p=0.917),  time:15.230, tt:2238.852\n",
      "Ep:147, loss:0.00001, loss_test:0.05760, lr:6.05e-03, fs:0.83696 (r=0.778,p=0.906),  time:15.238, tt:2255.203\n",
      "Ep:148, loss:0.00001, loss_test:0.05756, lr:5.99e-03, fs:0.83696 (r=0.778,p=0.906),  time:15.235, tt:2270.066\n",
      "Ep:149, loss:0.00001, loss_test:0.05758, lr:5.93e-03, fs:0.83696 (r=0.778,p=0.906),  time:15.242, tt:2286.293\n",
      "Ep:150, loss:0.00001, loss_test:0.05753, lr:5.87e-03, fs:0.83060 (r=0.768,p=0.905),  time:15.241, tt:2301.464\n",
      "Ep:151, loss:0.00001, loss_test:0.05741, lr:5.81e-03, fs:0.83060 (r=0.768,p=0.905),  time:15.251, tt:2318.102\n",
      "Ep:152, loss:0.00001, loss_test:0.05742, lr:5.75e-03, fs:0.83516 (r=0.768,p=0.916),  time:15.253, tt:2333.738\n",
      "Ep:153, loss:0.00001, loss_test:0.05737, lr:5.70e-03, fs:0.83516 (r=0.768,p=0.916),  time:15.253, tt:2348.945\n",
      "Ep:154, loss:0.00001, loss_test:0.05724, lr:5.64e-03, fs:0.83060 (r=0.768,p=0.905),  time:15.259, tt:2365.109\n",
      "Ep:155, loss:0.00001, loss_test:0.05717, lr:5.58e-03, fs:0.83060 (r=0.768,p=0.905),  time:15.258, tt:2380.291\n",
      "Ep:156, loss:0.00001, loss_test:0.05717, lr:5.53e-03, fs:0.83060 (r=0.768,p=0.905),  time:15.264, tt:2396.401\n",
      "Ep:157, loss:0.00001, loss_test:0.05715, lr:5.47e-03, fs:0.83516 (r=0.768,p=0.916),  time:15.265, tt:2411.944\n",
      "Ep:158, loss:0.00001, loss_test:0.05706, lr:5.42e-03, fs:0.83516 (r=0.768,p=0.916),  time:15.270, tt:2427.869\n",
      "Ep:159, loss:0.00001, loss_test:0.05700, lr:5.36e-03, fs:0.83060 (r=0.768,p=0.905),  time:15.268, tt:2442.916\n",
      "Ep:160, loss:0.00001, loss_test:0.05702, lr:5.31e-03, fs:0.83060 (r=0.768,p=0.905),  time:15.274, tt:2459.132\n",
      "Ep:161, loss:0.00001, loss_test:0.05704, lr:5.26e-03, fs:0.83060 (r=0.768,p=0.905),  time:15.272, tt:2474.005\n",
      "Ep:162, loss:0.00001, loss_test:0.05701, lr:5.20e-03, fs:0.83060 (r=0.768,p=0.905),  time:15.271, tt:2489.105\n",
      "Ep:163, loss:0.00001, loss_test:0.05698, lr:5.15e-03, fs:0.83516 (r=0.768,p=0.916),  time:15.275, tt:2505.148\n",
      "Ep:164, loss:0.00001, loss_test:0.05697, lr:5.10e-03, fs:0.83060 (r=0.768,p=0.905),  time:15.280, tt:2521.255\n",
      "Ep:165, loss:0.00001, loss_test:0.05699, lr:5.05e-03, fs:0.83060 (r=0.768,p=0.905),  time:15.287, tt:2537.597\n",
      "Ep:166, loss:0.00001, loss_test:0.05697, lr:5.00e-03, fs:0.83060 (r=0.768,p=0.905),  time:15.291, tt:2553.628\n",
      "Ep:167, loss:0.00001, loss_test:0.05694, lr:4.95e-03, fs:0.83516 (r=0.768,p=0.916),  time:15.292, tt:2569.031\n",
      "Ep:168, loss:0.00001, loss_test:0.05692, lr:4.90e-03, fs:0.83978 (r=0.768,p=0.927),  time:15.291, tt:2584.222\n",
      "Ep:169, loss:0.00001, loss_test:0.05690, lr:4.85e-03, fs:0.83978 (r=0.768,p=0.927),  time:15.289, tt:2599.046\n",
      "Ep:170, loss:0.00001, loss_test:0.05684, lr:4.80e-03, fs:0.83978 (r=0.768,p=0.927),  time:15.292, tt:2614.887\n",
      "Ep:171, loss:0.00001, loss_test:0.05688, lr:4.75e-03, fs:0.83978 (r=0.768,p=0.927),  time:15.298, tt:2631.255\n",
      "Ep:172, loss:0.00001, loss_test:0.05685, lr:4.71e-03, fs:0.83978 (r=0.768,p=0.927),  time:15.300, tt:2646.942\n",
      "Ep:173, loss:0.00001, loss_test:0.05674, lr:4.66e-03, fs:0.83978 (r=0.768,p=0.927),  time:15.301, tt:2662.350\n",
      "Ep:174, loss:0.00001, loss_test:0.05674, lr:4.61e-03, fs:0.83978 (r=0.768,p=0.927),  time:15.294, tt:2676.463\n",
      "Ep:175, loss:0.00001, loss_test:0.05675, lr:4.57e-03, fs:0.83978 (r=0.768,p=0.927),  time:15.292, tt:2691.330\n",
      "Ep:176, loss:0.00001, loss_test:0.05668, lr:4.52e-03, fs:0.83978 (r=0.768,p=0.927),  time:15.288, tt:2706.034\n",
      "Ep:177, loss:0.00001, loss_test:0.05658, lr:4.48e-03, fs:0.83978 (r=0.768,p=0.927),  time:15.288, tt:2721.296\n",
      "Ep:178, loss:0.00001, loss_test:0.05664, lr:4.43e-03, fs:0.84444 (r=0.768,p=0.938),  time:15.288, tt:2736.552\n",
      "Ep:179, loss:0.00001, loss_test:0.05664, lr:4.39e-03, fs:0.84444 (r=0.768,p=0.938),  time:15.290, tt:2752.250\n",
      "Ep:180, loss:0.00001, loss_test:0.05661, lr:4.34e-03, fs:0.84444 (r=0.768,p=0.938),  time:15.294, tt:2768.225\n",
      "Ep:181, loss:0.00001, loss_test:0.05663, lr:4.30e-03, fs:0.84444 (r=0.768,p=0.938),  time:15.299, tt:2784.360\n",
      "Ep:182, loss:0.00001, loss_test:0.05666, lr:4.26e-03, fs:0.84444 (r=0.768,p=0.938),  time:15.303, tt:2800.430\n",
      "Ep:183, loss:0.00001, loss_test:0.05665, lr:4.21e-03, fs:0.84444 (r=0.768,p=0.938),  time:15.304, tt:2815.989\n",
      "Ep:184, loss:0.00001, loss_test:0.05662, lr:4.17e-03, fs:0.84444 (r=0.768,p=0.938),  time:15.303, tt:2831.028\n",
      "Ep:185, loss:0.00001, loss_test:0.05662, lr:4.13e-03, fs:0.84444 (r=0.768,p=0.938),  time:15.303, tt:2846.432\n",
      "Ep:186, loss:0.00001, loss_test:0.05660, lr:4.09e-03, fs:0.84444 (r=0.768,p=0.938),  time:15.310, tt:2862.900\n",
      "Ep:187, loss:0.00001, loss_test:0.05656, lr:4.05e-03, fs:0.84444 (r=0.768,p=0.938),  time:15.311, tt:2878.507\n",
      "Ep:188, loss:0.00001, loss_test:0.05657, lr:4.01e-03, fs:0.84444 (r=0.768,p=0.938),  time:15.310, tt:2893.586\n",
      "Ep:189, loss:0.00001, loss_test:0.05654, lr:3.97e-03, fs:0.84444 (r=0.768,p=0.938),  time:15.314, tt:2909.709\n",
      "Ep:190, loss:0.00001, loss_test:0.05657, lr:3.93e-03, fs:0.84444 (r=0.768,p=0.938),  time:15.317, tt:2925.535\n",
      "Ep:191, loss:0.00001, loss_test:0.05660, lr:3.89e-03, fs:0.84444 (r=0.768,p=0.938),  time:15.320, tt:2941.408\n",
      "Ep:192, loss:0.00001, loss_test:0.05659, lr:3.85e-03, fs:0.84444 (r=0.768,p=0.938),  time:15.321, tt:2956.879\n",
      "Ep:193, loss:0.00001, loss_test:0.05655, lr:3.81e-03, fs:0.84444 (r=0.768,p=0.938),  time:15.325, tt:2973.103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:194, loss:0.00001, loss_test:0.05652, lr:3.77e-03, fs:0.84444 (r=0.768,p=0.938),  time:15.327, tt:2988.777\n",
      "Ep:195, loss:0.00001, loss_test:0.05655, lr:3.73e-03, fs:0.84444 (r=0.768,p=0.938),  time:15.327, tt:3004.043\n",
      "Ep:196, loss:0.00001, loss_test:0.05648, lr:3.70e-03, fs:0.84444 (r=0.768,p=0.938),  time:15.330, tt:3019.965\n",
      "Ep:197, loss:0.00001, loss_test:0.05653, lr:3.66e-03, fs:0.84444 (r=0.768,p=0.938),  time:15.329, tt:3035.185\n",
      "Ep:198, loss:0.00001, loss_test:0.05653, lr:3.62e-03, fs:0.84444 (r=0.768,p=0.938),  time:15.331, tt:3050.789\n",
      "Ep:199, loss:0.00001, loss_test:0.05648, lr:3.59e-03, fs:0.84444 (r=0.768,p=0.938),  time:15.335, tt:3066.936\n",
      "Ep:200, loss:0.00001, loss_test:0.05655, lr:3.55e-03, fs:0.84444 (r=0.768,p=0.938),  time:15.341, tt:3083.442\n",
      "Ep:201, loss:0.00001, loss_test:0.05655, lr:3.52e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.338, tt:3098.317\n",
      "Ep:202, loss:0.00001, loss_test:0.05647, lr:3.48e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.338, tt:3113.585\n",
      "Ep:203, loss:0.00001, loss_test:0.05653, lr:3.45e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.341, tt:3129.575\n",
      "Ep:204, loss:0.00001, loss_test:0.05659, lr:3.41e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.344, tt:3145.542\n",
      "Ep:205, loss:0.00001, loss_test:0.05652, lr:3.38e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.347, tt:3161.553\n",
      "Ep:206, loss:0.00001, loss_test:0.05646, lr:3.34e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.351, tt:3177.624\n",
      "Ep:207, loss:0.00001, loss_test:0.05650, lr:3.31e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.358, tt:3194.527\n",
      "Ep:208, loss:0.00001, loss_test:0.05653, lr:3.28e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.357, tt:3209.666\n",
      "Ep:209, loss:0.00001, loss_test:0.05646, lr:3.24e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.358, tt:3225.225\n",
      "Ep:210, loss:0.00001, loss_test:0.05639, lr:3.21e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.367, tt:3242.420\n",
      "Ep:211, loss:0.00001, loss_test:0.05649, lr:3.18e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.369, tt:3258.135\n",
      "Ep:212, loss:0.00001, loss_test:0.05653, lr:3.15e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.367, tt:3273.079\n",
      "Ep:213, loss:0.00001, loss_test:0.05647, lr:3.12e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.366, tt:3288.235\n",
      "Ep:214, loss:0.00001, loss_test:0.05642, lr:3.09e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.367, tt:3303.922\n",
      "Ep:215, loss:0.00001, loss_test:0.05644, lr:3.05e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.369, tt:3319.737\n",
      "Ep:216, loss:0.00001, loss_test:0.05649, lr:3.02e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.370, tt:3335.357\n",
      "Ep:217, loss:0.00001, loss_test:0.05644, lr:2.99e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.372, tt:3351.052\n",
      "Ep:218, loss:0.00001, loss_test:0.05640, lr:2.96e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.375, tt:3367.036\n",
      "Ep:219, loss:0.00001, loss_test:0.05644, lr:2.93e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.375, tt:3382.532\n",
      "Ep:220, loss:0.00001, loss_test:0.05649, lr:2.90e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.379, tt:3398.707\n",
      "Ep:221, loss:0.00001, loss_test:0.05643, lr:2.88e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.383, tt:3415.010\n",
      "Ep:222, loss:0.00001, loss_test:0.05637, lr:2.85e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.382, tt:3430.273\n",
      "Ep:223, loss:0.00001, loss_test:0.05639, lr:2.82e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.381, tt:3445.365\n",
      "Ep:224, loss:0.00001, loss_test:0.05638, lr:2.79e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.383, tt:3461.067\n",
      "Ep:225, loss:0.00001, loss_test:0.05627, lr:2.76e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.384, tt:3476.688\n",
      "Ep:226, loss:0.00001, loss_test:0.05622, lr:2.73e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.386, tt:3492.639\n",
      "Ep:227, loss:0.00001, loss_test:0.05630, lr:2.71e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.388, tt:3508.567\n",
      "Ep:228, loss:0.00001, loss_test:0.05631, lr:2.68e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.393, tt:3525.049\n",
      "Ep:229, loss:0.00001, loss_test:0.05624, lr:2.65e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.392, tt:3540.224\n",
      "Ep:230, loss:0.00001, loss_test:0.05621, lr:2.63e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.393, tt:3555.772\n",
      "Ep:231, loss:0.00001, loss_test:0.05627, lr:2.60e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.393, tt:3571.090\n",
      "Ep:232, loss:0.00001, loss_test:0.05627, lr:2.57e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.390, tt:3585.817\n",
      "Ep:233, loss:0.00001, loss_test:0.05619, lr:2.55e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.387, tt:3600.505\n",
      "Ep:234, loss:0.00001, loss_test:0.05613, lr:2.52e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.386, tt:3615.696\n",
      "Ep:235, loss:0.00001, loss_test:0.05616, lr:2.50e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.389, tt:3631.720\n",
      "Ep:236, loss:0.00001, loss_test:0.05617, lr:2.47e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.391, tt:3647.684\n",
      "Ep:237, loss:0.00001, loss_test:0.05613, lr:2.45e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.405, tt:3666.478\n",
      "Ep:238, loss:0.00001, loss_test:0.05609, lr:2.42e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.412, tt:3683.465\n",
      "Ep:239, loss:0.00001, loss_test:0.05611, lr:2.40e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.411, tt:3698.616\n",
      "Ep:240, loss:0.00001, loss_test:0.05614, lr:2.38e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.414, tt:3714.749\n",
      "Ep:241, loss:0.00001, loss_test:0.05612, lr:2.35e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.413, tt:3730.057\n",
      "Ep:242, loss:0.00001, loss_test:0.05608, lr:2.33e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.416, tt:3746.096\n",
      "Ep:243, loss:0.00001, loss_test:0.05607, lr:2.31e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.420, tt:3762.486\n",
      "Ep:244, loss:0.00001, loss_test:0.05608, lr:2.28e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.421, tt:3778.165\n",
      "Ep:245, loss:0.00001, loss_test:0.05607, lr:2.26e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.425, tt:3794.650\n",
      "Ep:246, loss:0.00001, loss_test:0.05602, lr:2.24e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.427, tt:3810.568\n",
      "Ep:247, loss:0.00001, loss_test:0.05601, lr:2.21e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.432, tt:3827.082\n",
      "Ep:248, loss:0.00001, loss_test:0.05603, lr:2.19e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.434, tt:3843.118\n",
      "Ep:249, loss:0.00001, loss_test:0.05602, lr:2.17e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.439, tt:3859.850\n",
      "Ep:250, loss:0.00001, loss_test:0.05599, lr:2.15e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.443, tt:3876.101\n",
      "Ep:251, loss:0.00001, loss_test:0.05603, lr:2.13e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.443, tt:3891.608\n",
      "Ep:252, loss:0.00001, loss_test:0.05604, lr:2.11e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.449, tt:3908.479\n",
      "Ep:253, loss:0.00001, loss_test:0.05603, lr:2.08e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.456, tt:3925.859\n",
      "Ep:254, loss:0.00001, loss_test:0.05602, lr:2.06e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.460, tt:3942.334\n",
      "Ep:255, loss:0.00001, loss_test:0.05602, lr:2.04e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.465, tt:3958.925\n",
      "Ep:256, loss:0.00001, loss_test:0.05601, lr:2.02e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.467, tt:3974.906\n",
      "Ep:257, loss:0.00001, loss_test:0.05599, lr:2.00e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.469, tt:3990.933\n",
      "Ep:258, loss:0.00001, loss_test:0.05599, lr:1.98e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.469, tt:4006.513\n",
      "Ep:259, loss:0.00001, loss_test:0.05601, lr:1.96e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.466, tt:4021.215\n",
      "Ep:260, loss:0.00001, loss_test:0.05599, lr:1.94e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.467, tt:4036.775\n",
      "Ep:261, loss:0.00001, loss_test:0.05596, lr:1.92e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.466, tt:4052.046\n",
      "Ep:262, loss:0.00001, loss_test:0.05598, lr:1.90e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.467, tt:4067.809\n",
      "Ep:263, loss:0.00001, loss_test:0.05597, lr:1.89e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.465, tt:4082.648\n",
      "Ep:264, loss:0.00001, loss_test:0.05594, lr:1.87e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.462, tt:4097.495\n",
      "Ep:265, loss:0.00001, loss_test:0.05594, lr:1.85e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.462, tt:4112.830\n",
      "Ep:266, loss:0.00001, loss_test:0.05595, lr:1.83e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.461, tt:4128.125\n",
      "Ep:267, loss:0.00001, loss_test:0.05593, lr:1.81e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.464, tt:4144.474\n",
      "Ep:268, loss:0.00001, loss_test:0.05590, lr:1.79e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.462, tt:4159.400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:269, loss:0.00001, loss_test:0.05593, lr:1.78e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.462, tt:4174.724\n",
      "Ep:270, loss:0.00001, loss_test:0.05594, lr:1.76e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.462, tt:4190.123\n",
      "Ep:271, loss:0.00001, loss_test:0.05593, lr:1.74e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.466, tt:4206.725\n",
      "Ep:272, loss:0.00001, loss_test:0.05592, lr:1.72e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.464, tt:4221.604\n",
      "Ep:273, loss:0.00001, loss_test:0.05594, lr:1.71e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.466, tt:4237.749\n",
      "Ep:274, loss:0.00001, loss_test:0.05595, lr:1.69e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.463, tt:4252.409\n",
      "Ep:275, loss:0.00001, loss_test:0.05593, lr:1.67e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.462, tt:4267.589\n",
      "Ep:276, loss:0.00001, loss_test:0.05591, lr:1.65e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.462, tt:4283.003\n",
      "Ep:277, loss:0.00001, loss_test:0.05593, lr:1.64e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.465, tt:4299.237\n",
      "Ep:278, loss:0.00001, loss_test:0.05593, lr:1.62e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.466, tt:4314.977\n",
      "Ep:279, loss:0.00001, loss_test:0.05592, lr:1.61e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.463, tt:4329.667\n",
      "Ep:280, loss:0.00001, loss_test:0.05590, lr:1.59e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.462, tt:4344.703\n",
      "Ep:281, loss:0.00001, loss_test:0.05592, lr:1.57e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.463, tt:4360.496\n",
      "Ep:282, loss:0.00001, loss_test:0.05595, lr:1.56e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.464, tt:4376.451\n",
      "Ep:283, loss:0.00001, loss_test:0.05595, lr:1.54e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.462, tt:4391.174\n",
      "Ep:284, loss:0.00001, loss_test:0.05593, lr:1.53e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.456, tt:4404.941\n",
      "Ep:285, loss:0.00001, loss_test:0.05595, lr:1.51e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.457, tt:4420.809\n",
      "Ep:286, loss:0.00001, loss_test:0.05595, lr:1.50e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.455, tt:4435.584\n",
      "Ep:287, loss:0.00001, loss_test:0.05592, lr:1.48e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.459, tt:4452.128\n",
      "Ep:288, loss:0.00001, loss_test:0.05591, lr:1.47e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.456, tt:4466.866\n",
      "Ep:289, loss:0.00001, loss_test:0.05590, lr:1.45e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.453, tt:4481.258\n",
      "Ep:290, loss:0.00001, loss_test:0.05590, lr:1.44e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.447, tt:4495.146\n",
      "Ep:291, loss:0.00001, loss_test:0.05589, lr:1.42e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.448, tt:4510.889\n",
      "Ep:292, loss:0.00001, loss_test:0.05592, lr:1.41e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.450, tt:4526.760\n",
      "Ep:293, loss:0.00001, loss_test:0.05591, lr:1.39e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.451, tt:4542.456\n",
      "Ep:294, loss:0.00001, loss_test:0.05590, lr:1.38e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.446, tt:4556.633\n",
      "Ep:295, loss:0.00001, loss_test:0.05593, lr:1.37e-03, fs:0.84916 (r=0.768,p=0.950),  time:15.442, tt:4570.748\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.13937, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.152, tt:13.152\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.13865, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.290, tt:32.580\n",
      "Ep:2, loss:0.00004, loss_test:0.13752, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:17.441, tt:52.324\n",
      "Ep:3, loss:0.00004, loss_test:0.13591, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:18.143, tt:72.572\n",
      "Ep:4, loss:0.00004, loss_test:0.13369, lr:1.00e-02, fs:0.67361 (r=0.980,p=0.513),  time:18.637, tt:93.187\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.13067, lr:1.00e-02, fs:0.67133 (r=0.970,p=0.513),  time:18.981, tt:113.884\n",
      "Ep:6, loss:0.00004, loss_test:0.12654, lr:1.00e-02, fs:0.66906 (r=0.939,p=0.520),  time:19.371, tt:135.600\n",
      "Ep:7, loss:0.00004, loss_test:0.12160, lr:1.00e-02, fs:0.65660 (r=0.879,p=0.524),  time:19.473, tt:155.786\n",
      "Ep:8, loss:0.00004, loss_test:0.11692, lr:1.00e-02, fs:0.67984 (r=0.869,p=0.558),  time:19.510, tt:175.587\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.11320, lr:1.00e-02, fs:0.69492 (r=0.828,p=0.599),  time:19.533, tt:195.327\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.11080, lr:1.00e-02, fs:0.71818 (r=0.798,p=0.653),  time:19.501, tt:214.508\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.10935, lr:1.00e-02, fs:0.68966 (r=0.707,p=0.673),  time:19.495, tt:233.937\n",
      "Ep:12, loss:0.00003, loss_test:0.10815, lr:1.00e-02, fs:0.68687 (r=0.687,p=0.687),  time:19.638, tt:255.300\n",
      "Ep:13, loss:0.00003, loss_test:0.10679, lr:1.00e-02, fs:0.69036 (r=0.687,p=0.694),  time:19.622, tt:274.711\n",
      "Ep:14, loss:0.00003, loss_test:0.10538, lr:1.00e-02, fs:0.70297 (r=0.717,p=0.689),  time:19.593, tt:293.901\n",
      "Ep:15, loss:0.00003, loss_test:0.10430, lr:1.00e-02, fs:0.71154 (r=0.747,p=0.679),  time:19.616, tt:313.857\n",
      "Ep:16, loss:0.00003, loss_test:0.10296, lr:1.00e-02, fs:0.70476 (r=0.747,p=0.667),  time:19.612, tt:333.400\n",
      "Ep:17, loss:0.00003, loss_test:0.10069, lr:1.00e-02, fs:0.70531 (r=0.737,p=0.676),  time:19.652, tt:353.739\n",
      "Ep:18, loss:0.00003, loss_test:0.09846, lr:1.00e-02, fs:0.71875 (r=0.697,p=0.742),  time:19.730, tt:374.874\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.09700, lr:1.00e-02, fs:0.68156 (r=0.616,p=0.762),  time:19.810, tt:396.192\n",
      "Ep:20, loss:0.00003, loss_test:0.09583, lr:1.00e-02, fs:0.68539 (r=0.616,p=0.772),  time:19.875, tt:417.384\n",
      "Ep:21, loss:0.00003, loss_test:0.09480, lr:1.00e-02, fs:0.69565 (r=0.646,p=0.753),  time:19.936, tt:438.588\n",
      "Ep:22, loss:0.00003, loss_test:0.09403, lr:1.00e-02, fs:0.70899 (r=0.677,p=0.744),  time:19.982, tt:459.574\n",
      "Ep:23, loss:0.00003, loss_test:0.09309, lr:1.00e-02, fs:0.74611 (r=0.727,p=0.766),  time:19.970, tt:479.282\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.09150, lr:1.00e-02, fs:0.72340 (r=0.687,p=0.764),  time:20.029, tt:500.734\n",
      "Ep:25, loss:0.00003, loss_test:0.08984, lr:1.00e-02, fs:0.73626 (r=0.677,p=0.807),  time:20.113, tt:522.934\n",
      "Ep:26, loss:0.00003, loss_test:0.08864, lr:1.00e-02, fs:0.73034 (r=0.657,p=0.823),  time:20.148, tt:543.986\n",
      "Ep:27, loss:0.00002, loss_test:0.08756, lr:1.00e-02, fs:0.75138 (r=0.687,p=0.829),  time:20.193, tt:565.409\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.08656, lr:1.00e-02, fs:0.77487 (r=0.747,p=0.804),  time:20.188, tt:585.440\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.08554, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:20.200, tt:606.006\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.08458, lr:1.00e-02, fs:0.76087 (r=0.707,p=0.824),  time:20.259, tt:628.015\n",
      "Ep:31, loss:0.00002, loss_test:0.08392, lr:1.00e-02, fs:0.75556 (r=0.687,p=0.840),  time:20.283, tt:649.046\n",
      "Ep:32, loss:0.00002, loss_test:0.08314, lr:1.00e-02, fs:0.77174 (r=0.717,p=0.835),  time:20.324, tt:670.702\n",
      "Ep:33, loss:0.00002, loss_test:0.08258, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:20.334, tt:691.369\n",
      "Ep:34, loss:0.00002, loss_test:0.08202, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:20.312, tt:710.920\n",
      "Ep:35, loss:0.00002, loss_test:0.08155, lr:1.00e-02, fs:0.76344 (r=0.717,p=0.816),  time:20.322, tt:731.595\n",
      "Ep:36, loss:0.00002, loss_test:0.08102, lr:1.00e-02, fs:0.74725 (r=0.687,p=0.819),  time:20.346, tt:752.818\n",
      "Ep:37, loss:0.00002, loss_test:0.08024, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:20.392, tt:774.906\n",
      "Ep:38, loss:0.00002, loss_test:0.07965, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:20.399, tt:795.553\n",
      "Ep:39, loss:0.00002, loss_test:0.07920, lr:1.00e-02, fs:0.77838 (r=0.727,p=0.837),  time:20.423, tt:816.929\n",
      "Ep:40, loss:0.00002, loss_test:0.07890, lr:1.00e-02, fs:0.75138 (r=0.687,p=0.829),  time:20.477, tt:839.567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:41, loss:0.00002, loss_test:0.07830, lr:9.90e-03, fs:0.76344 (r=0.717,p=0.816),  time:20.462, tt:859.398\n",
      "Ep:42, loss:0.00002, loss_test:0.07768, lr:9.80e-03, fs:0.77249 (r=0.737,p=0.811),  time:20.483, tt:880.764\n",
      "Ep:43, loss:0.00002, loss_test:0.07726, lr:9.70e-03, fs:0.76344 (r=0.717,p=0.816),  time:20.483, tt:901.264\n",
      "Ep:44, loss:0.00002, loss_test:0.07678, lr:9.61e-03, fs:0.75556 (r=0.687,p=0.840),  time:20.484, tt:921.795\n",
      "Ep:45, loss:0.00002, loss_test:0.07582, lr:9.51e-03, fs:0.77419 (r=0.727,p=0.828),  time:20.458, tt:941.054\n",
      "Ep:46, loss:0.00002, loss_test:0.07499, lr:9.41e-03, fs:0.78075 (r=0.737,p=0.830),  time:20.429, tt:960.180\n",
      "Ep:47, loss:0.00002, loss_test:0.07450, lr:9.32e-03, fs:0.77838 (r=0.727,p=0.837),  time:20.416, tt:979.960\n",
      "Ep:48, loss:0.00002, loss_test:0.07418, lr:9.23e-03, fs:0.77174 (r=0.717,p=0.835),  time:20.400, tt:999.600\n",
      "Ep:49, loss:0.00002, loss_test:0.07374, lr:9.14e-03, fs:0.77838 (r=0.727,p=0.837),  time:20.387, tt:1019.351\n",
      "Ep:50, loss:0.00002, loss_test:0.07338, lr:9.04e-03, fs:0.77419 (r=0.727,p=0.828),  time:20.379, tt:1039.346\n",
      "Ep:51, loss:0.00002, loss_test:0.07328, lr:8.95e-03, fs:0.77838 (r=0.727,p=0.837),  time:20.357, tt:1058.546\n",
      "Ep:52, loss:0.00002, loss_test:0.07311, lr:8.86e-03, fs:0.77838 (r=0.727,p=0.837),  time:20.354, tt:1078.745\n",
      "Ep:53, loss:0.00002, loss_test:0.07260, lr:8.78e-03, fs:0.77419 (r=0.727,p=0.828),  time:20.373, tt:1100.164\n",
      "Ep:54, loss:0.00001, loss_test:0.07224, lr:8.69e-03, fs:0.77419 (r=0.727,p=0.828),  time:20.353, tt:1119.403\n",
      "Ep:55, loss:0.00001, loss_test:0.07212, lr:8.60e-03, fs:0.77596 (r=0.717,p=0.845),  time:20.355, tt:1139.867\n",
      "Ep:56, loss:0.00001, loss_test:0.07175, lr:8.51e-03, fs:0.77174 (r=0.717,p=0.835),  time:20.342, tt:1159.470\n",
      "Ep:57, loss:0.00001, loss_test:0.07131, lr:8.43e-03, fs:0.77838 (r=0.727,p=0.837),  time:20.322, tt:1178.676\n",
      "Ep:58, loss:0.00001, loss_test:0.07128, lr:8.35e-03, fs:0.77838 (r=0.727,p=0.837),  time:20.316, tt:1198.615\n",
      "Ep:59, loss:0.00001, loss_test:0.07116, lr:8.26e-03, fs:0.77838 (r=0.727,p=0.837),  time:20.312, tt:1218.730\n",
      "Ep:60, loss:0.00001, loss_test:0.07087, lr:8.18e-03, fs:0.77838 (r=0.727,p=0.837),  time:20.306, tt:1238.670\n",
      "Ep:61, loss:0.00001, loss_test:0.07076, lr:8.10e-03, fs:0.77838 (r=0.727,p=0.837),  time:20.327, tt:1260.253\n",
      "Ep:62, loss:0.00001, loss_test:0.07073, lr:8.02e-03, fs:0.78261 (r=0.727,p=0.847),  time:20.340, tt:1281.445\n",
      "Ep:63, loss:0.00001, loss_test:0.07053, lr:7.94e-03, fs:0.78261 (r=0.727,p=0.847),  time:20.346, tt:1302.144\n",
      "Ep:64, loss:0.00001, loss_test:0.07051, lr:7.86e-03, fs:0.78261 (r=0.727,p=0.847),  time:20.367, tt:1323.869\n",
      "Ep:65, loss:0.00001, loss_test:0.07063, lr:7.78e-03, fs:0.78022 (r=0.717,p=0.855),  time:20.386, tt:1345.456\n",
      "Ep:66, loss:0.00001, loss_test:0.07058, lr:7.70e-03, fs:0.78022 (r=0.717,p=0.855),  time:20.407, tt:1367.250\n",
      "Ep:67, loss:0.00001, loss_test:0.07041, lr:7.62e-03, fs:0.78689 (r=0.727,p=0.857),  time:20.416, tt:1388.272\n",
      "Ep:68, loss:0.00001, loss_test:0.07059, lr:7.55e-03, fs:0.75978 (r=0.687,p=0.850),  time:20.427, tt:1409.443\n",
      "Ep:69, loss:0.00001, loss_test:0.07029, lr:7.47e-03, fs:0.76667 (r=0.697,p=0.852),  time:20.437, tt:1430.614\n",
      "Ep:70, loss:0.00001, loss_test:0.07014, lr:7.40e-03, fs:0.78022 (r=0.717,p=0.855),  time:20.441, tt:1451.293\n",
      "Ep:71, loss:0.00001, loss_test:0.07048, lr:7.32e-03, fs:0.75281 (r=0.677,p=0.848),  time:20.425, tt:1470.592\n",
      "Ep:72, loss:0.00001, loss_test:0.07019, lr:7.25e-03, fs:0.75978 (r=0.687,p=0.850),  time:20.424, tt:1490.979\n",
      "Ep:73, loss:0.00001, loss_test:0.06991, lr:7.18e-03, fs:0.78689 (r=0.727,p=0.857),  time:20.408, tt:1510.218\n",
      "Ep:74, loss:0.00001, loss_test:0.07014, lr:7.11e-03, fs:0.74576 (r=0.667,p=0.846),  time:20.398, tt:1529.861\n",
      "Ep:75, loss:0.00001, loss_test:0.06981, lr:7.03e-03, fs:0.75978 (r=0.687,p=0.850),  time:20.382, tt:1549.044\n",
      "Ep:76, loss:0.00001, loss_test:0.06935, lr:6.96e-03, fs:0.77348 (r=0.707,p=0.854),  time:20.362, tt:1567.900\n",
      "Ep:77, loss:0.00001, loss_test:0.06942, lr:6.89e-03, fs:0.75281 (r=0.677,p=0.848),  time:20.369, tt:1588.792\n",
      "Ep:78, loss:0.00001, loss_test:0.06949, lr:6.83e-03, fs:0.75000 (r=0.667,p=0.857),  time:20.371, tt:1609.346\n",
      "Ep:79, loss:0.00001, loss_test:0.06903, lr:6.76e-03, fs:0.76667 (r=0.697,p=0.852),  time:20.360, tt:1628.816\n",
      "Ep:80, loss:0.00001, loss_test:0.06878, lr:6.69e-03, fs:0.76667 (r=0.697,p=0.852),  time:20.357, tt:1648.915\n",
      "Ep:81, loss:0.00001, loss_test:0.06896, lr:6.62e-03, fs:0.77095 (r=0.697,p=0.863),  time:20.357, tt:1669.294\n",
      "Ep:82, loss:0.00001, loss_test:0.06866, lr:6.56e-03, fs:0.77095 (r=0.697,p=0.863),  time:20.352, tt:1689.236\n",
      "Ep:83, loss:0.00001, loss_test:0.06822, lr:6.49e-03, fs:0.76667 (r=0.697,p=0.852),  time:20.360, tt:1710.242\n",
      "Ep:84, loss:0.00001, loss_test:0.06818, lr:6.43e-03, fs:0.77528 (r=0.697,p=0.873),  time:20.351, tt:1729.819\n",
      "Ep:85, loss:0.00001, loss_test:0.06823, lr:6.36e-03, fs:0.77528 (r=0.697,p=0.873),  time:20.362, tt:1751.103\n",
      "Ep:86, loss:0.00001, loss_test:0.06783, lr:6.30e-03, fs:0.77528 (r=0.697,p=0.873),  time:20.349, tt:1770.342\n",
      "Ep:87, loss:0.00001, loss_test:0.06757, lr:6.24e-03, fs:0.77528 (r=0.697,p=0.873),  time:20.353, tt:1791.050\n",
      "Ep:88, loss:0.00001, loss_test:0.06766, lr:6.17e-03, fs:0.77528 (r=0.697,p=0.873),  time:20.354, tt:1811.524\n",
      "Ep:89, loss:0.00001, loss_test:0.06754, lr:6.11e-03, fs:0.77966 (r=0.697,p=0.885),  time:20.372, tt:1833.518\n",
      "Ep:90, loss:0.00001, loss_test:0.06719, lr:6.05e-03, fs:0.77528 (r=0.697,p=0.873),  time:20.361, tt:1852.883\n",
      "Ep:91, loss:0.00001, loss_test:0.06721, lr:5.99e-03, fs:0.77966 (r=0.697,p=0.885),  time:20.342, tt:1871.428\n",
      "Ep:92, loss:0.00001, loss_test:0.06735, lr:5.93e-03, fs:0.77966 (r=0.697,p=0.885),  time:20.337, tt:1891.378\n",
      "Ep:93, loss:0.00001, loss_test:0.06704, lr:5.87e-03, fs:0.77966 (r=0.697,p=0.885),  time:20.346, tt:1912.549\n",
      "Ep:94, loss:0.00001, loss_test:0.06680, lr:5.81e-03, fs:0.80000 (r=0.727,p=0.889),  time:20.351, tt:1933.321\n",
      "Ep:95, loss:0.00001, loss_test:0.06705, lr:5.75e-03, fs:0.78409 (r=0.697,p=0.896),  time:20.356, tt:1954.180\n",
      "Ep:96, loss:0.00001, loss_test:0.06699, lr:5.70e-03, fs:0.78409 (r=0.697,p=0.896),  time:20.349, tt:1973.879\n",
      "Ep:97, loss:0.00001, loss_test:0.06665, lr:5.64e-03, fs:0.77966 (r=0.697,p=0.885),  time:20.356, tt:1994.895\n",
      "Ep:98, loss:0.00001, loss_test:0.06683, lr:5.58e-03, fs:0.78409 (r=0.697,p=0.896),  time:20.353, tt:2014.903\n",
      "Ep:99, loss:0.00001, loss_test:0.06691, lr:5.53e-03, fs:0.77714 (r=0.687,p=0.895),  time:20.350, tt:2034.998\n",
      "Ep:100, loss:0.00001, loss_test:0.06660, lr:5.47e-03, fs:0.77966 (r=0.697,p=0.885),  time:20.353, tt:2055.658\n",
      "Ep:101, loss:0.00001, loss_test:0.06656, lr:5.42e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.350, tt:2075.661\n",
      "Ep:102, loss:0.00001, loss_test:0.06665, lr:5.36e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.344, tt:2095.476\n",
      "Ep:103, loss:0.00001, loss_test:0.06633, lr:5.31e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.350, tt:2116.355\n",
      "Ep:104, loss:0.00001, loss_test:0.06609, lr:5.26e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.350, tt:2136.757\n",
      "Ep:105, loss:0.00001, loss_test:0.06615, lr:5.20e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.347, tt:2156.752\n",
      "Ep:106, loss:0.00001, loss_test:0.06596, lr:5.15e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.341, tt:2176.456\n",
      "Ep:107, loss:0.00001, loss_test:0.06571, lr:5.10e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.329, tt:2195.537\n",
      "Ep:108, loss:0.00001, loss_test:0.06576, lr:5.05e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.320, tt:2214.853\n",
      "Ep:109, loss:0.00001, loss_test:0.06577, lr:5.00e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.317, tt:2234.844\n",
      "Ep:110, loss:0.00001, loss_test:0.06562, lr:4.95e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.319, tt:2255.415\n",
      "Ep:111, loss:0.00001, loss_test:0.06545, lr:4.90e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.310, tt:2274.749\n",
      "Ep:112, loss:0.00001, loss_test:0.06552, lr:4.85e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.314, tt:2295.460\n",
      "Ep:113, loss:0.00001, loss_test:0.06560, lr:4.80e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.311, tt:2315.458\n",
      "Ep:114, loss:0.00001, loss_test:0.06543, lr:4.75e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.306, tt:2335.137\n",
      "Ep:115, loss:0.00001, loss_test:0.06529, lr:4.71e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.301, tt:2354.863\n",
      "Ep:116, loss:0.00001, loss_test:0.06543, lr:4.66e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.286, tt:2373.511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:117, loss:0.00001, loss_test:0.06542, lr:4.61e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.276, tt:2392.546\n",
      "Ep:118, loss:0.00001, loss_test:0.06533, lr:4.57e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.267, tt:2411.741\n",
      "Ep:119, loss:0.00001, loss_test:0.06537, lr:4.52e-03, fs:0.77907 (r=0.677,p=0.918),  time:20.248, tt:2429.817\n",
      "Ep:120, loss:0.00001, loss_test:0.06545, lr:4.48e-03, fs:0.77907 (r=0.677,p=0.918),  time:20.238, tt:2448.820\n",
      "Ep:121, loss:0.00001, loss_test:0.06537, lr:4.43e-03, fs:0.77907 (r=0.677,p=0.918),  time:20.242, tt:2469.532\n",
      "Ep:122, loss:0.00001, loss_test:0.06533, lr:4.39e-03, fs:0.77907 (r=0.677,p=0.918),  time:20.238, tt:2489.296\n",
      "Ep:123, loss:0.00001, loss_test:0.06531, lr:4.34e-03, fs:0.77907 (r=0.677,p=0.918),  time:20.220, tt:2507.296\n",
      "Ep:124, loss:0.00001, loss_test:0.06524, lr:4.30e-03, fs:0.77907 (r=0.677,p=0.918),  time:20.221, tt:2527.562\n",
      "Ep:125, loss:0.00001, loss_test:0.06519, lr:4.26e-03, fs:0.77907 (r=0.677,p=0.918),  time:20.220, tt:2547.669\n",
      "Ep:126, loss:0.00001, loss_test:0.06516, lr:4.21e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.217, tt:2567.555\n",
      "Ep:127, loss:0.00001, loss_test:0.06500, lr:4.17e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.212, tt:2587.129\n",
      "Ep:128, loss:0.00001, loss_test:0.06490, lr:4.13e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.206, tt:2606.572\n",
      "Ep:129, loss:0.00001, loss_test:0.06488, lr:4.09e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.197, tt:2625.655\n",
      "Ep:130, loss:0.00001, loss_test:0.06476, lr:4.05e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.195, tt:2645.554\n",
      "Ep:131, loss:0.00001, loss_test:0.06465, lr:4.01e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.180, tt:2663.741\n",
      "Ep:132, loss:0.00001, loss_test:0.06464, lr:3.97e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.175, tt:2683.300\n",
      "Ep:133, loss:0.00001, loss_test:0.06456, lr:3.93e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.175, tt:2703.407\n",
      "Ep:134, loss:0.00001, loss_test:0.06449, lr:3.89e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.164, tt:2722.125\n",
      "Ep:135, loss:0.00001, loss_test:0.06442, lr:3.85e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.148, tt:2740.152\n",
      "Ep:136, loss:0.00001, loss_test:0.06430, lr:3.81e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.139, tt:2759.031\n",
      "Ep:137, loss:0.00001, loss_test:0.06435, lr:3.77e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.135, tt:2778.601\n",
      "Ep:138, loss:0.00001, loss_test:0.06417, lr:3.73e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.138, tt:2799.235\n",
      "Ep:139, loss:0.00001, loss_test:0.06408, lr:3.70e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.139, tt:2819.493\n",
      "Ep:140, loss:0.00001, loss_test:0.06416, lr:3.66e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.136, tt:2839.215\n",
      "Ep:141, loss:0.00001, loss_test:0.06397, lr:3.62e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.136, tt:2859.359\n",
      "Ep:142, loss:0.00001, loss_test:0.06385, lr:3.59e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.127, tt:2878.221\n",
      "Ep:143, loss:0.00001, loss_test:0.06393, lr:3.55e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.118, tt:2897.012\n",
      "Ep:144, loss:0.00001, loss_test:0.06381, lr:3.52e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.114, tt:2916.546\n",
      "Ep:145, loss:0.00001, loss_test:0.06375, lr:3.48e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.112, tt:2936.363\n",
      "Ep:146, loss:0.00001, loss_test:0.06390, lr:3.45e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.103, tt:2955.115\n",
      "Ep:147, loss:0.00001, loss_test:0.06381, lr:3.41e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.105, tt:2975.614\n",
      "Ep:148, loss:0.00001, loss_test:0.06375, lr:3.38e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.097, tt:2994.496\n",
      "Ep:149, loss:0.00001, loss_test:0.06388, lr:3.34e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.090, tt:3013.459\n",
      "Ep:150, loss:0.00001, loss_test:0.06380, lr:3.31e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.080, tt:3032.102\n",
      "Ep:151, loss:0.00001, loss_test:0.06370, lr:3.28e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.083, tt:3052.682\n",
      "Ep:152, loss:0.00001, loss_test:0.06373, lr:3.24e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.083, tt:3072.708\n",
      "Ep:153, loss:0.00001, loss_test:0.06376, lr:3.21e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.091, tt:3093.986\n",
      "Ep:154, loss:0.00001, loss_test:0.06378, lr:3.18e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.087, tt:3113.529\n",
      "Ep:155, loss:0.00001, loss_test:0.06372, lr:3.15e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.086, tt:3133.468\n",
      "Ep:156, loss:0.00000, loss_test:0.06374, lr:3.12e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.075, tt:3151.748\n",
      "Ep:157, loss:0.00000, loss_test:0.06365, lr:3.09e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.069, tt:3170.934\n",
      "Ep:158, loss:0.00000, loss_test:0.06368, lr:3.05e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.065, tt:3190.270\n",
      "Ep:159, loss:0.00000, loss_test:0.06357, lr:3.02e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.057, tt:3209.129\n",
      "Ep:160, loss:0.00000, loss_test:0.06373, lr:2.99e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.049, tt:3227.848\n",
      "Ep:161, loss:0.00000, loss_test:0.06371, lr:2.96e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.034, tt:3245.447\n",
      "Ep:162, loss:0.00000, loss_test:0.06359, lr:2.93e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.030, tt:3264.834\n",
      "Ep:163, loss:0.00000, loss_test:0.06373, lr:2.90e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.024, tt:3283.913\n",
      "Ep:164, loss:0.00000, loss_test:0.06377, lr:2.88e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.016, tt:3302.624\n",
      "Ep:165, loss:0.00000, loss_test:0.06355, lr:2.85e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.011, tt:3321.860\n",
      "Ep:166, loss:0.00000, loss_test:0.06367, lr:2.82e-03, fs:0.76923 (r=0.657,p=0.929),  time:20.006, tt:3341.046\n",
      "Ep:167, loss:0.00000, loss_test:0.06388, lr:2.79e-03, fs:0.76923 (r=0.657,p=0.929),  time:20.003, tt:3360.549\n",
      "Ep:168, loss:0.00000, loss_test:0.06368, lr:2.76e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.995, tt:3379.224\n",
      "Ep:169, loss:0.00000, loss_test:0.06365, lr:2.73e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.983, tt:3397.071\n",
      "Ep:170, loss:0.00000, loss_test:0.06377, lr:2.71e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.972, tt:3415.164\n",
      "Ep:171, loss:0.00000, loss_test:0.06372, lr:2.68e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.974, tt:3435.462\n",
      "Ep:172, loss:0.00000, loss_test:0.06367, lr:2.65e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.962, tt:3453.461\n",
      "Ep:173, loss:0.00000, loss_test:0.06377, lr:2.63e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.959, tt:3472.931\n",
      "Ep:174, loss:0.00000, loss_test:0.06372, lr:2.60e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.949, tt:3491.029\n",
      "Ep:175, loss:0.00000, loss_test:0.06367, lr:2.57e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.952, tt:3511.536\n",
      "Ep:176, loss:0.00000, loss_test:0.06377, lr:2.55e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.959, tt:3532.771\n",
      "Ep:177, loss:0.00000, loss_test:0.06364, lr:2.52e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.953, tt:3551.702\n",
      "Ep:178, loss:0.00000, loss_test:0.06366, lr:2.50e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.940, tt:3569.238\n",
      "Ep:179, loss:0.00000, loss_test:0.06374, lr:2.47e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.943, tt:3589.690\n",
      "Ep:180, loss:0.00000, loss_test:0.06365, lr:2.45e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.937, tt:3608.642\n",
      "Ep:181, loss:0.00000, loss_test:0.06372, lr:2.42e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.928, tt:3626.885\n",
      "Ep:182, loss:0.00000, loss_test:0.06367, lr:2.40e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.927, tt:3646.685\n",
      "Ep:183, loss:0.00000, loss_test:0.06363, lr:2.38e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.921, tt:3665.477\n",
      "Ep:184, loss:0.00000, loss_test:0.06382, lr:2.35e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.938, tt:3688.602\n",
      "Ep:185, loss:0.00000, loss_test:0.06374, lr:2.33e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.944, tt:3709.643\n",
      "Ep:186, loss:0.00000, loss_test:0.06362, lr:2.31e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.942, tt:3729.191\n",
      "Ep:187, loss:0.00000, loss_test:0.06374, lr:2.28e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.940, tt:3748.806\n",
      "Ep:188, loss:0.00000, loss_test:0.06373, lr:2.26e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.944, tt:3769.348\n",
      "Ep:189, loss:0.00000, loss_test:0.06366, lr:2.24e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.950, tt:3790.575\n",
      "Ep:190, loss:0.00000, loss_test:0.06377, lr:2.21e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.953, tt:3811.082\n",
      "Ep:191, loss:0.00000, loss_test:0.06377, lr:2.19e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.951, tt:3830.509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:192, loss:0.00000, loss_test:0.06370, lr:2.17e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.943, tt:3848.984\n",
      "Ep:193, loss:0.00000, loss_test:0.06373, lr:2.15e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.936, tt:3867.515\n",
      "Ep:194, loss:0.00000, loss_test:0.06374, lr:2.13e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.935, tt:3887.243\n",
      "Ep:195, loss:0.00000, loss_test:0.06373, lr:2.11e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.939, tt:3908.021\n",
      "Ep:196, loss:0.00000, loss_test:0.06381, lr:2.08e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.940, tt:3928.083\n",
      "Ep:197, loss:0.00000, loss_test:0.06382, lr:2.06e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.944, tt:3948.950\n",
      "Ep:198, loss:0.00000, loss_test:0.06379, lr:2.04e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.943, tt:3968.640\n",
      "Ep:199, loss:0.00000, loss_test:0.06381, lr:2.02e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.939, tt:3987.820\n",
      "Ep:200, loss:0.00000, loss_test:0.06386, lr:2.00e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.929, tt:4005.798\n",
      "Ep:201, loss:0.00000, loss_test:0.06382, lr:1.98e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.927, tt:4025.244\n",
      "Ep:202, loss:0.00000, loss_test:0.06385, lr:1.96e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.925, tt:4044.851\n",
      "Ep:203, loss:0.00000, loss_test:0.06378, lr:1.94e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.928, tt:4065.390\n",
      "Ep:204, loss:0.00000, loss_test:0.06386, lr:1.92e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.931, tt:4085.937\n",
      "Ep:205, loss:0.00000, loss_test:0.06379, lr:1.90e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.922, tt:4103.928\n",
      "Ep:206, loss:0.00000, loss_test:0.06379, lr:1.89e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.921, tt:4123.598\n",
      "Ep:207, loss:0.00000, loss_test:0.06378, lr:1.87e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.916, tt:4142.541\n",
      "Ep:208, loss:0.00000, loss_test:0.06381, lr:1.85e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.919, tt:4163.092\n",
      "Ep:209, loss:0.00000, loss_test:0.06371, lr:1.83e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.917, tt:4182.584\n",
      "Ep:210, loss:0.00000, loss_test:0.06387, lr:1.81e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.911, tt:4201.275\n",
      "Ep:211, loss:0.00000, loss_test:0.06378, lr:1.79e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.908, tt:4220.580\n",
      "Ep:212, loss:0.00000, loss_test:0.06368, lr:1.78e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.909, tt:4240.603\n",
      "Ep:213, loss:0.00000, loss_test:0.06383, lr:1.76e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.909, tt:4260.435\n",
      "Ep:214, loss:0.00000, loss_test:0.06378, lr:1.74e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.904, tt:4279.258\n",
      "Ep:215, loss:0.00000, loss_test:0.06368, lr:1.72e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.902, tt:4298.861\n",
      "Ep:216, loss:0.00000, loss_test:0.06386, lr:1.71e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.914, tt:4321.372\n",
      "Ep:217, loss:0.00000, loss_test:0.06379, lr:1.69e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.914, tt:4341.156\n",
      "Ep:218, loss:0.00000, loss_test:0.06367, lr:1.67e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.910, tt:4360.216\n",
      "Ep:219, loss:0.00000, loss_test:0.06389, lr:1.65e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.914, tt:4381.024\n",
      "Ep:220, loss:0.00000, loss_test:0.06388, lr:1.64e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.911, tt:4400.392\n",
      "Ep:221, loss:0.00000, loss_test:0.06373, lr:1.62e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.910, tt:4419.914\n",
      "Ep:222, loss:0.00000, loss_test:0.06376, lr:1.61e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.911, tt:4440.163\n",
      "Ep:223, loss:0.00000, loss_test:0.06389, lr:1.59e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.911, tt:4460.159\n",
      "Ep:224, loss:0.00000, loss_test:0.06381, lr:1.57e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.909, tt:4479.632\n",
      "Ep:225, loss:0.00000, loss_test:0.06371, lr:1.56e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.913, tt:4500.448\n",
      "Ep:226, loss:0.00000, loss_test:0.06381, lr:1.54e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.921, tt:4522.135\n",
      "Ep:227, loss:0.00000, loss_test:0.06380, lr:1.53e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.924, tt:4542.689\n",
      "Ep:228, loss:0.00000, loss_test:0.06368, lr:1.51e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.925, tt:4562.812\n",
      "Ep:229, loss:0.00000, loss_test:0.06379, lr:1.50e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.928, tt:4583.380\n",
      "Ep:230, loss:0.00000, loss_test:0.06382, lr:1.48e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.928, tt:4603.360\n",
      "Ep:231, loss:0.00000, loss_test:0.06373, lr:1.47e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.927, tt:4623.060\n",
      "Ep:232, loss:0.00000, loss_test:0.06378, lr:1.45e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.927, tt:4642.975\n",
      "Ep:233, loss:0.00000, loss_test:0.06385, lr:1.44e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.931, tt:4663.810\n",
      "Ep:234, loss:0.00000, loss_test:0.06379, lr:1.42e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.934, tt:4684.549\n",
      "Ep:235, loss:0.00000, loss_test:0.06379, lr:1.41e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.932, tt:4704.034\n",
      "Ep:236, loss:0.00000, loss_test:0.06390, lr:1.39e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.934, tt:4724.332\n",
      "Ep:237, loss:0.00000, loss_test:0.06383, lr:1.38e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.932, tt:4743.883\n",
      "Ep:238, loss:0.00000, loss_test:0.06376, lr:1.37e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.931, tt:4763.558\n",
      "Ep:239, loss:0.00000, loss_test:0.06396, lr:1.35e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.936, tt:4784.666\n",
      "Ep:240, loss:0.00000, loss_test:0.06397, lr:1.34e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.934, tt:4804.035\n",
      "Ep:241, loss:0.00000, loss_test:0.06380, lr:1.33e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.941, tt:4825.834\n",
      "Ep:242, loss:0.00000, loss_test:0.06382, lr:1.31e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.941, tt:4845.644\n",
      "Ep:243, loss:0.00000, loss_test:0.06393, lr:1.30e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.943, tt:4866.088\n",
      "Ep:244, loss:0.00000, loss_test:0.06395, lr:1.29e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.944, tt:4886.303\n",
      "Ep:245, loss:0.00000, loss_test:0.06385, lr:1.27e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.943, tt:4906.055\n",
      "Ep:246, loss:0.00000, loss_test:0.06388, lr:1.26e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.941, tt:4925.474\n",
      "Ep:247, loss:0.00000, loss_test:0.06396, lr:1.25e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.944, tt:4946.082\n",
      "Ep:248, loss:0.00000, loss_test:0.06394, lr:1.24e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.946, tt:4966.589\n",
      "Ep:249, loss:0.00000, loss_test:0.06389, lr:1.22e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.949, tt:4987.242\n",
      "Ep:250, loss:0.00000, loss_test:0.06398, lr:1.21e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.952, tt:5007.981\n",
      "Ep:251, loss:0.00000, loss_test:0.06395, lr:1.20e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.951, tt:5027.773\n",
      "Ep:252, loss:0.00000, loss_test:0.06388, lr:1.19e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.953, tt:5048.200\n",
      "Ep:253, loss:0.00000, loss_test:0.06402, lr:1.18e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.953, tt:5068.019\n",
      "Ep:254, loss:0.00000, loss_test:0.06404, lr:1.16e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.958, tt:5089.165\n",
      "Ep:255, loss:0.00000, loss_test:0.06393, lr:1.15e-03, fs:0.78824 (r=0.677,p=0.944),  time:19.954, tt:5108.105\n",
      "Ep:256, loss:0.00000, loss_test:0.06397, lr:1.14e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.953, tt:5127.992\n",
      "Ep:257, loss:0.00000, loss_test:0.06406, lr:1.13e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.955, tt:5148.296\n",
      "Ep:258, loss:0.00000, loss_test:0.06404, lr:1.12e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.957, tt:5168.894\n",
      "Ep:259, loss:0.00000, loss_test:0.06396, lr:1.11e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.958, tt:5189.104\n",
      "Ep:260, loss:0.00000, loss_test:0.06408, lr:1.10e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.956, tt:5208.412\n",
      "Ep:261, loss:0.00000, loss_test:0.06404, lr:1.08e-03, fs:0.78824 (r=0.677,p=0.944),  time:19.953, tt:5227.643\n",
      "Ep:262, loss:0.00000, loss_test:0.06397, lr:1.07e-03, fs:0.78824 (r=0.677,p=0.944),  time:19.950, tt:5246.735\n",
      "Ep:263, loss:0.00000, loss_test:0.06409, lr:1.06e-03, fs:0.78824 (r=0.677,p=0.944),  time:19.953, tt:5267.724\n",
      "Ep:264, loss:0.00000, loss_test:0.06410, lr:1.05e-03, fs:0.78824 (r=0.677,p=0.944),  time:19.954, tt:5287.787\n",
      "Ep:265, loss:0.00000, loss_test:0.06401, lr:1.04e-03, fs:0.78824 (r=0.677,p=0.944),  time:19.959, tt:5309.089\n",
      "Ep:266, loss:0.00000, loss_test:0.06402, lr:1.03e-03, fs:0.78824 (r=0.677,p=0.944),  time:19.955, tt:5328.063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:267, loss:0.00000, loss_test:0.06412, lr:1.02e-03, fs:0.78824 (r=0.677,p=0.944),  time:19.957, tt:5348.493\n",
      "Ep:268, loss:0.00000, loss_test:0.06408, lr:1.01e-03, fs:0.78824 (r=0.677,p=0.944),  time:19.952, tt:5367.118\n",
      "Ep:269, loss:0.00000, loss_test:0.06400, lr:1.00e-03, fs:0.78824 (r=0.677,p=0.944),  time:19.948, tt:5386.066\n",
      "Ep:270, loss:0.00000, loss_test:0.06414, lr:9.91e-04, fs:0.78824 (r=0.677,p=0.944),  time:19.946, tt:5405.359\n",
      "Ep:271, loss:0.00000, loss_test:0.06419, lr:9.81e-04, fs:0.78824 (r=0.677,p=0.944),  time:19.945, tt:5425.101\n",
      "Ep:272, loss:0.00000, loss_test:0.06411, lr:9.71e-04, fs:0.78824 (r=0.677,p=0.944),  time:19.944, tt:5444.721\n",
      "Ep:273, loss:0.00000, loss_test:0.06403, lr:9.62e-04, fs:0.78824 (r=0.677,p=0.944),  time:19.945, tt:5464.970\n",
      "Ep:274, loss:0.00000, loss_test:0.06415, lr:9.52e-04, fs:0.78824 (r=0.677,p=0.944),  time:19.942, tt:5483.977\n",
      "Ep:275, loss:0.00000, loss_test:0.06420, lr:9.42e-04, fs:0.78824 (r=0.677,p=0.944),  time:19.942, tt:5503.857\n",
      "Ep:276, loss:0.00000, loss_test:0.06411, lr:9.33e-04, fs:0.78824 (r=0.677,p=0.944),  time:19.936, tt:5522.158\n",
      "Ep:277, loss:0.00000, loss_test:0.06409, lr:9.24e-04, fs:0.78824 (r=0.677,p=0.944),  time:19.931, tt:5540.716\n",
      "Ep:278, loss:0.00000, loss_test:0.06419, lr:9.14e-04, fs:0.78824 (r=0.677,p=0.944),  time:19.934, tt:5561.604\n",
      "Ep:279, loss:0.00000, loss_test:0.06420, lr:9.05e-04, fs:0.78824 (r=0.677,p=0.944),  time:19.936, tt:5582.060\n",
      "Ep:280, loss:0.00000, loss_test:0.06410, lr:8.96e-04, fs:0.78824 (r=0.677,p=0.944),  time:19.932, tt:5600.831\n",
      "Ep:281, loss:0.00000, loss_test:0.06404, lr:8.87e-04, fs:0.78824 (r=0.677,p=0.944),  time:19.933, tt:5621.168\n",
      "Ep:282, loss:0.00000, loss_test:0.06418, lr:8.78e-04, fs:0.78824 (r=0.677,p=0.944),  time:19.930, tt:5640.115\n",
      "Ep:283, loss:0.00000, loss_test:0.06423, lr:8.70e-04, fs:0.79290 (r=0.677,p=0.957),  time:19.931, tt:5660.275\n",
      "Ep:284, loss:0.00000, loss_test:0.06415, lr:8.61e-04, fs:0.78824 (r=0.677,p=0.944),  time:19.931, tt:5680.466\n",
      "Ep:285, loss:0.00000, loss_test:0.06408, lr:8.52e-04, fs:0.78824 (r=0.677,p=0.944),  time:19.931, tt:5700.139\n",
      "Ep:286, loss:0.00000, loss_test:0.06415, lr:8.44e-04, fs:0.78824 (r=0.677,p=0.944),  time:19.929, tt:5719.723\n",
      "Ep:287, loss:0.00000, loss_test:0.06420, lr:8.35e-04, fs:0.79290 (r=0.677,p=0.957),  time:19.925, tt:5738.375\n",
      "Ep:288, loss:0.00000, loss_test:0.06416, lr:8.27e-04, fs:0.78824 (r=0.677,p=0.944),  time:19.922, tt:5757.414\n",
      "Ep:289, loss:0.00000, loss_test:0.06411, lr:8.19e-04, fs:0.77381 (r=0.657,p=0.942),  time:19.916, tt:5775.585\n",
      "Ep:290, loss:0.00000, loss_test:0.06417, lr:8.11e-04, fs:0.77381 (r=0.657,p=0.942),  time:19.916, tt:5795.410\n",
      "Ep:291, loss:0.00000, loss_test:0.06420, lr:8.02e-04, fs:0.79290 (r=0.677,p=0.957),  time:19.913, tt:5814.688\n",
      "Ep:292, loss:0.00000, loss_test:0.06414, lr:7.94e-04, fs:0.78824 (r=0.677,p=0.944),  time:19.910, tt:5833.711\n",
      "Ep:293, loss:0.00000, loss_test:0.06414, lr:7.87e-04, fs:0.78824 (r=0.677,p=0.944),  time:19.911, tt:5853.754\n",
      "Ep:294, loss:0.00000, loss_test:0.06420, lr:7.79e-04, fs:0.77844 (r=0.657,p=0.956),  time:19.910, tt:5873.466\n",
      "Ep:295, loss:0.00000, loss_test:0.06418, lr:7.71e-04, fs:0.77844 (r=0.657,p=0.956),  time:19.898, tt:5889.699\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.13103, lr:1.00e-02, fs:0.66429 (r=0.939,p=0.514),  time:15.122, tt:15.122\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.12948, lr:1.00e-02, fs:0.66187 (r=0.929,p=0.514),  time:16.197, tt:32.394\n",
      "Ep:2, loss:0.00004, loss_test:0.12731, lr:1.00e-02, fs:0.66909 (r=0.929,p=0.523),  time:16.595, tt:49.786\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.12443, lr:1.00e-02, fs:0.65918 (r=0.889,p=0.524),  time:16.772, tt:67.088\n",
      "Ep:4, loss:0.00004, loss_test:0.12075, lr:1.00e-02, fs:0.67969 (r=0.879,p=0.554),  time:16.956, tt:84.778\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.11689, lr:1.00e-02, fs:0.68826 (r=0.859,p=0.574),  time:16.994, tt:101.963\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.11358, lr:1.00e-02, fs:0.71130 (r=0.859,p=0.607),  time:16.999, tt:118.992\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.11148, lr:1.00e-02, fs:0.70940 (r=0.838,p=0.615),  time:17.075, tt:136.597\n",
      "Ep:8, loss:0.00004, loss_test:0.10992, lr:1.00e-02, fs:0.71111 (r=0.808,p=0.635),  time:17.090, tt:153.806\n",
      "Ep:9, loss:0.00003, loss_test:0.10848, lr:1.00e-02, fs:0.71429 (r=0.808,p=0.640),  time:17.117, tt:171.169\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.10722, lr:1.00e-02, fs:0.71171 (r=0.798,p=0.642),  time:17.119, tt:188.310\n",
      "Ep:11, loss:0.00003, loss_test:0.10584, lr:1.00e-02, fs:0.71818 (r=0.798,p=0.653),  time:17.080, tt:204.958\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.10456, lr:1.00e-02, fs:0.71818 (r=0.798,p=0.653),  time:17.110, tt:222.434\n",
      "Ep:13, loss:0.00003, loss_test:0.10313, lr:1.00e-02, fs:0.73059 (r=0.808,p=0.667),  time:17.060, tt:238.846\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.10145, lr:1.00e-02, fs:0.73394 (r=0.808,p=0.672),  time:17.117, tt:256.754\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.09972, lr:1.00e-02, fs:0.74312 (r=0.818,p=0.681),  time:17.142, tt:274.266\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.09825, lr:1.00e-02, fs:0.74074 (r=0.808,p=0.684),  time:17.182, tt:292.089\n",
      "Ep:17, loss:0.00003, loss_test:0.09708, lr:1.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:17.248, tt:310.472\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.09592, lr:1.00e-02, fs:0.76279 (r=0.828,p=0.707),  time:17.377, tt:330.168\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.09525, lr:1.00e-02, fs:0.76852 (r=0.838,p=0.709),  time:17.369, tt:347.376\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.09484, lr:1.00e-02, fs:0.76852 (r=0.838,p=0.709),  time:17.438, tt:366.195\n",
      "Ep:21, loss:0.00003, loss_test:0.09431, lr:1.00e-02, fs:0.76852 (r=0.838,p=0.709),  time:17.450, tt:383.894\n",
      "Ep:22, loss:0.00003, loss_test:0.09338, lr:1.00e-02, fs:0.76056 (r=0.818,p=0.711),  time:17.525, tt:403.077\n",
      "Ep:23, loss:0.00003, loss_test:0.09243, lr:1.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:17.583, tt:421.995\n",
      "Ep:24, loss:0.00003, loss_test:0.09151, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:17.596, tt:439.912\n",
      "Ep:25, loss:0.00003, loss_test:0.09064, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:17.640, tt:458.643\n",
      "Ep:26, loss:0.00003, loss_test:0.08983, lr:1.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:17.662, tt:476.882\n",
      "Ep:27, loss:0.00003, loss_test:0.08899, lr:1.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:17.655, tt:494.345\n",
      "Ep:28, loss:0.00003, loss_test:0.08798, lr:1.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:17.668, tt:512.371\n",
      "Ep:29, loss:0.00003, loss_test:0.08688, lr:1.00e-02, fs:0.77725 (r=0.828,p=0.732),  time:17.630, tt:528.911\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.08595, lr:1.00e-02, fs:0.77725 (r=0.828,p=0.732),  time:17.671, tt:547.789\n",
      "Ep:31, loss:0.00002, loss_test:0.08507, lr:1.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:17.710, tt:566.712\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.08420, lr:1.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:17.754, tt:585.888\n",
      "Ep:33, loss:0.00002, loss_test:0.08325, lr:1.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:17.774, tt:604.331\n",
      "Ep:34, loss:0.00002, loss_test:0.08221, lr:1.00e-02, fs:0.78641 (r=0.818,p=0.757),  time:17.825, tt:623.858\n",
      "Ep:35, loss:0.00002, loss_test:0.08127, lr:1.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:17.867, tt:643.208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:36, loss:0.00002, loss_test:0.08058, lr:1.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:17.900, tt:662.305\n",
      "Ep:37, loss:0.00002, loss_test:0.07995, lr:1.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:17.929, tt:681.283\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.07922, lr:1.00e-02, fs:0.80769 (r=0.848,p=0.771),  time:17.951, tt:700.086\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.07854, lr:1.00e-02, fs:0.80769 (r=0.848,p=0.771),  time:17.992, tt:719.679\n",
      "Ep:40, loss:0.00002, loss_test:0.07779, lr:1.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:18.021, tt:738.854\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.07708, lr:1.00e-02, fs:0.80769 (r=0.848,p=0.771),  time:18.047, tt:757.974\n",
      "Ep:42, loss:0.00002, loss_test:0.07633, lr:1.00e-02, fs:0.81159 (r=0.848,p=0.778),  time:18.070, tt:777.029\n",
      "Ep:43, loss:0.00002, loss_test:0.07547, lr:1.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:18.106, tt:796.651\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.07461, lr:1.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:18.143, tt:816.442\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.07375, lr:1.00e-02, fs:0.82692 (r=0.869,p=0.789),  time:18.164, tt:835.563\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.07299, lr:1.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:18.223, tt:856.471\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.07222, lr:1.00e-02, fs:0.83495 (r=0.869,p=0.804),  time:18.240, tt:875.498\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.07155, lr:1.00e-02, fs:0.85437 (r=0.889,p=0.822),  time:18.255, tt:894.498\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.07094, lr:1.00e-02, fs:0.84615 (r=0.889,p=0.807),  time:18.261, tt:913.048\n",
      "Ep:50, loss:0.00002, loss_test:0.07031, lr:1.00e-02, fs:0.84615 (r=0.889,p=0.807),  time:18.257, tt:931.112\n",
      "Ep:51, loss:0.00002, loss_test:0.06974, lr:1.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:18.262, tt:949.599\n",
      "Ep:52, loss:0.00002, loss_test:0.06921, lr:1.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:18.269, tt:968.242\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.06881, lr:1.00e-02, fs:0.85854 (r=0.889,p=0.830),  time:18.291, tt:987.714\n",
      "Ep:54, loss:0.00002, loss_test:0.06853, lr:1.00e-02, fs:0.86957 (r=0.909,p=0.833),  time:18.322, tt:1007.689\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.06813, lr:1.00e-02, fs:0.86538 (r=0.909,p=0.826),  time:18.343, tt:1027.181\n",
      "Ep:56, loss:0.00002, loss_test:0.06776, lr:1.00e-02, fs:0.86957 (r=0.909,p=0.833),  time:18.375, tt:1047.380\n",
      "Ep:57, loss:0.00002, loss_test:0.06719, lr:1.00e-02, fs:0.86957 (r=0.909,p=0.833),  time:18.397, tt:1067.032\n",
      "Ep:58, loss:0.00002, loss_test:0.06680, lr:1.00e-02, fs:0.86538 (r=0.909,p=0.826),  time:18.384, tt:1084.644\n",
      "Ep:59, loss:0.00002, loss_test:0.06627, lr:1.00e-02, fs:0.86538 (r=0.909,p=0.826),  time:18.398, tt:1103.863\n",
      "Ep:60, loss:0.00002, loss_test:0.06609, lr:1.00e-02, fs:0.86538 (r=0.909,p=0.826),  time:18.413, tt:1123.184\n",
      "Ep:61, loss:0.00002, loss_test:0.06597, lr:1.00e-02, fs:0.86538 (r=0.909,p=0.826),  time:18.438, tt:1143.132\n",
      "Ep:62, loss:0.00001, loss_test:0.06558, lr:1.00e-02, fs:0.87081 (r=0.919,p=0.827),  time:18.454, tt:1162.604\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.06541, lr:1.00e-02, fs:0.87081 (r=0.919,p=0.827),  time:18.479, tt:1182.645\n",
      "Ep:64, loss:0.00001, loss_test:0.06496, lr:1.00e-02, fs:0.87500 (r=0.919,p=0.835),  time:18.489, tt:1201.761\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.06478, lr:1.00e-02, fs:0.87500 (r=0.919,p=0.835),  time:18.501, tt:1221.087\n",
      "Ep:66, loss:0.00001, loss_test:0.06461, lr:1.00e-02, fs:0.88038 (r=0.929,p=0.836),  time:18.515, tt:1240.490\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.06448, lr:1.00e-02, fs:0.88350 (r=0.919,p=0.850),  time:18.525, tt:1259.726\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.06439, lr:1.00e-02, fs:0.88350 (r=0.919,p=0.850),  time:18.538, tt:1279.098\n",
      "Ep:69, loss:0.00001, loss_test:0.06420, lr:1.00e-02, fs:0.87805 (r=0.909,p=0.849),  time:18.554, tt:1298.758\n",
      "Ep:70, loss:0.00001, loss_test:0.06392, lr:1.00e-02, fs:0.88350 (r=0.919,p=0.850),  time:18.571, tt:1318.556\n",
      "Ep:71, loss:0.00001, loss_test:0.06379, lr:1.00e-02, fs:0.86700 (r=0.889,p=0.846),  time:18.600, tt:1339.176\n",
      "Ep:72, loss:0.00001, loss_test:0.06337, lr:1.00e-02, fs:0.87805 (r=0.909,p=0.849),  time:18.605, tt:1358.148\n",
      "Ep:73, loss:0.00001, loss_test:0.06329, lr:1.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:18.607, tt:1376.900\n",
      "Ep:74, loss:0.00001, loss_test:0.06293, lr:1.00e-02, fs:0.88235 (r=0.909,p=0.857),  time:18.600, tt:1394.994\n",
      "Ep:75, loss:0.00001, loss_test:0.06286, lr:1.00e-02, fs:0.88000 (r=0.889,p=0.871),  time:18.623, tt:1415.385\n",
      "Ep:76, loss:0.00001, loss_test:0.06247, lr:1.00e-02, fs:0.89552 (r=0.909,p=0.882),  time:18.632, tt:1434.692\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.06246, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:18.637, tt:1453.685\n",
      "Ep:78, loss:0.00001, loss_test:0.06190, lr:1.00e-02, fs:0.90000 (r=0.909,p=0.891),  time:18.644, tt:1472.862\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00001, loss_test:0.06153, lr:1.00e-02, fs:0.90000 (r=0.909,p=0.891),  time:18.651, tt:1492.044\n",
      "Ep:80, loss:0.00001, loss_test:0.06160, lr:1.00e-02, fs:0.88205 (r=0.869,p=0.896),  time:18.667, tt:1512.039\n",
      "Ep:81, loss:0.00001, loss_test:0.06114, lr:1.00e-02, fs:0.88889 (r=0.889,p=0.889),  time:18.671, tt:1531.058\n",
      "Ep:82, loss:0.00001, loss_test:0.06122, lr:1.00e-02, fs:0.88205 (r=0.869,p=0.896),  time:18.685, tt:1550.845\n",
      "Ep:83, loss:0.00001, loss_test:0.06102, lr:1.00e-02, fs:0.88205 (r=0.869,p=0.896),  time:18.685, tt:1569.540\n",
      "Ep:84, loss:0.00001, loss_test:0.06093, lr:1.00e-02, fs:0.90909 (r=0.909,p=0.909),  time:18.698, tt:1589.331\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00001, loss_test:0.06140, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:18.699, tt:1608.115\n",
      "Ep:86, loss:0.00001, loss_test:0.06086, lr:1.00e-02, fs:0.90355 (r=0.899,p=0.908),  time:18.702, tt:1627.110\n",
      "Ep:87, loss:0.00001, loss_test:0.06082, lr:1.00e-02, fs:0.88083 (r=0.859,p=0.904),  time:18.719, tt:1647.301\n",
      "Ep:88, loss:0.00001, loss_test:0.06051, lr:1.00e-02, fs:0.88083 (r=0.859,p=0.904),  time:18.720, tt:1666.079\n",
      "Ep:89, loss:0.00001, loss_test:0.06036, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:18.722, tt:1684.999\n",
      "Ep:90, loss:0.00001, loss_test:0.06085, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:18.726, tt:1704.038\n",
      "Ep:91, loss:0.00001, loss_test:0.06017, lr:1.00e-02, fs:0.88083 (r=0.859,p=0.904),  time:18.740, tt:1724.059\n",
      "Ep:92, loss:0.00001, loss_test:0.06072, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:18.741, tt:1742.878\n",
      "Ep:93, loss:0.00001, loss_test:0.06005, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:18.745, tt:1762.033\n",
      "Ep:94, loss:0.00001, loss_test:0.06033, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:18.746, tt:1780.877\n",
      "Ep:95, loss:0.00001, loss_test:0.06060, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:18.746, tt:1799.572\n",
      "Ep:96, loss:0.00001, loss_test:0.06047, lr:9.90e-03, fs:0.85106 (r=0.808,p=0.899),  time:18.747, tt:1818.495\n",
      "Ep:97, loss:0.00001, loss_test:0.06076, lr:9.80e-03, fs:0.84492 (r=0.798,p=0.898),  time:18.754, tt:1837.918\n",
      "Ep:98, loss:0.00001, loss_test:0.06025, lr:9.70e-03, fs:0.86316 (r=0.828,p=0.901),  time:18.758, tt:1857.012\n",
      "Ep:99, loss:0.00001, loss_test:0.06049, lr:9.61e-03, fs:0.85106 (r=0.808,p=0.899),  time:18.757, tt:1875.743\n",
      "Ep:100, loss:0.00001, loss_test:0.06010, lr:9.51e-03, fs:0.85106 (r=0.808,p=0.899),  time:18.763, tt:1895.087\n",
      "Ep:101, loss:0.00001, loss_test:0.06042, lr:9.41e-03, fs:0.84946 (r=0.798,p=0.908),  time:18.764, tt:1913.974\n",
      "Ep:102, loss:0.00001, loss_test:0.05995, lr:9.32e-03, fs:0.84783 (r=0.788,p=0.918),  time:18.765, tt:1932.817\n",
      "Ep:103, loss:0.00001, loss_test:0.05984, lr:9.23e-03, fs:0.86022 (r=0.808,p=0.920),  time:18.768, tt:1951.912\n",
      "Ep:104, loss:0.00001, loss_test:0.05951, lr:9.14e-03, fs:0.85246 (r=0.788,p=0.929),  time:18.766, tt:1970.395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:105, loss:0.00001, loss_test:0.06007, lr:9.04e-03, fs:0.83333 (r=0.758,p=0.926),  time:18.776, tt:1990.246\n",
      "Ep:106, loss:0.00001, loss_test:0.05941, lr:8.95e-03, fs:0.83516 (r=0.768,p=0.916),  time:18.783, tt:2009.789\n",
      "Ep:107, loss:0.00001, loss_test:0.05896, lr:8.86e-03, fs:0.84946 (r=0.798,p=0.908),  time:18.778, tt:2027.998\n",
      "Ep:108, loss:0.00001, loss_test:0.05902, lr:8.78e-03, fs:0.85246 (r=0.788,p=0.929),  time:18.769, tt:2045.781\n",
      "Ep:109, loss:0.00001, loss_test:0.05924, lr:8.69e-03, fs:0.81356 (r=0.727,p=0.923),  time:18.774, tt:2065.157\n",
      "Ep:110, loss:0.00001, loss_test:0.05989, lr:8.60e-03, fs:0.82682 (r=0.747,p=0.925),  time:18.767, tt:2083.104\n",
      "Ep:111, loss:0.00001, loss_test:0.05865, lr:8.51e-03, fs:0.84783 (r=0.788,p=0.918),  time:18.768, tt:2101.999\n",
      "Ep:112, loss:0.00001, loss_test:0.05966, lr:8.43e-03, fs:0.84153 (r=0.778,p=0.917),  time:18.758, tt:2119.666\n",
      "Ep:113, loss:0.00001, loss_test:0.05939, lr:8.35e-03, fs:0.80682 (r=0.717,p=0.922),  time:18.753, tt:2137.849\n",
      "Ep:114, loss:0.00001, loss_test:0.05946, lr:8.26e-03, fs:0.80682 (r=0.717,p=0.922),  time:18.754, tt:2156.764\n",
      "Ep:115, loss:0.00001, loss_test:0.05889, lr:8.18e-03, fs:0.84783 (r=0.788,p=0.918),  time:18.753, tt:2175.316\n",
      "Ep:116, loss:0.00001, loss_test:0.05872, lr:8.10e-03, fs:0.82682 (r=0.747,p=0.925),  time:18.759, tt:2194.771\n",
      "Ep:117, loss:0.00001, loss_test:0.06042, lr:8.02e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.768, tt:2214.610\n",
      "Ep:118, loss:0.00001, loss_test:0.05890, lr:7.94e-03, fs:0.81356 (r=0.727,p=0.923),  time:18.769, tt:2233.542\n",
      "Ep:119, loss:0.00001, loss_test:0.05925, lr:7.86e-03, fs:0.81143 (r=0.717,p=0.934),  time:18.774, tt:2252.937\n",
      "Ep:120, loss:0.00001, loss_test:0.05950, lr:7.78e-03, fs:0.82022 (r=0.737,p=0.924),  time:18.783, tt:2272.752\n",
      "Ep:121, loss:0.00001, loss_test:0.05890, lr:7.70e-03, fs:0.81356 (r=0.727,p=0.923),  time:18.789, tt:2292.291\n",
      "Ep:122, loss:0.00001, loss_test:0.06025, lr:7.62e-03, fs:0.81143 (r=0.717,p=0.934),  time:18.788, tt:2310.887\n",
      "Ep:123, loss:0.00001, loss_test:0.05943, lr:7.55e-03, fs:0.80000 (r=0.707,p=0.921),  time:18.798, tt:2330.934\n",
      "Ep:124, loss:0.00001, loss_test:0.05924, lr:7.47e-03, fs:0.80000 (r=0.707,p=0.921),  time:18.802, tt:2350.309\n",
      "Ep:125, loss:0.00001, loss_test:0.05992, lr:7.40e-03, fs:0.81356 (r=0.727,p=0.923),  time:18.806, tt:2369.503\n",
      "Ep:126, loss:0.00001, loss_test:0.05941, lr:7.32e-03, fs:0.80000 (r=0.707,p=0.921),  time:18.805, tt:2388.172\n",
      "Ep:127, loss:0.00001, loss_test:0.06095, lr:7.25e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.807, tt:2407.251\n",
      "Ep:128, loss:0.00001, loss_test:0.06012, lr:7.18e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.811, tt:2426.662\n",
      "Ep:129, loss:0.00001, loss_test:0.05972, lr:7.11e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.814, tt:2445.842\n",
      "Ep:130, loss:0.00001, loss_test:0.06070, lr:7.03e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.813, tt:2464.469\n",
      "Ep:131, loss:0.00001, loss_test:0.06011, lr:6.96e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.818, tt:2483.935\n",
      "Ep:132, loss:0.00001, loss_test:0.06068, lr:6.89e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.822, tt:2503.383\n",
      "Ep:133, loss:0.00001, loss_test:0.06032, lr:6.83e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.817, tt:2521.543\n",
      "Ep:134, loss:0.00001, loss_test:0.06052, lr:6.76e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.819, tt:2540.558\n",
      "Ep:135, loss:0.00001, loss_test:0.06150, lr:6.69e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.819, tt:2559.426\n",
      "Ep:136, loss:0.00001, loss_test:0.06076, lr:6.62e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.815, tt:2577.637\n",
      "Ep:137, loss:0.00001, loss_test:0.06132, lr:6.56e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.819, tt:2597.020\n",
      "Ep:138, loss:0.00001, loss_test:0.06125, lr:6.49e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.818, tt:2615.694\n",
      "Ep:139, loss:0.00001, loss_test:0.06149, lr:6.43e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.816, tt:2634.229\n",
      "Ep:140, loss:0.00001, loss_test:0.06155, lr:6.36e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.813, tt:2652.632\n",
      "Ep:141, loss:0.00000, loss_test:0.06156, lr:6.30e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.810, tt:2671.074\n",
      "Ep:142, loss:0.00000, loss_test:0.06141, lr:6.24e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.809, tt:2689.650\n",
      "Ep:143, loss:0.00000, loss_test:0.06160, lr:6.17e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.806, tt:2708.093\n",
      "Ep:144, loss:0.00000, loss_test:0.06141, lr:6.11e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.795, tt:2725.272\n",
      "Ep:145, loss:0.00000, loss_test:0.06147, lr:6.05e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.794, tt:2743.959\n",
      "Ep:146, loss:0.00000, loss_test:0.06143, lr:5.99e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.793, tt:2762.601\n",
      "Ep:147, loss:0.00000, loss_test:0.06171, lr:5.93e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.792, tt:2781.199\n",
      "Ep:148, loss:0.00000, loss_test:0.06157, lr:5.87e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.792, tt:2799.962\n",
      "Ep:149, loss:0.00000, loss_test:0.06189, lr:5.81e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.793, tt:2818.960\n",
      "Ep:150, loss:0.00000, loss_test:0.06165, lr:5.75e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.792, tt:2837.617\n",
      "Ep:151, loss:0.00000, loss_test:0.06169, lr:5.70e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.789, tt:2855.936\n",
      "Ep:152, loss:0.00000, loss_test:0.06169, lr:5.64e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.789, tt:2874.751\n",
      "Ep:153, loss:0.00000, loss_test:0.06220, lr:5.58e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.779, tt:2891.894\n",
      "Ep:154, loss:0.00000, loss_test:0.06155, lr:5.53e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.772, tt:2909.689\n",
      "Ep:155, loss:0.00000, loss_test:0.06242, lr:5.47e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.760, tt:2926.632\n",
      "Ep:156, loss:0.00000, loss_test:0.06216, lr:5.42e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.759, tt:2945.171\n",
      "Ep:157, loss:0.00000, loss_test:0.06235, lr:5.36e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.755, tt:2963.226\n",
      "Ep:158, loss:0.00000, loss_test:0.06240, lr:5.31e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.757, tt:2982.393\n",
      "Ep:159, loss:0.00000, loss_test:0.06254, lr:5.26e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.753, tt:3000.541\n",
      "Ep:160, loss:0.00000, loss_test:0.06239, lr:5.20e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.759, tt:3020.279\n",
      "Ep:161, loss:0.00000, loss_test:0.06227, lr:5.15e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.760, tt:3039.182\n",
      "Ep:162, loss:0.00000, loss_test:0.06274, lr:5.10e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.759, tt:3057.693\n",
      "Ep:163, loss:0.00000, loss_test:0.06243, lr:5.05e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.758, tt:3076.236\n",
      "Ep:164, loss:0.00000, loss_test:0.06266, lr:5.00e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.752, tt:3094.087\n",
      "Ep:165, loss:0.00000, loss_test:0.06260, lr:4.95e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.753, tt:3112.940\n",
      "Ep:166, loss:0.00000, loss_test:0.06307, lr:4.90e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.750, tt:3131.187\n",
      "Ep:167, loss:0.00000, loss_test:0.06273, lr:4.85e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.748, tt:3149.638\n",
      "Ep:168, loss:0.00000, loss_test:0.06257, lr:4.80e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.743, tt:3167.589\n",
      "Ep:169, loss:0.00000, loss_test:0.06332, lr:4.75e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.735, tt:3184.933\n",
      "Ep:170, loss:0.00000, loss_test:0.06296, lr:4.71e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.729, tt:3202.641\n",
      "Ep:171, loss:0.00000, loss_test:0.06318, lr:4.66e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.730, tt:3221.545\n",
      "Ep:172, loss:0.00000, loss_test:0.06287, lr:4.61e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.724, tt:3239.303\n",
      "Ep:173, loss:0.00000, loss_test:0.06303, lr:4.57e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.723, tt:3257.866\n",
      "Ep:174, loss:0.00000, loss_test:0.06365, lr:4.52e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.718, tt:3275.569\n",
      "Ep:175, loss:0.00000, loss_test:0.06313, lr:4.48e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.723, tt:3295.164\n",
      "Ep:176, loss:0.00000, loss_test:0.06373, lr:4.43e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.718, tt:3313.050\n",
      "Ep:177, loss:0.00000, loss_test:0.06348, lr:4.39e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.720, tt:3332.177\n",
      "Ep:178, loss:0.00000, loss_test:0.06335, lr:4.34e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.727, tt:3352.088\n",
      "Ep:179, loss:0.00000, loss_test:0.06368, lr:4.30e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.723, tt:3370.095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:180, loss:0.00000, loss_test:0.06354, lr:4.26e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.724, tt:3388.981\n",
      "Ep:181, loss:0.00000, loss_test:0.06358, lr:4.21e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.724, tt:3407.677\n",
      "Ep:182, loss:0.00000, loss_test:0.06341, lr:4.17e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.722, tt:3426.113\n",
      "Ep:183, loss:0.00000, loss_test:0.06348, lr:4.13e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.733, tt:3446.827\n",
      "Ep:184, loss:0.00000, loss_test:0.06372, lr:4.09e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.728, tt:3464.728\n",
      "Ep:185, loss:0.00000, loss_test:0.06367, lr:4.05e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.729, tt:3483.673\n",
      "Ep:186, loss:0.00000, loss_test:0.06388, lr:4.01e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.730, tt:3502.603\n",
      "Ep:187, loss:0.00000, loss_test:0.06373, lr:3.97e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.729, tt:3521.103\n",
      "Ep:188, loss:0.00000, loss_test:0.06372, lr:3.93e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.727, tt:3539.446\n",
      "Ep:189, loss:0.00000, loss_test:0.06399, lr:3.89e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.730, tt:3558.693\n",
      "Ep:190, loss:0.00000, loss_test:0.06387, lr:3.85e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.734, tt:3578.236\n",
      "Ep:191, loss:0.00000, loss_test:0.06392, lr:3.81e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.734, tt:3596.963\n",
      "Ep:192, loss:0.00000, loss_test:0.06388, lr:3.77e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.736, tt:3616.143\n",
      "Ep:193, loss:0.00000, loss_test:0.06407, lr:3.73e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.741, tt:3635.697\n",
      "Ep:194, loss:0.00000, loss_test:0.06417, lr:3.70e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.744, tt:3655.076\n",
      "Ep:195, loss:0.00000, loss_test:0.06413, lr:3.66e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.746, tt:3674.216\n",
      "Ep:196, loss:0.00000, loss_test:0.06402, lr:3.62e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.744, tt:3692.575\n",
      "Ep:197, loss:0.00000, loss_test:0.06427, lr:3.59e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.744, tt:3711.347\n",
      "Ep:198, loss:0.00000, loss_test:0.06419, lr:3.55e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.741, tt:3729.522\n",
      "Ep:199, loss:0.00000, loss_test:0.06419, lr:3.52e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.739, tt:3747.830\n",
      "Ep:200, loss:0.00000, loss_test:0.06418, lr:3.48e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.739, tt:3766.491\n",
      "Ep:201, loss:0.00000, loss_test:0.06462, lr:3.45e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.742, tt:3785.983\n",
      "Ep:202, loss:0.00000, loss_test:0.06443, lr:3.41e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.745, tt:3805.234\n",
      "Ep:203, loss:0.00000, loss_test:0.06411, lr:3.38e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.747, tt:3824.409\n",
      "Ep:204, loss:0.00000, loss_test:0.06468, lr:3.34e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.749, tt:3843.492\n",
      "Ep:205, loss:0.00000, loss_test:0.06472, lr:3.31e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.748, tt:3862.120\n",
      "Ep:206, loss:0.00000, loss_test:0.06437, lr:3.28e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.755, tt:3882.194\n",
      "Ep:207, loss:0.00000, loss_test:0.06475, lr:3.24e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.761, tt:3902.340\n",
      "Ep:208, loss:0.00000, loss_test:0.06472, lr:3.21e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.761, tt:3921.104\n",
      "Ep:209, loss:0.00000, loss_test:0.06456, lr:3.18e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.763, tt:3940.208\n",
      "Ep:210, loss:0.00000, loss_test:0.06499, lr:3.15e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.763, tt:3959.003\n",
      "Ep:211, loss:0.00000, loss_test:0.06487, lr:3.12e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.757, tt:3976.447\n",
      "Ep:212, loss:0.00000, loss_test:0.06459, lr:3.09e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.764, tt:3996.685\n",
      "Ep:213, loss:0.00000, loss_test:0.06500, lr:3.05e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.762, tt:4015.073\n",
      "Ep:214, loss:0.00000, loss_test:0.06510, lr:3.02e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.758, tt:4033.012\n",
      "Ep:215, loss:0.00000, loss_test:0.06477, lr:2.99e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.758, tt:4051.812\n",
      "Ep:216, loss:0.00000, loss_test:0.06487, lr:2.96e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.758, tt:4070.574\n",
      "Ep:217, loss:0.00000, loss_test:0.06513, lr:2.93e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.761, tt:4089.852\n",
      "Ep:218, loss:0.00000, loss_test:0.06501, lr:2.90e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.761, tt:4108.759\n",
      "Ep:219, loss:0.00000, loss_test:0.06476, lr:2.88e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.755, tt:4126.130\n",
      "Ep:220, loss:0.00000, loss_test:0.06520, lr:2.85e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.751, tt:4144.037\n",
      "Ep:221, loss:0.00000, loss_test:0.06530, lr:2.82e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.751, tt:4162.765\n",
      "Ep:222, loss:0.00000, loss_test:0.06505, lr:2.79e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.757, tt:4182.704\n",
      "Ep:223, loss:0.00000, loss_test:0.06509, lr:2.76e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.757, tt:4201.467\n",
      "Ep:224, loss:0.00000, loss_test:0.06532, lr:2.73e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.754, tt:4219.615\n",
      "Ep:225, loss:0.00000, loss_test:0.06533, lr:2.71e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.757, tt:4239.076\n",
      "Ep:226, loss:0.00000, loss_test:0.06519, lr:2.68e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.756, tt:4257.708\n",
      "Ep:227, loss:0.00000, loss_test:0.06523, lr:2.65e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.759, tt:4277.076\n",
      "Ep:228, loss:0.00000, loss_test:0.06533, lr:2.63e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.764, tt:4296.882\n",
      "Ep:229, loss:0.00000, loss_test:0.06521, lr:2.60e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.764, tt:4315.772\n",
      "Ep:230, loss:0.00000, loss_test:0.06532, lr:2.57e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.767, tt:4335.251\n",
      "Ep:231, loss:0.00000, loss_test:0.06529, lr:2.55e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.761, tt:4352.474\n",
      "Ep:232, loss:0.00000, loss_test:0.06540, lr:2.52e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.756, tt:4370.244\n",
      "Ep:233, loss:0.00000, loss_test:0.06539, lr:2.50e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.756, tt:4388.951\n",
      "Ep:234, loss:0.00000, loss_test:0.06524, lr:2.47e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.757, tt:4407.857\n",
      "Ep:235, loss:0.00000, loss_test:0.06549, lr:2.45e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.757, tt:4426.768\n",
      "Ep:236, loss:0.00000, loss_test:0.06555, lr:2.42e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.759, tt:4445.923\n",
      "Ep:237, loss:0.00000, loss_test:0.06540, lr:2.40e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.765, tt:4466.050\n",
      "Ep:238, loss:0.00000, loss_test:0.06549, lr:2.38e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.769, tt:4485.800\n",
      "Ep:239, loss:0.00000, loss_test:0.06547, lr:2.35e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.771, tt:4504.956\n",
      "Ep:240, loss:0.00000, loss_test:0.06553, lr:2.33e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.770, tt:4523.523\n",
      "Ep:241, loss:0.00000, loss_test:0.06549, lr:2.31e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.782, tt:4545.186\n",
      "Ep:242, loss:0.00000, loss_test:0.06573, lr:2.28e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.787, tt:4565.237\n",
      "Ep:243, loss:0.00000, loss_test:0.06571, lr:2.26e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.786, tt:4583.752\n",
      "Ep:244, loss:0.00000, loss_test:0.06556, lr:2.24e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.787, tt:4602.711\n",
      "Ep:245, loss:0.00000, loss_test:0.06561, lr:2.21e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.792, tt:4622.849\n",
      "Ep:246, loss:0.00000, loss_test:0.06565, lr:2.19e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.793, tt:4641.916\n",
      "Ep:247, loss:0.00000, loss_test:0.06566, lr:2.17e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.796, tt:4661.436\n",
      "Ep:248, loss:0.00000, loss_test:0.06570, lr:2.15e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.795, tt:4679.911\n",
      "Ep:249, loss:0.00000, loss_test:0.06566, lr:2.13e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.796, tt:4698.934\n",
      "Ep:250, loss:0.00000, loss_test:0.06580, lr:2.11e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.796, tt:4717.794\n",
      "Ep:251, loss:0.00000, loss_test:0.06581, lr:2.08e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.798, tt:4737.125\n",
      "Ep:252, loss:0.00000, loss_test:0.06565, lr:2.06e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.803, tt:4757.184\n",
      "Ep:253, loss:0.00000, loss_test:0.06579, lr:2.04e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.803, tt:4776.087\n",
      "Ep:254, loss:0.00000, loss_test:0.06584, lr:2.02e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.802, tt:4794.526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:255, loss:0.00000, loss_test:0.06580, lr:2.00e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.800, tt:4812.867\n",
      "Ep:256, loss:0.00000, loss_test:0.06569, lr:1.98e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.804, tt:4832.614\n",
      "Ep:257, loss:0.00000, loss_test:0.06585, lr:1.96e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.808, tt:4852.429\n",
      "Ep:258, loss:0.00000, loss_test:0.06586, lr:1.94e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.807, tt:4871.091\n",
      "Ep:259, loss:0.00000, loss_test:0.06593, lr:1.92e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.807, tt:4889.810\n",
      "Ep:260, loss:0.00000, loss_test:0.06591, lr:1.90e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.807, tt:4908.633\n",
      "Ep:261, loss:0.00000, loss_test:0.06591, lr:1.89e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.804, tt:4926.700\n",
      "Ep:262, loss:0.00000, loss_test:0.06598, lr:1.87e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.802, tt:4944.932\n",
      "Ep:263, loss:0.00000, loss_test:0.06594, lr:1.85e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.800, tt:4963.255\n",
      "Ep:264, loss:0.00000, loss_test:0.06583, lr:1.83e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.800, tt:4982.087\n",
      "Ep:265, loss:0.00000, loss_test:0.06601, lr:1.81e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.800, tt:5000.706\n",
      "Ep:266, loss:0.00000, loss_test:0.06602, lr:1.79e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.800, tt:5019.553\n",
      "Ep:267, loss:0.00000, loss_test:0.06598, lr:1.78e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.799, tt:5038.096\n",
      "Ep:268, loss:0.00000, loss_test:0.06599, lr:1.76e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.798, tt:5056.755\n",
      "Ep:269, loss:0.00000, loss_test:0.06602, lr:1.74e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.800, tt:5075.892\n",
      "Ep:270, loss:0.00000, loss_test:0.06603, lr:1.72e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.801, tt:5094.962\n",
      "Ep:271, loss:0.00000, loss_test:0.06604, lr:1.71e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.805, tt:5114.911\n",
      "Ep:272, loss:0.00000, loss_test:0.06594, lr:1.69e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.809, tt:5134.818\n",
      "Ep:273, loss:0.00000, loss_test:0.06619, lr:1.67e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.814, tt:5155.044\n",
      "Ep:274, loss:0.00000, loss_test:0.06626, lr:1.65e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.814, tt:5173.892\n",
      "Ep:275, loss:0.00000, loss_test:0.06615, lr:1.64e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.811, tt:5191.931\n",
      "Ep:276, loss:0.00000, loss_test:0.06603, lr:1.62e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.813, tt:5211.242\n",
      "Ep:277, loss:0.00000, loss_test:0.06617, lr:1.61e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.814, tt:5230.228\n",
      "Ep:278, loss:0.00000, loss_test:0.06622, lr:1.59e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.817, tt:5249.829\n",
      "Ep:279, loss:0.00000, loss_test:0.06619, lr:1.57e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.817, tt:5268.769\n",
      "Ep:280, loss:0.00000, loss_test:0.06614, lr:1.56e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.816, tt:5287.347\n",
      "Ep:281, loss:0.00000, loss_test:0.06619, lr:1.54e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.813, tt:5305.215\n",
      "Ep:282, loss:0.00000, loss_test:0.06629, lr:1.53e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.814, tt:5324.266\n",
      "Ep:283, loss:0.00000, loss_test:0.06631, lr:1.51e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.812, tt:5342.528\n",
      "Ep:284, loss:0.00000, loss_test:0.06621, lr:1.50e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.814, tt:5362.091\n",
      "Ep:285, loss:0.00000, loss_test:0.06617, lr:1.48e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.812, tt:5380.146\n",
      "Ep:286, loss:0.00000, loss_test:0.06628, lr:1.47e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.812, tt:5398.974\n",
      "Ep:287, loss:0.00000, loss_test:0.06628, lr:1.45e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.813, tt:5418.282\n",
      "Ep:288, loss:0.00000, loss_test:0.06622, lr:1.44e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.811, tt:5436.252\n",
      "Ep:289, loss:0.00000, loss_test:0.06626, lr:1.42e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.810, tt:5454.834\n",
      "Ep:290, loss:0.00000, loss_test:0.06627, lr:1.41e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.809, tt:5473.298\n",
      "Ep:291, loss:0.00000, loss_test:0.06632, lr:1.39e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.809, tt:5492.330\n",
      "Ep:292, loss:0.00000, loss_test:0.06627, lr:1.38e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.808, tt:5510.890\n",
      "Ep:293, loss:0.00000, loss_test:0.06618, lr:1.37e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.811, tt:5530.390\n",
      "Ep:294, loss:0.00000, loss_test:0.06635, lr:1.35e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.812, tt:5549.521\n",
      "Ep:295, loss:0.00000, loss_test:0.06641, lr:1.34e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.786, tt:5560.680\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,True)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14417, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:34.060, tt:34.060\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.14147, lr:1.00e-02, fs:0.65763 (r=0.980,p=0.495),  time:41.135, tt:82.270\n",
      "Ep:2, loss:0.00053, loss_test:0.13473, lr:1.00e-02, fs:0.65480 (r=0.929,p=0.505),  time:47.123, tt:141.369\n",
      "Ep:3, loss:0.00048, loss_test:0.12529, lr:1.00e-02, fs:0.63063 (r=0.707,p=0.569),  time:51.200, tt:204.801\n",
      "Ep:4, loss:0.00046, loss_test:0.12037, lr:1.00e-02, fs:0.65990 (r=0.657,p=0.663),  time:53.961, tt:269.807\n",
      "Ep:5, loss:0.00043, loss_test:0.11667, lr:1.00e-02, fs:0.65138 (r=0.717,p=0.597),  time:55.456, tt:332.738\n",
      "Ep:6, loss:0.00041, loss_test:0.11406, lr:1.00e-02, fs:0.65625 (r=0.636,p=0.677),  time:56.848, tt:397.933\n",
      "Ep:7, loss:0.00039, loss_test:0.11156, lr:1.00e-02, fs:0.66667 (r=0.657,p=0.677),  time:58.047, tt:464.372\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00037, loss_test:0.10818, lr:1.00e-02, fs:0.67708 (r=0.657,p=0.699),  time:59.219, tt:532.968\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00035, loss_test:0.10688, lr:1.00e-02, fs:0.68085 (r=0.646,p=0.719),  time:59.929, tt:599.289\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00033, loss_test:0.10493, lr:1.00e-02, fs:0.71277 (r=0.677,p=0.753),  time:60.494, tt:665.430\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00031, loss_test:0.10369, lr:1.00e-02, fs:0.70718 (r=0.646,p=0.780),  time:61.080, tt:732.956\n",
      "Ep:12, loss:0.00030, loss_test:0.10198, lr:1.00e-02, fs:0.70718 (r=0.646,p=0.780),  time:61.627, tt:801.151\n",
      "Ep:13, loss:0.00028, loss_test:0.10076, lr:1.00e-02, fs:0.70391 (r=0.636,p=0.787),  time:61.819, tt:865.462\n",
      "Ep:14, loss:0.00027, loss_test:0.10053, lr:1.00e-02, fs:0.70857 (r=0.626,p=0.816),  time:62.153, tt:932.290\n",
      "Ep:15, loss:0.00026, loss_test:0.09953, lr:1.00e-02, fs:0.70056 (r=0.626,p=0.795),  time:62.503, tt:1000.044\n",
      "Ep:16, loss:0.00024, loss_test:0.09896, lr:1.00e-02, fs:0.72000 (r=0.636,p=0.829),  time:62.587, tt:1063.975\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00023, loss_test:0.09948, lr:1.00e-02, fs:0.72727 (r=0.646,p=0.831),  time:62.701, tt:1128.625\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00022, loss_test:0.09729, lr:1.00e-02, fs:0.74576 (r=0.667,p=0.846),  time:62.858, tt:1194.298\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00021, loss_test:0.09712, lr:1.00e-02, fs:0.74157 (r=0.667,p=0.835),  time:62.914, tt:1258.290\n",
      "Ep:20, loss:0.00020, loss_test:0.09887, lr:1.00e-02, fs:0.75145 (r=0.657,p=0.878),  time:63.106, tt:1325.232\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00019, loss_test:0.09870, lr:1.00e-02, fs:0.74713 (r=0.657,p=0.867),  time:63.240, tt:1391.273\n",
      "Ep:22, loss:0.00018, loss_test:0.09893, lr:1.00e-02, fs:0.75581 (r=0.657,p=0.890),  time:63.348, tt:1456.996\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00018, loss_test:0.09791, lr:1.00e-02, fs:0.75581 (r=0.657,p=0.890),  time:63.362, tt:1520.697\n",
      "Ep:24, loss:0.00017, loss_test:0.09660, lr:1.00e-02, fs:0.75145 (r=0.657,p=0.878),  time:63.410, tt:1585.238\n",
      "Ep:25, loss:0.00016, loss_test:0.09746, lr:1.00e-02, fs:0.75581 (r=0.657,p=0.890),  time:63.536, tt:1651.937\n",
      "Ep:26, loss:0.00015, loss_test:0.09771, lr:1.00e-02, fs:0.75581 (r=0.657,p=0.890),  time:63.620, tt:1717.746\n",
      "Ep:27, loss:0.00015, loss_test:0.09629, lr:1.00e-02, fs:0.76301 (r=0.667,p=0.892),  time:63.740, tt:1784.709\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00014, loss_test:0.09642, lr:1.00e-02, fs:0.76301 (r=0.667,p=0.892),  time:63.826, tt:1850.968\n",
      "Ep:29, loss:0.00014, loss_test:0.09321, lr:1.00e-02, fs:0.77011 (r=0.677,p=0.893),  time:63.934, tt:1918.028\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00013, loss_test:0.09590, lr:1.00e-02, fs:0.76744 (r=0.667,p=0.904),  time:63.990, tt:1983.679\n",
      "Ep:31, loss:0.00013, loss_test:0.09419, lr:1.00e-02, fs:0.76301 (r=0.667,p=0.892),  time:63.985, tt:2047.534\n",
      "Ep:32, loss:0.00012, loss_test:0.09711, lr:1.00e-02, fs:0.77193 (r=0.667,p=0.917),  time:64.048, tt:2113.598\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00012, loss_test:0.09506, lr:1.00e-02, fs:0.76301 (r=0.667,p=0.892),  time:64.031, tt:2177.043\n",
      "Ep:34, loss:0.00011, loss_test:0.09486, lr:1.00e-02, fs:0.76744 (r=0.667,p=0.904),  time:64.049, tt:2241.726\n",
      "Ep:35, loss:0.00011, loss_test:0.09452, lr:1.00e-02, fs:0.77193 (r=0.667,p=0.917),  time:64.126, tt:2308.542\n",
      "Ep:36, loss:0.00010, loss_test:0.09706, lr:1.00e-02, fs:0.76190 (r=0.646,p=0.928),  time:64.221, tt:2376.191\n",
      "Ep:37, loss:0.00010, loss_test:0.09117, lr:1.00e-02, fs:0.77907 (r=0.677,p=0.918),  time:64.243, tt:2441.219\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00010, loss_test:0.09542, lr:1.00e-02, fs:0.78107 (r=0.667,p=0.943),  time:64.302, tt:2507.793\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00009, loss_test:0.09536, lr:1.00e-02, fs:0.77647 (r=0.667,p=0.930),  time:64.384, tt:2575.342\n",
      "Ep:40, loss:0.00009, loss_test:0.09621, lr:1.00e-02, fs:0.77647 (r=0.667,p=0.930),  time:64.409, tt:2640.759\n",
      "Ep:41, loss:0.00009, loss_test:0.09451, lr:1.00e-02, fs:0.76923 (r=0.657,p=0.929),  time:64.409, tt:2705.166\n",
      "Ep:42, loss:0.00008, loss_test:0.09314, lr:1.00e-02, fs:0.77193 (r=0.667,p=0.917),  time:64.409, tt:2769.573\n",
      "Ep:43, loss:0.00008, loss_test:0.09468, lr:1.00e-02, fs:0.75740 (r=0.646,p=0.914),  time:64.446, tt:2835.625\n",
      "Ep:44, loss:0.00008, loss_test:0.09245, lr:1.00e-02, fs:0.77193 (r=0.667,p=0.917),  time:64.495, tt:2902.272\n",
      "Ep:45, loss:0.00008, loss_test:0.09960, lr:1.00e-02, fs:0.76647 (r=0.646,p=0.941),  time:64.576, tt:2970.499\n",
      "Ep:46, loss:0.00007, loss_test:0.10301, lr:1.00e-02, fs:0.75904 (r=0.636,p=0.940),  time:64.631, tt:3037.650\n",
      "Ep:47, loss:0.00007, loss_test:0.09929, lr:1.00e-02, fs:0.75904 (r=0.636,p=0.940),  time:64.622, tt:3101.845\n",
      "Ep:48, loss:0.00007, loss_test:0.10237, lr:1.00e-02, fs:0.75904 (r=0.636,p=0.940),  time:64.634, tt:3167.044\n",
      "Ep:49, loss:0.00007, loss_test:0.09861, lr:1.00e-02, fs:0.76647 (r=0.646,p=0.941),  time:64.638, tt:3231.915\n",
      "Ep:50, loss:0.00006, loss_test:0.09881, lr:9.90e-03, fs:0.75152 (r=0.626,p=0.939),  time:64.643, tt:3296.773\n",
      "Ep:51, loss:0.00006, loss_test:0.09968, lr:9.80e-03, fs:0.75904 (r=0.636,p=0.940),  time:64.618, tt:3360.130\n",
      "Ep:52, loss:0.00006, loss_test:0.10157, lr:9.70e-03, fs:0.76647 (r=0.646,p=0.941),  time:64.663, tt:3427.145\n",
      "Ep:53, loss:0.00006, loss_test:0.10376, lr:9.61e-03, fs:0.74390 (r=0.616,p=0.938),  time:64.696, tt:3493.567\n",
      "Ep:54, loss:0.00006, loss_test:0.10637, lr:9.51e-03, fs:0.75152 (r=0.626,p=0.939),  time:64.722, tt:3559.720\n",
      "Ep:55, loss:0.00006, loss_test:0.10242, lr:9.41e-03, fs:0.75152 (r=0.626,p=0.939),  time:64.769, tt:3627.043\n",
      "Ep:56, loss:0.00005, loss_test:0.10823, lr:9.32e-03, fs:0.74390 (r=0.616,p=0.938),  time:64.813, tt:3694.366\n",
      "Ep:57, loss:0.00005, loss_test:0.09847, lr:9.23e-03, fs:0.75904 (r=0.636,p=0.940),  time:64.776, tt:3757.009\n",
      "Ep:58, loss:0.00005, loss_test:0.10608, lr:9.14e-03, fs:0.74390 (r=0.616,p=0.938),  time:64.777, tt:3821.815\n",
      "Ep:59, loss:0.00005, loss_test:0.10502, lr:9.04e-03, fs:0.75152 (r=0.626,p=0.939),  time:64.803, tt:3888.202\n",
      "Ep:60, loss:0.00004, loss_test:0.10216, lr:8.95e-03, fs:0.75610 (r=0.626,p=0.954),  time:64.829, tt:3954.577\n",
      "Ep:61, loss:0.00004, loss_test:0.10867, lr:8.86e-03, fs:0.74390 (r=0.616,p=0.938),  time:64.863, tt:4021.485\n",
      "Ep:62, loss:0.00004, loss_test:0.10713, lr:8.78e-03, fs:0.74847 (r=0.616,p=0.953),  time:64.886, tt:4087.788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00004, loss_test:0.10889, lr:8.69e-03, fs:0.74847 (r=0.616,p=0.953),  time:64.929, tt:4155.427\n",
      "Ep:64, loss:0.00004, loss_test:0.10676, lr:8.60e-03, fs:0.74847 (r=0.616,p=0.953),  time:64.941, tt:4221.197\n",
      "Ep:65, loss:0.00004, loss_test:0.10562, lr:8.51e-03, fs:0.75610 (r=0.626,p=0.954),  time:64.957, tt:4287.149\n",
      "Ep:66, loss:0.00004, loss_test:0.10832, lr:8.43e-03, fs:0.74847 (r=0.616,p=0.953),  time:64.984, tt:4353.932\n",
      "Ep:67, loss:0.00004, loss_test:0.10672, lr:8.35e-03, fs:0.74847 (r=0.616,p=0.953),  time:65.052, tt:4423.540\n",
      "Ep:68, loss:0.00003, loss_test:0.10861, lr:8.26e-03, fs:0.74847 (r=0.616,p=0.953),  time:65.075, tt:4490.162\n",
      "Ep:69, loss:0.00003, loss_test:0.10872, lr:8.18e-03, fs:0.74847 (r=0.616,p=0.953),  time:65.127, tt:4558.868\n",
      "Ep:70, loss:0.00003, loss_test:0.10848, lr:8.10e-03, fs:0.74847 (r=0.616,p=0.953),  time:65.164, tt:4626.615\n",
      "Ep:71, loss:0.00003, loss_test:0.10999, lr:8.02e-03, fs:0.74847 (r=0.616,p=0.953),  time:65.194, tt:4693.999\n",
      "Ep:72, loss:0.00003, loss_test:0.11080, lr:7.94e-03, fs:0.74847 (r=0.616,p=0.953),  time:65.245, tt:4762.910\n",
      "Ep:73, loss:0.00003, loss_test:0.10949, lr:7.86e-03, fs:0.75309 (r=0.616,p=0.968),  time:65.256, tt:4828.945\n",
      "Ep:74, loss:0.00003, loss_test:0.11189, lr:7.78e-03, fs:0.75309 (r=0.616,p=0.968),  time:65.288, tt:4896.577\n",
      "Ep:75, loss:0.00003, loss_test:0.11055, lr:7.70e-03, fs:0.74847 (r=0.616,p=0.953),  time:65.286, tt:4961.725\n",
      "Ep:76, loss:0.00003, loss_test:0.10938, lr:7.62e-03, fs:0.75309 (r=0.616,p=0.968),  time:65.281, tt:5026.636\n",
      "Ep:77, loss:0.00003, loss_test:0.10954, lr:7.55e-03, fs:0.75309 (r=0.616,p=0.968),  time:65.295, tt:5093.009\n",
      "Ep:78, loss:0.00003, loss_test:0.11231, lr:7.47e-03, fs:0.74534 (r=0.606,p=0.968),  time:65.316, tt:5159.968\n",
      "Ep:79, loss:0.00002, loss_test:0.10939, lr:7.40e-03, fs:0.75309 (r=0.616,p=0.968),  time:65.358, tt:5228.676\n",
      "Ep:80, loss:0.00002, loss_test:0.11118, lr:7.32e-03, fs:0.75309 (r=0.616,p=0.968),  time:65.364, tt:5294.481\n",
      "Ep:81, loss:0.00002, loss_test:0.11098, lr:7.25e-03, fs:0.74534 (r=0.606,p=0.968),  time:65.379, tt:5361.080\n",
      "Ep:82, loss:0.00002, loss_test:0.10944, lr:7.18e-03, fs:0.75309 (r=0.616,p=0.968),  time:65.428, tt:5430.535\n",
      "Ep:83, loss:0.00002, loss_test:0.10911, lr:7.11e-03, fs:0.75309 (r=0.616,p=0.968),  time:65.450, tt:5497.829\n",
      "Ep:84, loss:0.00002, loss_test:0.11093, lr:7.03e-03, fs:0.74534 (r=0.606,p=0.968),  time:65.462, tt:5564.297\n",
      "Ep:85, loss:0.00002, loss_test:0.11139, lr:6.96e-03, fs:0.75309 (r=0.616,p=0.968),  time:65.462, tt:5629.693\n",
      "Ep:86, loss:0.00002, loss_test:0.11231, lr:6.89e-03, fs:0.74534 (r=0.606,p=0.968),  time:65.485, tt:5697.224\n",
      "Ep:87, loss:0.00002, loss_test:0.11338, lr:6.83e-03, fs:0.74534 (r=0.606,p=0.968),  time:65.505, tt:5764.466\n",
      "Ep:88, loss:0.00002, loss_test:0.10910, lr:6.76e-03, fs:0.75309 (r=0.616,p=0.968),  time:65.510, tt:5830.386\n",
      "Ep:89, loss:0.00002, loss_test:0.11448, lr:6.69e-03, fs:0.74534 (r=0.606,p=0.968),  time:65.511, tt:5895.950\n",
      "Ep:90, loss:0.00002, loss_test:0.11038, lr:6.62e-03, fs:0.75309 (r=0.616,p=0.968),  time:65.541, tt:5964.254\n",
      "Ep:91, loss:0.00002, loss_test:0.11362, lr:6.56e-03, fs:0.74534 (r=0.606,p=0.968),  time:65.573, tt:6032.713\n",
      "Ep:92, loss:0.00002, loss_test:0.11481, lr:6.49e-03, fs:0.74534 (r=0.606,p=0.968),  time:65.563, tt:6097.376\n",
      "Ep:93, loss:0.00002, loss_test:0.11038, lr:6.43e-03, fs:0.74534 (r=0.606,p=0.968),  time:65.574, tt:6163.939\n",
      "Ep:94, loss:0.00002, loss_test:0.11355, lr:6.36e-03, fs:0.74534 (r=0.606,p=0.968),  time:65.581, tt:6230.202\n",
      "Ep:95, loss:0.00002, loss_test:0.11064, lr:6.30e-03, fs:0.74534 (r=0.606,p=0.968),  time:65.591, tt:6296.741\n",
      "Ep:96, loss:0.00002, loss_test:0.11507, lr:6.24e-03, fs:0.75000 (r=0.606,p=0.984),  time:65.626, tt:6365.732\n",
      "Ep:97, loss:0.00002, loss_test:0.11306, lr:6.17e-03, fs:0.75000 (r=0.606,p=0.984),  time:65.632, tt:6431.944\n",
      "Ep:98, loss:0.00002, loss_test:0.11350, lr:6.11e-03, fs:0.74534 (r=0.606,p=0.968),  time:65.633, tt:6497.624\n",
      "Ep:99, loss:0.00002, loss_test:0.11096, lr:6.05e-03, fs:0.74534 (r=0.606,p=0.968),  time:65.650, tt:6564.976\n",
      "Ep:100, loss:0.00002, loss_test:0.11424, lr:5.99e-03, fs:0.74534 (r=0.606,p=0.968),  time:65.659, tt:6631.514\n",
      "Ep:101, loss:0.00002, loss_test:0.11302, lr:5.93e-03, fs:0.75000 (r=0.606,p=0.984),  time:65.674, tt:6698.736\n",
      "Ep:102, loss:0.00002, loss_test:0.11152, lr:5.87e-03, fs:0.74534 (r=0.606,p=0.968),  time:65.675, tt:6764.562\n",
      "Ep:103, loss:0.00002, loss_test:0.11372, lr:5.81e-03, fs:0.74534 (r=0.606,p=0.968),  time:65.685, tt:6831.194\n",
      "Ep:104, loss:0.00001, loss_test:0.11386, lr:5.75e-03, fs:0.75000 (r=0.606,p=0.984),  time:65.637, tt:6891.861\n",
      "Ep:105, loss:0.00001, loss_test:0.11420, lr:5.70e-03, fs:0.75000 (r=0.606,p=0.984),  time:65.586, tt:6952.118\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14416, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:74.508, tt:74.508\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00054, loss_test:0.13890, lr:1.00e-02, fs:0.65753 (r=0.970,p=0.497),  time:71.942, tt:143.883\n",
      "Ep:2, loss:0.00050, loss_test:0.12593, lr:1.00e-02, fs:0.66122 (r=0.818,p=0.555),  time:75.850, tt:227.551\n",
      "Ep:3, loss:0.00046, loss_test:0.11918, lr:1.00e-02, fs:0.61692 (r=0.626,p=0.608),  time:77.572, tt:310.286\n",
      "Ep:4, loss:0.00043, loss_test:0.11372, lr:1.00e-02, fs:0.66355 (r=0.717,p=0.617),  time:78.124, tt:390.621\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00040, loss_test:0.10894, lr:1.00e-02, fs:0.68394 (r=0.667,p=0.702),  time:78.721, tt:472.324\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00037, loss_test:0.10698, lr:1.00e-02, fs:0.69388 (r=0.687,p=0.701),  time:78.585, tt:550.092\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00035, loss_test:0.10519, lr:1.00e-02, fs:0.69841 (r=0.667,p=0.733),  time:78.947, tt:631.575\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00032, loss_test:0.10436, lr:1.00e-02, fs:0.70213 (r=0.667,p=0.742),  time:79.295, tt:713.654\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00030, loss_test:0.10210, lr:1.00e-02, fs:0.66667 (r=0.636,p=0.700),  time:79.627, tt:796.271\n",
      "Ep:10, loss:0.00028, loss_test:0.10421, lr:1.00e-02, fs:0.66667 (r=0.596,p=0.756),  time:79.865, tt:878.515\n",
      "Ep:11, loss:0.00026, loss_test:0.10075, lr:1.00e-02, fs:0.67033 (r=0.616,p=0.735),  time:80.006, tt:960.066\n",
      "Ep:12, loss:0.00024, loss_test:0.10086, lr:1.00e-02, fs:0.67429 (r=0.596,p=0.776),  time:80.266, tt:1043.461\n",
      "Ep:13, loss:0.00022, loss_test:0.10471, lr:1.00e-02, fs:0.68605 (r=0.596,p=0.808),  time:80.421, tt:1125.896\n",
      "Ep:14, loss:0.00021, loss_test:0.10175, lr:1.00e-02, fs:0.68966 (r=0.606,p=0.800),  time:80.860, tt:1212.903\n",
      "Ep:15, loss:0.00019, loss_test:0.10099, lr:1.00e-02, fs:0.70520 (r=0.616,p=0.824),  time:81.075, tt:1297.197\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.10282, lr:1.00e-02, fs:0.71006 (r=0.606,p=0.857),  time:81.011, tt:1377.182\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.10048, lr:1.00e-02, fs:0.74419 (r=0.646,p=0.877),  time:81.218, tt:1461.923\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00016, loss_test:0.10474, lr:1.00e-02, fs:0.71084 (r=0.596,p=0.881),  time:81.269, tt:1544.103\n",
      "Ep:19, loss:0.00015, loss_test:0.10580, lr:1.00e-02, fs:0.72619 (r=0.616,p=0.884),  time:81.313, tt:1626.262\n",
      "Ep:20, loss:0.00014, loss_test:0.10797, lr:1.00e-02, fs:0.71856 (r=0.606,p=0.882),  time:81.407, tt:1709.553\n",
      "Ep:21, loss:0.00013, loss_test:0.09758, lr:1.00e-02, fs:0.72189 (r=0.616,p=0.871),  time:81.372, tt:1790.192\n",
      "Ep:22, loss:0.00012, loss_test:0.09654, lr:1.00e-02, fs:0.72619 (r=0.616,p=0.884),  time:81.390, tt:1871.963\n",
      "Ep:23, loss:0.00011, loss_test:0.10946, lr:1.00e-02, fs:0.72727 (r=0.606,p=0.909),  time:81.432, tt:1954.362\n",
      "Ep:24, loss:0.00010, loss_test:0.10577, lr:1.00e-02, fs:0.72727 (r=0.606,p=0.909),  time:81.588, tt:2039.701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:25, loss:0.00009, loss_test:0.10389, lr:1.00e-02, fs:0.73620 (r=0.606,p=0.938),  time:81.670, tt:2123.428\n",
      "Ep:26, loss:0.00009, loss_test:0.11015, lr:1.00e-02, fs:0.73171 (r=0.606,p=0.923),  time:81.670, tt:2205.099\n",
      "Ep:27, loss:0.00008, loss_test:0.10836, lr:1.00e-02, fs:0.73171 (r=0.606,p=0.923),  time:81.709, tt:2287.861\n",
      "Ep:28, loss:0.00007, loss_test:0.11040, lr:1.00e-02, fs:0.73620 (r=0.606,p=0.938),  time:81.848, tt:2373.588\n",
      "Ep:29, loss:0.00007, loss_test:0.10577, lr:9.90e-03, fs:0.73620 (r=0.606,p=0.938),  time:81.905, tt:2457.158\n",
      "Ep:30, loss:0.00006, loss_test:0.10368, lr:9.80e-03, fs:0.73620 (r=0.606,p=0.938),  time:81.905, tt:2539.070\n",
      "Ep:31, loss:0.00006, loss_test:0.10367, lr:9.70e-03, fs:0.73620 (r=0.606,p=0.938),  time:81.926, tt:2621.629\n",
      "Ep:32, loss:0.00005, loss_test:0.11756, lr:9.61e-03, fs:0.73620 (r=0.606,p=0.938),  time:82.013, tt:2706.425\n",
      "Ep:33, loss:0.00005, loss_test:0.10916, lr:9.51e-03, fs:0.73620 (r=0.606,p=0.938),  time:82.163, tt:2793.534\n",
      "Ep:34, loss:0.00005, loss_test:0.10884, lr:9.41e-03, fs:0.73620 (r=0.606,p=0.938),  time:82.170, tt:2875.961\n",
      "Ep:35, loss:0.00004, loss_test:0.11061, lr:9.32e-03, fs:0.74074 (r=0.606,p=0.952),  time:82.141, tt:2957.079\n",
      "Ep:36, loss:0.00004, loss_test:0.10655, lr:9.23e-03, fs:0.74074 (r=0.606,p=0.952),  time:82.151, tt:3039.578\n",
      "Ep:37, loss:0.00004, loss_test:0.10674, lr:9.14e-03, fs:0.74074 (r=0.606,p=0.952),  time:82.241, tt:3125.177\n",
      "Ep:38, loss:0.00004, loss_test:0.11546, lr:9.04e-03, fs:0.74534 (r=0.606,p=0.968),  time:82.208, tt:3206.111\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.11328, lr:9.04e-03, fs:0.74074 (r=0.606,p=0.952),  time:82.155, tt:3286.214\n",
      "Ep:40, loss:0.00003, loss_test:0.10936, lr:9.04e-03, fs:0.74534 (r=0.606,p=0.968),  time:82.221, tt:3371.049\n",
      "Ep:41, loss:0.00003, loss_test:0.12131, lr:9.04e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.199, tt:3452.375\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.12714, lr:9.04e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.210, tt:3535.016\n",
      "Ep:43, loss:0.00003, loss_test:0.12365, lr:9.04e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.319, tt:3622.039\n",
      "Ep:44, loss:0.00002, loss_test:0.12128, lr:9.04e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.334, tt:3705.049\n",
      "Ep:45, loss:0.00002, loss_test:0.11741, lr:9.04e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.345, tt:3787.877\n",
      "Ep:46, loss:0.00002, loss_test:0.12345, lr:9.04e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.390, tt:3872.344\n",
      "Ep:47, loss:0.00002, loss_test:0.12160, lr:9.04e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.360, tt:3953.282\n",
      "Ep:48, loss:0.00002, loss_test:0.11484, lr:9.04e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.312, tt:4033.305\n",
      "Ep:49, loss:0.00002, loss_test:0.11956, lr:9.04e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.286, tt:4114.324\n",
      "Ep:50, loss:0.00001, loss_test:0.11840, lr:9.04e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.296, tt:4197.084\n",
      "Ep:51, loss:0.00001, loss_test:0.11399, lr:9.04e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.350, tt:4282.220\n",
      "Ep:52, loss:0.00001, loss_test:0.11796, lr:9.04e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.440, tt:4369.332\n",
      "Ep:53, loss:0.00001, loss_test:0.11472, lr:8.95e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.416, tt:4450.451\n",
      "Ep:54, loss:0.00001, loss_test:0.11483, lr:8.86e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.434, tt:4533.846\n",
      "Ep:55, loss:0.00001, loss_test:0.11966, lr:8.78e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.414, tt:4615.171\n",
      "Ep:56, loss:0.00001, loss_test:0.11651, lr:8.69e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.409, tt:4697.338\n",
      "Ep:57, loss:0.00001, loss_test:0.11671, lr:8.60e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.450, tt:4782.126\n",
      "Ep:58, loss:0.00001, loss_test:0.12383, lr:8.51e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.441, tt:4863.998\n",
      "Ep:59, loss:0.00001, loss_test:0.12298, lr:8.43e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.403, tt:4944.151\n",
      "Ep:60, loss:0.00001, loss_test:0.11969, lr:8.35e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.383, tt:5025.351\n",
      "Ep:61, loss:0.00001, loss_test:0.12265, lr:8.26e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.362, tt:5106.432\n",
      "Ep:62, loss:0.00001, loss_test:0.12017, lr:8.18e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.349, tt:5188.003\n",
      "Ep:63, loss:0.00001, loss_test:0.12199, lr:8.10e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.322, tt:5268.579\n",
      "Ep:64, loss:0.00001, loss_test:0.12444, lr:8.02e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.339, tt:5352.029\n",
      "Ep:65, loss:0.00001, loss_test:0.11810, lr:7.94e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.309, tt:5432.425\n",
      "Ep:66, loss:0.00001, loss_test:0.11892, lr:7.86e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.270, tt:5512.077\n",
      "Ep:67, loss:0.00001, loss_test:0.11964, lr:7.78e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.267, tt:5594.139\n",
      "Ep:68, loss:0.00001, loss_test:0.12065, lr:7.70e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.253, tt:5675.441\n",
      "Ep:69, loss:0.00001, loss_test:0.12214, lr:7.62e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.269, tt:5758.813\n",
      "Ep:70, loss:0.00001, loss_test:0.11938, lr:7.55e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.288, tt:5842.468\n",
      "Ep:71, loss:0.00001, loss_test:0.12120, lr:7.47e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.275, tt:5923.815\n",
      "Ep:72, loss:0.00000, loss_test:0.11870, lr:7.40e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.286, tt:6006.878\n",
      "Ep:73, loss:0.00000, loss_test:0.11940, lr:7.32e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.279, tt:6088.643\n",
      "Ep:74, loss:0.00000, loss_test:0.11811, lr:7.25e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.277, tt:6170.800\n",
      "Ep:75, loss:0.00000, loss_test:0.11790, lr:7.18e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.264, tt:6252.095\n",
      "Ep:76, loss:0.00000, loss_test:0.12152, lr:7.11e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.275, tt:6335.185\n",
      "Ep:77, loss:0.00000, loss_test:0.12017, lr:7.03e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.287, tt:6418.396\n",
      "Ep:78, loss:0.00000, loss_test:0.12036, lr:6.96e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.306, tt:6502.194\n",
      "Ep:79, loss:0.00000, loss_test:0.11937, lr:6.89e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.383, tt:6590.679\n",
      "Ep:80, loss:0.00000, loss_test:0.12009, lr:6.83e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.384, tt:6673.066\n",
      "Ep:81, loss:0.00000, loss_test:0.11888, lr:6.76e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.354, tt:6753.056\n",
      "Ep:82, loss:0.00000, loss_test:0.12076, lr:6.69e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.312, tt:6831.908\n",
      "Ep:83, loss:0.00000, loss_test:0.11946, lr:6.62e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.319, tt:6914.830\n",
      "Ep:84, loss:0.00000, loss_test:0.12091, lr:6.56e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.303, tt:6995.735\n",
      "Ep:85, loss:0.00000, loss_test:0.11953, lr:6.49e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.296, tt:7077.482\n",
      "Ep:86, loss:0.00000, loss_test:0.12053, lr:6.43e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.309, tt:7160.877\n",
      "Ep:87, loss:0.00000, loss_test:0.12073, lr:6.36e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.283, tt:7240.924\n",
      "Ep:88, loss:0.00000, loss_test:0.11977, lr:6.30e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.315, tt:7326.079\n",
      "Ep:89, loss:0.00000, loss_test:0.12049, lr:6.24e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.328, tt:7409.519\n",
      "Ep:90, loss:0.00000, loss_test:0.11956, lr:6.17e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.325, tt:7491.533\n",
      "Ep:91, loss:0.00000, loss_test:0.12142, lr:6.11e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.329, tt:7574.297\n",
      "Ep:92, loss:0.00000, loss_test:0.11912, lr:6.05e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.346, tt:7658.148\n",
      "Ep:93, loss:0.00000, loss_test:0.12051, lr:5.99e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.396, tt:7745.251\n",
      "Ep:94, loss:0.00000, loss_test:0.12023, lr:5.93e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.425, tt:7830.418\n",
      "Ep:95, loss:0.00000, loss_test:0.12081, lr:5.87e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.416, tt:7911.897\n",
      "Ep:96, loss:0.00000, loss_test:0.11964, lr:5.81e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.433, tt:7996.020\n",
      "Ep:97, loss:0.00000, loss_test:0.11948, lr:5.75e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.409, tt:8076.075\n",
      "Ep:98, loss:0.00000, loss_test:0.12010, lr:5.70e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.397, tt:8157.315\n",
      "Ep:99, loss:0.00000, loss_test:0.12079, lr:5.64e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.389, tt:8238.927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:100, loss:0.00000, loss_test:0.11976, lr:5.58e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.409, tt:8323.333\n",
      "Ep:101, loss:0.00000, loss_test:0.12000, lr:5.53e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.412, tt:8406.050\n",
      "Ep:102, loss:0.00000, loss_test:0.11953, lr:5.47e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.410, tt:8488.199\n",
      "Ep:103, loss:0.00000, loss_test:0.12023, lr:5.42e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.383, tt:8567.822\n",
      "Ep:104, loss:0.00000, loss_test:0.11984, lr:5.36e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.358, tt:8647.625\n",
      "Ep:105, loss:0.00000, loss_test:0.12106, lr:5.31e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.341, tt:8728.176\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00053, loss_test:0.14012, lr:1.00e-02, fs:0.64539 (r=0.919,p=0.497),  time:68.039, tt:68.039\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00050, loss_test:0.13128, lr:1.00e-02, fs:0.64286 (r=0.818,p=0.529),  time:67.884, tt:135.768\n",
      "Ep:2, loss:0.00048, loss_test:0.12550, lr:1.00e-02, fs:0.66379 (r=0.778,p=0.579),  time:68.561, tt:205.683\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00045, loss_test:0.12081, lr:1.00e-02, fs:0.62555 (r=0.717,p=0.555),  time:70.266, tt:281.064\n",
      "Ep:4, loss:0.00042, loss_test:0.11627, lr:1.00e-02, fs:0.63889 (r=0.697,p=0.590),  time:71.206, tt:356.031\n",
      "Ep:5, loss:0.00039, loss_test:0.11403, lr:1.00e-02, fs:0.67000 (r=0.677,p=0.663),  time:71.446, tt:428.676\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00036, loss_test:0.11196, lr:1.00e-02, fs:0.68041 (r=0.667,p=0.695),  time:71.833, tt:502.833\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00034, loss_test:0.11085, lr:1.00e-02, fs:0.67358 (r=0.657,p=0.691),  time:72.218, tt:577.741\n",
      "Ep:8, loss:0.00032, loss_test:0.11130, lr:1.00e-02, fs:0.68020 (r=0.677,p=0.684),  time:72.632, tt:653.689\n",
      "Ep:9, loss:0.00030, loss_test:0.11307, lr:1.00e-02, fs:0.68041 (r=0.667,p=0.695),  time:72.534, tt:725.344\n",
      "Ep:10, loss:0.00029, loss_test:0.11273, lr:1.00e-02, fs:0.65263 (r=0.626,p=0.681),  time:72.814, tt:800.956\n",
      "Ep:11, loss:0.00027, loss_test:0.11231, lr:1.00e-02, fs:0.68394 (r=0.667,p=0.702),  time:73.075, tt:876.906\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00026, loss_test:0.11146, lr:1.00e-02, fs:0.70157 (r=0.677,p=0.728),  time:73.215, tt:951.794\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00025, loss_test:0.11078, lr:1.00e-02, fs:0.72251 (r=0.697,p=0.750),  time:73.384, tt:1027.379\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00023, loss_test:0.11419, lr:1.00e-02, fs:0.69231 (r=0.636,p=0.759),  time:73.675, tt:1105.130\n",
      "Ep:15, loss:0.00022, loss_test:0.11667, lr:1.00e-02, fs:0.69613 (r=0.636,p=0.768),  time:73.733, tt:1179.729\n",
      "Ep:16, loss:0.00021, loss_test:0.11414, lr:1.00e-02, fs:0.68478 (r=0.636,p=0.741),  time:73.775, tt:1254.168\n",
      "Ep:17, loss:0.00020, loss_test:0.11300, lr:1.00e-02, fs:0.68852 (r=0.636,p=0.750),  time:74.050, tt:1332.907\n",
      "Ep:18, loss:0.00019, loss_test:0.11906, lr:1.00e-02, fs:0.69714 (r=0.616,p=0.803),  time:74.078, tt:1407.490\n",
      "Ep:19, loss:0.00018, loss_test:0.11787, lr:1.00e-02, fs:0.69714 (r=0.616,p=0.803),  time:74.042, tt:1480.832\n",
      "Ep:20, loss:0.00017, loss_test:0.12262, lr:1.00e-02, fs:0.70115 (r=0.616,p=0.813),  time:74.002, tt:1554.048\n",
      "Ep:21, loss:0.00016, loss_test:0.12382, lr:1.00e-02, fs:0.69364 (r=0.606,p=0.811),  time:73.943, tt:1626.755\n",
      "Ep:22, loss:0.00015, loss_test:0.12312, lr:1.00e-02, fs:0.70520 (r=0.616,p=0.824),  time:73.858, tt:1698.723\n",
      "Ep:23, loss:0.00014, loss_test:0.11853, lr:1.00e-02, fs:0.71676 (r=0.626,p=0.838),  time:73.851, tt:1772.422\n",
      "Ep:24, loss:0.00013, loss_test:0.12573, lr:1.00e-02, fs:0.72093 (r=0.626,p=0.849),  time:73.732, tt:1843.293\n",
      "Ep:25, loss:0.00013, loss_test:0.13436, lr:9.90e-03, fs:0.71515 (r=0.596,p=0.894),  time:73.761, tt:1917.793\n",
      "Ep:26, loss:0.00012, loss_test:0.11798, lr:9.80e-03, fs:0.70857 (r=0.626,p=0.816),  time:73.724, tt:1990.552\n",
      "Ep:27, loss:0.00012, loss_test:0.12393, lr:9.70e-03, fs:0.70930 (r=0.616,p=0.836),  time:73.609, tt:2061.053\n",
      "Ep:28, loss:0.00011, loss_test:0.13507, lr:9.61e-03, fs:0.71429 (r=0.606,p=0.870),  time:73.713, tt:2137.667\n",
      "Ep:29, loss:0.00011, loss_test:0.13269, lr:9.51e-03, fs:0.72727 (r=0.606,p=0.909),  time:73.721, tt:2211.639\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00010, loss_test:0.12490, lr:9.51e-03, fs:0.71856 (r=0.606,p=0.882),  time:73.689, tt:2284.349\n",
      "Ep:31, loss:0.00010, loss_test:0.11685, lr:9.51e-03, fs:0.71264 (r=0.626,p=0.827),  time:73.731, tt:2359.392\n",
      "Ep:32, loss:0.00010, loss_test:0.12642, lr:9.51e-03, fs:0.72727 (r=0.606,p=0.909),  time:73.726, tt:2432.951\n",
      "Ep:33, loss:0.00009, loss_test:0.12939, lr:9.51e-03, fs:0.72289 (r=0.606,p=0.896),  time:73.714, tt:2506.278\n",
      "Ep:34, loss:0.00008, loss_test:0.13568, lr:9.51e-03, fs:0.72727 (r=0.606,p=0.909),  time:73.694, tt:2579.289\n",
      "Ep:35, loss:0.00008, loss_test:0.13526, lr:9.51e-03, fs:0.73171 (r=0.606,p=0.923),  time:73.671, tt:2652.172\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00008, loss_test:0.12595, lr:9.51e-03, fs:0.72289 (r=0.606,p=0.896),  time:73.729, tt:2727.957\n",
      "Ep:37, loss:0.00007, loss_test:0.12420, lr:9.51e-03, fs:0.71856 (r=0.606,p=0.882),  time:73.718, tt:2801.298\n",
      "Ep:38, loss:0.00008, loss_test:0.13636, lr:9.51e-03, fs:0.73620 (r=0.606,p=0.938),  time:73.718, tt:2875.010\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00007, loss_test:0.13465, lr:9.51e-03, fs:0.73171 (r=0.606,p=0.923),  time:73.689, tt:2947.544\n",
      "Ep:40, loss:0.00007, loss_test:0.13710, lr:9.51e-03, fs:0.73620 (r=0.606,p=0.938),  time:73.604, tt:3017.751\n",
      "Ep:41, loss:0.00006, loss_test:0.13300, lr:9.51e-03, fs:0.73620 (r=0.606,p=0.938),  time:73.523, tt:3087.964\n",
      "Ep:42, loss:0.00006, loss_test:0.13147, lr:9.51e-03, fs:0.73620 (r=0.606,p=0.938),  time:73.542, tt:3162.299\n",
      "Ep:43, loss:0.00006, loss_test:0.13288, lr:9.51e-03, fs:0.73171 (r=0.606,p=0.923),  time:73.557, tt:3236.503\n",
      "Ep:44, loss:0.00005, loss_test:0.13377, lr:9.51e-03, fs:0.73620 (r=0.606,p=0.938),  time:73.596, tt:3311.810\n",
      "Ep:45, loss:0.00005, loss_test:0.12930, lr:9.51e-03, fs:0.73620 (r=0.606,p=0.938),  time:73.640, tt:3387.441\n",
      "Ep:46, loss:0.00005, loss_test:0.12621, lr:9.51e-03, fs:0.73171 (r=0.606,p=0.923),  time:73.642, tt:3461.188\n",
      "Ep:47, loss:0.00005, loss_test:0.14506, lr:9.51e-03, fs:0.72727 (r=0.606,p=0.909),  time:73.661, tt:3535.739\n",
      "Ep:48, loss:0.00007, loss_test:0.14865, lr:9.51e-03, fs:0.73171 (r=0.606,p=0.923),  time:73.668, tt:3609.734\n",
      "Ep:49, loss:0.00006, loss_test:0.13775, lr:9.51e-03, fs:0.73171 (r=0.606,p=0.923),  time:73.635, tt:3681.749\n",
      "Ep:50, loss:0.00006, loss_test:0.12455, lr:9.41e-03, fs:0.73171 (r=0.606,p=0.923),  time:73.665, tt:3756.934\n",
      "Ep:51, loss:0.00005, loss_test:0.13571, lr:9.32e-03, fs:0.74074 (r=0.606,p=0.952),  time:73.726, tt:3833.769\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00005, loss_test:0.13536, lr:9.32e-03, fs:0.74534 (r=0.606,p=0.968),  time:73.767, tt:3909.647\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00005, loss_test:0.13626, lr:9.32e-03, fs:0.74074 (r=0.606,p=0.952),  time:73.783, tt:3984.307\n",
      "Ep:54, loss:0.00004, loss_test:0.13581, lr:9.32e-03, fs:0.73171 (r=0.606,p=0.923),  time:73.799, tt:4058.969\n",
      "Ep:55, loss:0.00004, loss_test:0.13728, lr:9.32e-03, fs:0.73171 (r=0.606,p=0.923),  time:73.797, tt:4132.635\n",
      "Ep:56, loss:0.00004, loss_test:0.13853, lr:9.32e-03, fs:0.73171 (r=0.606,p=0.923),  time:73.760, tt:4204.339\n",
      "Ep:57, loss:0.00004, loss_test:0.13717, lr:9.32e-03, fs:0.73620 (r=0.606,p=0.938),  time:73.822, tt:4281.661\n",
      "Ep:58, loss:0.00004, loss_test:0.13248, lr:9.32e-03, fs:0.74074 (r=0.606,p=0.952),  time:73.800, tt:4354.204\n",
      "Ep:59, loss:0.00003, loss_test:0.13953, lr:9.32e-03, fs:0.74074 (r=0.606,p=0.952),  time:73.764, tt:4425.813\n",
      "Ep:60, loss:0.00003, loss_test:0.13666, lr:9.32e-03, fs:0.73620 (r=0.606,p=0.938),  time:73.730, tt:4497.507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00003, loss_test:0.13751, lr:9.32e-03, fs:0.73620 (r=0.606,p=0.938),  time:73.710, tt:4570.023\n",
      "Ep:62, loss:0.00003, loss_test:0.13623, lr:9.32e-03, fs:0.73171 (r=0.606,p=0.923),  time:73.692, tt:4642.610\n",
      "Ep:63, loss:0.00003, loss_test:0.13982, lr:9.32e-03, fs:0.74074 (r=0.606,p=0.952),  time:73.698, tt:4716.676\n",
      "Ep:64, loss:0.00003, loss_test:0.13723, lr:9.23e-03, fs:0.74074 (r=0.606,p=0.952),  time:73.668, tt:4788.432\n",
      "Ep:65, loss:0.00003, loss_test:0.13287, lr:9.14e-03, fs:0.74074 (r=0.606,p=0.952),  time:73.640, tt:4860.261\n",
      "Ep:66, loss:0.00003, loss_test:0.13390, lr:9.04e-03, fs:0.74074 (r=0.606,p=0.952),  time:73.665, tt:4935.569\n",
      "Ep:67, loss:0.00003, loss_test:0.14448, lr:8.95e-03, fs:0.74534 (r=0.606,p=0.968),  time:73.657, tt:5008.684\n",
      "Ep:68, loss:0.00003, loss_test:0.14676, lr:8.86e-03, fs:0.74534 (r=0.606,p=0.968),  time:73.724, tt:5086.945\n",
      "Ep:69, loss:0.00003, loss_test:0.14437, lr:8.78e-03, fs:0.73171 (r=0.606,p=0.923),  time:73.745, tt:5162.175\n",
      "Ep:70, loss:0.00003, loss_test:0.14385, lr:8.69e-03, fs:0.73171 (r=0.606,p=0.923),  time:73.719, tt:5234.084\n",
      "Ep:71, loss:0.00003, loss_test:0.14452, lr:8.60e-03, fs:0.73620 (r=0.606,p=0.938),  time:73.720, tt:5307.863\n",
      "Ep:72, loss:0.00003, loss_test:0.14745, lr:8.51e-03, fs:0.74074 (r=0.606,p=0.952),  time:73.745, tt:5383.378\n",
      "Ep:73, loss:0.00003, loss_test:0.14770, lr:8.43e-03, fs:0.74534 (r=0.606,p=0.968),  time:73.770, tt:5458.957\n",
      "Ep:74, loss:0.00003, loss_test:0.14559, lr:8.35e-03, fs:0.74534 (r=0.606,p=0.968),  time:73.756, tt:5531.716\n",
      "Ep:75, loss:0.00002, loss_test:0.14824, lr:8.26e-03, fs:0.74534 (r=0.606,p=0.968),  time:73.770, tt:5606.511\n",
      "Ep:76, loss:0.00003, loss_test:0.15025, lr:8.18e-03, fs:0.74074 (r=0.606,p=0.952),  time:73.804, tt:5682.874\n",
      "Ep:77, loss:0.00002, loss_test:0.14939, lr:8.10e-03, fs:0.74074 (r=0.606,p=0.952),  time:73.782, tt:5754.988\n",
      "Ep:78, loss:0.00002, loss_test:0.14706, lr:8.02e-03, fs:0.74534 (r=0.606,p=0.968),  time:73.815, tt:5831.409\n",
      "Ep:79, loss:0.00002, loss_test:0.14570, lr:7.94e-03, fs:0.74074 (r=0.606,p=0.952),  time:73.812, tt:5904.937\n",
      "Ep:80, loss:0.00002, loss_test:0.14172, lr:7.86e-03, fs:0.74074 (r=0.606,p=0.952),  time:73.822, tt:5979.552\n",
      "Ep:81, loss:0.00002, loss_test:0.14244, lr:7.78e-03, fs:0.74074 (r=0.606,p=0.952),  time:73.821, tt:6053.303\n",
      "Ep:82, loss:0.00002, loss_test:0.14255, lr:7.70e-03, fs:0.74074 (r=0.606,p=0.952),  time:73.867, tt:6130.943\n",
      "Ep:83, loss:0.00002, loss_test:0.14677, lr:7.62e-03, fs:0.74074 (r=0.606,p=0.952),  time:73.860, tt:6204.272\n",
      "Ep:84, loss:0.00002, loss_test:0.15203, lr:7.55e-03, fs:0.74534 (r=0.606,p=0.968),  time:73.866, tt:6278.607\n",
      "Ep:85, loss:0.00002, loss_test:0.15093, lr:7.47e-03, fs:0.74534 (r=0.606,p=0.968),  time:73.873, tt:6353.052\n",
      "Ep:86, loss:0.00002, loss_test:0.14952, lr:7.40e-03, fs:0.74074 (r=0.606,p=0.952),  time:73.882, tt:6427.698\n",
      "Ep:87, loss:0.00002, loss_test:0.14834, lr:7.32e-03, fs:0.74074 (r=0.606,p=0.952),  time:73.891, tt:6502.364\n",
      "Ep:88, loss:0.00002, loss_test:0.14941, lr:7.25e-03, fs:0.74074 (r=0.606,p=0.952),  time:73.903, tt:6577.332\n",
      "Ep:89, loss:0.00002, loss_test:0.14938, lr:7.18e-03, fs:0.74074 (r=0.606,p=0.952),  time:73.951, tt:6655.599\n",
      "Ep:90, loss:0.00002, loss_test:0.15062, lr:7.11e-03, fs:0.74074 (r=0.606,p=0.952),  time:73.949, tt:6729.334\n",
      "Ep:91, loss:0.00002, loss_test:0.14893, lr:7.03e-03, fs:0.74074 (r=0.606,p=0.952),  time:73.988, tt:6806.896\n",
      "Ep:92, loss:0.00001, loss_test:0.14722, lr:6.96e-03, fs:0.74074 (r=0.606,p=0.952),  time:74.011, tt:6882.994\n",
      "Ep:93, loss:0.00001, loss_test:0.14571, lr:6.89e-03, fs:0.74074 (r=0.606,p=0.952),  time:74.021, tt:6957.938\n",
      "Ep:94, loss:0.00001, loss_test:0.14880, lr:6.83e-03, fs:0.74074 (r=0.606,p=0.952),  time:74.023, tt:7032.214\n",
      "Ep:95, loss:0.00001, loss_test:0.14935, lr:6.76e-03, fs:0.74074 (r=0.606,p=0.952),  time:74.032, tt:7107.061\n",
      "Ep:96, loss:0.00001, loss_test:0.15087, lr:6.69e-03, fs:0.74074 (r=0.606,p=0.952),  time:74.074, tt:7185.216\n",
      "Ep:97, loss:0.00001, loss_test:0.14932, lr:6.62e-03, fs:0.74074 (r=0.606,p=0.952),  time:74.074, tt:7259.262\n",
      "Ep:98, loss:0.00001, loss_test:0.15049, lr:6.56e-03, fs:0.74074 (r=0.606,p=0.952),  time:74.095, tt:7335.358\n",
      "Ep:99, loss:0.00001, loss_test:0.14923, lr:6.49e-03, fs:0.74074 (r=0.606,p=0.952),  time:74.095, tt:7409.544\n",
      "Ep:100, loss:0.00001, loss_test:0.14925, lr:6.43e-03, fs:0.74074 (r=0.606,p=0.952),  time:74.128, tt:7486.922\n",
      "Ep:101, loss:0.00001, loss_test:0.14820, lr:6.36e-03, fs:0.74074 (r=0.606,p=0.952),  time:74.138, tt:7562.092\n",
      "Ep:102, loss:0.00001, loss_test:0.15086, lr:6.30e-03, fs:0.74074 (r=0.606,p=0.952),  time:74.160, tt:7638.454\n",
      "Ep:103, loss:0.00001, loss_test:0.14942, lr:6.24e-03, fs:0.74074 (r=0.606,p=0.952),  time:74.170, tt:7713.644\n",
      "Ep:104, loss:0.00001, loss_test:0.14921, lr:6.17e-03, fs:0.74074 (r=0.606,p=0.952),  time:74.120, tt:7782.623\n",
      "Ep:105, loss:0.00001, loss_test:0.15039, lr:6.11e-03, fs:0.74074 (r=0.606,p=0.952),  time:73.944, tt:7838.046\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"5-5\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,True)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00009, loss_test:0.02288, lr:6.00e-02, fs:0.66148 (r=0.859,p=0.538),  time:17.809, tt:17.809\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02527, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:21.020, tt:42.041\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02653, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.161, tt:69.483\n",
      "Ep:3, loss:0.00005, loss_test:0.02638, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.969, tt:103.875\n",
      "Ep:4, loss:0.00005, loss_test:0.02546, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:27.893, tt:139.467\n",
      "Ep:5, loss:0.00005, loss_test:0.02439, lr:6.00e-02, fs:0.66901 (r=0.960,p=0.514),  time:29.220, tt:175.319\n",
      "Ep:6, loss:0.00005, loss_test:0.02355, lr:6.00e-02, fs:0.65201 (r=0.899,p=0.511),  time:29.943, tt:209.599\n",
      "Ep:7, loss:0.00005, loss_test:0.02273, lr:6.00e-02, fs:0.66667 (r=0.899,p=0.530),  time:30.418, tt:243.341\n",
      "Ep:8, loss:0.00005, loss_test:0.02205, lr:6.00e-02, fs:0.66418 (r=0.899,p=0.527),  time:30.910, tt:278.185\n",
      "Ep:9, loss:0.00004, loss_test:0.02147, lr:6.00e-02, fs:0.67391 (r=0.939,p=0.525),  time:31.282, tt:312.819\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.02090, lr:6.00e-02, fs:0.67626 (r=0.949,p=0.525),  time:31.596, tt:347.552\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.02010, lr:6.00e-02, fs:0.68613 (r=0.949,p=0.537),  time:31.831, tt:381.969\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01942, lr:6.00e-02, fs:0.69925 (r=0.939,p=0.557),  time:32.067, tt:416.866\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01895, lr:6.00e-02, fs:0.70992 (r=0.939,p=0.571),  time:32.200, tt:450.805\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01853, lr:6.00e-02, fs:0.71538 (r=0.939,p=0.578),  time:32.381, tt:485.714\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.01817, lr:6.00e-02, fs:0.71538 (r=0.939,p=0.578),  time:32.499, tt:519.976\n",
      "Ep:16, loss:0.00004, loss_test:0.01783, lr:6.00e-02, fs:0.71815 (r=0.939,p=0.581),  time:32.638, tt:554.841\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.01746, lr:6.00e-02, fs:0.71654 (r=0.919,p=0.587),  time:32.743, tt:589.366\n",
      "Ep:18, loss:0.00003, loss_test:0.01713, lr:6.00e-02, fs:0.70916 (r=0.899,p=0.586),  time:32.862, tt:624.378\n",
      "Ep:19, loss:0.00003, loss_test:0.01688, lr:6.00e-02, fs:0.70635 (r=0.899,p=0.582),  time:32.923, tt:658.458\n",
      "Ep:20, loss:0.00003, loss_test:0.01669, lr:6.00e-02, fs:0.72065 (r=0.899,p=0.601),  time:32.970, tt:692.370\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01661, lr:6.00e-02, fs:0.73251 (r=0.899,p=0.618),  time:33.119, tt:728.623\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01651, lr:6.00e-02, fs:0.74167 (r=0.899,p=0.631),  time:33.235, tt:764.402\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01638, lr:6.00e-02, fs:0.74790 (r=0.899,p=0.640),  time:33.374, tt:800.970\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01629, lr:6.00e-02, fs:0.74043 (r=0.879,p=0.640),  time:33.356, tt:833.903\n",
      "Ep:25, loss:0.00003, loss_test:0.01612, lr:6.00e-02, fs:0.74262 (r=0.889,p=0.638),  time:33.386, tt:868.040\n",
      "Ep:26, loss:0.00003, loss_test:0.01590, lr:6.00e-02, fs:0.74262 (r=0.889,p=0.638),  time:33.487, tt:904.136\n",
      "Ep:27, loss:0.00003, loss_test:0.01561, lr:6.00e-02, fs:0.74678 (r=0.879,p=0.649),  time:33.529, tt:938.819\n",
      "Ep:28, loss:0.00003, loss_test:0.01531, lr:6.00e-02, fs:0.75000 (r=0.879,p=0.654),  time:33.568, tt:973.479\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01507, lr:6.00e-02, fs:0.75862 (r=0.889,p=0.662),  time:33.581, tt:1007.435\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01482, lr:6.00e-02, fs:0.77119 (r=0.919,p=0.664),  time:33.627, tt:1042.428\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01468, lr:6.00e-02, fs:0.77966 (r=0.929,p=0.672),  time:33.656, tt:1076.999\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01447, lr:6.00e-02, fs:0.77447 (r=0.919,p=0.669),  time:33.689, tt:1111.734\n",
      "Ep:33, loss:0.00002, loss_test:0.01421, lr:6.00e-02, fs:0.77586 (r=0.909,p=0.677),  time:33.711, tt:1146.180\n",
      "Ep:34, loss:0.00002, loss_test:0.01407, lr:6.00e-02, fs:0.76724 (r=0.899,p=0.669),  time:33.781, tt:1182.321\n",
      "Ep:35, loss:0.00002, loss_test:0.01378, lr:6.00e-02, fs:0.77729 (r=0.899,p=0.685),  time:33.845, tt:1218.428\n",
      "Ep:36, loss:0.00002, loss_test:0.01364, lr:6.00e-02, fs:0.77586 (r=0.909,p=0.677),  time:33.853, tt:1252.576\n",
      "Ep:37, loss:0.00002, loss_test:0.01357, lr:6.00e-02, fs:0.76522 (r=0.889,p=0.672),  time:33.906, tt:1288.419\n",
      "Ep:38, loss:0.00002, loss_test:0.01349, lr:6.00e-02, fs:0.78761 (r=0.899,p=0.701),  time:33.982, tt:1325.313\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01336, lr:6.00e-02, fs:0.79646 (r=0.909,p=0.709),  time:34.034, tt:1361.357\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01336, lr:6.00e-02, fs:0.79111 (r=0.899,p=0.706),  time:34.059, tt:1396.408\n",
      "Ep:41, loss:0.00002, loss_test:0.01315, lr:6.00e-02, fs:0.79646 (r=0.909,p=0.709),  time:34.074, tt:1431.092\n",
      "Ep:42, loss:0.00002, loss_test:0.01298, lr:6.00e-02, fs:0.81818 (r=0.909,p=0.744),  time:34.072, tt:1465.102\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01318, lr:6.00e-02, fs:0.78924 (r=0.889,p=0.710),  time:34.089, tt:1499.920\n",
      "Ep:44, loss:0.00001, loss_test:0.01279, lr:6.00e-02, fs:0.81279 (r=0.899,p=0.742),  time:34.115, tt:1535.165\n",
      "Ep:45, loss:0.00001, loss_test:0.01270, lr:6.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:34.156, tt:1571.189\n",
      "Ep:46, loss:0.00001, loss_test:0.01333, lr:6.00e-02, fs:0.78027 (r=0.879,p=0.702),  time:34.157, tt:1605.390\n",
      "Ep:47, loss:0.00001, loss_test:0.01265, lr:6.00e-02, fs:0.82028 (r=0.899,p=0.754),  time:34.195, tt:1641.366\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.01247, lr:6.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:34.211, tt:1676.335\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01373, lr:6.00e-02, fs:0.78140 (r=0.848,p=0.724),  time:34.229, tt:1711.469\n",
      "Ep:50, loss:0.00001, loss_test:0.01241, lr:6.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:34.231, tt:1745.789\n",
      "Ep:51, loss:0.00001, loss_test:0.01255, lr:6.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:34.260, tt:1781.542\n",
      "Ep:52, loss:0.00001, loss_test:0.01318, lr:6.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:34.269, tt:1816.254\n",
      "Ep:53, loss:0.00001, loss_test:0.01266, lr:6.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:34.258, tt:1849.942\n",
      "Ep:54, loss:0.00001, loss_test:0.01277, lr:6.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:34.281, tt:1885.436\n",
      "Ep:55, loss:0.00001, loss_test:0.01341, lr:6.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:34.277, tt:1919.505\n",
      "Ep:56, loss:0.00001, loss_test:0.01353, lr:6.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:34.271, tt:1953.465\n",
      "Ep:57, loss:0.00001, loss_test:0.01354, lr:6.00e-02, fs:0.77551 (r=0.768,p=0.784),  time:34.299, tt:1989.336\n",
      "Ep:58, loss:0.00001, loss_test:0.01370, lr:6.00e-02, fs:0.77551 (r=0.768,p=0.784),  time:34.304, tt:2023.921\n",
      "Ep:59, loss:0.00001, loss_test:0.01388, lr:6.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:34.306, tt:2058.366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00001, loss_test:0.01445, lr:5.94e-02, fs:0.77083 (r=0.747,p=0.796),  time:34.324, tt:2093.793\n",
      "Ep:61, loss:0.00001, loss_test:0.01441, lr:5.88e-02, fs:0.77660 (r=0.737,p=0.820),  time:34.342, tt:2129.213\n",
      "Ep:62, loss:0.00001, loss_test:0.01438, lr:5.82e-02, fs:0.78571 (r=0.778,p=0.794),  time:34.348, tt:2163.934\n",
      "Ep:63, loss:0.00001, loss_test:0.01518, lr:5.76e-02, fs:0.72821 (r=0.717,p=0.740),  time:34.332, tt:2197.273\n",
      "Ep:64, loss:0.00001, loss_test:0.01340, lr:5.71e-02, fs:0.77778 (r=0.778,p=0.778),  time:34.295, tt:2229.156\n",
      "Ep:65, loss:0.00001, loss_test:0.01405, lr:5.65e-02, fs:0.73529 (r=0.758,p=0.714),  time:34.321, tt:2265.195\n",
      "Ep:66, loss:0.00001, loss_test:0.01345, lr:5.59e-02, fs:0.82353 (r=0.848,p=0.800),  time:34.328, tt:2299.950\n",
      "Ep:67, loss:0.00001, loss_test:0.01470, lr:5.54e-02, fs:0.74146 (r=0.768,p=0.717),  time:34.345, tt:2335.485\n",
      "Ep:68, loss:0.00001, loss_test:0.01354, lr:5.48e-02, fs:0.80392 (r=0.828,p=0.781),  time:34.341, tt:2369.533\n",
      "Ep:69, loss:0.00001, loss_test:0.01493, lr:5.43e-02, fs:0.75622 (r=0.768,p=0.745),  time:34.356, tt:2404.935\n",
      "Ep:70, loss:0.00001, loss_test:0.01479, lr:5.37e-02, fs:0.78307 (r=0.747,p=0.822),  time:34.354, tt:2439.115\n",
      "Ep:71, loss:0.00001, loss_test:0.01474, lr:5.32e-02, fs:0.78947 (r=0.758,p=0.824),  time:34.372, tt:2474.770\n",
      "Ep:72, loss:0.00001, loss_test:0.01580, lr:5.27e-02, fs:0.74194 (r=0.697,p=0.793),  time:34.389, tt:2510.393\n",
      "Ep:73, loss:0.00001, loss_test:0.01566, lr:5.21e-02, fs:0.77838 (r=0.727,p=0.837),  time:34.391, tt:2544.948\n",
      "Ep:74, loss:0.00001, loss_test:0.01642, lr:5.16e-02, fs:0.72928 (r=0.667,p=0.805),  time:34.391, tt:2579.305\n",
      "Ep:75, loss:0.00001, loss_test:0.01655, lr:5.11e-02, fs:0.77174 (r=0.717,p=0.835),  time:34.398, tt:2614.210\n",
      "Ep:76, loss:0.00001, loss_test:0.01706, lr:5.06e-02, fs:0.73034 (r=0.657,p=0.823),  time:34.404, tt:2649.108\n",
      "Ep:77, loss:0.00001, loss_test:0.01701, lr:5.01e-02, fs:0.77596 (r=0.717,p=0.845),  time:34.418, tt:2684.593\n",
      "Ep:78, loss:0.00001, loss_test:0.01781, lr:4.96e-02, fs:0.72727 (r=0.646,p=0.831),  time:34.426, tt:2719.643\n",
      "Ep:79, loss:0.00001, loss_test:0.01758, lr:4.91e-02, fs:0.76923 (r=0.707,p=0.843),  time:34.424, tt:2753.937\n",
      "Ep:80, loss:0.00001, loss_test:0.01796, lr:4.86e-02, fs:0.74157 (r=0.667,p=0.835),  time:34.423, tt:2788.240\n",
      "Ep:81, loss:0.00001, loss_test:0.01822, lr:4.81e-02, fs:0.74444 (r=0.677,p=0.827),  time:34.423, tt:2822.685\n",
      "Ep:82, loss:0.00001, loss_test:0.01845, lr:4.76e-02, fs:0.75556 (r=0.687,p=0.840),  time:34.414, tt:2856.324\n",
      "Ep:83, loss:0.00000, loss_test:0.01874, lr:4.71e-02, fs:0.72316 (r=0.646,p=0.821),  time:34.415, tt:2890.881\n",
      "Ep:84, loss:0.00000, loss_test:0.01915, lr:4.67e-02, fs:0.75556 (r=0.687,p=0.840),  time:34.398, tt:2923.821\n",
      "Ep:85, loss:0.00000, loss_test:0.01982, lr:4.62e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.396, tt:2958.065\n",
      "Ep:86, loss:0.00000, loss_test:0.02026, lr:4.57e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.392, tt:2992.144\n",
      "Ep:87, loss:0.00000, loss_test:0.02035, lr:4.53e-02, fs:0.71591 (r=0.636,p=0.818),  time:34.390, tt:3026.312\n",
      "Ep:88, loss:0.00000, loss_test:0.02097, lr:4.48e-02, fs:0.71264 (r=0.626,p=0.827),  time:34.386, tt:3060.371\n",
      "Ep:89, loss:0.00000, loss_test:0.02094, lr:4.44e-02, fs:0.70857 (r=0.626,p=0.816),  time:34.375, tt:3093.717\n",
      "Ep:90, loss:0.00000, loss_test:0.02152, lr:4.39e-02, fs:0.71264 (r=0.626,p=0.827),  time:34.373, tt:3127.925\n",
      "Ep:91, loss:0.00000, loss_test:0.02168, lr:4.35e-02, fs:0.70857 (r=0.626,p=0.816),  time:34.373, tt:3162.354\n",
      "Ep:92, loss:0.00000, loss_test:0.02226, lr:4.31e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.405, tt:3199.689\n",
      "Ep:93, loss:0.00000, loss_test:0.02240, lr:4.26e-02, fs:0.70857 (r=0.626,p=0.816),  time:34.397, tt:3233.337\n",
      "Ep:94, loss:0.00000, loss_test:0.02246, lr:4.22e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.397, tt:3267.759\n",
      "Ep:95, loss:0.00000, loss_test:0.02305, lr:4.18e-02, fs:0.70115 (r=0.616,p=0.813),  time:34.389, tt:3301.332\n",
      "Ep:96, loss:0.00000, loss_test:0.02347, lr:4.14e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.397, tt:3336.527\n",
      "Ep:97, loss:0.00000, loss_test:0.02313, lr:4.10e-02, fs:0.71264 (r=0.626,p=0.827),  time:34.392, tt:3370.460\n",
      "Ep:98, loss:0.00000, loss_test:0.02389, lr:4.05e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.403, tt:3405.893\n",
      "Ep:99, loss:0.00000, loss_test:0.02401, lr:4.01e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.400, tt:3440.045\n",
      "Ep:100, loss:0.00000, loss_test:0.02367, lr:3.97e-02, fs:0.71264 (r=0.626,p=0.827),  time:34.397, tt:3474.049\n",
      "Ep:101, loss:0.00000, loss_test:0.02502, lr:3.93e-02, fs:0.70930 (r=0.616,p=0.836),  time:34.387, tt:3507.472\n",
      "Ep:102, loss:0.00000, loss_test:0.02442, lr:3.89e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.370, tt:3540.148\n",
      "Ep:103, loss:0.00000, loss_test:0.02444, lr:3.86e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.374, tt:3574.889\n",
      "Ep:104, loss:0.00000, loss_test:0.02517, lr:3.82e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.361, tt:3607.883\n",
      "Ep:105, loss:0.00000, loss_test:0.02473, lr:3.78e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.354, tt:3641.572\n",
      "Ep:106, loss:0.00000, loss_test:0.02558, lr:3.74e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.346, tt:3675.048\n",
      "Ep:107, loss:0.00000, loss_test:0.02546, lr:3.70e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.349, tt:3709.655\n",
      "Ep:108, loss:0.00000, loss_test:0.02547, lr:3.67e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.354, tt:3744.541\n",
      "Ep:109, loss:0.00000, loss_test:0.02599, lr:3.63e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.342, tt:3777.624\n",
      "Ep:110, loss:0.00000, loss_test:0.02570, lr:3.59e-02, fs:0.70930 (r=0.616,p=0.836),  time:34.338, tt:3811.519\n",
      "Ep:111, loss:0.00000, loss_test:0.02625, lr:3.56e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.349, tt:3847.040\n",
      "Ep:112, loss:0.00000, loss_test:0.02644, lr:3.52e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.367, tt:3883.522\n",
      "Ep:113, loss:0.00000, loss_test:0.02621, lr:3.49e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.370, tt:3918.187\n",
      "Ep:114, loss:0.00000, loss_test:0.02668, lr:3.45e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.373, tt:3952.847\n",
      "Ep:115, loss:0.00000, loss_test:0.02698, lr:3.42e-02, fs:0.70930 (r=0.616,p=0.836),  time:34.370, tt:3986.937\n",
      "Ep:116, loss:0.00000, loss_test:0.02685, lr:3.38e-02, fs:0.70930 (r=0.616,p=0.836),  time:34.363, tt:4020.518\n",
      "Ep:117, loss:0.00000, loss_test:0.02736, lr:3.35e-02, fs:0.71345 (r=0.616,p=0.847),  time:34.350, tt:4053.262\n",
      "Ep:118, loss:0.00000, loss_test:0.02724, lr:3.32e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.329, tt:4085.103\n",
      "Ep:119, loss:0.00000, loss_test:0.02754, lr:3.28e-02, fs:0.71345 (r=0.616,p=0.847),  time:34.312, tt:4117.416\n",
      "Ep:120, loss:0.00000, loss_test:0.02769, lr:3.25e-02, fs:0.70930 (r=0.616,p=0.836),  time:34.318, tt:4152.484\n",
      "Ep:121, loss:0.00000, loss_test:0.02769, lr:3.22e-02, fs:0.71345 (r=0.616,p=0.847),  time:34.308, tt:4185.585\n",
      "Ep:122, loss:0.00000, loss_test:0.02794, lr:3.19e-02, fs:0.70930 (r=0.616,p=0.836),  time:34.306, tt:4219.657\n",
      "Ep:123, loss:0.00000, loss_test:0.02796, lr:3.15e-02, fs:0.71345 (r=0.616,p=0.847),  time:34.283, tt:4251.089\n",
      "Ep:124, loss:0.00000, loss_test:0.02802, lr:3.12e-02, fs:0.71345 (r=0.616,p=0.847),  time:34.283, tt:4285.377\n",
      "Ep:125, loss:0.00000, loss_test:0.02828, lr:3.09e-02, fs:0.71345 (r=0.616,p=0.847),  time:34.285, tt:4319.916\n",
      "Ep:126, loss:0.00000, loss_test:0.02828, lr:3.06e-02, fs:0.71345 (r=0.616,p=0.847),  time:34.284, tt:4354.111\n",
      "Ep:127, loss:0.00000, loss_test:0.02871, lr:3.03e-02, fs:0.71345 (r=0.616,p=0.847),  time:34.274, tt:4387.021\n",
      "Ep:128, loss:0.00000, loss_test:0.02847, lr:3.00e-02, fs:0.71345 (r=0.616,p=0.847),  time:34.278, tt:4421.924\n",
      "Ep:129, loss:0.00000, loss_test:0.02878, lr:2.97e-02, fs:0.71345 (r=0.616,p=0.847),  time:34.275, tt:4455.764\n",
      "Ep:130, loss:0.00000, loss_test:0.02880, lr:2.94e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.267, tt:4488.929\n",
      "Ep:131, loss:0.00000, loss_test:0.02892, lr:2.91e-02, fs:0.71345 (r=0.616,p=0.847),  time:34.269, tt:4523.530\n",
      "Ep:132, loss:0.00000, loss_test:0.02897, lr:2.88e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.273, tt:4558.284\n",
      "Ep:133, loss:0.00000, loss_test:0.02910, lr:2.85e-02, fs:0.71345 (r=0.616,p=0.847),  time:34.274, tt:4592.763\n",
      "Ep:134, loss:0.00000, loss_test:0.02931, lr:2.82e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.288, tt:4628.854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00000, loss_test:0.02919, lr:2.80e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.296, tt:4664.293\n",
      "Ep:136, loss:0.00000, loss_test:0.02940, lr:2.77e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.305, tt:4699.810\n",
      "Ep:137, loss:0.00000, loss_test:0.02954, lr:2.74e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.306, tt:4734.195\n",
      "Ep:138, loss:0.00000, loss_test:0.02954, lr:2.71e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.309, tt:4769.007\n",
      "Ep:139, loss:0.00000, loss_test:0.02974, lr:2.69e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.326, tt:4805.671\n",
      "Ep:140, loss:0.00000, loss_test:0.02975, lr:2.66e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.337, tt:4841.586\n",
      "Ep:141, loss:0.00000, loss_test:0.02975, lr:2.63e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.334, tt:4875.495\n",
      "Ep:142, loss:0.00000, loss_test:0.03013, lr:2.61e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.337, tt:4910.170\n",
      "Ep:143, loss:0.00000, loss_test:0.03002, lr:2.58e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.333, tt:4943.918\n",
      "Ep:144, loss:0.00000, loss_test:0.03020, lr:2.55e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.344, tt:4979.914\n",
      "Ep:145, loss:0.00000, loss_test:0.03047, lr:2.53e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.348, tt:5014.785\n",
      "Ep:146, loss:0.00000, loss_test:0.03018, lr:2.50e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.344, tt:5048.641\n",
      "Ep:147, loss:0.00000, loss_test:0.03053, lr:2.48e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.340, tt:5082.343\n",
      "Ep:148, loss:0.00000, loss_test:0.03048, lr:2.45e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.339, tt:5116.469\n",
      "Ep:149, loss:0.00000, loss_test:0.03049, lr:2.43e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.344, tt:5151.629\n",
      "Ep:150, loss:0.00000, loss_test:0.03058, lr:2.40e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.350, tt:5186.841\n",
      "Ep:151, loss:0.00000, loss_test:0.03069, lr:2.38e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.349, tt:5221.079\n",
      "Ep:152, loss:0.00000, loss_test:0.03081, lr:2.36e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.342, tt:5254.303\n",
      "Ep:153, loss:0.00000, loss_test:0.03083, lr:2.33e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.337, tt:5287.951\n",
      "Ep:154, loss:0.00000, loss_test:0.03104, lr:2.31e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.342, tt:5323.072\n",
      "Ep:155, loss:0.00000, loss_test:0.03099, lr:2.29e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.332, tt:5355.850\n",
      "Ep:156, loss:0.00000, loss_test:0.03102, lr:2.26e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.334, tt:5390.473\n",
      "Ep:157, loss:0.00000, loss_test:0.03121, lr:2.24e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.339, tt:5425.545\n",
      "Ep:158, loss:0.00000, loss_test:0.03096, lr:2.22e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.335, tt:5459.285\n",
      "Ep:159, loss:0.00000, loss_test:0.03147, lr:2.20e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.332, tt:5493.181\n",
      "Ep:160, loss:0.00000, loss_test:0.03122, lr:2.17e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.332, tt:5527.459\n",
      "Ep:161, loss:0.00000, loss_test:0.03137, lr:2.15e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.334, tt:5562.071\n",
      "Ep:162, loss:0.00000, loss_test:0.03140, lr:2.13e-02, fs:0.73054 (r=0.616,p=0.897),  time:34.337, tt:5596.853\n",
      "Ep:163, loss:0.00000, loss_test:0.03152, lr:2.11e-02, fs:0.72619 (r=0.616,p=0.884),  time:34.337, tt:5631.226\n",
      "Ep:164, loss:0.00000, loss_test:0.03142, lr:2.09e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.326, tt:5663.822\n",
      "Ep:165, loss:0.00000, loss_test:0.03151, lr:2.07e-02, fs:0.72619 (r=0.616,p=0.884),  time:34.337, tt:5699.874\n",
      "Ep:166, loss:0.00000, loss_test:0.03153, lr:2.05e-02, fs:0.72619 (r=0.616,p=0.884),  time:34.345, tt:5735.548\n",
      "Ep:167, loss:0.00000, loss_test:0.03169, lr:2.03e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.350, tt:5770.719\n",
      "Ep:168, loss:0.00000, loss_test:0.03175, lr:2.01e-02, fs:0.73054 (r=0.616,p=0.897),  time:34.359, tt:5806.677\n",
      "Ep:169, loss:0.00000, loss_test:0.03175, lr:1.99e-02, fs:0.73054 (r=0.616,p=0.897),  time:34.368, tt:5842.574\n",
      "Ep:170, loss:0.00000, loss_test:0.03172, lr:1.97e-02, fs:0.72619 (r=0.616,p=0.884),  time:34.369, tt:5877.152\n",
      "Ep:171, loss:0.00000, loss_test:0.03172, lr:1.95e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.375, tt:5912.568\n",
      "Ep:172, loss:0.00000, loss_test:0.03192, lr:1.93e-02, fs:0.72619 (r=0.616,p=0.884),  time:34.372, tt:5946.392\n",
      "Ep:173, loss:0.00000, loss_test:0.03192, lr:1.91e-02, fs:0.73054 (r=0.616,p=0.897),  time:34.374, tt:5981.000\n",
      "Ep:174, loss:0.00000, loss_test:0.03185, lr:1.89e-02, fs:0.73054 (r=0.616,p=0.897),  time:34.372, tt:6015.120\n",
      "Ep:175, loss:0.00000, loss_test:0.03200, lr:1.87e-02, fs:0.72619 (r=0.616,p=0.884),  time:34.373, tt:6049.689\n",
      "Ep:176, loss:0.00000, loss_test:0.03196, lr:1.85e-02, fs:0.73054 (r=0.616,p=0.897),  time:34.389, tt:6086.872\n",
      "Ep:177, loss:0.00000, loss_test:0.03219, lr:1.83e-02, fs:0.73054 (r=0.616,p=0.897),  time:34.395, tt:6122.233\n",
      "Ep:178, loss:0.00000, loss_test:0.03210, lr:1.81e-02, fs:0.73054 (r=0.616,p=0.897),  time:34.403, tt:6158.221\n",
      "Ep:179, loss:0.00000, loss_test:0.03211, lr:1.80e-02, fs:0.72619 (r=0.616,p=0.884),  time:34.410, tt:6193.734\n",
      "Ep:180, loss:0.00000, loss_test:0.03228, lr:1.78e-02, fs:0.73054 (r=0.616,p=0.897),  time:34.422, tt:6230.372\n",
      "Ep:181, loss:0.00000, loss_test:0.03223, lr:1.76e-02, fs:0.73054 (r=0.616,p=0.897),  time:34.427, tt:6265.638\n",
      "Ep:182, loss:0.00000, loss_test:0.03224, lr:1.74e-02, fs:0.73054 (r=0.616,p=0.897),  time:34.423, tt:6299.353\n",
      "Ep:183, loss:0.00000, loss_test:0.03231, lr:1.73e-02, fs:0.72619 (r=0.616,p=0.884),  time:34.434, tt:6335.798\n",
      "Ep:184, loss:0.00000, loss_test:0.03234, lr:1.71e-02, fs:0.73054 (r=0.616,p=0.897),  time:34.431, tt:6369.819\n",
      "Ep:185, loss:0.00000, loss_test:0.03235, lr:1.69e-02, fs:0.73054 (r=0.616,p=0.897),  time:34.434, tt:6404.684\n",
      "Ep:186, loss:0.00000, loss_test:0.03244, lr:1.67e-02, fs:0.73054 (r=0.616,p=0.897),  time:34.442, tt:6440.728\n",
      "Ep:187, loss:0.00000, loss_test:0.03249, lr:1.66e-02, fs:0.73054 (r=0.616,p=0.897),  time:34.454, tt:6477.368\n",
      "Ep:188, loss:0.00000, loss_test:0.03236, lr:1.64e-02, fs:0.72619 (r=0.616,p=0.884),  time:34.456, tt:6512.097\n",
      "Ep:189, loss:0.00000, loss_test:0.03254, lr:1.62e-02, fs:0.73054 (r=0.616,p=0.897),  time:34.466, tt:6548.529\n",
      "Ep:190, loss:0.00000, loss_test:0.03261, lr:1.61e-02, fs:0.73054 (r=0.616,p=0.897),  time:34.477, tt:6585.045\n",
      "Ep:191, loss:0.00000, loss_test:0.03256, lr:1.59e-02, fs:0.72619 (r=0.616,p=0.884),  time:34.477, tt:6619.495\n",
      "Ep:192, loss:0.00000, loss_test:0.03260, lr:1.58e-02, fs:0.73054 (r=0.616,p=0.897),  time:34.478, tt:6654.247\n",
      "Ep:193, loss:0.00000, loss_test:0.03272, lr:1.56e-02, fs:0.73054 (r=0.616,p=0.897),  time:34.474, tt:6687.888\n",
      "Ep:194, loss:0.00000, loss_test:0.03271, lr:1.54e-02, fs:0.73054 (r=0.616,p=0.897),  time:34.458, tt:6719.403\n",
      "Ep:195, loss:0.00000, loss_test:0.03262, lr:1.53e-02, fs:0.73054 (r=0.616,p=0.897),  time:34.433, tt:6748.831\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02024, lr:6.00e-02, fs:0.65134 (r=0.859,p=0.525),  time:27.316, tt:27.316\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02286, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.714, tt:53.428\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02490, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.788, tt:83.365\n",
      "Ep:3, loss:0.00005, loss_test:0.02517, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.834, tt:111.336\n",
      "Ep:4, loss:0.00005, loss_test:0.02438, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.157, tt:140.787\n",
      "Ep:5, loss:0.00005, loss_test:0.02312, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.212, tt:169.270\n",
      "Ep:6, loss:0.00004, loss_test:0.02157, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:28.302, tt:198.111\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.02005, lr:6.00e-02, fs:0.66897 (r=0.980,p=0.508),  time:28.367, tt:226.939\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:8, loss:0.00004, loss_test:0.01887, lr:6.00e-02, fs:0.68841 (r=0.960,p=0.537),  time:28.524, tt:256.712\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01814, lr:6.00e-02, fs:0.67939 (r=0.899,p=0.546),  time:28.613, tt:286.133\n",
      "Ep:10, loss:0.00004, loss_test:0.01767, lr:6.00e-02, fs:0.70079 (r=0.899,p=0.574),  time:28.612, tt:314.737\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01730, lr:6.00e-02, fs:0.71595 (r=0.929,p=0.582),  time:28.643, tt:343.714\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01714, lr:6.00e-02, fs:0.72519 (r=0.960,p=0.583),  time:28.648, tt:372.420\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01698, lr:6.00e-02, fs:0.72308 (r=0.949,p=0.584),  time:28.783, tt:402.965\n",
      "Ep:14, loss:0.00003, loss_test:0.01679, lr:6.00e-02, fs:0.73077 (r=0.960,p=0.590),  time:28.761, tt:431.413\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01656, lr:6.00e-02, fs:0.74219 (r=0.960,p=0.605),  time:28.807, tt:460.910\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01633, lr:6.00e-02, fs:0.74900 (r=0.949,p=0.618),  time:28.859, tt:490.611\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01611, lr:6.00e-02, fs:0.75200 (r=0.949,p=0.623),  time:28.864, tt:519.545\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01591, lr:6.00e-02, fs:0.75000 (r=0.939,p=0.624),  time:28.957, tt:550.177\n",
      "Ep:19, loss:0.00003, loss_test:0.01572, lr:6.00e-02, fs:0.75610 (r=0.939,p=0.633),  time:28.925, tt:578.493\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01554, lr:6.00e-02, fs:0.76543 (r=0.939,p=0.646),  time:28.973, tt:608.442\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01538, lr:6.00e-02, fs:0.76860 (r=0.939,p=0.650),  time:29.016, tt:638.362\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01523, lr:6.00e-02, fs:0.77049 (r=0.949,p=0.648),  time:29.005, tt:667.115\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01508, lr:6.00e-02, fs:0.77049 (r=0.949,p=0.648),  time:29.041, tt:696.992\n",
      "Ep:24, loss:0.00003, loss_test:0.01493, lr:6.00e-02, fs:0.77686 (r=0.949,p=0.657),  time:29.031, tt:725.779\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01480, lr:6.00e-02, fs:0.78992 (r=0.949,p=0.676),  time:29.081, tt:756.097\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01468, lr:6.00e-02, fs:0.79325 (r=0.949,p=0.681),  time:29.059, tt:784.582\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01455, lr:6.00e-02, fs:0.79325 (r=0.949,p=0.681),  time:29.038, tt:813.071\n",
      "Ep:28, loss:0.00002, loss_test:0.01442, lr:6.00e-02, fs:0.79325 (r=0.949,p=0.681),  time:29.003, tt:841.101\n",
      "Ep:29, loss:0.00002, loss_test:0.01429, lr:6.00e-02, fs:0.79325 (r=0.949,p=0.681),  time:29.063, tt:871.890\n",
      "Ep:30, loss:0.00002, loss_test:0.01416, lr:6.00e-02, fs:0.79325 (r=0.949,p=0.681),  time:29.122, tt:902.773\n",
      "Ep:31, loss:0.00002, loss_test:0.01405, lr:6.00e-02, fs:0.80508 (r=0.960,p=0.693),  time:29.141, tt:932.527\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01393, lr:6.00e-02, fs:0.81702 (r=0.970,p=0.706),  time:29.194, tt:963.393\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01382, lr:6.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:29.158, tt:991.365\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01372, lr:6.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:29.187, tt:1021.542\n",
      "Ep:35, loss:0.00002, loss_test:0.01363, lr:6.00e-02, fs:0.82251 (r=0.960,p=0.720),  time:29.209, tt:1051.524\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01354, lr:6.00e-02, fs:0.82251 (r=0.960,p=0.720),  time:29.241, tt:1081.925\n",
      "Ep:37, loss:0.00002, loss_test:0.01344, lr:6.00e-02, fs:0.83262 (r=0.980,p=0.724),  time:29.316, tt:1114.012\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01335, lr:6.00e-02, fs:0.83621 (r=0.980,p=0.729),  time:29.332, tt:1143.951\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01328, lr:6.00e-02, fs:0.83983 (r=0.980,p=0.735),  time:29.340, tt:1173.596\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01319, lr:6.00e-02, fs:0.84716 (r=0.980,p=0.746),  time:29.388, tt:1204.910\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01310, lr:6.00e-02, fs:0.84348 (r=0.980,p=0.740),  time:29.423, tt:1235.785\n",
      "Ep:42, loss:0.00002, loss_test:0.01303, lr:6.00e-02, fs:0.85088 (r=0.980,p=0.752),  time:29.431, tt:1265.535\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01296, lr:6.00e-02, fs:0.85088 (r=0.980,p=0.752),  time:29.467, tt:1296.552\n",
      "Ep:44, loss:0.00002, loss_test:0.01289, lr:6.00e-02, fs:0.85463 (r=0.980,p=0.758),  time:29.494, tt:1327.235\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01283, lr:6.00e-02, fs:0.85463 (r=0.980,p=0.758),  time:29.488, tt:1356.457\n",
      "Ep:46, loss:0.00002, loss_test:0.01275, lr:6.00e-02, fs:0.85463 (r=0.980,p=0.758),  time:29.488, tt:1385.956\n",
      "Ep:47, loss:0.00002, loss_test:0.01269, lr:6.00e-02, fs:0.85463 (r=0.980,p=0.758),  time:29.523, tt:1417.082\n",
      "Ep:48, loss:0.00002, loss_test:0.01262, lr:6.00e-02, fs:0.85841 (r=0.980,p=0.764),  time:29.563, tt:1448.589\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01256, lr:6.00e-02, fs:0.86344 (r=0.990,p=0.766),  time:29.554, tt:1477.707\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01250, lr:6.00e-02, fs:0.86344 (r=0.990,p=0.766),  time:29.572, tt:1508.160\n",
      "Ep:51, loss:0.00002, loss_test:0.01246, lr:6.00e-02, fs:0.86726 (r=0.990,p=0.772),  time:29.573, tt:1537.822\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01242, lr:6.00e-02, fs:0.86726 (r=0.990,p=0.772),  time:29.590, tt:1568.292\n",
      "Ep:53, loss:0.00002, loss_test:0.01238, lr:6.00e-02, fs:0.86726 (r=0.990,p=0.772),  time:29.605, tt:1598.667\n",
      "Ep:54, loss:0.00002, loss_test:0.01234, lr:6.00e-02, fs:0.86222 (r=0.980,p=0.770),  time:29.599, tt:1627.969\n",
      "Ep:55, loss:0.00002, loss_test:0.01230, lr:6.00e-02, fs:0.86222 (r=0.980,p=0.770),  time:29.628, tt:1659.175\n",
      "Ep:56, loss:0.00002, loss_test:0.01226, lr:6.00e-02, fs:0.86726 (r=0.990,p=0.772),  time:29.641, tt:1689.546\n",
      "Ep:57, loss:0.00002, loss_test:0.01222, lr:6.00e-02, fs:0.86099 (r=0.970,p=0.774),  time:29.650, tt:1719.717\n",
      "Ep:58, loss:0.00002, loss_test:0.01217, lr:6.00e-02, fs:0.87111 (r=0.990,p=0.778),  time:29.652, tt:1749.459\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00002, loss_test:0.01217, lr:6.00e-02, fs:0.86607 (r=0.980,p=0.776),  time:29.692, tt:1781.532\n",
      "Ep:60, loss:0.00002, loss_test:0.01214, lr:6.00e-02, fs:0.86099 (r=0.970,p=0.774),  time:29.710, tt:1812.325\n",
      "Ep:61, loss:0.00001, loss_test:0.01210, lr:6.00e-02, fs:0.87387 (r=0.980,p=0.789),  time:29.699, tt:1841.353\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01207, lr:6.00e-02, fs:0.87387 (r=0.980,p=0.789),  time:29.722, tt:1872.516\n",
      "Ep:63, loss:0.00001, loss_test:0.01204, lr:6.00e-02, fs:0.87387 (r=0.980,p=0.789),  time:29.730, tt:1902.703\n",
      "Ep:64, loss:0.00001, loss_test:0.01200, lr:6.00e-02, fs:0.87387 (r=0.980,p=0.789),  time:29.716, tt:1931.569\n",
      "Ep:65, loss:0.00001, loss_test:0.01197, lr:6.00e-02, fs:0.87783 (r=0.980,p=0.795),  time:29.674, tt:1958.515\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.01196, lr:6.00e-02, fs:0.87156 (r=0.960,p=0.798),  time:29.657, tt:1987.007\n",
      "Ep:67, loss:0.00001, loss_test:0.01193, lr:6.00e-02, fs:0.87156 (r=0.960,p=0.798),  time:29.661, tt:2016.958\n",
      "Ep:68, loss:0.00001, loss_test:0.01190, lr:6.00e-02, fs:0.87156 (r=0.960,p=0.798),  time:29.665, tt:2046.854\n",
      "Ep:69, loss:0.00001, loss_test:0.01187, lr:6.00e-02, fs:0.87671 (r=0.970,p=0.800),  time:29.690, tt:2078.329\n",
      "Ep:70, loss:0.00001, loss_test:0.01185, lr:6.00e-02, fs:0.87671 (r=0.970,p=0.800),  time:29.710, tt:2109.423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:71, loss:0.00001, loss_test:0.01182, lr:6.00e-02, fs:0.87671 (r=0.970,p=0.800),  time:29.709, tt:2139.018\n",
      "Ep:72, loss:0.00001, loss_test:0.01181, lr:6.00e-02, fs:0.87671 (r=0.970,p=0.800),  time:29.738, tt:2170.856\n",
      "Ep:73, loss:0.00001, loss_test:0.01178, lr:6.00e-02, fs:0.86636 (r=0.949,p=0.797),  time:29.749, tt:2201.443\n",
      "Ep:74, loss:0.00001, loss_test:0.01178, lr:6.00e-02, fs:0.86636 (r=0.949,p=0.797),  time:29.737, tt:2230.259\n",
      "Ep:75, loss:0.00001, loss_test:0.01177, lr:6.00e-02, fs:0.86636 (r=0.949,p=0.797),  time:29.736, tt:2259.933\n",
      "Ep:76, loss:0.00001, loss_test:0.01177, lr:6.00e-02, fs:0.86636 (r=0.949,p=0.797),  time:29.730, tt:2289.195\n",
      "Ep:77, loss:0.00001, loss_test:0.01174, lr:5.94e-02, fs:0.86636 (r=0.949,p=0.797),  time:29.724, tt:2318.441\n",
      "Ep:78, loss:0.00001, loss_test:0.01172, lr:5.88e-02, fs:0.87037 (r=0.949,p=0.803),  time:29.716, tt:2347.568\n",
      "Ep:79, loss:0.00001, loss_test:0.01170, lr:5.82e-02, fs:0.87442 (r=0.949,p=0.810),  time:29.692, tt:2375.355\n",
      "Ep:80, loss:0.00001, loss_test:0.01170, lr:5.76e-02, fs:0.87442 (r=0.949,p=0.810),  time:29.694, tt:2405.218\n",
      "Ep:81, loss:0.00001, loss_test:0.01170, lr:5.71e-02, fs:0.87442 (r=0.949,p=0.810),  time:29.723, tt:2437.253\n",
      "Ep:82, loss:0.00001, loss_test:0.01170, lr:5.65e-02, fs:0.87442 (r=0.949,p=0.810),  time:29.736, tt:2468.060\n",
      "Ep:83, loss:0.00001, loss_test:0.01168, lr:5.59e-02, fs:0.87442 (r=0.949,p=0.810),  time:29.740, tt:2498.127\n",
      "Ep:84, loss:0.00001, loss_test:0.01165, lr:5.54e-02, fs:0.87442 (r=0.949,p=0.810),  time:29.736, tt:2527.578\n",
      "Ep:85, loss:0.00001, loss_test:0.01162, lr:5.48e-02, fs:0.87442 (r=0.949,p=0.810),  time:29.744, tt:2557.950\n",
      "Ep:86, loss:0.00001, loss_test:0.01162, lr:5.43e-02, fs:0.87442 (r=0.949,p=0.810),  time:29.748, tt:2588.084\n",
      "Ep:87, loss:0.00001, loss_test:0.01161, lr:5.37e-02, fs:0.87442 (r=0.949,p=0.810),  time:29.749, tt:2617.923\n",
      "Ep:88, loss:0.00001, loss_test:0.01161, lr:5.32e-02, fs:0.87442 (r=0.949,p=0.810),  time:29.748, tt:2647.534\n",
      "Ep:89, loss:0.00001, loss_test:0.01159, lr:5.27e-02, fs:0.87442 (r=0.949,p=0.810),  time:29.759, tt:2678.273\n",
      "Ep:90, loss:0.00001, loss_test:0.01158, lr:5.21e-02, fs:0.87442 (r=0.949,p=0.810),  time:29.761, tt:2708.252\n",
      "Ep:91, loss:0.00001, loss_test:0.01159, lr:5.16e-02, fs:0.87442 (r=0.949,p=0.810),  time:29.771, tt:2738.934\n",
      "Ep:92, loss:0.00001, loss_test:0.01160, lr:5.11e-02, fs:0.87442 (r=0.949,p=0.810),  time:29.780, tt:2769.530\n",
      "Ep:93, loss:0.00001, loss_test:0.01161, lr:5.06e-02, fs:0.87442 (r=0.949,p=0.810),  time:29.782, tt:2799.529\n",
      "Ep:94, loss:0.00001, loss_test:0.01159, lr:5.01e-02, fs:0.87442 (r=0.949,p=0.810),  time:29.799, tt:2830.908\n",
      "Ep:95, loss:0.00001, loss_test:0.01158, lr:4.96e-02, fs:0.87442 (r=0.949,p=0.810),  time:29.788, tt:2859.639\n",
      "Ep:96, loss:0.00001, loss_test:0.01157, lr:4.91e-02, fs:0.87442 (r=0.949,p=0.810),  time:29.805, tt:2891.043\n",
      "Ep:97, loss:0.00001, loss_test:0.01157, lr:4.86e-02, fs:0.87442 (r=0.949,p=0.810),  time:29.815, tt:2921.873\n",
      "Ep:98, loss:0.00001, loss_test:0.01157, lr:4.81e-02, fs:0.87442 (r=0.949,p=0.810),  time:29.824, tt:2952.558\n",
      "Ep:99, loss:0.00001, loss_test:0.01156, lr:4.76e-02, fs:0.87442 (r=0.949,p=0.810),  time:29.816, tt:2981.590\n",
      "Ep:100, loss:0.00001, loss_test:0.01158, lr:4.71e-02, fs:0.87442 (r=0.949,p=0.810),  time:29.832, tt:3012.984\n",
      "Ep:101, loss:0.00001, loss_test:0.01157, lr:4.67e-02, fs:0.87442 (r=0.949,p=0.810),  time:29.843, tt:3043.958\n",
      "Ep:102, loss:0.00001, loss_test:0.01156, lr:4.62e-02, fs:0.87442 (r=0.949,p=0.810),  time:29.843, tt:3073.857\n",
      "Ep:103, loss:0.00001, loss_test:0.01155, lr:4.57e-02, fs:0.87442 (r=0.949,p=0.810),  time:29.844, tt:3103.747\n",
      "Ep:104, loss:0.00001, loss_test:0.01155, lr:4.53e-02, fs:0.87442 (r=0.949,p=0.810),  time:29.842, tt:3133.438\n",
      "Ep:105, loss:0.00001, loss_test:0.01158, lr:4.48e-02, fs:0.87850 (r=0.949,p=0.817),  time:29.850, tt:3164.068\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00001, loss_test:0.01160, lr:4.48e-02, fs:0.87324 (r=0.939,p=0.816),  time:29.854, tt:3194.349\n",
      "Ep:107, loss:0.00001, loss_test:0.01159, lr:4.48e-02, fs:0.87324 (r=0.939,p=0.816),  time:29.847, tt:3223.508\n",
      "Ep:108, loss:0.00001, loss_test:0.01159, lr:4.48e-02, fs:0.87324 (r=0.939,p=0.816),  time:29.843, tt:3252.899\n",
      "Ep:109, loss:0.00001, loss_test:0.01158, lr:4.48e-02, fs:0.87324 (r=0.939,p=0.816),  time:29.848, tt:3283.281\n",
      "Ep:110, loss:0.00001, loss_test:0.01158, lr:4.48e-02, fs:0.87324 (r=0.939,p=0.816),  time:29.846, tt:3312.903\n",
      "Ep:111, loss:0.00001, loss_test:0.01159, lr:4.48e-02, fs:0.87324 (r=0.939,p=0.816),  time:29.856, tt:3343.910\n",
      "Ep:112, loss:0.00001, loss_test:0.01160, lr:4.48e-02, fs:0.87736 (r=0.939,p=0.823),  time:29.864, tt:3374.677\n",
      "Ep:113, loss:0.00001, loss_test:0.01161, lr:4.48e-02, fs:0.87736 (r=0.939,p=0.823),  time:29.860, tt:3404.035\n",
      "Ep:114, loss:0.00001, loss_test:0.01162, lr:4.48e-02, fs:0.87736 (r=0.939,p=0.823),  time:29.850, tt:3432.710\n",
      "Ep:115, loss:0.00001, loss_test:0.01163, lr:4.48e-02, fs:0.87736 (r=0.939,p=0.823),  time:29.860, tt:3463.718\n",
      "Ep:116, loss:0.00001, loss_test:0.01165, lr:4.48e-02, fs:0.87736 (r=0.939,p=0.823),  time:29.861, tt:3493.723\n",
      "Ep:117, loss:0.00001, loss_test:0.01164, lr:4.44e-02, fs:0.87736 (r=0.939,p=0.823),  time:29.857, tt:3523.101\n",
      "Ep:118, loss:0.00001, loss_test:0.01165, lr:4.39e-02, fs:0.87736 (r=0.939,p=0.823),  time:29.851, tt:3552.305\n",
      "Ep:119, loss:0.00001, loss_test:0.01166, lr:4.35e-02, fs:0.87736 (r=0.939,p=0.823),  time:29.847, tt:3581.675\n",
      "Ep:120, loss:0.00001, loss_test:0.01167, lr:4.31e-02, fs:0.87736 (r=0.939,p=0.823),  time:29.846, tt:3611.391\n",
      "Ep:121, loss:0.00001, loss_test:0.01169, lr:4.26e-02, fs:0.88152 (r=0.939,p=0.830),  time:29.843, tt:3640.901\n",
      "##########Best model found so far##########\n",
      "Ep:122, loss:0.00001, loss_test:0.01169, lr:4.26e-02, fs:0.88571 (r=0.939,p=0.838),  time:29.840, tt:3670.272\n",
      "##########Best model found so far##########\n",
      "Ep:123, loss:0.00001, loss_test:0.01168, lr:4.26e-02, fs:0.88571 (r=0.939,p=0.838),  time:29.847, tt:3701.061\n",
      "Ep:124, loss:0.00001, loss_test:0.01169, lr:4.26e-02, fs:0.88995 (r=0.939,p=0.845),  time:29.849, tt:3731.089\n",
      "##########Best model found so far##########\n",
      "Ep:125, loss:0.00001, loss_test:0.01171, lr:4.26e-02, fs:0.88995 (r=0.939,p=0.845),  time:29.854, tt:3761.606\n",
      "Ep:126, loss:0.00001, loss_test:0.01171, lr:4.26e-02, fs:0.88995 (r=0.939,p=0.845),  time:29.852, tt:3791.204\n",
      "Ep:127, loss:0.00001, loss_test:0.01173, lr:4.26e-02, fs:0.88995 (r=0.939,p=0.845),  time:29.850, tt:3820.853\n",
      "Ep:128, loss:0.00001, loss_test:0.01175, lr:4.26e-02, fs:0.88995 (r=0.939,p=0.845),  time:29.851, tt:3850.824\n",
      "Ep:129, loss:0.00001, loss_test:0.01176, lr:4.26e-02, fs:0.88995 (r=0.939,p=0.845),  time:29.844, tt:3879.742\n",
      "Ep:130, loss:0.00001, loss_test:0.01177, lr:4.26e-02, fs:0.88995 (r=0.939,p=0.845),  time:29.841, tt:3909.229\n",
      "Ep:131, loss:0.00001, loss_test:0.01178, lr:4.26e-02, fs:0.88995 (r=0.939,p=0.845),  time:29.833, tt:3937.976\n",
      "Ep:132, loss:0.00001, loss_test:0.01180, lr:4.26e-02, fs:0.88995 (r=0.939,p=0.845),  time:29.829, tt:3967.214\n",
      "Ep:133, loss:0.00001, loss_test:0.01181, lr:4.26e-02, fs:0.89423 (r=0.939,p=0.853),  time:29.835, tt:3997.837\n",
      "##########Best model found so far##########\n",
      "Ep:134, loss:0.00001, loss_test:0.01182, lr:4.26e-02, fs:0.89423 (r=0.939,p=0.853),  time:29.831, tt:4027.230\n",
      "Ep:135, loss:0.00001, loss_test:0.01183, lr:4.26e-02, fs:0.89855 (r=0.939,p=0.861),  time:29.836, tt:4057.745\n",
      "##########Best model found so far##########\n",
      "Ep:136, loss:0.00001, loss_test:0.01185, lr:4.26e-02, fs:0.90291 (r=0.939,p=0.869),  time:29.837, tt:4087.625\n",
      "##########Best model found so far##########\n",
      "Ep:137, loss:0.00001, loss_test:0.01186, lr:4.26e-02, fs:0.90291 (r=0.939,p=0.869),  time:29.838, tt:4117.624\n",
      "Ep:138, loss:0.00001, loss_test:0.01188, lr:4.26e-02, fs:0.90291 (r=0.939,p=0.869),  time:29.830, tt:4146.374\n",
      "Ep:139, loss:0.00001, loss_test:0.01188, lr:4.26e-02, fs:0.90291 (r=0.939,p=0.869),  time:29.826, tt:4175.624\n",
      "Ep:140, loss:0.00001, loss_test:0.01190, lr:4.26e-02, fs:0.90291 (r=0.939,p=0.869),  time:29.822, tt:4204.921\n",
      "Ep:141, loss:0.00001, loss_test:0.01189, lr:4.26e-02, fs:0.90291 (r=0.939,p=0.869),  time:29.819, tt:4234.231\n",
      "Ep:142, loss:0.00001, loss_test:0.01192, lr:4.26e-02, fs:0.90732 (r=0.939,p=0.877),  time:29.819, tt:4264.156\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:143, loss:0.00001, loss_test:0.01193, lr:4.26e-02, fs:0.90732 (r=0.939,p=0.877),  time:29.826, tt:4294.952\n",
      "Ep:144, loss:0.00001, loss_test:0.01193, lr:4.26e-02, fs:0.90732 (r=0.939,p=0.877),  time:29.830, tt:4325.317\n",
      "Ep:145, loss:0.00001, loss_test:0.01196, lr:4.26e-02, fs:0.90732 (r=0.939,p=0.877),  time:29.826, tt:4354.592\n",
      "Ep:146, loss:0.00001, loss_test:0.01198, lr:4.26e-02, fs:0.90732 (r=0.939,p=0.877),  time:29.835, tt:4385.802\n",
      "Ep:147, loss:0.00001, loss_test:0.01199, lr:4.26e-02, fs:0.90732 (r=0.939,p=0.877),  time:29.841, tt:4416.469\n",
      "Ep:148, loss:0.00001, loss_test:0.01202, lr:4.26e-02, fs:0.90732 (r=0.939,p=0.877),  time:29.841, tt:4446.265\n",
      "Ep:149, loss:0.00001, loss_test:0.01203, lr:4.26e-02, fs:0.90732 (r=0.939,p=0.877),  time:29.833, tt:4474.983\n",
      "Ep:150, loss:0.00001, loss_test:0.01205, lr:4.26e-02, fs:0.90732 (r=0.939,p=0.877),  time:29.828, tt:4504.018\n",
      "Ep:151, loss:0.00001, loss_test:0.01205, lr:4.26e-02, fs:0.90732 (r=0.939,p=0.877),  time:29.825, tt:4533.430\n",
      "Ep:152, loss:0.00001, loss_test:0.01208, lr:4.26e-02, fs:0.90732 (r=0.939,p=0.877),  time:29.834, tt:4564.545\n",
      "Ep:153, loss:0.00001, loss_test:0.01210, lr:4.26e-02, fs:0.91176 (r=0.939,p=0.886),  time:29.846, tt:4596.287\n",
      "##########Best model found so far##########\n",
      "Ep:154, loss:0.00001, loss_test:0.01213, lr:4.26e-02, fs:0.91176 (r=0.939,p=0.886),  time:29.857, tt:4627.804\n",
      "Ep:155, loss:0.00001, loss_test:0.01214, lr:4.26e-02, fs:0.91176 (r=0.939,p=0.886),  time:29.858, tt:4657.887\n",
      "Ep:156, loss:0.00001, loss_test:0.01217, lr:4.26e-02, fs:0.91626 (r=0.939,p=0.894),  time:29.859, tt:4687.819\n",
      "##########Best model found so far##########\n",
      "Ep:157, loss:0.00001, loss_test:0.01218, lr:4.26e-02, fs:0.91626 (r=0.939,p=0.894),  time:29.857, tt:4717.427\n",
      "Ep:158, loss:0.00001, loss_test:0.01220, lr:4.26e-02, fs:0.91626 (r=0.939,p=0.894),  time:29.861, tt:4747.842\n",
      "Ep:159, loss:0.00001, loss_test:0.01220, lr:4.26e-02, fs:0.91626 (r=0.939,p=0.894),  time:29.864, tt:4778.245\n",
      "Ep:160, loss:0.00001, loss_test:0.01223, lr:4.26e-02, fs:0.91626 (r=0.939,p=0.894),  time:29.864, tt:4808.041\n",
      "Ep:161, loss:0.00001, loss_test:0.01227, lr:4.26e-02, fs:0.91626 (r=0.939,p=0.894),  time:29.859, tt:4837.223\n",
      "Ep:162, loss:0.00001, loss_test:0.01229, lr:4.26e-02, fs:0.91626 (r=0.939,p=0.894),  time:29.863, tt:4867.618\n",
      "Ep:163, loss:0.00001, loss_test:0.01231, lr:4.26e-02, fs:0.91626 (r=0.939,p=0.894),  time:29.867, tt:4898.260\n",
      "Ep:164, loss:0.00001, loss_test:0.01230, lr:4.26e-02, fs:0.91626 (r=0.939,p=0.894),  time:29.873, tt:4929.023\n",
      "Ep:165, loss:0.00001, loss_test:0.01233, lr:4.26e-02, fs:0.91626 (r=0.939,p=0.894),  time:29.876, tt:4959.334\n",
      "Ep:166, loss:0.00001, loss_test:0.01235, lr:4.26e-02, fs:0.91626 (r=0.939,p=0.894),  time:29.878, tt:4989.672\n",
      "Ep:167, loss:0.00001, loss_test:0.01238, lr:4.26e-02, fs:0.92079 (r=0.939,p=0.903),  time:29.870, tt:5018.178\n",
      "##########Best model found so far##########\n",
      "Ep:168, loss:0.00001, loss_test:0.01242, lr:4.26e-02, fs:0.92537 (r=0.939,p=0.912),  time:29.872, tt:5048.423\n",
      "##########Best model found so far##########\n",
      "Ep:169, loss:0.00001, loss_test:0.01244, lr:4.26e-02, fs:0.92000 (r=0.929,p=0.911),  time:29.870, tt:5077.938\n",
      "Ep:170, loss:0.00001, loss_test:0.01244, lr:4.26e-02, fs:0.92000 (r=0.929,p=0.911),  time:29.876, tt:5108.873\n",
      "Ep:171, loss:0.00001, loss_test:0.01245, lr:4.26e-02, fs:0.92462 (r=0.929,p=0.920),  time:29.874, tt:5138.251\n",
      "Ep:172, loss:0.00001, loss_test:0.01249, lr:4.26e-02, fs:0.92462 (r=0.929,p=0.920),  time:29.876, tt:5168.598\n",
      "Ep:173, loss:0.00001, loss_test:0.01251, lr:4.26e-02, fs:0.92462 (r=0.929,p=0.920),  time:29.880, tt:5199.156\n",
      "Ep:174, loss:0.00001, loss_test:0.01253, lr:4.26e-02, fs:0.92462 (r=0.929,p=0.920),  time:29.885, tt:5229.891\n",
      "Ep:175, loss:0.00001, loss_test:0.01254, lr:4.26e-02, fs:0.92462 (r=0.929,p=0.920),  time:29.885, tt:5259.798\n",
      "Ep:176, loss:0.00000, loss_test:0.01257, lr:4.26e-02, fs:0.92462 (r=0.929,p=0.920),  time:29.889, tt:5290.381\n",
      "Ep:177, loss:0.00000, loss_test:0.01259, lr:4.26e-02, fs:0.92462 (r=0.929,p=0.920),  time:29.893, tt:5321.000\n",
      "Ep:178, loss:0.00000, loss_test:0.01262, lr:4.26e-02, fs:0.92462 (r=0.929,p=0.920),  time:29.894, tt:5351.011\n",
      "Ep:179, loss:0.00000, loss_test:0.01264, lr:4.26e-02, fs:0.92462 (r=0.929,p=0.920),  time:29.895, tt:5381.034\n",
      "Ep:180, loss:0.00000, loss_test:0.01265, lr:4.22e-02, fs:0.92462 (r=0.929,p=0.920),  time:29.901, tt:5412.125\n",
      "Ep:181, loss:0.00000, loss_test:0.01268, lr:4.18e-02, fs:0.92462 (r=0.929,p=0.920),  time:29.902, tt:5442.208\n",
      "Ep:182, loss:0.00000, loss_test:0.01270, lr:4.14e-02, fs:0.92462 (r=0.929,p=0.920),  time:29.907, tt:5472.918\n",
      "Ep:183, loss:0.00000, loss_test:0.01274, lr:4.10e-02, fs:0.92462 (r=0.929,p=0.920),  time:29.909, tt:5503.321\n",
      "Ep:184, loss:0.00000, loss_test:0.01277, lr:4.05e-02, fs:0.92462 (r=0.929,p=0.920),  time:29.921, tt:5535.331\n",
      "Ep:185, loss:0.00000, loss_test:0.01277, lr:4.01e-02, fs:0.92462 (r=0.929,p=0.920),  time:29.933, tt:5567.467\n",
      "Ep:186, loss:0.00000, loss_test:0.01277, lr:3.97e-02, fs:0.92462 (r=0.929,p=0.920),  time:29.931, tt:5597.104\n",
      "Ep:187, loss:0.00000, loss_test:0.01279, lr:3.93e-02, fs:0.92462 (r=0.929,p=0.920),  time:29.942, tt:5629.186\n",
      "Ep:188, loss:0.00000, loss_test:0.01283, lr:3.89e-02, fs:0.92462 (r=0.929,p=0.920),  time:29.944, tt:5659.470\n",
      "Ep:189, loss:0.00000, loss_test:0.01285, lr:3.86e-02, fs:0.92462 (r=0.929,p=0.920),  time:29.941, tt:5688.744\n",
      "Ep:190, loss:0.00000, loss_test:0.01288, lr:3.82e-02, fs:0.91919 (r=0.919,p=0.919),  time:29.946, tt:5719.719\n",
      "Ep:191, loss:0.00000, loss_test:0.01291, lr:3.78e-02, fs:0.91919 (r=0.919,p=0.919),  time:29.950, tt:5750.391\n",
      "Ep:192, loss:0.00000, loss_test:0.01293, lr:3.74e-02, fs:0.91919 (r=0.919,p=0.919),  time:29.949, tt:5780.154\n",
      "Ep:193, loss:0.00000, loss_test:0.01296, lr:3.70e-02, fs:0.91919 (r=0.919,p=0.919),  time:29.945, tt:5809.376\n",
      "Ep:194, loss:0.00000, loss_test:0.01298, lr:3.67e-02, fs:0.91371 (r=0.909,p=0.918),  time:29.937, tt:5837.748\n",
      "Ep:195, loss:0.00000, loss_test:0.01302, lr:3.63e-02, fs:0.90816 (r=0.899,p=0.918),  time:29.947, tt:5869.569\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02060, lr:6.00e-02, fs:0.65035 (r=0.939,p=0.497),  time:32.653, tt:32.653\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02494, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.720, tt:69.440\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02676, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.917, tt:107.750\n",
      "Ep:3, loss:0.00005, loss_test:0.02648, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.271, tt:145.085\n",
      "Ep:4, loss:0.00005, loss_test:0.02525, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.827, tt:184.133\n",
      "Ep:5, loss:0.00005, loss_test:0.02342, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.190, tt:223.140\n",
      "Ep:6, loss:0.00004, loss_test:0.02133, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:37.279, tt:260.954\n",
      "Ep:7, loss:0.00004, loss_test:0.01956, lr:6.00e-02, fs:0.68571 (r=0.970,p=0.530),  time:37.447, tt:299.578\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01861, lr:6.00e-02, fs:0.69732 (r=0.919,p=0.562),  time:37.619, tt:338.571\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01821, lr:6.00e-02, fs:0.70039 (r=0.909,p=0.570),  time:37.697, tt:376.974\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01791, lr:6.00e-02, fs:0.71875 (r=0.929,p=0.586),  time:37.716, tt:414.878\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01776, lr:6.00e-02, fs:0.71264 (r=0.939,p=0.574),  time:37.911, tt:454.933\n",
      "Ep:12, loss:0.00004, loss_test:0.01765, lr:6.00e-02, fs:0.71970 (r=0.960,p=0.576),  time:38.099, tt:495.289\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01734, lr:6.00e-02, fs:0.72453 (r=0.970,p=0.578),  time:38.163, tt:534.277\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:14, loss:0.00003, loss_test:0.01690, lr:6.00e-02, fs:0.73282 (r=0.970,p=0.589),  time:38.304, tt:574.561\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01649, lr:6.00e-02, fs:0.73643 (r=0.960,p=0.597),  time:38.328, tt:613.244\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01618, lr:6.00e-02, fs:0.73307 (r=0.929,p=0.605),  time:38.411, tt:652.984\n",
      "Ep:17, loss:0.00003, loss_test:0.01587, lr:6.00e-02, fs:0.73600 (r=0.929,p=0.609),  time:38.448, tt:692.069\n",
      "Ep:18, loss:0.00003, loss_test:0.01562, lr:6.00e-02, fs:0.74494 (r=0.929,p=0.622),  time:38.511, tt:731.708\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01541, lr:6.00e-02, fs:0.75102 (r=0.929,p=0.630),  time:38.521, tt:770.415\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01520, lr:6.00e-02, fs:0.75610 (r=0.939,p=0.633),  time:38.523, tt:808.990\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01499, lr:6.00e-02, fs:0.76113 (r=0.949,p=0.635),  time:38.628, tt:849.806\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01479, lr:6.00e-02, fs:0.77551 (r=0.960,p=0.651),  time:38.692, tt:889.912\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01458, lr:6.00e-02, fs:0.78512 (r=0.960,p=0.664),  time:38.713, tt:929.104\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01438, lr:6.00e-02, fs:0.79167 (r=0.960,p=0.674),  time:38.735, tt:968.366\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01417, lr:6.00e-02, fs:0.79167 (r=0.960,p=0.674),  time:38.768, tt:1007.969\n",
      "Ep:26, loss:0.00002, loss_test:0.01398, lr:6.00e-02, fs:0.79498 (r=0.960,p=0.679),  time:38.801, tt:1047.636\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01380, lr:6.00e-02, fs:0.79832 (r=0.960,p=0.683),  time:38.813, tt:1086.766\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01364, lr:6.00e-02, fs:0.80508 (r=0.960,p=0.693),  time:38.847, tt:1126.573\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01344, lr:6.00e-02, fs:0.82203 (r=0.980,p=0.708),  time:38.818, tt:1164.552\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01327, lr:6.00e-02, fs:0.82906 (r=0.980,p=0.719),  time:38.857, tt:1204.571\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01312, lr:6.00e-02, fs:0.82553 (r=0.980,p=0.713),  time:38.893, tt:1244.569\n",
      "Ep:32, loss:0.00002, loss_test:0.01297, lr:6.00e-02, fs:0.84120 (r=0.990,p=0.731),  time:38.842, tt:1281.773\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01282, lr:6.00e-02, fs:0.84348 (r=0.980,p=0.740),  time:38.903, tt:1322.694\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01268, lr:6.00e-02, fs:0.83983 (r=0.980,p=0.735),  time:38.886, tt:1361.021\n",
      "Ep:35, loss:0.00002, loss_test:0.01256, lr:6.00e-02, fs:0.84716 (r=0.980,p=0.746),  time:38.928, tt:1401.396\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01244, lr:6.00e-02, fs:0.84716 (r=0.980,p=0.746),  time:38.904, tt:1439.447\n",
      "Ep:37, loss:0.00002, loss_test:0.01235, lr:6.00e-02, fs:0.84956 (r=0.970,p=0.756),  time:38.936, tt:1479.551\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01225, lr:6.00e-02, fs:0.84956 (r=0.970,p=0.756),  time:38.978, tt:1520.142\n",
      "Ep:39, loss:0.00002, loss_test:0.01218, lr:6.00e-02, fs:0.85714 (r=0.970,p=0.768),  time:38.990, tt:1559.600\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01208, lr:6.00e-02, fs:0.86099 (r=0.970,p=0.774),  time:39.008, tt:1599.346\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01197, lr:6.00e-02, fs:0.86099 (r=0.970,p=0.774),  time:38.994, tt:1637.736\n",
      "Ep:42, loss:0.00002, loss_test:0.01188, lr:6.00e-02, fs:0.86099 (r=0.970,p=0.774),  time:38.954, tt:1675.031\n",
      "Ep:43, loss:0.00002, loss_test:0.01182, lr:6.00e-02, fs:0.86486 (r=0.970,p=0.780),  time:38.982, tt:1715.195\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01178, lr:6.00e-02, fs:0.86878 (r=0.970,p=0.787),  time:38.965, tt:1753.403\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01170, lr:6.00e-02, fs:0.86878 (r=0.970,p=0.787),  time:38.947, tt:1791.564\n",
      "Ep:46, loss:0.00002, loss_test:0.01164, lr:6.00e-02, fs:0.87273 (r=0.970,p=0.793),  time:38.923, tt:1829.374\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01159, lr:6.00e-02, fs:0.87273 (r=0.970,p=0.793),  time:38.896, tt:1867.020\n",
      "Ep:48, loss:0.00002, loss_test:0.01153, lr:6.00e-02, fs:0.87273 (r=0.970,p=0.793),  time:38.918, tt:1906.969\n",
      "Ep:49, loss:0.00001, loss_test:0.01148, lr:6.00e-02, fs:0.87671 (r=0.970,p=0.800),  time:38.893, tt:1944.672\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01141, lr:6.00e-02, fs:0.87671 (r=0.970,p=0.800),  time:38.911, tt:1984.443\n",
      "Ep:51, loss:0.00001, loss_test:0.01137, lr:6.00e-02, fs:0.87671 (r=0.970,p=0.800),  time:38.877, tt:2021.617\n",
      "Ep:52, loss:0.00001, loss_test:0.01133, lr:6.00e-02, fs:0.87671 (r=0.970,p=0.800),  time:38.870, tt:2060.089\n",
      "Ep:53, loss:0.00001, loss_test:0.01129, lr:6.00e-02, fs:0.87671 (r=0.970,p=0.800),  time:38.884, tt:2099.724\n",
      "Ep:54, loss:0.00001, loss_test:0.01122, lr:6.00e-02, fs:0.87783 (r=0.980,p=0.795),  time:38.880, tt:2138.387\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01116, lr:6.00e-02, fs:0.87783 (r=0.980,p=0.795),  time:38.919, tt:2179.465\n",
      "Ep:56, loss:0.00001, loss_test:0.01113, lr:6.00e-02, fs:0.88584 (r=0.980,p=0.808),  time:38.973, tt:2221.472\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.01109, lr:6.00e-02, fs:0.88584 (r=0.980,p=0.808),  time:38.966, tt:2260.039\n",
      "Ep:58, loss:0.00001, loss_test:0.01107, lr:6.00e-02, fs:0.88584 (r=0.980,p=0.808),  time:38.966, tt:2298.994\n",
      "Ep:59, loss:0.00001, loss_test:0.01104, lr:6.00e-02, fs:0.88584 (r=0.980,p=0.808),  time:38.951, tt:2337.033\n",
      "Ep:60, loss:0.00001, loss_test:0.01103, lr:6.00e-02, fs:0.88584 (r=0.980,p=0.808),  time:38.956, tt:2376.325\n",
      "Ep:61, loss:0.00001, loss_test:0.01101, lr:6.00e-02, fs:0.88991 (r=0.980,p=0.815),  time:38.941, tt:2414.324\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01095, lr:6.00e-02, fs:0.88991 (r=0.980,p=0.815),  time:38.926, tt:2452.330\n",
      "Ep:63, loss:0.00001, loss_test:0.01095, lr:6.00e-02, fs:0.88991 (r=0.980,p=0.815),  time:38.906, tt:2489.963\n",
      "Ep:64, loss:0.00001, loss_test:0.01088, lr:6.00e-02, fs:0.88991 (r=0.980,p=0.815),  time:38.884, tt:2527.447\n",
      "Ep:65, loss:0.00001, loss_test:0.01087, lr:6.00e-02, fs:0.90323 (r=0.990,p=0.831),  time:38.849, tt:2564.029\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.01088, lr:6.00e-02, fs:0.89908 (r=0.990,p=0.824),  time:38.848, tt:2602.830\n",
      "Ep:67, loss:0.00001, loss_test:0.01087, lr:6.00e-02, fs:0.90323 (r=0.990,p=0.831),  time:38.845, tt:2641.453\n",
      "Ep:68, loss:0.00001, loss_test:0.01082, lr:6.00e-02, fs:0.90826 (r=1.000,p=0.832),  time:38.820, tt:2678.581\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01080, lr:6.00e-02, fs:0.91244 (r=1.000,p=0.839),  time:38.820, tt:2717.379\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.01081, lr:6.00e-02, fs:0.91244 (r=1.000,p=0.839),  time:38.820, tt:2756.224\n",
      "Ep:71, loss:0.00001, loss_test:0.01079, lr:6.00e-02, fs:0.91244 (r=1.000,p=0.839),  time:38.812, tt:2794.469\n",
      "Ep:72, loss:0.00001, loss_test:0.01080, lr:6.00e-02, fs:0.91244 (r=1.000,p=0.839),  time:38.819, tt:2833.814\n",
      "Ep:73, loss:0.00001, loss_test:0.01079, lr:6.00e-02, fs:0.91244 (r=1.000,p=0.839),  time:38.825, tt:2873.059\n",
      "Ep:74, loss:0.00001, loss_test:0.01076, lr:6.00e-02, fs:0.91244 (r=1.000,p=0.839),  time:38.805, tt:2910.401\n",
      "Ep:75, loss:0.00001, loss_test:0.01080, lr:6.00e-02, fs:0.91244 (r=1.000,p=0.839),  time:38.802, tt:2948.956\n",
      "Ep:76, loss:0.00001, loss_test:0.01078, lr:6.00e-02, fs:0.91667 (r=1.000,p=0.846),  time:38.802, tt:2987.740\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:77, loss:0.00001, loss_test:0.01076, lr:6.00e-02, fs:0.91667 (r=1.000,p=0.846),  time:38.786, tt:3025.291\n",
      "Ep:78, loss:0.00001, loss_test:0.01080, lr:6.00e-02, fs:0.91667 (r=1.000,p=0.846),  time:38.767, tt:3062.578\n",
      "Ep:79, loss:0.00001, loss_test:0.01083, lr:6.00e-02, fs:0.91667 (r=1.000,p=0.846),  time:38.750, tt:3100.005\n",
      "Ep:80, loss:0.00001, loss_test:0.01080, lr:6.00e-02, fs:0.91667 (r=1.000,p=0.846),  time:38.761, tt:3139.679\n",
      "Ep:81, loss:0.00001, loss_test:0.01082, lr:6.00e-02, fs:0.91667 (r=1.000,p=0.846),  time:38.738, tt:3176.490\n",
      "Ep:82, loss:0.00001, loss_test:0.01080, lr:6.00e-02, fs:0.91667 (r=1.000,p=0.846),  time:38.745, tt:3215.834\n",
      "Ep:83, loss:0.00001, loss_test:0.01082, lr:6.00e-02, fs:0.91667 (r=1.000,p=0.846),  time:38.735, tt:3253.770\n",
      "Ep:84, loss:0.00001, loss_test:0.01080, lr:6.00e-02, fs:0.91667 (r=1.000,p=0.846),  time:38.703, tt:3289.728\n",
      "Ep:85, loss:0.00001, loss_test:0.01083, lr:6.00e-02, fs:0.91667 (r=1.000,p=0.846),  time:38.701, tt:3328.308\n",
      "Ep:86, loss:0.00001, loss_test:0.01084, lr:6.00e-02, fs:0.91667 (r=1.000,p=0.846),  time:38.685, tt:3365.599\n",
      "Ep:87, loss:0.00001, loss_test:0.01084, lr:6.00e-02, fs:0.92093 (r=1.000,p=0.853),  time:38.686, tt:3404.358\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00001, loss_test:0.01083, lr:6.00e-02, fs:0.92093 (r=1.000,p=0.853),  time:38.673, tt:3441.871\n",
      "Ep:89, loss:0.00001, loss_test:0.01083, lr:6.00e-02, fs:0.92093 (r=1.000,p=0.853),  time:38.673, tt:3480.582\n",
      "Ep:90, loss:0.00001, loss_test:0.01085, lr:6.00e-02, fs:0.92093 (r=1.000,p=0.853),  time:38.664, tt:3518.413\n",
      "Ep:91, loss:0.00001, loss_test:0.01091, lr:6.00e-02, fs:0.91080 (r=0.980,p=0.851),  time:38.653, tt:3556.087\n",
      "Ep:92, loss:0.00001, loss_test:0.01094, lr:6.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:38.657, tt:3595.074\n",
      "Ep:93, loss:0.00001, loss_test:0.01093, lr:6.00e-02, fs:0.91080 (r=0.980,p=0.851),  time:38.651, tt:3633.241\n",
      "Ep:94, loss:0.00001, loss_test:0.01092, lr:6.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:38.647, tt:3671.467\n",
      "Ep:95, loss:0.00001, loss_test:0.01096, lr:6.00e-02, fs:0.91429 (r=0.970,p=0.865),  time:38.653, tt:3710.671\n",
      "Ep:96, loss:0.00001, loss_test:0.01096, lr:6.00e-02, fs:0.91429 (r=0.970,p=0.865),  time:38.659, tt:3749.958\n",
      "Ep:97, loss:0.00001, loss_test:0.01096, lr:6.00e-02, fs:0.91429 (r=0.970,p=0.865),  time:38.653, tt:3787.989\n",
      "Ep:98, loss:0.00001, loss_test:0.01098, lr:6.00e-02, fs:0.91429 (r=0.970,p=0.865),  time:38.643, tt:3825.703\n",
      "Ep:99, loss:0.00001, loss_test:0.01101, lr:5.94e-02, fs:0.91866 (r=0.970,p=0.873),  time:38.633, tt:3863.291\n",
      "Ep:100, loss:0.00001, loss_test:0.01107, lr:5.88e-02, fs:0.91866 (r=0.970,p=0.873),  time:38.636, tt:3902.219\n",
      "Ep:101, loss:0.00001, loss_test:0.01112, lr:5.82e-02, fs:0.91866 (r=0.970,p=0.873),  time:38.638, tt:3941.050\n",
      "Ep:102, loss:0.00001, loss_test:0.01113, lr:5.76e-02, fs:0.92308 (r=0.970,p=0.881),  time:38.638, tt:3979.749\n",
      "##########Best model found so far##########\n",
      "Ep:103, loss:0.00001, loss_test:0.01118, lr:5.76e-02, fs:0.92754 (r=0.970,p=0.889),  time:38.634, tt:4017.887\n",
      "##########Best model found so far##########\n",
      "Ep:104, loss:0.00001, loss_test:0.01123, lr:5.76e-02, fs:0.92754 (r=0.970,p=0.889),  time:38.622, tt:4055.272\n",
      "Ep:105, loss:0.00001, loss_test:0.01126, lr:5.76e-02, fs:0.92754 (r=0.970,p=0.889),  time:38.623, tt:4094.040\n",
      "Ep:106, loss:0.00001, loss_test:0.01127, lr:5.76e-02, fs:0.93204 (r=0.970,p=0.897),  time:38.624, tt:4132.759\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00001, loss_test:0.01129, lr:5.76e-02, fs:0.93204 (r=0.970,p=0.897),  time:38.620, tt:4170.973\n",
      "Ep:108, loss:0.00001, loss_test:0.01133, lr:5.76e-02, fs:0.92157 (r=0.949,p=0.895),  time:38.605, tt:4207.899\n",
      "Ep:109, loss:0.00001, loss_test:0.01134, lr:5.76e-02, fs:0.92157 (r=0.949,p=0.895),  time:38.611, tt:4247.198\n",
      "Ep:110, loss:0.00001, loss_test:0.01136, lr:5.76e-02, fs:0.92157 (r=0.949,p=0.895),  time:38.617, tt:4286.469\n",
      "Ep:111, loss:0.00001, loss_test:0.01143, lr:5.76e-02, fs:0.92157 (r=0.949,p=0.895),  time:38.608, tt:4324.140\n",
      "Ep:112, loss:0.00001, loss_test:0.01146, lr:5.76e-02, fs:0.92157 (r=0.949,p=0.895),  time:38.616, tt:4363.585\n",
      "Ep:113, loss:0.00001, loss_test:0.01148, lr:5.76e-02, fs:0.92157 (r=0.949,p=0.895),  time:38.617, tt:4402.348\n",
      "Ep:114, loss:0.00001, loss_test:0.01153, lr:5.76e-02, fs:0.92157 (r=0.949,p=0.895),  time:38.615, tt:4440.719\n",
      "Ep:115, loss:0.00000, loss_test:0.01156, lr:5.76e-02, fs:0.93069 (r=0.949,p=0.913),  time:38.603, tt:4477.945\n",
      "Ep:116, loss:0.00000, loss_test:0.01163, lr:5.76e-02, fs:0.92537 (r=0.939,p=0.912),  time:38.591, tt:4515.180\n",
      "Ep:117, loss:0.00000, loss_test:0.01163, lr:5.76e-02, fs:0.92079 (r=0.939,p=0.903),  time:38.584, tt:4552.925\n",
      "Ep:118, loss:0.00000, loss_test:0.01169, lr:5.71e-02, fs:0.92537 (r=0.939,p=0.912),  time:38.572, tt:4590.064\n",
      "Ep:119, loss:0.00000, loss_test:0.01172, lr:5.65e-02, fs:0.93000 (r=0.939,p=0.921),  time:38.582, tt:4629.818\n",
      "Ep:120, loss:0.00000, loss_test:0.01175, lr:5.59e-02, fs:0.92537 (r=0.939,p=0.912),  time:38.585, tt:4668.774\n",
      "Ep:121, loss:0.00000, loss_test:0.01177, lr:5.54e-02, fs:0.91919 (r=0.919,p=0.919),  time:38.574, tt:4706.044\n",
      "Ep:122, loss:0.00000, loss_test:0.01180, lr:5.48e-02, fs:0.91371 (r=0.909,p=0.918),  time:38.575, tt:4744.680\n",
      "Ep:123, loss:0.00000, loss_test:0.01187, lr:5.43e-02, fs:0.91371 (r=0.909,p=0.918),  time:38.576, tt:4783.445\n",
      "Ep:124, loss:0.00000, loss_test:0.01189, lr:5.37e-02, fs:0.91371 (r=0.909,p=0.918),  time:38.568, tt:4820.939\n",
      "Ep:125, loss:0.00000, loss_test:0.01192, lr:5.32e-02, fs:0.91371 (r=0.909,p=0.918),  time:38.560, tt:4858.602\n",
      "Ep:126, loss:0.00000, loss_test:0.01193, lr:5.27e-02, fs:0.91371 (r=0.909,p=0.918),  time:38.568, tt:4898.074\n",
      "Ep:127, loss:0.00000, loss_test:0.01199, lr:5.21e-02, fs:0.91371 (r=0.909,p=0.918),  time:38.550, tt:4934.462\n",
      "Ep:128, loss:0.00000, loss_test:0.01205, lr:5.16e-02, fs:0.91837 (r=0.909,p=0.928),  time:38.539, tt:4971.565\n",
      "Ep:129, loss:0.00000, loss_test:0.01205, lr:5.11e-02, fs:0.90816 (r=0.899,p=0.918),  time:38.547, tt:5011.143\n",
      "Ep:130, loss:0.00000, loss_test:0.01211, lr:5.06e-02, fs:0.90256 (r=0.889,p=0.917),  time:38.540, tt:5048.755\n",
      "Ep:131, loss:0.00000, loss_test:0.01215, lr:5.01e-02, fs:0.90155 (r=0.879,p=0.926),  time:38.546, tt:5088.045\n",
      "Ep:132, loss:0.00000, loss_test:0.01216, lr:4.96e-02, fs:0.90155 (r=0.879,p=0.926),  time:38.553, tt:5127.600\n",
      "Ep:133, loss:0.00000, loss_test:0.01218, lr:4.91e-02, fs:0.89005 (r=0.859,p=0.924),  time:38.554, tt:5166.244\n",
      "Ep:134, loss:0.00000, loss_test:0.01222, lr:4.86e-02, fs:0.89005 (r=0.859,p=0.924),  time:38.550, tt:5204.299\n",
      "Ep:135, loss:0.00000, loss_test:0.01230, lr:4.81e-02, fs:0.89005 (r=0.859,p=0.924),  time:38.548, tt:5242.494\n",
      "Ep:136, loss:0.00000, loss_test:0.01234, lr:4.76e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.558, tt:5282.425\n",
      "Ep:137, loss:0.00000, loss_test:0.01233, lr:4.71e-02, fs:0.88421 (r=0.848,p=0.923),  time:38.554, tt:5320.396\n",
      "Ep:138, loss:0.00000, loss_test:0.01239, lr:4.67e-02, fs:0.87831 (r=0.838,p=0.922),  time:38.534, tt:5356.171\n",
      "Ep:139, loss:0.00000, loss_test:0.01241, lr:4.62e-02, fs:0.86631 (r=0.818,p=0.920),  time:38.546, tt:5396.498\n",
      "Ep:140, loss:0.00000, loss_test:0.01243, lr:4.57e-02, fs:0.88298 (r=0.838,p=0.933),  time:38.535, tt:5433.397\n",
      "Ep:141, loss:0.00000, loss_test:0.01246, lr:4.53e-02, fs:0.88298 (r=0.838,p=0.933),  time:38.537, tt:5472.219\n",
      "Ep:142, loss:0.00000, loss_test:0.01249, lr:4.48e-02, fs:0.84783 (r=0.788,p=0.918),  time:38.534, tt:5510.314\n",
      "Ep:143, loss:0.00000, loss_test:0.01253, lr:4.44e-02, fs:0.87097 (r=0.818,p=0.931),  time:38.531, tt:5548.410\n",
      "Ep:144, loss:0.00000, loss_test:0.01257, lr:4.39e-02, fs:0.85870 (r=0.798,p=0.929),  time:38.531, tt:5587.065\n",
      "Ep:145, loss:0.00000, loss_test:0.01260, lr:4.35e-02, fs:0.82022 (r=0.737,p=0.924),  time:38.531, tt:5625.523\n",
      "Ep:146, loss:0.00000, loss_test:0.01265, lr:4.31e-02, fs:0.85870 (r=0.798,p=0.929),  time:38.530, tt:5663.939\n",
      "Ep:147, loss:0.00000, loss_test:0.01270, lr:4.26e-02, fs:0.83978 (r=0.768,p=0.927),  time:38.531, tt:5702.614\n",
      "Ep:148, loss:0.00000, loss_test:0.01269, lr:4.22e-02, fs:0.81356 (r=0.727,p=0.923),  time:38.538, tt:5742.153\n",
      "Ep:149, loss:0.00000, loss_test:0.01271, lr:4.18e-02, fs:0.83978 (r=0.768,p=0.927),  time:38.543, tt:5781.479\n",
      "Ep:150, loss:0.00000, loss_test:0.01275, lr:4.14e-02, fs:0.82022 (r=0.737,p=0.924),  time:38.536, tt:5819.009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:151, loss:0.00000, loss_test:0.01278, lr:4.10e-02, fs:0.81356 (r=0.727,p=0.923),  time:38.530, tt:5856.513\n",
      "Ep:152, loss:0.00000, loss_test:0.01280, lr:4.05e-02, fs:0.84615 (r=0.778,p=0.928),  time:38.525, tt:5894.251\n",
      "Ep:153, loss:0.00000, loss_test:0.01281, lr:4.01e-02, fs:0.80682 (r=0.717,p=0.922),  time:38.521, tt:5932.203\n",
      "Ep:154, loss:0.00000, loss_test:0.01282, lr:3.97e-02, fs:0.80682 (r=0.717,p=0.922),  time:38.529, tt:5972.018\n",
      "Ep:155, loss:0.00000, loss_test:0.01286, lr:3.93e-02, fs:0.80682 (r=0.717,p=0.922),  time:38.530, tt:6010.673\n",
      "Ep:156, loss:0.00000, loss_test:0.01289, lr:3.89e-02, fs:0.80000 (r=0.707,p=0.921),  time:38.528, tt:6048.828\n",
      "Ep:157, loss:0.00000, loss_test:0.01294, lr:3.86e-02, fs:0.80682 (r=0.717,p=0.922),  time:38.535, tt:6088.494\n",
      "Ep:158, loss:0.00000, loss_test:0.01297, lr:3.82e-02, fs:0.80682 (r=0.717,p=0.922),  time:38.537, tt:6127.368\n",
      "Ep:159, loss:0.00000, loss_test:0.01300, lr:3.78e-02, fs:0.80000 (r=0.707,p=0.921),  time:38.537, tt:6165.883\n",
      "Ep:160, loss:0.00000, loss_test:0.01302, lr:3.74e-02, fs:0.80000 (r=0.707,p=0.921),  time:38.537, tt:6204.534\n",
      "Ep:161, loss:0.00000, loss_test:0.01306, lr:3.70e-02, fs:0.80000 (r=0.707,p=0.921),  time:38.543, tt:6243.992\n",
      "Ep:162, loss:0.00000, loss_test:0.01305, lr:3.67e-02, fs:0.80000 (r=0.707,p=0.921),  time:38.533, tt:6280.941\n",
      "Ep:163, loss:0.00000, loss_test:0.01310, lr:3.63e-02, fs:0.80000 (r=0.707,p=0.921),  time:38.543, tt:6321.013\n",
      "Ep:164, loss:0.00000, loss_test:0.01312, lr:3.59e-02, fs:0.80000 (r=0.707,p=0.921),  time:38.542, tt:6359.479\n",
      "Ep:165, loss:0.00000, loss_test:0.01314, lr:3.56e-02, fs:0.78613 (r=0.687,p=0.919),  time:38.552, tt:6399.551\n",
      "Ep:166, loss:0.00000, loss_test:0.01316, lr:3.52e-02, fs:0.79310 (r=0.697,p=0.920),  time:38.543, tt:6436.743\n",
      "Ep:167, loss:0.00000, loss_test:0.01322, lr:3.49e-02, fs:0.78613 (r=0.687,p=0.919),  time:38.563, tt:6478.609\n",
      "Ep:168, loss:0.00000, loss_test:0.01326, lr:3.45e-02, fs:0.78613 (r=0.687,p=0.919),  time:38.562, tt:6517.003\n",
      "Ep:169, loss:0.00000, loss_test:0.01326, lr:3.42e-02, fs:0.78613 (r=0.687,p=0.919),  time:38.574, tt:6557.659\n",
      "Ep:170, loss:0.00000, loss_test:0.01328, lr:3.38e-02, fs:0.79310 (r=0.697,p=0.920),  time:38.581, tt:6597.386\n",
      "Ep:171, loss:0.00000, loss_test:0.01333, lr:3.35e-02, fs:0.78613 (r=0.687,p=0.919),  time:38.576, tt:6635.068\n",
      "Ep:172, loss:0.00000, loss_test:0.01337, lr:3.32e-02, fs:0.78613 (r=0.687,p=0.919),  time:38.579, tt:6674.120\n",
      "Ep:173, loss:0.00000, loss_test:0.01338, lr:3.28e-02, fs:0.78613 (r=0.687,p=0.919),  time:38.586, tt:6714.035\n",
      "Ep:174, loss:0.00000, loss_test:0.01338, lr:3.25e-02, fs:0.78613 (r=0.687,p=0.919),  time:38.586, tt:6752.500\n",
      "Ep:175, loss:0.00000, loss_test:0.01343, lr:3.22e-02, fs:0.77907 (r=0.677,p=0.918),  time:38.577, tt:6789.540\n",
      "Ep:176, loss:0.00000, loss_test:0.01346, lr:3.19e-02, fs:0.77907 (r=0.677,p=0.918),  time:38.571, tt:6827.146\n",
      "Ep:177, loss:0.00000, loss_test:0.01347, lr:3.15e-02, fs:0.78363 (r=0.677,p=0.931),  time:38.573, tt:6865.990\n",
      "Ep:178, loss:0.00000, loss_test:0.01350, lr:3.12e-02, fs:0.78363 (r=0.677,p=0.931),  time:38.575, tt:6904.983\n",
      "Ep:179, loss:0.00000, loss_test:0.01354, lr:3.09e-02, fs:0.77907 (r=0.677,p=0.918),  time:38.573, tt:6943.218\n",
      "Ep:180, loss:0.00000, loss_test:0.01355, lr:3.06e-02, fs:0.77193 (r=0.667,p=0.917),  time:38.583, tt:6983.537\n",
      "Ep:181, loss:0.00000, loss_test:0.01357, lr:3.03e-02, fs:0.78363 (r=0.677,p=0.931),  time:38.579, tt:7021.439\n",
      "Ep:182, loss:0.00000, loss_test:0.01362, lr:3.00e-02, fs:0.77647 (r=0.667,p=0.930),  time:38.578, tt:7059.775\n",
      "Ep:183, loss:0.00000, loss_test:0.01364, lr:2.97e-02, fs:0.77647 (r=0.667,p=0.930),  time:38.567, tt:7096.243\n",
      "Ep:184, loss:0.00000, loss_test:0.01364, lr:2.94e-02, fs:0.77647 (r=0.667,p=0.930),  time:38.561, tt:7133.802\n",
      "Ep:185, loss:0.00000, loss_test:0.01368, lr:2.91e-02, fs:0.77647 (r=0.667,p=0.930),  time:38.563, tt:7172.801\n",
      "Ep:186, loss:0.00000, loss_test:0.01370, lr:2.88e-02, fs:0.77647 (r=0.667,p=0.930),  time:38.563, tt:7211.337\n",
      "Ep:187, loss:0.00000, loss_test:0.01369, lr:2.85e-02, fs:0.77647 (r=0.667,p=0.930),  time:38.567, tt:7250.679\n",
      "Ep:188, loss:0.00000, loss_test:0.01374, lr:2.82e-02, fs:0.77647 (r=0.667,p=0.930),  time:38.567, tt:7289.198\n",
      "Ep:189, loss:0.00000, loss_test:0.01378, lr:2.80e-02, fs:0.77647 (r=0.667,p=0.930),  time:38.572, tt:7328.616\n",
      "Ep:190, loss:0.00000, loss_test:0.01379, lr:2.77e-02, fs:0.77647 (r=0.667,p=0.930),  time:38.577, tt:7368.143\n",
      "Ep:191, loss:0.00000, loss_test:0.01380, lr:2.74e-02, fs:0.77647 (r=0.667,p=0.930),  time:38.572, tt:7405.871\n",
      "Ep:192, loss:0.00000, loss_test:0.01381, lr:2.71e-02, fs:0.77647 (r=0.667,p=0.930),  time:38.565, tt:7443.033\n",
      "Ep:193, loss:0.00000, loss_test:0.01385, lr:2.69e-02, fs:0.77647 (r=0.667,p=0.930),  time:38.564, tt:7481.404\n",
      "Ep:194, loss:0.00000, loss_test:0.01386, lr:2.66e-02, fs:0.77647 (r=0.667,p=0.930),  time:38.556, tt:7518.400\n",
      "Ep:195, loss:0.00000, loss_test:0.01389, lr:2.63e-02, fs:0.77647 (r=0.667,p=0.930),  time:38.534, tt:7552.720\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02100, lr:6.00e-02, fs:0.63971 (r=0.879,p=0.503),  time:23.489, tt:23.489\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02525, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.411, tt:56.821\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02728, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.818, tt:92.455\n",
      "Ep:3, loss:0.00005, loss_test:0.02737, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.569, tt:126.277\n",
      "Ep:4, loss:0.00005, loss_test:0.02645, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.205, tt:161.027\n",
      "Ep:5, loss:0.00005, loss_test:0.02481, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.411, tt:194.465\n",
      "Ep:6, loss:0.00005, loss_test:0.02273, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:32.581, tt:228.069\n",
      "Ep:7, loss:0.00004, loss_test:0.02082, lr:6.00e-02, fs:0.66667 (r=0.939,p=0.517),  time:32.776, tt:262.205\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01947, lr:6.00e-02, fs:0.69173 (r=0.929,p=0.551),  time:32.997, tt:296.973\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01860, lr:6.00e-02, fs:0.70000 (r=0.919,p=0.565),  time:33.137, tt:331.373\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01836, lr:6.00e-02, fs:0.69888 (r=0.949,p=0.553),  time:33.146, tt:364.606\n",
      "Ep:11, loss:0.00004, loss_test:0.01829, lr:6.00e-02, fs:0.70370 (r=0.960,p=0.556),  time:33.244, tt:398.927\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01806, lr:6.00e-02, fs:0.71111 (r=0.970,p=0.561),  time:33.349, tt:433.535\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01765, lr:6.00e-02, fs:0.72453 (r=0.970,p=0.578),  time:33.488, tt:468.839\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01713, lr:6.00e-02, fs:0.73004 (r=0.970,p=0.585),  time:33.536, tt:503.036\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01671, lr:6.00e-02, fs:0.72587 (r=0.949,p=0.588),  time:33.659, tt:538.545\n",
      "Ep:16, loss:0.00003, loss_test:0.01634, lr:6.00e-02, fs:0.73725 (r=0.949,p=0.603),  time:33.716, tt:573.168\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01602, lr:6.00e-02, fs:0.74510 (r=0.960,p=0.609),  time:33.725, tt:607.044\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01571, lr:6.00e-02, fs:0.74219 (r=0.960,p=0.605),  time:33.804, tt:642.272\n",
      "Ep:19, loss:0.00003, loss_test:0.01539, lr:6.00e-02, fs:0.74219 (r=0.960,p=0.605),  time:33.934, tt:678.688\n",
      "Ep:20, loss:0.00003, loss_test:0.01511, lr:6.00e-02, fs:0.74016 (r=0.949,p=0.606),  time:34.074, tt:715.559\n",
      "Ep:21, loss:0.00003, loss_test:0.01486, lr:6.00e-02, fs:0.74603 (r=0.949,p=0.614),  time:34.137, tt:751.022\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:22, loss:0.00003, loss_test:0.01459, lr:6.00e-02, fs:0.75502 (r=0.949,p=0.627),  time:34.250, tt:787.751\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01435, lr:6.00e-02, fs:0.76113 (r=0.949,p=0.635),  time:34.323, tt:823.763\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01412, lr:6.00e-02, fs:0.76423 (r=0.949,p=0.639),  time:34.399, tt:859.964\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01392, lr:6.00e-02, fs:0.76543 (r=0.939,p=0.646),  time:34.487, tt:896.656\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01374, lr:6.00e-02, fs:0.77366 (r=0.949,p=0.653),  time:34.459, tt:930.381\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01354, lr:6.00e-02, fs:0.78333 (r=0.949,p=0.667),  time:34.543, tt:967.212\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01335, lr:6.00e-02, fs:0.78838 (r=0.960,p=0.669),  time:34.590, tt:1003.107\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01318, lr:6.00e-02, fs:0.80498 (r=0.980,p=0.683),  time:34.626, tt:1038.790\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01302, lr:6.00e-02, fs:0.81513 (r=0.980,p=0.698),  time:34.648, tt:1074.092\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01285, lr:6.00e-02, fs:0.82008 (r=0.990,p=0.700),  time:34.618, tt:1107.769\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01269, lr:6.00e-02, fs:0.83051 (r=0.990,p=0.715),  time:34.652, tt:1143.510\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01251, lr:6.00e-02, fs:0.83051 (r=0.990,p=0.715),  time:34.648, tt:1178.028\n",
      "Ep:34, loss:0.00002, loss_test:0.01238, lr:6.00e-02, fs:0.83051 (r=0.990,p=0.715),  time:34.686, tt:1214.011\n",
      "Ep:35, loss:0.00002, loss_test:0.01225, lr:6.00e-02, fs:0.83404 (r=0.990,p=0.721),  time:34.646, tt:1247.244\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01212, lr:6.00e-02, fs:0.83404 (r=0.990,p=0.721),  time:34.685, tt:1283.355\n",
      "Ep:37, loss:0.00002, loss_test:0.01202, lr:6.00e-02, fs:0.83761 (r=0.990,p=0.726),  time:34.685, tt:1318.043\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01189, lr:6.00e-02, fs:0.84120 (r=0.990,p=0.731),  time:34.690, tt:1352.929\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01176, lr:6.00e-02, fs:0.84483 (r=0.990,p=0.737),  time:34.690, tt:1387.592\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01167, lr:6.00e-02, fs:0.84120 (r=0.990,p=0.731),  time:34.738, tt:1424.265\n",
      "Ep:41, loss:0.00002, loss_test:0.01156, lr:6.00e-02, fs:0.84483 (r=0.990,p=0.737),  time:34.720, tt:1458.260\n",
      "Ep:42, loss:0.00002, loss_test:0.01147, lr:6.00e-02, fs:0.84483 (r=0.990,p=0.737),  time:34.759, tt:1494.624\n",
      "Ep:43, loss:0.00002, loss_test:0.01137, lr:6.00e-02, fs:0.85217 (r=0.990,p=0.748),  time:34.763, tt:1529.567\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01125, lr:6.00e-02, fs:0.85217 (r=0.990,p=0.748),  time:34.771, tt:1564.709\n",
      "Ep:45, loss:0.00001, loss_test:0.01118, lr:6.00e-02, fs:0.85590 (r=0.990,p=0.754),  time:34.765, tt:1599.168\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01113, lr:6.00e-02, fs:0.85590 (r=0.990,p=0.754),  time:34.800, tt:1635.587\n",
      "Ep:47, loss:0.00001, loss_test:0.01105, lr:6.00e-02, fs:0.85965 (r=0.990,p=0.760),  time:34.792, tt:1670.007\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.01097, lr:6.00e-02, fs:0.86344 (r=0.990,p=0.766),  time:34.781, tt:1704.272\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01091, lr:6.00e-02, fs:0.86726 (r=0.990,p=0.772),  time:34.780, tt:1738.987\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01084, lr:6.00e-02, fs:0.86726 (r=0.990,p=0.772),  time:34.779, tt:1773.740\n",
      "Ep:51, loss:0.00001, loss_test:0.01078, lr:6.00e-02, fs:0.86726 (r=0.990,p=0.772),  time:34.778, tt:1808.467\n",
      "Ep:52, loss:0.00001, loss_test:0.01076, lr:6.00e-02, fs:0.86726 (r=0.990,p=0.772),  time:34.778, tt:1843.210\n",
      "Ep:53, loss:0.00001, loss_test:0.01075, lr:6.00e-02, fs:0.86726 (r=0.990,p=0.772),  time:34.741, tt:1876.022\n",
      "Ep:54, loss:0.00001, loss_test:0.01066, lr:6.00e-02, fs:0.87111 (r=0.990,p=0.778),  time:34.739, tt:1910.622\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01061, lr:6.00e-02, fs:0.87111 (r=0.990,p=0.778),  time:34.752, tt:1946.131\n",
      "Ep:56, loss:0.00001, loss_test:0.01061, lr:6.00e-02, fs:0.87111 (r=0.990,p=0.778),  time:34.756, tt:1981.082\n",
      "Ep:57, loss:0.00001, loss_test:0.01058, lr:6.00e-02, fs:0.87111 (r=0.990,p=0.778),  time:34.752, tt:2015.588\n",
      "Ep:58, loss:0.00001, loss_test:0.01054, lr:6.00e-02, fs:0.86607 (r=0.980,p=0.776),  time:34.757, tt:2050.636\n",
      "Ep:59, loss:0.00001, loss_test:0.01051, lr:6.00e-02, fs:0.87111 (r=0.990,p=0.778),  time:34.773, tt:2086.352\n",
      "Ep:60, loss:0.00001, loss_test:0.01050, lr:6.00e-02, fs:0.86607 (r=0.980,p=0.776),  time:34.772, tt:2121.067\n",
      "Ep:61, loss:0.00001, loss_test:0.01048, lr:6.00e-02, fs:0.86099 (r=0.970,p=0.774),  time:34.792, tt:2157.107\n",
      "Ep:62, loss:0.00001, loss_test:0.01042, lr:6.00e-02, fs:0.86486 (r=0.970,p=0.780),  time:34.814, tt:2193.303\n",
      "Ep:63, loss:0.00001, loss_test:0.01038, lr:6.00e-02, fs:0.86486 (r=0.970,p=0.780),  time:34.846, tt:2230.146\n",
      "Ep:64, loss:0.00001, loss_test:0.01040, lr:6.00e-02, fs:0.86878 (r=0.970,p=0.787),  time:34.858, tt:2265.741\n",
      "Ep:65, loss:0.00001, loss_test:0.01041, lr:6.00e-02, fs:0.86878 (r=0.970,p=0.787),  time:34.858, tt:2300.644\n",
      "Ep:66, loss:0.00001, loss_test:0.01039, lr:5.94e-02, fs:0.87273 (r=0.970,p=0.793),  time:34.868, tt:2336.170\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01037, lr:5.94e-02, fs:0.86878 (r=0.970,p=0.787),  time:34.888, tt:2372.351\n",
      "Ep:68, loss:0.00001, loss_test:0.01041, lr:5.94e-02, fs:0.86878 (r=0.970,p=0.787),  time:34.908, tt:2408.682\n",
      "Ep:69, loss:0.00001, loss_test:0.01040, lr:5.94e-02, fs:0.87273 (r=0.970,p=0.793),  time:34.927, tt:2444.869\n",
      "Ep:70, loss:0.00001, loss_test:0.01036, lr:5.94e-02, fs:0.87273 (r=0.970,p=0.793),  time:34.930, tt:2480.019\n",
      "Ep:71, loss:0.00001, loss_test:0.01037, lr:5.94e-02, fs:0.86758 (r=0.960,p=0.792),  time:34.922, tt:2514.392\n",
      "Ep:72, loss:0.00001, loss_test:0.01037, lr:5.94e-02, fs:0.87156 (r=0.960,p=0.798),  time:34.926, tt:2549.616\n",
      "Ep:73, loss:0.00001, loss_test:0.01036, lr:5.94e-02, fs:0.87558 (r=0.960,p=0.805),  time:34.935, tt:2585.184\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00001, loss_test:0.01040, lr:5.94e-02, fs:0.87963 (r=0.960,p=0.812),  time:34.933, tt:2619.956\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00001, loss_test:0.01039, lr:5.94e-02, fs:0.87558 (r=0.960,p=0.805),  time:34.954, tt:2656.470\n",
      "Ep:76, loss:0.00001, loss_test:0.01040, lr:5.94e-02, fs:0.87963 (r=0.960,p=0.812),  time:34.931, tt:2689.716\n",
      "Ep:77, loss:0.00001, loss_test:0.01046, lr:5.94e-02, fs:0.88785 (r=0.960,p=0.826),  time:34.950, tt:2726.067\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.01043, lr:5.94e-02, fs:0.88785 (r=0.960,p=0.826),  time:34.953, tt:2761.278\n",
      "Ep:79, loss:0.00001, loss_test:0.01045, lr:5.94e-02, fs:0.88785 (r=0.960,p=0.826),  time:34.973, tt:2797.848\n",
      "Ep:80, loss:0.00001, loss_test:0.01042, lr:5.94e-02, fs:0.89623 (r=0.960,p=0.841),  time:34.990, tt:2834.214\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00001, loss_test:0.01052, lr:5.94e-02, fs:0.88785 (r=0.960,p=0.826),  time:35.006, tt:2870.460\n",
      "Ep:82, loss:0.00001, loss_test:0.01051, lr:5.94e-02, fs:0.90047 (r=0.960,p=0.848),  time:35.024, tt:2907.021\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.01059, lr:5.94e-02, fs:0.88785 (r=0.960,p=0.826),  time:35.038, tt:2943.162\n",
      "Ep:84, loss:0.00001, loss_test:0.01057, lr:5.94e-02, fs:0.90047 (r=0.960,p=0.848),  time:35.060, tt:2980.067\n",
      "Ep:85, loss:0.00001, loss_test:0.01056, lr:5.94e-02, fs:0.90476 (r=0.960,p=0.856),  time:35.070, tt:3015.998\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:86, loss:0.00001, loss_test:0.01062, lr:5.94e-02, fs:0.90047 (r=0.960,p=0.848),  time:35.085, tt:3052.390\n",
      "Ep:87, loss:0.00001, loss_test:0.01064, lr:5.94e-02, fs:0.90476 (r=0.960,p=0.856),  time:35.092, tt:3088.134\n",
      "Ep:88, loss:0.00001, loss_test:0.01074, lr:5.94e-02, fs:0.89952 (r=0.949,p=0.855),  time:35.110, tt:3124.797\n",
      "Ep:89, loss:0.00001, loss_test:0.01075, lr:5.94e-02, fs:0.89952 (r=0.949,p=0.855),  time:35.122, tt:3160.957\n",
      "Ep:90, loss:0.00001, loss_test:0.01073, lr:5.94e-02, fs:0.89952 (r=0.949,p=0.855),  time:35.113, tt:3195.278\n",
      "Ep:91, loss:0.00001, loss_test:0.01075, lr:5.94e-02, fs:0.89952 (r=0.949,p=0.855),  time:35.121, tt:3231.117\n",
      "Ep:92, loss:0.00001, loss_test:0.01086, lr:5.94e-02, fs:0.89952 (r=0.949,p=0.855),  time:35.112, tt:3265.460\n",
      "Ep:93, loss:0.00001, loss_test:0.01091, lr:5.94e-02, fs:0.89952 (r=0.949,p=0.855),  time:35.111, tt:3300.454\n",
      "Ep:94, loss:0.00001, loss_test:0.01095, lr:5.94e-02, fs:0.89952 (r=0.949,p=0.855),  time:35.085, tt:3333.037\n",
      "Ep:95, loss:0.00001, loss_test:0.01090, lr:5.94e-02, fs:0.89423 (r=0.939,p=0.853),  time:35.078, tt:3367.453\n",
      "Ep:96, loss:0.00001, loss_test:0.01103, lr:5.94e-02, fs:0.89855 (r=0.939,p=0.861),  time:35.077, tt:3402.515\n",
      "Ep:97, loss:0.00000, loss_test:0.01102, lr:5.88e-02, fs:0.90291 (r=0.939,p=0.869),  time:35.042, tt:3434.148\n",
      "Ep:98, loss:0.00000, loss_test:0.01109, lr:5.82e-02, fs:0.89855 (r=0.939,p=0.861),  time:35.041, tt:3469.075\n",
      "Ep:99, loss:0.00000, loss_test:0.01104, lr:5.76e-02, fs:0.89855 (r=0.939,p=0.861),  time:35.037, tt:3503.682\n",
      "Ep:100, loss:0.00000, loss_test:0.01123, lr:5.71e-02, fs:0.90291 (r=0.939,p=0.869),  time:35.022, tt:3537.237\n",
      "Ep:101, loss:0.00000, loss_test:0.01117, lr:5.65e-02, fs:0.90291 (r=0.939,p=0.869),  time:35.008, tt:3570.832\n",
      "Ep:102, loss:0.00000, loss_test:0.01124, lr:5.59e-02, fs:0.89216 (r=0.919,p=0.867),  time:35.004, tt:3605.388\n",
      "Ep:103, loss:0.00000, loss_test:0.01132, lr:5.54e-02, fs:0.89756 (r=0.929,p=0.868),  time:35.000, tt:3640.027\n",
      "Ep:104, loss:0.00000, loss_test:0.01127, lr:5.48e-02, fs:0.90196 (r=0.929,p=0.876),  time:34.998, tt:3674.757\n",
      "Ep:105, loss:0.00000, loss_test:0.01144, lr:5.43e-02, fs:0.88557 (r=0.899,p=0.873),  time:34.995, tt:3709.437\n",
      "Ep:106, loss:0.00000, loss_test:0.01138, lr:5.37e-02, fs:0.89109 (r=0.909,p=0.874),  time:34.973, tt:3742.084\n",
      "Ep:107, loss:0.00000, loss_test:0.01150, lr:5.32e-02, fs:0.89000 (r=0.899,p=0.881),  time:34.947, tt:3774.236\n",
      "Ep:108, loss:0.00000, loss_test:0.01153, lr:5.27e-02, fs:0.89000 (r=0.899,p=0.881),  time:34.918, tt:3806.111\n",
      "Ep:109, loss:0.00000, loss_test:0.01163, lr:5.21e-02, fs:0.89000 (r=0.899,p=0.881),  time:34.899, tt:3838.871\n",
      "Ep:110, loss:0.00000, loss_test:0.01156, lr:5.16e-02, fs:0.89000 (r=0.899,p=0.881),  time:34.879, tt:3871.601\n",
      "Ep:111, loss:0.00000, loss_test:0.01174, lr:5.11e-02, fs:0.89000 (r=0.899,p=0.881),  time:34.863, tt:3904.640\n",
      "Ep:112, loss:0.00000, loss_test:0.01167, lr:5.06e-02, fs:0.89000 (r=0.899,p=0.881),  time:34.860, tt:3939.199\n",
      "Ep:113, loss:0.00000, loss_test:0.01181, lr:5.01e-02, fs:0.89000 (r=0.899,p=0.881),  time:34.853, tt:3973.239\n",
      "Ep:114, loss:0.00000, loss_test:0.01176, lr:4.96e-02, fs:0.89000 (r=0.899,p=0.881),  time:34.848, tt:4007.573\n",
      "Ep:115, loss:0.00000, loss_test:0.01185, lr:4.91e-02, fs:0.89000 (r=0.899,p=0.881),  time:34.838, tt:4041.250\n",
      "Ep:116, loss:0.00000, loss_test:0.01186, lr:4.86e-02, fs:0.88442 (r=0.889,p=0.880),  time:34.834, tt:4075.585\n",
      "Ep:117, loss:0.00000, loss_test:0.01190, lr:4.81e-02, fs:0.88442 (r=0.889,p=0.880),  time:34.831, tt:4110.032\n",
      "Ep:118, loss:0.00000, loss_test:0.01192, lr:4.76e-02, fs:0.88442 (r=0.889,p=0.880),  time:34.819, tt:4143.432\n",
      "Ep:119, loss:0.00000, loss_test:0.01201, lr:4.71e-02, fs:0.88442 (r=0.889,p=0.880),  time:34.821, tt:4178.469\n",
      "Ep:120, loss:0.00000, loss_test:0.01207, lr:4.67e-02, fs:0.88889 (r=0.889,p=0.889),  time:34.818, tt:4213.027\n",
      "Ep:121, loss:0.00000, loss_test:0.01206, lr:4.62e-02, fs:0.88889 (r=0.889,p=0.889),  time:34.807, tt:4246.446\n",
      "Ep:122, loss:0.00000, loss_test:0.01215, lr:4.57e-02, fs:0.88889 (r=0.889,p=0.889),  time:34.801, tt:4280.561\n",
      "Ep:123, loss:0.00000, loss_test:0.01218, lr:4.53e-02, fs:0.88889 (r=0.889,p=0.889),  time:34.801, tt:4315.275\n",
      "Ep:124, loss:0.00000, loss_test:0.01216, lr:4.48e-02, fs:0.88889 (r=0.889,p=0.889),  time:34.789, tt:4348.679\n",
      "Ep:125, loss:0.00000, loss_test:0.01227, lr:4.44e-02, fs:0.88889 (r=0.889,p=0.889),  time:34.784, tt:4382.830\n",
      "Ep:126, loss:0.00000, loss_test:0.01232, lr:4.39e-02, fs:0.88889 (r=0.889,p=0.889),  time:34.769, tt:4415.673\n",
      "Ep:127, loss:0.00000, loss_test:0.01230, lr:4.35e-02, fs:0.88889 (r=0.889,p=0.889),  time:34.765, tt:4449.927\n",
      "Ep:128, loss:0.00000, loss_test:0.01234, lr:4.31e-02, fs:0.88889 (r=0.889,p=0.889),  time:34.761, tt:4484.145\n",
      "Ep:129, loss:0.00000, loss_test:0.01244, lr:4.26e-02, fs:0.88889 (r=0.889,p=0.889),  time:34.751, tt:4517.679\n",
      "Ep:130, loss:0.00000, loss_test:0.01247, lr:4.22e-02, fs:0.88889 (r=0.889,p=0.889),  time:34.738, tt:4550.693\n",
      "Ep:131, loss:0.00000, loss_test:0.01253, lr:4.18e-02, fs:0.88325 (r=0.879,p=0.888),  time:34.736, tt:4585.086\n",
      "Ep:132, loss:0.00000, loss_test:0.01252, lr:4.14e-02, fs:0.88889 (r=0.889,p=0.889),  time:34.731, tt:4619.260\n",
      "Ep:133, loss:0.00000, loss_test:0.01264, lr:4.10e-02, fs:0.87755 (r=0.869,p=0.887),  time:34.736, tt:4654.615\n",
      "Ep:134, loss:0.00000, loss_test:0.01261, lr:4.05e-02, fs:0.88325 (r=0.879,p=0.888),  time:34.739, tt:4689.751\n",
      "Ep:135, loss:0.00000, loss_test:0.01269, lr:4.01e-02, fs:0.87755 (r=0.869,p=0.887),  time:34.753, tt:4726.466\n",
      "Ep:136, loss:0.00000, loss_test:0.01272, lr:3.97e-02, fs:0.87179 (r=0.859,p=0.885),  time:34.760, tt:4762.081\n",
      "Ep:137, loss:0.00000, loss_test:0.01271, lr:3.93e-02, fs:0.87179 (r=0.859,p=0.885),  time:34.755, tt:4796.128\n",
      "Ep:138, loss:0.00000, loss_test:0.01280, lr:3.89e-02, fs:0.86010 (r=0.838,p=0.883),  time:34.743, tt:4829.247\n",
      "Ep:139, loss:0.00000, loss_test:0.01285, lr:3.86e-02, fs:0.85417 (r=0.828,p=0.882),  time:34.746, tt:4864.434\n",
      "Ep:140, loss:0.00000, loss_test:0.01286, lr:3.82e-02, fs:0.85417 (r=0.828,p=0.882),  time:34.742, tt:4898.588\n",
      "Ep:141, loss:0.00000, loss_test:0.01292, lr:3.78e-02, fs:0.84817 (r=0.818,p=0.880),  time:34.736, tt:4932.500\n",
      "Ep:142, loss:0.00000, loss_test:0.01292, lr:3.74e-02, fs:0.84211 (r=0.808,p=0.879),  time:34.742, tt:4968.118\n",
      "Ep:143, loss:0.00000, loss_test:0.01299, lr:3.70e-02, fs:0.82979 (r=0.788,p=0.876),  time:34.741, tt:5002.688\n",
      "Ep:144, loss:0.00000, loss_test:0.01298, lr:3.67e-02, fs:0.82979 (r=0.788,p=0.876),  time:34.736, tt:5036.755\n",
      "Ep:145, loss:0.00000, loss_test:0.01307, lr:3.63e-02, fs:0.81720 (r=0.768,p=0.874),  time:34.733, tt:5071.067\n",
      "Ep:146, loss:0.00000, loss_test:0.01308, lr:3.59e-02, fs:0.80435 (r=0.747,p=0.871),  time:34.735, tt:5106.006\n",
      "Ep:147, loss:0.00000, loss_test:0.01311, lr:3.56e-02, fs:0.81081 (r=0.758,p=0.872),  time:34.766, tt:5145.321\n",
      "Ep:148, loss:0.00000, loss_test:0.01317, lr:3.52e-02, fs:0.80435 (r=0.747,p=0.871),  time:34.762, tt:5179.577\n",
      "Ep:149, loss:0.00000, loss_test:0.01320, lr:3.49e-02, fs:0.79781 (r=0.737,p=0.869),  time:34.767, tt:5215.046\n",
      "Ep:150, loss:0.00000, loss_test:0.01331, lr:3.45e-02, fs:0.80435 (r=0.747,p=0.871),  time:34.765, tt:5249.479\n",
      "Ep:151, loss:0.00000, loss_test:0.01319, lr:3.42e-02, fs:0.79781 (r=0.737,p=0.869),  time:34.767, tt:5284.557\n",
      "Ep:152, loss:0.00000, loss_test:0.01335, lr:3.38e-02, fs:0.79781 (r=0.737,p=0.869),  time:34.768, tt:5319.496\n",
      "Ep:153, loss:0.00000, loss_test:0.01330, lr:3.35e-02, fs:0.77778 (r=0.707,p=0.864),  time:34.772, tt:5354.927\n",
      "Ep:154, loss:0.00000, loss_test:0.01345, lr:3.32e-02, fs:0.79121 (r=0.727,p=0.867),  time:34.769, tt:5389.122\n",
      "Ep:155, loss:0.00000, loss_test:0.01331, lr:3.28e-02, fs:0.77095 (r=0.697,p=0.863),  time:34.762, tt:5422.898\n",
      "Ep:156, loss:0.00000, loss_test:0.01345, lr:3.25e-02, fs:0.79121 (r=0.727,p=0.867),  time:34.751, tt:5455.916\n",
      "Ep:157, loss:0.00000, loss_test:0.01342, lr:3.22e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.753, tt:5491.040\n",
      "Ep:158, loss:0.00000, loss_test:0.01351, lr:3.19e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.750, tt:5525.277\n",
      "Ep:159, loss:0.00000, loss_test:0.01355, lr:3.15e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.755, tt:5560.776\n",
      "Ep:160, loss:0.00000, loss_test:0.01352, lr:3.12e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.751, tt:5594.934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:161, loss:0.00000, loss_test:0.01362, lr:3.09e-02, fs:0.77778 (r=0.707,p=0.864),  time:34.742, tt:5628.246\n",
      "Ep:162, loss:0.00000, loss_test:0.01355, lr:3.06e-02, fs:0.77095 (r=0.697,p=0.863),  time:34.744, tt:5663.210\n",
      "Ep:163, loss:0.00000, loss_test:0.01372, lr:3.03e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.740, tt:5697.353\n",
      "Ep:164, loss:0.00000, loss_test:0.01361, lr:3.00e-02, fs:0.76404 (r=0.687,p=0.861),  time:34.738, tt:5731.729\n",
      "Ep:165, loss:0.00000, loss_test:0.01376, lr:2.97e-02, fs:0.77095 (r=0.697,p=0.863),  time:34.726, tt:5764.461\n",
      "Ep:166, loss:0.00000, loss_test:0.01370, lr:2.94e-02, fs:0.76404 (r=0.687,p=0.861),  time:34.728, tt:5799.591\n",
      "Ep:167, loss:0.00000, loss_test:0.01377, lr:2.91e-02, fs:0.75706 (r=0.677,p=0.859),  time:34.723, tt:5833.418\n",
      "Ep:168, loss:0.00000, loss_test:0.01383, lr:2.88e-02, fs:0.75706 (r=0.677,p=0.859),  time:34.721, tt:5867.841\n",
      "Ep:169, loss:0.00000, loss_test:0.01382, lr:2.85e-02, fs:0.75706 (r=0.677,p=0.859),  time:34.723, tt:5902.913\n",
      "Ep:170, loss:0.00000, loss_test:0.01389, lr:2.82e-02, fs:0.75706 (r=0.677,p=0.859),  time:34.733, tt:5939.412\n",
      "Ep:171, loss:0.00000, loss_test:0.01388, lr:2.80e-02, fs:0.75706 (r=0.677,p=0.859),  time:34.739, tt:5975.094\n",
      "Ep:172, loss:0.00000, loss_test:0.01394, lr:2.77e-02, fs:0.75706 (r=0.677,p=0.859),  time:34.741, tt:6010.202\n",
      "Ep:173, loss:0.00000, loss_test:0.01393, lr:2.74e-02, fs:0.75706 (r=0.677,p=0.859),  time:34.751, tt:6046.688\n",
      "Ep:174, loss:0.00000, loss_test:0.01394, lr:2.71e-02, fs:0.75706 (r=0.677,p=0.859),  time:34.758, tt:6082.600\n",
      "Ep:175, loss:0.00000, loss_test:0.01399, lr:2.69e-02, fs:0.75706 (r=0.677,p=0.859),  time:34.771, tt:6119.671\n",
      "Ep:176, loss:0.00000, loss_test:0.01401, lr:2.66e-02, fs:0.75000 (r=0.667,p=0.857),  time:34.779, tt:6155.914\n",
      "Ep:177, loss:0.00000, loss_test:0.01405, lr:2.63e-02, fs:0.75000 (r=0.667,p=0.857),  time:34.784, tt:6191.512\n",
      "Ep:178, loss:0.00000, loss_test:0.01407, lr:2.61e-02, fs:0.75000 (r=0.667,p=0.857),  time:34.786, tt:6226.619\n",
      "Ep:179, loss:0.00000, loss_test:0.01407, lr:2.58e-02, fs:0.75706 (r=0.677,p=0.859),  time:34.793, tt:6262.779\n",
      "Ep:180, loss:0.00000, loss_test:0.01413, lr:2.55e-02, fs:0.75000 (r=0.667,p=0.857),  time:34.801, tt:6298.971\n",
      "Ep:181, loss:0.00000, loss_test:0.01417, lr:2.53e-02, fs:0.75429 (r=0.667,p=0.868),  time:34.808, tt:6335.121\n",
      "Ep:182, loss:0.00000, loss_test:0.01419, lr:2.50e-02, fs:0.75429 (r=0.667,p=0.868),  time:34.812, tt:6370.570\n",
      "Ep:183, loss:0.00000, loss_test:0.01421, lr:2.48e-02, fs:0.75429 (r=0.667,p=0.868),  time:34.819, tt:6406.705\n",
      "Ep:184, loss:0.00000, loss_test:0.01422, lr:2.45e-02, fs:0.75429 (r=0.667,p=0.868),  time:34.830, tt:6443.504\n",
      "Ep:185, loss:0.00000, loss_test:0.01427, lr:2.43e-02, fs:0.75429 (r=0.667,p=0.868),  time:34.866, tt:6485.039\n",
      "Ep:186, loss:0.00000, loss_test:0.01429, lr:2.40e-02, fs:0.75429 (r=0.667,p=0.868),  time:34.880, tt:6522.581\n",
      "Ep:187, loss:0.00000, loss_test:0.01434, lr:2.38e-02, fs:0.75429 (r=0.667,p=0.868),  time:34.893, tt:6559.919\n",
      "Ep:188, loss:0.00000, loss_test:0.01436, lr:2.36e-02, fs:0.75429 (r=0.667,p=0.868),  time:34.903, tt:6596.581\n",
      "Ep:189, loss:0.00000, loss_test:0.01435, lr:2.33e-02, fs:0.75429 (r=0.667,p=0.868),  time:34.915, tt:6633.796\n",
      "Ep:190, loss:0.00000, loss_test:0.01440, lr:2.31e-02, fs:0.75429 (r=0.667,p=0.868),  time:34.926, tt:6670.886\n",
      "Ep:191, loss:0.00000, loss_test:0.01442, lr:2.29e-02, fs:0.75429 (r=0.667,p=0.868),  time:34.930, tt:6706.513\n",
      "Ep:192, loss:0.00000, loss_test:0.01444, lr:2.26e-02, fs:0.75429 (r=0.667,p=0.868),  time:34.935, tt:6742.400\n",
      "Ep:193, loss:0.00000, loss_test:0.01448, lr:2.24e-02, fs:0.75429 (r=0.667,p=0.868),  time:34.854, tt:6761.603\n",
      "Ep:194, loss:0.00000, loss_test:0.01449, lr:2.22e-02, fs:0.75429 (r=0.667,p=0.868),  time:34.752, tt:6776.674\n",
      "Ep:195, loss:0.00000, loss_test:0.01451, lr:2.20e-02, fs:0.75429 (r=0.667,p=0.868),  time:34.642, tt:6789.920\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"5-5\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14622, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:50.888, tt:50.888\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14548, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:52.177, tt:104.354\n",
      "Ep:2, loss:0.00028, loss_test:0.14410, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:52.158, tt:156.474\n",
      "Ep:3, loss:0.00027, loss_test:0.14163, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:52.065, tt:208.261\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.13719, lr:1.00e-02, fs:0.65068 (r=0.960,p=0.492),  time:52.009, tt:260.045\n",
      "Ep:5, loss:0.00025, loss_test:0.12893, lr:1.00e-02, fs:0.65637 (r=0.859,p=0.531),  time:52.143, tt:312.860\n",
      "Ep:6, loss:0.00023, loss_test:0.11876, lr:1.00e-02, fs:0.63889 (r=0.697,p=0.590),  time:51.846, tt:362.920\n",
      "Ep:7, loss:0.00022, loss_test:0.11586, lr:1.00e-02, fs:0.63810 (r=0.677,p=0.604),  time:51.921, tt:415.371\n",
      "Ep:8, loss:0.00021, loss_test:0.11170, lr:1.00e-02, fs:0.68161 (r=0.768,p=0.613),  time:51.968, tt:467.710\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.11045, lr:1.00e-02, fs:0.66964 (r=0.758,p=0.600),  time:51.844, tt:518.444\n",
      "Ep:10, loss:0.00020, loss_test:0.10919, lr:1.00e-02, fs:0.69484 (r=0.747,p=0.649),  time:51.746, tt:569.204\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.10757, lr:1.00e-02, fs:0.72038 (r=0.768,p=0.679),  time:51.728, tt:620.736\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.10600, lr:1.00e-02, fs:0.72300 (r=0.778,p=0.675),  time:51.759, tt:672.866\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.10399, lr:1.00e-02, fs:0.72115 (r=0.758,p=0.688),  time:51.812, tt:725.369\n",
      "Ep:14, loss:0.00018, loss_test:0.10264, lr:1.00e-02, fs:0.73367 (r=0.737,p=0.730),  time:51.964, tt:779.463\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.10063, lr:1.00e-02, fs:0.73632 (r=0.747,p=0.725),  time:51.981, tt:831.695\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.10113, lr:1.00e-02, fs:0.73298 (r=0.707,p=0.761),  time:52.064, tt:885.080\n",
      "Ep:17, loss:0.00016, loss_test:0.09940, lr:1.00e-02, fs:0.74112 (r=0.737,p=0.745),  time:52.011, tt:936.193\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.09850, lr:1.00e-02, fs:0.73684 (r=0.707,p=0.769),  time:52.099, tt:989.879\n",
      "Ep:19, loss:0.00015, loss_test:0.09800, lr:1.00e-02, fs:0.74737 (r=0.717,p=0.780),  time:51.979, tt:1039.583\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.09603, lr:1.00e-02, fs:0.74346 (r=0.717,p=0.772),  time:52.077, tt:1093.610\n",
      "Ep:21, loss:0.00014, loss_test:0.09615, lr:1.00e-02, fs:0.74194 (r=0.697,p=0.793),  time:52.016, tt:1144.343\n",
      "Ep:22, loss:0.00013, loss_test:0.09432, lr:1.00e-02, fs:0.75789 (r=0.727,p=0.791),  time:52.029, tt:1196.663\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00013, loss_test:0.09315, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:52.058, tt:1249.384\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00013, loss_test:0.09318, lr:1.00e-02, fs:0.76503 (r=0.707,p=0.833),  time:52.101, tt:1302.520\n",
      "Ep:25, loss:0.00012, loss_test:0.09114, lr:1.00e-02, fs:0.77320 (r=0.758,p=0.789),  time:52.068, tt:1353.772\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00012, loss_test:0.09325, lr:1.00e-02, fs:0.76503 (r=0.707,p=0.833),  time:52.008, tt:1404.219\n",
      "Ep:27, loss:0.00012, loss_test:0.09324, lr:1.00e-02, fs:0.77596 (r=0.717,p=0.845),  time:52.017, tt:1456.468\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00011, loss_test:0.08976, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:52.142, tt:1512.126\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00011, loss_test:0.09283, lr:1.00e-02, fs:0.77596 (r=0.717,p=0.845),  time:52.137, tt:1564.111\n",
      "Ep:30, loss:0.00011, loss_test:0.09241, lr:1.00e-02, fs:0.78261 (r=0.727,p=0.847),  time:52.070, tt:1614.155\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00010, loss_test:0.08899, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:52.043, tt:1665.382\n",
      "Ep:32, loss:0.00010, loss_test:0.09013, lr:1.00e-02, fs:0.77838 (r=0.727,p=0.837),  time:51.982, tt:1715.394\n",
      "Ep:33, loss:0.00009, loss_test:0.08725, lr:1.00e-02, fs:0.80214 (r=0.758,p=0.852),  time:52.032, tt:1769.081\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00009, loss_test:0.08746, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:52.044, tt:1821.555\n",
      "Ep:35, loss:0.00009, loss_test:0.09069, lr:1.00e-02, fs:0.78889 (r=0.717,p=0.877),  time:51.998, tt:1871.913\n",
      "Ep:36, loss:0.00009, loss_test:0.08675, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:51.970, tt:1922.878\n",
      "Ep:37, loss:0.00008, loss_test:0.08749, lr:1.00e-02, fs:0.80220 (r=0.737,p=0.880),  time:52.024, tt:1976.900\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00008, loss_test:0.09069, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:52.023, tt:2028.886\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00008, loss_test:0.08550, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:52.031, tt:2081.251\n",
      "Ep:40, loss:0.00008, loss_test:0.08781, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:52.076, tt:2135.110\n",
      "Ep:41, loss:0.00008, loss_test:0.09102, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:52.049, tt:2186.079\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00007, loss_test:0.08443, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:52.010, tt:2236.427\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00007, loss_test:0.08890, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:52.019, tt:2288.854\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00007, loss_test:0.08397, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:51.993, tt:2339.694\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00007, loss_test:0.08612, lr:1.00e-02, fs:0.82418 (r=0.758,p=0.904),  time:51.975, tt:2390.830\n",
      "Ep:46, loss:0.00006, loss_test:0.08430, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:51.939, tt:2441.136\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00006, loss_test:0.08479, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:51.910, tt:2491.701\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00006, loss_test:0.08480, lr:1.00e-02, fs:0.83799 (r=0.758,p=0.938),  time:51.900, tt:2543.102\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00006, loss_test:0.08805, lr:1.00e-02, fs:0.83799 (r=0.758,p=0.938),  time:51.914, tt:2595.723\n",
      "Ep:50, loss:0.00005, loss_test:0.08322, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:51.881, tt:2645.948\n",
      "Ep:51, loss:0.00006, loss_test:0.08519, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:51.829, tt:2695.130\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00005, loss_test:0.08389, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:51.862, tt:2748.704\n",
      "Ep:53, loss:0.00005, loss_test:0.08689, lr:1.00e-02, fs:0.83146 (r=0.747,p=0.937),  time:51.870, tt:2800.976\n",
      "Ep:54, loss:0.00005, loss_test:0.08410, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:51.855, tt:2852.031\n",
      "Ep:55, loss:0.00005, loss_test:0.08498, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:51.860, tt:2904.163\n",
      "Ep:56, loss:0.00004, loss_test:0.09549, lr:1.00e-02, fs:0.84746 (r=0.758,p=0.962),  time:51.846, tt:2955.194\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00005, loss_test:0.08163, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:51.865, tt:3008.171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00005, loss_test:0.09745, lr:1.00e-02, fs:0.79518 (r=0.667,p=0.985),  time:51.862, tt:3059.859\n",
      "Ep:59, loss:0.00004, loss_test:0.08698, lr:1.00e-02, fs:0.83799 (r=0.758,p=0.938),  time:51.859, tt:3111.542\n",
      "Ep:60, loss:0.00004, loss_test:0.09076, lr:1.00e-02, fs:0.83237 (r=0.727,p=0.973),  time:51.867, tt:3163.862\n",
      "Ep:61, loss:0.00004, loss_test:0.08800, lr:1.00e-02, fs:0.82759 (r=0.727,p=0.960),  time:51.852, tt:3214.801\n",
      "Ep:62, loss:0.00004, loss_test:0.08772, lr:1.00e-02, fs:0.83799 (r=0.758,p=0.938),  time:51.828, tt:3265.173\n",
      "Ep:63, loss:0.00004, loss_test:0.08999, lr:1.00e-02, fs:0.84270 (r=0.758,p=0.949),  time:51.839, tt:3317.701\n",
      "Ep:64, loss:0.00003, loss_test:0.08882, lr:1.00e-02, fs:0.80233 (r=0.697,p=0.945),  time:51.851, tt:3370.297\n",
      "Ep:65, loss:0.00004, loss_test:0.09376, lr:1.00e-02, fs:0.84571 (r=0.747,p=0.974),  time:51.860, tt:3422.778\n",
      "Ep:66, loss:0.00003, loss_test:0.08524, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:51.870, tt:3475.318\n",
      "Ep:67, loss:0.00003, loss_test:0.09924, lr:1.00e-02, fs:0.80240 (r=0.677,p=0.985),  time:51.897, tt:3529.000\n",
      "Ep:68, loss:0.00003, loss_test:0.08636, lr:9.90e-03, fs:0.82022 (r=0.737,p=0.924),  time:51.905, tt:3581.428\n",
      "Ep:69, loss:0.00003, loss_test:0.09349, lr:9.80e-03, fs:0.81657 (r=0.697,p=0.986),  time:51.904, tt:3633.250\n",
      "Ep:70, loss:0.00003, loss_test:0.09008, lr:9.70e-03, fs:0.84270 (r=0.758,p=0.949),  time:51.901, tt:3684.949\n",
      "Ep:71, loss:0.00003, loss_test:0.09279, lr:9.61e-03, fs:0.84916 (r=0.768,p=0.950),  time:51.916, tt:3737.964\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00003, loss_test:0.09224, lr:9.61e-03, fs:0.81395 (r=0.707,p=0.959),  time:51.905, tt:3789.093\n",
      "Ep:73, loss:0.00003, loss_test:0.09201, lr:9.61e-03, fs:0.81609 (r=0.717,p=0.947),  time:51.931, tt:3842.930\n",
      "Ep:74, loss:0.00003, loss_test:0.09333, lr:9.61e-03, fs:0.82759 (r=0.727,p=0.960),  time:51.923, tt:3894.244\n",
      "Ep:75, loss:0.00002, loss_test:0.08735, lr:9.61e-03, fs:0.82081 (r=0.717,p=0.959),  time:51.909, tt:3945.085\n",
      "Ep:76, loss:0.00002, loss_test:0.09494, lr:9.61e-03, fs:0.80240 (r=0.677,p=0.985),  time:51.856, tt:3992.934\n",
      "Ep:77, loss:0.00002, loss_test:0.08695, lr:9.61e-03, fs:0.83429 (r=0.737,p=0.961),  time:51.871, tt:4045.938\n",
      "Ep:78, loss:0.00002, loss_test:0.09288, lr:9.61e-03, fs:0.80240 (r=0.677,p=0.985),  time:51.869, tt:4097.627\n",
      "Ep:79, loss:0.00002, loss_test:0.09692, lr:9.61e-03, fs:0.80240 (r=0.677,p=0.985),  time:51.857, tt:4148.576\n",
      "Ep:80, loss:0.00002, loss_test:0.08808, lr:9.61e-03, fs:0.82682 (r=0.747,p=0.925),  time:51.887, tt:4202.840\n",
      "Ep:81, loss:0.00002, loss_test:0.09751, lr:9.61e-03, fs:0.80240 (r=0.677,p=0.985),  time:51.888, tt:4254.780\n",
      "Ep:82, loss:0.00002, loss_test:0.08600, lr:9.61e-03, fs:0.80702 (r=0.697,p=0.958),  time:51.880, tt:4306.035\n",
      "Ep:83, loss:0.00002, loss_test:0.10051, lr:9.51e-03, fs:0.83908 (r=0.737,p=0.973),  time:51.881, tt:4358.023\n",
      "Ep:84, loss:0.00002, loss_test:0.08436, lr:9.41e-03, fs:0.80925 (r=0.707,p=0.946),  time:51.879, tt:4409.679\n",
      "Ep:85, loss:0.00002, loss_test:0.09989, lr:9.32e-03, fs:0.78788 (r=0.657,p=0.985),  time:51.861, tt:4460.003\n",
      "Ep:86, loss:0.00002, loss_test:0.08700, lr:9.23e-03, fs:0.82286 (r=0.727,p=0.947),  time:51.873, tt:4512.992\n",
      "Ep:87, loss:0.00002, loss_test:0.09310, lr:9.14e-03, fs:0.76543 (r=0.626,p=0.984),  time:51.885, tt:4565.915\n",
      "Ep:88, loss:0.00002, loss_test:0.08807, lr:9.04e-03, fs:0.82759 (r=0.727,p=0.960),  time:51.890, tt:4618.219\n",
      "Ep:89, loss:0.00002, loss_test:0.09481, lr:8.95e-03, fs:0.80952 (r=0.687,p=0.986),  time:51.867, tt:4668.007\n",
      "Ep:90, loss:0.00002, loss_test:0.08705, lr:8.86e-03, fs:0.81395 (r=0.707,p=0.959),  time:51.881, tt:4721.203\n",
      "Ep:91, loss:0.00002, loss_test:0.09770, lr:8.78e-03, fs:0.79518 (r=0.667,p=0.985),  time:51.884, tt:4773.325\n",
      "Ep:92, loss:0.00001, loss_test:0.08620, lr:8.69e-03, fs:0.81395 (r=0.707,p=0.959),  time:51.889, tt:4825.691\n",
      "Ep:93, loss:0.00001, loss_test:0.09540, lr:8.60e-03, fs:0.82353 (r=0.707,p=0.986),  time:51.895, tt:4878.115\n",
      "Ep:94, loss:0.00001, loss_test:0.09153, lr:8.51e-03, fs:0.81657 (r=0.697,p=0.986),  time:51.903, tt:4930.817\n",
      "Ep:95, loss:0.00001, loss_test:0.09487, lr:8.43e-03, fs:0.86517 (r=0.778,p=0.975),  time:51.930, tt:4985.301\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00001, loss_test:0.09472, lr:8.43e-03, fs:0.81657 (r=0.697,p=0.986),  time:51.942, tt:5038.347\n",
      "Ep:97, loss:0.00001, loss_test:0.09271, lr:8.43e-03, fs:0.83721 (r=0.727,p=0.986),  time:51.942, tt:5090.306\n",
      "Ep:98, loss:0.00001, loss_test:0.09520, lr:8.43e-03, fs:0.82353 (r=0.707,p=0.986),  time:51.945, tt:5142.584\n",
      "Ep:99, loss:0.00001, loss_test:0.09174, lr:8.43e-03, fs:0.81657 (r=0.697,p=0.986),  time:51.941, tt:5194.133\n",
      "Ep:100, loss:0.00001, loss_test:0.08991, lr:8.43e-03, fs:0.82353 (r=0.707,p=0.986),  time:51.938, tt:5245.755\n",
      "Ep:101, loss:0.00001, loss_test:0.09425, lr:8.43e-03, fs:0.82353 (r=0.707,p=0.986),  time:51.976, tt:5301.507\n",
      "Ep:102, loss:0.00001, loss_test:0.09129, lr:8.43e-03, fs:0.81871 (r=0.707,p=0.972),  time:51.969, tt:5352.806\n",
      "Ep:103, loss:0.00001, loss_test:0.09274, lr:8.43e-03, fs:0.82353 (r=0.707,p=0.986),  time:51.953, tt:5403.110\n",
      "Ep:104, loss:0.00001, loss_test:0.09248, lr:8.43e-03, fs:0.82353 (r=0.707,p=0.986),  time:51.950, tt:5454.733\n",
      "Ep:105, loss:0.00001, loss_test:0.09064, lr:8.43e-03, fs:0.82353 (r=0.707,p=0.986),  time:51.950, tt:5506.692\n",
      "Ep:106, loss:0.00001, loss_test:0.09221, lr:8.43e-03, fs:0.82353 (r=0.707,p=0.986),  time:51.936, tt:5557.194\n",
      "Ep:107, loss:0.00001, loss_test:0.09226, lr:8.35e-03, fs:0.82353 (r=0.707,p=0.986),  time:51.937, tt:5609.145\n",
      "Ep:108, loss:0.00001, loss_test:0.09552, lr:8.26e-03, fs:0.82840 (r=0.707,p=1.000),  time:51.929, tt:5660.229\n",
      "Ep:109, loss:0.00001, loss_test:0.09158, lr:8.18e-03, fs:0.82353 (r=0.707,p=0.986),  time:51.928, tt:5712.073\n",
      "Ep:110, loss:0.00001, loss_test:0.09172, lr:8.10e-03, fs:0.82840 (r=0.707,p=1.000),  time:51.915, tt:5762.582\n",
      "Ep:111, loss:0.00001, loss_test:0.09413, lr:8.02e-03, fs:0.82353 (r=0.707,p=0.986),  time:51.915, tt:5814.466\n",
      "Ep:112, loss:0.00001, loss_test:0.09127, lr:7.94e-03, fs:0.82840 (r=0.707,p=1.000),  time:51.907, tt:5865.465\n",
      "Ep:113, loss:0.00001, loss_test:0.09241, lr:7.86e-03, fs:0.82353 (r=0.707,p=0.986),  time:51.901, tt:5916.752\n",
      "Ep:114, loss:0.00001, loss_test:0.09403, lr:7.78e-03, fs:0.82353 (r=0.707,p=0.986),  time:51.896, tt:5968.008\n",
      "Ep:115, loss:0.00001, loss_test:0.09114, lr:7.70e-03, fs:0.82840 (r=0.707,p=1.000),  time:51.888, tt:6019.039\n",
      "Ep:116, loss:0.00001, loss_test:0.09467, lr:7.62e-03, fs:0.82353 (r=0.707,p=0.986),  time:51.884, tt:6070.434\n",
      "Ep:117, loss:0.00001, loss_test:0.09177, lr:7.55e-03, fs:0.82840 (r=0.707,p=1.000),  time:51.895, tt:6123.650\n",
      "Ep:118, loss:0.00001, loss_test:0.09548, lr:7.47e-03, fs:0.82353 (r=0.707,p=0.986),  time:51.904, tt:6176.605\n",
      "Ep:119, loss:0.00001, loss_test:0.09509, lr:7.40e-03, fs:0.82840 (r=0.707,p=1.000),  time:51.906, tt:6228.713\n",
      "Ep:120, loss:0.00001, loss_test:0.09230, lr:7.32e-03, fs:0.82353 (r=0.707,p=0.986),  time:51.901, tt:6280.029\n",
      "Ep:121, loss:0.00001, loss_test:0.09603, lr:7.25e-03, fs:0.82353 (r=0.707,p=0.986),  time:51.900, tt:6331.780\n",
      "Ep:122, loss:0.00001, loss_test:0.09423, lr:7.18e-03, fs:0.82353 (r=0.707,p=0.986),  time:51.886, tt:6382.011\n",
      "Ep:123, loss:0.00000, loss_test:0.09428, lr:7.11e-03, fs:0.82353 (r=0.707,p=0.986),  time:51.887, tt:6434.002\n",
      "Ep:124, loss:0.00000, loss_test:0.09403, lr:7.03e-03, fs:0.82353 (r=0.707,p=0.986),  time:51.868, tt:6483.450\n",
      "Ep:125, loss:0.00000, loss_test:0.09494, lr:6.96e-03, fs:0.82840 (r=0.707,p=1.000),  time:51.879, tt:6536.729\n",
      "Ep:126, loss:0.00000, loss_test:0.09412, lr:6.89e-03, fs:0.82353 (r=0.707,p=0.986),  time:51.874, tt:6587.956\n",
      "Ep:127, loss:0.00000, loss_test:0.09756, lr:6.83e-03, fs:0.82840 (r=0.707,p=1.000),  time:51.910, tt:6644.490\n",
      "Ep:128, loss:0.00000, loss_test:0.09436, lr:6.76e-03, fs:0.82353 (r=0.707,p=0.986),  time:51.920, tt:6697.701\n",
      "Ep:129, loss:0.00000, loss_test:0.09683, lr:6.69e-03, fs:0.82840 (r=0.707,p=1.000),  time:51.955, tt:6754.124\n",
      "Ep:130, loss:0.00000, loss_test:0.09515, lr:6.62e-03, fs:0.82353 (r=0.707,p=0.986),  time:51.954, tt:6806.016\n",
      "Ep:131, loss:0.00000, loss_test:0.09687, lr:6.56e-03, fs:0.82840 (r=0.707,p=1.000),  time:51.958, tt:6858.517\n",
      "Ep:132, loss:0.00000, loss_test:0.09585, lr:6.49e-03, fs:0.82353 (r=0.707,p=0.986),  time:51.959, tt:6910.601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00000, loss_test:0.09560, lr:6.43e-03, fs:0.82840 (r=0.707,p=1.000),  time:51.966, tt:6963.500\n",
      "Ep:134, loss:0.00000, loss_test:0.09758, lr:6.36e-03, fs:0.82353 (r=0.707,p=0.986),  time:51.969, tt:7015.876\n",
      "Ep:135, loss:0.00000, loss_test:0.09457, lr:6.30e-03, fs:0.82353 (r=0.707,p=0.986),  time:51.977, tt:7068.807\n",
      "Ep:136, loss:0.00000, loss_test:0.09805, lr:6.24e-03, fs:0.82353 (r=0.707,p=0.986),  time:51.984, tt:7121.864\n",
      "Ep:137, loss:0.00000, loss_test:0.09703, lr:6.17e-03, fs:0.82840 (r=0.707,p=1.000),  time:52.002, tt:7176.217\n",
      "Ep:138, loss:0.00000, loss_test:0.09619, lr:6.11e-03, fs:0.82353 (r=0.707,p=0.986),  time:52.017, tt:7230.293\n",
      "Ep:139, loss:0.00000, loss_test:0.09635, lr:6.05e-03, fs:0.82840 (r=0.707,p=1.000),  time:52.002, tt:7280.278\n",
      "Ep:140, loss:0.00000, loss_test:0.09597, lr:5.99e-03, fs:0.82353 (r=0.707,p=0.986),  time:51.998, tt:7331.662\n",
      "Ep:141, loss:0.00000, loss_test:0.09767, lr:5.93e-03, fs:0.82840 (r=0.707,p=1.000),  time:52.024, tt:7387.404\n",
      "Ep:142, loss:0.00000, loss_test:0.09509, lr:5.87e-03, fs:0.82353 (r=0.707,p=0.986),  time:52.023, tt:7439.311\n",
      "Ep:143, loss:0.00000, loss_test:0.09717, lr:5.81e-03, fs:0.82840 (r=0.707,p=1.000),  time:52.040, tt:7493.690\n",
      "Ep:144, loss:0.00000, loss_test:0.09664, lr:5.75e-03, fs:0.82353 (r=0.707,p=0.986),  time:52.041, tt:7545.983\n",
      "Ep:145, loss:0.00000, loss_test:0.09645, lr:5.70e-03, fs:0.82840 (r=0.707,p=1.000),  time:52.044, tt:7598.374\n",
      "Ep:146, loss:0.00000, loss_test:0.09705, lr:5.64e-03, fs:0.82353 (r=0.707,p=0.986),  time:52.055, tt:7652.133\n",
      "Ep:147, loss:0.00000, loss_test:0.09642, lr:5.58e-03, fs:0.81657 (r=0.697,p=0.986),  time:52.049, tt:7703.280\n",
      "Ep:148, loss:0.00000, loss_test:0.09669, lr:5.53e-03, fs:0.82353 (r=0.707,p=0.986),  time:52.051, tt:7755.635\n",
      "Ep:149, loss:0.00000, loss_test:0.09682, lr:5.47e-03, fs:0.82353 (r=0.707,p=0.986),  time:52.044, tt:7806.612\n",
      "Ep:150, loss:0.00000, loss_test:0.09688, lr:5.42e-03, fs:0.82353 (r=0.707,p=0.986),  time:52.053, tt:7860.027\n",
      "Ep:151, loss:0.00000, loss_test:0.09723, lr:5.36e-03, fs:0.82353 (r=0.707,p=0.986),  time:52.063, tt:7913.568\n",
      "Ep:152, loss:0.00000, loss_test:0.09606, lr:5.31e-03, fs:0.82353 (r=0.707,p=0.986),  time:52.058, tt:7964.828\n",
      "Ep:153, loss:0.00000, loss_test:0.09734, lr:5.26e-03, fs:0.82353 (r=0.707,p=0.986),  time:52.029, tt:8012.520\n",
      "Ep:154, loss:0.00000, loss_test:0.09687, lr:5.20e-03, fs:0.82353 (r=0.707,p=0.986),  time:52.002, tt:8060.380\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14755, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:48.318, tt:48.318\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14697, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:50.463, tt:100.925\n",
      "Ep:2, loss:0.00027, loss_test:0.14584, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:51.215, tt:153.644\n",
      "Ep:3, loss:0.00027, loss_test:0.14382, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:51.482, tt:205.929\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.14053, lr:1.00e-02, fs:0.61303 (r=0.808,p=0.494),  time:51.697, tt:258.487\n",
      "Ep:5, loss:0.00024, loss_test:0.13818, lr:1.00e-02, fs:0.60287 (r=0.636,p=0.573),  time:51.693, tt:310.159\n",
      "Ep:6, loss:0.00022, loss_test:0.14155, lr:1.00e-02, fs:0.60104 (r=0.586,p=0.617),  time:51.861, tt:363.030\n",
      "Ep:7, loss:0.00021, loss_test:0.13787, lr:1.00e-02, fs:0.59487 (r=0.586,p=0.604),  time:52.478, tt:419.825\n",
      "Ep:8, loss:0.00020, loss_test:0.13301, lr:1.00e-02, fs:0.59596 (r=0.596,p=0.596),  time:52.572, tt:473.152\n",
      "Ep:9, loss:0.00020, loss_test:0.13303, lr:1.00e-02, fs:0.59487 (r=0.586,p=0.604),  time:52.458, tt:524.575\n",
      "Ep:10, loss:0.00019, loss_test:0.13832, lr:1.00e-02, fs:0.54749 (r=0.495,p=0.613),  time:52.386, tt:576.246\n",
      "Ep:11, loss:0.00018, loss_test:0.13196, lr:1.00e-02, fs:0.59893 (r=0.566,p=0.636),  time:52.290, tt:627.479\n",
      "Ep:12, loss:0.00018, loss_test:0.12786, lr:1.00e-02, fs:0.59375 (r=0.576,p=0.613),  time:52.220, tt:678.855\n",
      "Ep:13, loss:0.00017, loss_test:0.13050, lr:1.00e-02, fs:0.54237 (r=0.485,p=0.615),  time:52.161, tt:730.248\n",
      "Ep:14, loss:0.00017, loss_test:0.12793, lr:1.00e-02, fs:0.58696 (r=0.545,p=0.635),  time:52.177, tt:782.648\n",
      "Ep:15, loss:0.00016, loss_test:0.12605, lr:9.90e-03, fs:0.58696 (r=0.545,p=0.635),  time:52.226, tt:835.616\n",
      "Ep:16, loss:0.00016, loss_test:0.12778, lr:9.80e-03, fs:0.57303 (r=0.515,p=0.646),  time:52.336, tt:889.705\n",
      "Ep:17, loss:0.00015, loss_test:0.12541, lr:9.70e-03, fs:0.59341 (r=0.545,p=0.651),  time:52.310, tt:941.585\n",
      "Ep:18, loss:0.00015, loss_test:0.12561, lr:9.61e-03, fs:0.58427 (r=0.525,p=0.658),  time:52.221, tt:992.200\n",
      "Ep:19, loss:0.00014, loss_test:0.12429, lr:9.51e-03, fs:0.60000 (r=0.545,p=0.667),  time:51.987, tt:1039.744\n",
      "Ep:20, loss:0.00014, loss_test:0.12339, lr:9.41e-03, fs:0.59551 (r=0.535,p=0.671),  time:52.059, tt:1093.239\n",
      "Ep:21, loss:0.00013, loss_test:0.12204, lr:9.32e-03, fs:0.61878 (r=0.566,p=0.683),  time:51.751, tt:1138.511\n",
      "Ep:22, loss:0.00013, loss_test:0.12232, lr:9.23e-03, fs:0.62147 (r=0.556,p=0.705),  time:51.723, tt:1189.630\n",
      "Ep:23, loss:0.00013, loss_test:0.12081, lr:9.14e-03, fs:0.64444 (r=0.586,p=0.716),  time:51.686, tt:1240.465\n",
      "Ep:24, loss:0.00012, loss_test:0.12276, lr:9.04e-03, fs:0.62500 (r=0.556,p=0.714),  time:51.763, tt:1294.080\n",
      "Ep:25, loss:0.00012, loss_test:0.12067, lr:8.95e-03, fs:0.63333 (r=0.576,p=0.704),  time:51.865, tt:1348.487\n",
      "Ep:26, loss:0.00011, loss_test:0.12169, lr:8.86e-03, fs:0.62857 (r=0.556,p=0.724),  time:51.872, tt:1400.556\n",
      "Ep:27, loss:0.00011, loss_test:0.12014, lr:8.78e-03, fs:0.62570 (r=0.566,p=0.700),  time:51.835, tt:1451.393\n",
      "Ep:28, loss:0.00011, loss_test:0.12144, lr:8.69e-03, fs:0.63584 (r=0.556,p=0.743),  time:51.874, tt:1504.348\n",
      "Ep:29, loss:0.00010, loss_test:0.12095, lr:8.60e-03, fs:0.63218 (r=0.556,p=0.733),  time:51.874, tt:1556.207\n",
      "Ep:30, loss:0.00010, loss_test:0.12005, lr:8.51e-03, fs:0.64804 (r=0.586,p=0.725),  time:51.875, tt:1608.117\n",
      "Ep:31, loss:0.00010, loss_test:0.12169, lr:8.43e-03, fs:0.65116 (r=0.566,p=0.767),  time:51.873, tt:1659.939\n",
      "Ep:32, loss:0.00009, loss_test:0.12020, lr:8.35e-03, fs:0.66667 (r=0.606,p=0.741),  time:51.864, tt:1711.502\n",
      "Ep:33, loss:0.00009, loss_test:0.12121, lr:8.26e-03, fs:0.65116 (r=0.566,p=0.767),  time:51.796, tt:1761.051\n",
      "Ep:34, loss:0.00009, loss_test:0.12505, lr:8.18e-03, fs:0.66667 (r=0.566,p=0.812),  time:51.825, tt:1813.862\n",
      "Ep:35, loss:0.00009, loss_test:0.11911, lr:8.10e-03, fs:0.66667 (r=0.606,p=0.741),  time:51.813, tt:1865.268\n",
      "Ep:36, loss:0.00008, loss_test:0.12169, lr:8.02e-03, fs:0.65497 (r=0.566,p=0.778),  time:51.939, tt:1921.728\n",
      "Ep:37, loss:0.00008, loss_test:0.11944, lr:7.94e-03, fs:0.67816 (r=0.596,p=0.787),  time:51.982, tt:1975.323\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00008, loss_test:0.11918, lr:7.94e-03, fs:0.67039 (r=0.606,p=0.750),  time:52.021, tt:2028.805\n",
      "Ep:39, loss:0.00008, loss_test:0.12120, lr:7.94e-03, fs:0.66667 (r=0.576,p=0.792),  time:52.131, tt:2085.242\n",
      "Ep:40, loss:0.00007, loss_test:0.11840, lr:7.94e-03, fs:0.69663 (r=0.626,p=0.785),  time:52.131, tt:2137.389\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00007, loss_test:0.12576, lr:7.94e-03, fs:0.67073 (r=0.556,p=0.846),  time:52.146, tt:2190.153\n",
      "Ep:42, loss:0.00007, loss_test:0.11746, lr:7.94e-03, fs:0.70000 (r=0.636,p=0.778),  time:52.103, tt:2240.433\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00007, loss_test:0.12104, lr:7.94e-03, fs:0.67857 (r=0.576,p=0.826),  time:52.098, tt:2292.321\n",
      "Ep:44, loss:0.00007, loss_test:0.12319, lr:7.94e-03, fs:0.69091 (r=0.576,p=0.864),  time:52.064, tt:2342.887\n",
      "Ep:45, loss:0.00007, loss_test:0.11752, lr:7.94e-03, fs:0.70718 (r=0.646,p=0.780),  time:52.065, tt:2394.973\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00006, loss_test:0.12031, lr:7.94e-03, fs:0.69822 (r=0.596,p=0.843),  time:52.062, tt:2446.898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:47, loss:0.00006, loss_test:0.12006, lr:7.94e-03, fs:0.69822 (r=0.596,p=0.843),  time:52.061, tt:2498.907\n",
      "Ep:48, loss:0.00006, loss_test:0.11845, lr:7.94e-03, fs:0.72626 (r=0.657,p=0.812),  time:52.117, tt:2553.754\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00006, loss_test:0.11958, lr:7.94e-03, fs:0.69822 (r=0.596,p=0.843),  time:52.126, tt:2606.314\n",
      "Ep:50, loss:0.00006, loss_test:0.12257, lr:7.94e-03, fs:0.70175 (r=0.606,p=0.833),  time:52.124, tt:2658.313\n",
      "Ep:51, loss:0.00005, loss_test:0.11715, lr:7.94e-03, fs:0.71676 (r=0.626,p=0.838),  time:52.122, tt:2710.330\n",
      "Ep:52, loss:0.00005, loss_test:0.12232, lr:7.94e-03, fs:0.70238 (r=0.596,p=0.855),  time:52.166, tt:2764.798\n",
      "Ep:53, loss:0.00005, loss_test:0.11873, lr:7.94e-03, fs:0.71006 (r=0.606,p=0.857),  time:52.198, tt:2818.701\n",
      "Ep:54, loss:0.00005, loss_test:0.11840, lr:7.94e-03, fs:0.70930 (r=0.616,p=0.836),  time:52.170, tt:2869.356\n",
      "Ep:55, loss:0.00005, loss_test:0.12192, lr:7.94e-03, fs:0.70659 (r=0.596,p=0.868),  time:52.147, tt:2920.225\n",
      "Ep:56, loss:0.00005, loss_test:0.11709, lr:7.94e-03, fs:0.72414 (r=0.636,p=0.840),  time:52.130, tt:2971.425\n",
      "Ep:57, loss:0.00005, loss_test:0.12044, lr:7.94e-03, fs:0.71429 (r=0.606,p=0.870),  time:52.132, tt:3023.672\n",
      "Ep:58, loss:0.00004, loss_test:0.11953, lr:7.94e-03, fs:0.71765 (r=0.616,p=0.859),  time:52.141, tt:3076.292\n",
      "Ep:59, loss:0.00004, loss_test:0.11743, lr:7.94e-03, fs:0.71345 (r=0.616,p=0.847),  time:52.138, tt:3128.259\n",
      "Ep:60, loss:0.00004, loss_test:0.12530, lr:7.86e-03, fs:0.71951 (r=0.596,p=0.908),  time:52.146, tt:3180.879\n",
      "Ep:61, loss:0.00004, loss_test:0.11602, lr:7.78e-03, fs:0.70857 (r=0.626,p=0.816),  time:52.131, tt:3232.151\n",
      "Ep:62, loss:0.00004, loss_test:0.12467, lr:7.70e-03, fs:0.71515 (r=0.596,p=0.894),  time:52.124, tt:3283.822\n",
      "Ep:63, loss:0.00004, loss_test:0.12302, lr:7.62e-03, fs:0.70659 (r=0.596,p=0.868),  time:52.101, tt:3334.452\n",
      "Ep:64, loss:0.00004, loss_test:0.11893, lr:7.55e-03, fs:0.72941 (r=0.626,p=0.873),  time:52.106, tt:3386.873\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00004, loss_test:0.12216, lr:7.55e-03, fs:0.73054 (r=0.616,p=0.897),  time:52.108, tt:3439.154\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00004, loss_test:0.11967, lr:7.55e-03, fs:0.71765 (r=0.616,p=0.859),  time:52.093, tt:3490.223\n",
      "Ep:67, loss:0.00004, loss_test:0.12031, lr:7.55e-03, fs:0.72619 (r=0.616,p=0.884),  time:52.106, tt:3543.218\n",
      "Ep:68, loss:0.00004, loss_test:0.11714, lr:7.55e-03, fs:0.72941 (r=0.626,p=0.873),  time:52.123, tt:3596.481\n",
      "Ep:69, loss:0.00003, loss_test:0.11991, lr:7.55e-03, fs:0.73054 (r=0.616,p=0.897),  time:52.148, tt:3650.380\n",
      "Ep:70, loss:0.00003, loss_test:0.11983, lr:7.55e-03, fs:0.72941 (r=0.626,p=0.873),  time:52.172, tt:3704.178\n",
      "Ep:71, loss:0.00003, loss_test:0.11851, lr:7.55e-03, fs:0.71765 (r=0.616,p=0.859),  time:52.167, tt:3755.989\n",
      "Ep:72, loss:0.00003, loss_test:0.12331, lr:7.55e-03, fs:0.72619 (r=0.616,p=0.884),  time:52.144, tt:3806.481\n",
      "Ep:73, loss:0.00003, loss_test:0.11817, lr:7.55e-03, fs:0.71765 (r=0.616,p=0.859),  time:52.155, tt:3859.500\n",
      "Ep:74, loss:0.00003, loss_test:0.12067, lr:7.55e-03, fs:0.73373 (r=0.626,p=0.886),  time:52.177, tt:3913.292\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00003, loss_test:0.11936, lr:7.55e-03, fs:0.71429 (r=0.606,p=0.870),  time:52.204, tt:3967.506\n",
      "Ep:76, loss:0.00003, loss_test:0.12059, lr:7.55e-03, fs:0.73373 (r=0.626,p=0.886),  time:52.174, tt:4017.403\n",
      "Ep:77, loss:0.00003, loss_test:0.12038, lr:7.55e-03, fs:0.71429 (r=0.606,p=0.870),  time:52.167, tt:4069.020\n",
      "Ep:78, loss:0.00003, loss_test:0.11988, lr:7.55e-03, fs:0.72941 (r=0.626,p=0.873),  time:52.175, tt:4121.828\n",
      "Ep:79, loss:0.00003, loss_test:0.12311, lr:7.55e-03, fs:0.70303 (r=0.586,p=0.879),  time:52.162, tt:4172.932\n",
      "Ep:80, loss:0.00003, loss_test:0.12272, lr:7.55e-03, fs:0.72289 (r=0.606,p=0.896),  time:52.118, tt:4221.564\n",
      "Ep:81, loss:0.00002, loss_test:0.11814, lr:7.55e-03, fs:0.72189 (r=0.616,p=0.871),  time:52.036, tt:4266.964\n",
      "Ep:82, loss:0.00002, loss_test:0.12579, lr:7.55e-03, fs:0.68750 (r=0.556,p=0.902),  time:51.958, tt:4312.480\n",
      "Ep:83, loss:0.00002, loss_test:0.12150, lr:7.55e-03, fs:0.71084 (r=0.596,p=0.881),  time:51.909, tt:4360.380\n",
      "Ep:84, loss:0.00002, loss_test:0.12103, lr:7.55e-03, fs:0.69512 (r=0.576,p=0.877),  time:51.893, tt:4410.871\n",
      "Ep:85, loss:0.00002, loss_test:0.12056, lr:7.55e-03, fs:0.71429 (r=0.606,p=0.870),  time:51.905, tt:4463.849\n",
      "Ep:86, loss:0.00002, loss_test:0.12547, lr:7.47e-03, fs:0.62745 (r=0.485,p=0.889),  time:51.897, tt:4515.015\n",
      "Ep:87, loss:0.00002, loss_test:0.11814, lr:7.40e-03, fs:0.72941 (r=0.626,p=0.873),  time:51.886, tt:4565.954\n",
      "Ep:88, loss:0.00002, loss_test:0.13109, lr:7.32e-03, fs:0.59459 (r=0.444,p=0.898),  time:51.882, tt:4617.486\n",
      "Ep:89, loss:0.00002, loss_test:0.11829, lr:7.25e-03, fs:0.72941 (r=0.626,p=0.873),  time:51.878, tt:4669.013\n",
      "Ep:90, loss:0.00002, loss_test:0.13165, lr:7.18e-03, fs:0.57931 (r=0.424,p=0.913),  time:51.877, tt:4720.836\n",
      "Ep:91, loss:0.00002, loss_test:0.12283, lr:7.11e-03, fs:0.71084 (r=0.596,p=0.881),  time:51.856, tt:4770.735\n",
      "Ep:92, loss:0.00002, loss_test:0.12368, lr:7.03e-03, fs:0.63636 (r=0.495,p=0.891),  time:51.859, tt:4822.902\n",
      "Ep:93, loss:0.00002, loss_test:0.13179, lr:6.96e-03, fs:0.58503 (r=0.434,p=0.896),  time:51.859, tt:4874.792\n",
      "Ep:94, loss:0.00002, loss_test:0.12464, lr:6.89e-03, fs:0.62338 (r=0.485,p=0.873),  time:51.847, tt:4925.452\n",
      "Ep:95, loss:0.00002, loss_test:0.13151, lr:6.83e-03, fs:0.57931 (r=0.424,p=0.913),  time:51.842, tt:4976.832\n",
      "Ep:96, loss:0.00002, loss_test:0.12501, lr:6.76e-03, fs:0.64516 (r=0.505,p=0.893),  time:51.824, tt:5026.932\n",
      "Ep:97, loss:0.00002, loss_test:0.12912, lr:6.69e-03, fs:0.59459 (r=0.444,p=0.898),  time:51.822, tt:5078.562\n",
      "Ep:98, loss:0.00002, loss_test:0.12261, lr:6.62e-03, fs:0.60000 (r=0.455,p=0.882),  time:51.811, tt:5129.255\n",
      "Ep:99, loss:0.00002, loss_test:0.12816, lr:6.56e-03, fs:0.62252 (r=0.475,p=0.904),  time:51.811, tt:5181.126\n",
      "Ep:100, loss:0.00002, loss_test:0.12800, lr:6.49e-03, fs:0.59310 (r=0.434,p=0.935),  time:51.802, tt:5232.014\n",
      "Ep:101, loss:0.00002, loss_test:0.12463, lr:6.43e-03, fs:0.65409 (r=0.525,p=0.867),  time:51.787, tt:5282.279\n",
      "Ep:102, loss:0.00002, loss_test:0.13115, lr:6.36e-03, fs:0.58333 (r=0.424,p=0.933),  time:51.825, tt:5337.946\n",
      "Ep:103, loss:0.00002, loss_test:0.12238, lr:6.30e-03, fs:0.65823 (r=0.525,p=0.881),  time:51.798, tt:5387.042\n",
      "Ep:104, loss:0.00002, loss_test:0.13141, lr:6.24e-03, fs:0.57931 (r=0.424,p=0.913),  time:51.802, tt:5439.242\n",
      "Ep:105, loss:0.00001, loss_test:0.12292, lr:6.17e-03, fs:0.61438 (r=0.475,p=0.870),  time:51.800, tt:5490.747\n",
      "Ep:106, loss:0.00001, loss_test:0.12966, lr:6.11e-03, fs:0.57931 (r=0.424,p=0.913),  time:51.803, tt:5542.954\n",
      "Ep:107, loss:0.00001, loss_test:0.12532, lr:6.05e-03, fs:0.60274 (r=0.444,p=0.936),  time:51.779, tt:5592.181\n",
      "Ep:108, loss:0.00001, loss_test:0.12698, lr:5.99e-03, fs:0.58904 (r=0.434,p=0.915),  time:51.772, tt:5643.099\n",
      "Ep:109, loss:0.00001, loss_test:0.12483, lr:5.93e-03, fs:0.58904 (r=0.434,p=0.915),  time:51.766, tt:5694.302\n",
      "Ep:110, loss:0.00001, loss_test:0.12791, lr:5.87e-03, fs:0.60403 (r=0.455,p=0.900),  time:51.749, tt:5744.186\n",
      "Ep:111, loss:0.00001, loss_test:0.12625, lr:5.81e-03, fs:0.58904 (r=0.434,p=0.915),  time:51.727, tt:5793.471\n",
      "Ep:112, loss:0.00001, loss_test:0.12860, lr:5.75e-03, fs:0.59864 (r=0.444,p=0.917),  time:51.731, tt:5845.591\n",
      "Ep:113, loss:0.00001, loss_test:0.12555, lr:5.70e-03, fs:0.59310 (r=0.434,p=0.935),  time:51.732, tt:5897.402\n",
      "Ep:114, loss:0.00001, loss_test:0.12920, lr:5.64e-03, fs:0.59864 (r=0.444,p=0.917),  time:51.726, tt:5948.484\n",
      "Ep:115, loss:0.00001, loss_test:0.12711, lr:5.58e-03, fs:0.60274 (r=0.444,p=0.936),  time:51.706, tt:5997.907\n",
      "Ep:116, loss:0.00001, loss_test:0.12888, lr:5.53e-03, fs:0.60274 (r=0.444,p=0.936),  time:51.714, tt:6050.513\n",
      "Ep:117, loss:0.00001, loss_test:0.12606, lr:5.47e-03, fs:0.60811 (r=0.455,p=0.918),  time:51.719, tt:6102.836\n",
      "Ep:118, loss:0.00001, loss_test:0.13040, lr:5.42e-03, fs:0.59310 (r=0.434,p=0.935),  time:51.715, tt:6154.120\n",
      "Ep:119, loss:0.00001, loss_test:0.12702, lr:5.36e-03, fs:0.60274 (r=0.444,p=0.936),  time:51.718, tt:6206.134\n",
      "Ep:120, loss:0.00001, loss_test:0.12996, lr:5.31e-03, fs:0.59310 (r=0.434,p=0.935),  time:51.715, tt:6257.573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:121, loss:0.00001, loss_test:0.12829, lr:5.26e-03, fs:0.60274 (r=0.444,p=0.936),  time:51.735, tt:6311.680\n",
      "Ep:122, loss:0.00001, loss_test:0.12799, lr:5.20e-03, fs:0.59310 (r=0.434,p=0.935),  time:51.729, tt:6362.718\n",
      "Ep:123, loss:0.00001, loss_test:0.12983, lr:5.15e-03, fs:0.59864 (r=0.444,p=0.917),  time:51.714, tt:6412.597\n",
      "Ep:124, loss:0.00001, loss_test:0.12827, lr:5.10e-03, fs:0.60274 (r=0.444,p=0.936),  time:51.707, tt:6463.369\n",
      "Ep:125, loss:0.00001, loss_test:0.12898, lr:5.05e-03, fs:0.59310 (r=0.434,p=0.935),  time:51.707, tt:6515.137\n",
      "Ep:126, loss:0.00001, loss_test:0.12950, lr:5.00e-03, fs:0.58333 (r=0.424,p=0.933),  time:51.702, tt:6566.097\n",
      "Ep:127, loss:0.00001, loss_test:0.12839, lr:4.95e-03, fs:0.61224 (r=0.455,p=0.938),  time:51.699, tt:6617.454\n",
      "Ep:128, loss:0.00001, loss_test:0.12908, lr:4.90e-03, fs:0.58333 (r=0.424,p=0.933),  time:51.684, tt:6667.237\n",
      "Ep:129, loss:0.00001, loss_test:0.12799, lr:4.85e-03, fs:0.62162 (r=0.465,p=0.939),  time:51.672, tt:6717.369\n",
      "Ep:130, loss:0.00001, loss_test:0.13221, lr:4.80e-03, fs:0.58741 (r=0.424,p=0.955),  time:51.679, tt:6769.957\n",
      "Ep:131, loss:0.00001, loss_test:0.12822, lr:4.75e-03, fs:0.60274 (r=0.444,p=0.936),  time:51.659, tt:6819.004\n",
      "Ep:132, loss:0.00001, loss_test:0.13159, lr:4.71e-03, fs:0.58333 (r=0.424,p=0.933),  time:51.667, tt:6871.725\n",
      "Ep:133, loss:0.00001, loss_test:0.13127, lr:4.66e-03, fs:0.58333 (r=0.424,p=0.933),  time:51.668, tt:6923.549\n",
      "Ep:134, loss:0.00001, loss_test:0.12771, lr:4.61e-03, fs:0.61224 (r=0.455,p=0.938),  time:51.667, tt:6975.008\n",
      "Ep:135, loss:0.00001, loss_test:0.13367, lr:4.57e-03, fs:0.58333 (r=0.424,p=0.933),  time:51.658, tt:7025.538\n",
      "Ep:136, loss:0.00001, loss_test:0.12695, lr:4.52e-03, fs:0.62162 (r=0.465,p=0.939),  time:51.651, tt:7076.158\n",
      "Ep:137, loss:0.00001, loss_test:0.13198, lr:4.48e-03, fs:0.58333 (r=0.424,p=0.933),  time:51.652, tt:7128.024\n",
      "Ep:138, loss:0.00001, loss_test:0.12801, lr:4.43e-03, fs:0.63087 (r=0.475,p=0.940),  time:51.671, tt:7182.275\n",
      "Ep:139, loss:0.00001, loss_test:0.13236, lr:4.39e-03, fs:0.58333 (r=0.424,p=0.933),  time:51.687, tt:7236.121\n",
      "Ep:140, loss:0.00001, loss_test:0.12956, lr:4.34e-03, fs:0.61224 (r=0.455,p=0.938),  time:51.695, tt:7288.965\n",
      "Ep:141, loss:0.00001, loss_test:0.13229, lr:4.30e-03, fs:0.58333 (r=0.424,p=0.933),  time:51.694, tt:7340.565\n",
      "Ep:142, loss:0.00001, loss_test:0.13036, lr:4.26e-03, fs:0.59310 (r=0.434,p=0.935),  time:51.678, tt:7389.931\n",
      "Ep:143, loss:0.00001, loss_test:0.13178, lr:4.21e-03, fs:0.58333 (r=0.424,p=0.933),  time:51.666, tt:7439.910\n",
      "Ep:144, loss:0.00001, loss_test:0.13270, lr:4.17e-03, fs:0.58333 (r=0.424,p=0.933),  time:51.664, tt:7491.290\n",
      "Ep:145, loss:0.00001, loss_test:0.13034, lr:4.13e-03, fs:0.58333 (r=0.424,p=0.933),  time:51.665, tt:7543.049\n",
      "Ep:146, loss:0.00001, loss_test:0.13153, lr:4.09e-03, fs:0.58333 (r=0.424,p=0.933),  time:51.654, tt:7593.124\n",
      "Ep:147, loss:0.00001, loss_test:0.12930, lr:4.05e-03, fs:0.60274 (r=0.444,p=0.936),  time:51.654, tt:7644.845\n",
      "Ep:148, loss:0.00001, loss_test:0.13137, lr:4.01e-03, fs:0.58333 (r=0.424,p=0.933),  time:51.656, tt:7696.758\n",
      "Ep:149, loss:0.00001, loss_test:0.13001, lr:3.97e-03, fs:0.61224 (r=0.455,p=0.938),  time:51.651, tt:7747.677\n",
      "Ep:150, loss:0.00001, loss_test:0.13305, lr:3.93e-03, fs:0.58333 (r=0.424,p=0.933),  time:51.657, tt:7800.234\n",
      "Ep:151, loss:0.00001, loss_test:0.13362, lr:3.89e-03, fs:0.58333 (r=0.424,p=0.933),  time:51.661, tt:7852.403\n",
      "Ep:152, loss:0.00001, loss_test:0.13078, lr:3.85e-03, fs:0.56338 (r=0.404,p=0.930),  time:51.670, tt:7905.562\n",
      "Ep:153, loss:0.00001, loss_test:0.13183, lr:3.81e-03, fs:0.58333 (r=0.424,p=0.933),  time:51.682, tt:7959.097\n",
      "Ep:154, loss:0.00001, loss_test:0.12997, lr:3.77e-03, fs:0.60274 (r=0.444,p=0.936),  time:51.631, tt:8002.868\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00029, loss_test:0.14539, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:18.739, tt:18.739\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14468, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.488, tt:38.975\n",
      "Ep:2, loss:0.00028, loss_test:0.14348, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.121, tt:60.362\n",
      "Ep:3, loss:0.00028, loss_test:0.14166, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.440, tt:85.762\n",
      "Ep:4, loss:0.00028, loss_test:0.13899, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.329, tt:106.647\n",
      "Ep:5, loss:0.00027, loss_test:0.13477, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:21.116, tt:126.694\n",
      "Ep:6, loss:0.00026, loss_test:0.12763, lr:1.00e-02, fs:0.65714 (r=0.929,p=0.508),  time:20.937, tt:146.558\n",
      "Ep:7, loss:0.00025, loss_test:0.11746, lr:1.00e-02, fs:0.66079 (r=0.758,p=0.586),  time:21.110, tt:168.877\n",
      "Ep:8, loss:0.00023, loss_test:0.11313, lr:1.00e-02, fs:0.64921 (r=0.626,p=0.674),  time:20.954, tt:188.589\n",
      "Ep:9, loss:0.00023, loss_test:0.11135, lr:1.00e-02, fs:0.65969 (r=0.636,p=0.685),  time:20.881, tt:208.813\n",
      "Ep:10, loss:0.00022, loss_test:0.11141, lr:1.00e-02, fs:0.67299 (r=0.717,p=0.634),  time:21.040, tt:231.438\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.10745, lr:1.00e-02, fs:0.69268 (r=0.717,p=0.670),  time:21.002, tt:252.026\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.10428, lr:1.00e-02, fs:0.67391 (r=0.626,p=0.729),  time:21.015, tt:273.194\n",
      "Ep:13, loss:0.00019, loss_test:0.10255, lr:1.00e-02, fs:0.72821 (r=0.717,p=0.740),  time:20.986, tt:293.802\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.10099, lr:1.00e-02, fs:0.74000 (r=0.747,p=0.733),  time:21.032, tt:315.475\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.09958, lr:1.00e-02, fs:0.74490 (r=0.737,p=0.753),  time:21.060, tt:336.957\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.09880, lr:1.00e-02, fs:0.73913 (r=0.687,p=0.800),  time:21.085, tt:358.440\n",
      "Ep:17, loss:0.00016, loss_test:0.09623, lr:1.00e-02, fs:0.77083 (r=0.747,p=0.796),  time:21.170, tt:381.055\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.09469, lr:1.00e-02, fs:0.77005 (r=0.727,p=0.818),  time:21.137, tt:401.603\n",
      "Ep:19, loss:0.00015, loss_test:0.09294, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:21.156, tt:423.114\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.09114, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:21.177, tt:444.718\n",
      "Ep:21, loss:0.00014, loss_test:0.09067, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:21.138, tt:465.038\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00013, loss_test:0.08956, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:21.113, tt:485.594\n",
      "Ep:23, loss:0.00012, loss_test:0.08927, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:21.055, tt:505.329\n",
      "Ep:24, loss:0.00012, loss_test:0.08736, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:21.097, tt:527.433\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00011, loss_test:0.08802, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:21.105, tt:548.739\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00011, loss_test:0.08725, lr:1.00e-02, fs:0.81967 (r=0.758,p=0.893),  time:21.073, tt:568.963\n",
      "Ep:27, loss:0.00010, loss_test:0.08724, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:21.026, tt:588.733\n",
      "Ep:28, loss:0.00010, loss_test:0.08486, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:20.971, tt:608.165\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00010, loss_test:0.08763, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:20.978, tt:629.348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:30, loss:0.00009, loss_test:0.08158, lr:1.00e-02, fs:0.88776 (r=0.879,p=0.897),  time:20.968, tt:650.007\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00009, loss_test:0.08550, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:20.969, tt:671.008\n",
      "Ep:32, loss:0.00008, loss_test:0.08018, lr:1.00e-02, fs:0.90625 (r=0.879,p=0.935),  time:20.994, tt:692.806\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00008, loss_test:0.08057, lr:1.00e-02, fs:0.90155 (r=0.879,p=0.926),  time:21.019, tt:714.631\n",
      "Ep:34, loss:0.00008, loss_test:0.08429, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:21.003, tt:735.100\n",
      "Ep:35, loss:0.00007, loss_test:0.07807, lr:1.00e-02, fs:0.90722 (r=0.889,p=0.926),  time:21.003, tt:756.121\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00007, loss_test:0.08392, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:20.990, tt:776.627\n",
      "Ep:37, loss:0.00007, loss_test:0.07781, lr:1.00e-02, fs:0.90722 (r=0.889,p=0.926),  time:20.997, tt:797.882\n",
      "Ep:38, loss:0.00006, loss_test:0.08302, lr:1.00e-02, fs:0.89005 (r=0.859,p=0.924),  time:20.962, tt:817.510\n",
      "Ep:39, loss:0.00006, loss_test:0.07845, lr:1.00e-02, fs:0.90722 (r=0.889,p=0.926),  time:20.985, tt:839.408\n",
      "Ep:40, loss:0.00006, loss_test:0.08154, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:20.980, tt:860.197\n",
      "Ep:41, loss:0.00005, loss_test:0.08095, lr:1.00e-02, fs:0.89474 (r=0.859,p=0.934),  time:20.988, tt:881.488\n",
      "Ep:42, loss:0.00005, loss_test:0.07900, lr:1.00e-02, fs:0.89474 (r=0.859,p=0.934),  time:20.999, tt:902.972\n",
      "Ep:43, loss:0.00005, loss_test:0.08312, lr:1.00e-02, fs:0.90052 (r=0.869,p=0.935),  time:21.031, tt:925.368\n",
      "Ep:44, loss:0.00005, loss_test:0.08095, lr:1.00e-02, fs:0.89474 (r=0.859,p=0.934),  time:21.051, tt:947.315\n",
      "Ep:45, loss:0.00004, loss_test:0.08124, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:21.127, tt:971.827\n",
      "Ep:46, loss:0.00004, loss_test:0.07998, lr:1.00e-02, fs:0.91192 (r=0.889,p=0.936),  time:21.209, tt:996.803\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00004, loss_test:0.08439, lr:1.00e-02, fs:0.85714 (r=0.788,p=0.940),  time:21.221, tt:1018.591\n",
      "Ep:48, loss:0.00004, loss_test:0.08071, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:21.238, tt:1040.654\n",
      "Ep:49, loss:0.00004, loss_test:0.08400, lr:1.00e-02, fs:0.89474 (r=0.859,p=0.934),  time:21.302, tt:1065.097\n",
      "Ep:50, loss:0.00004, loss_test:0.08149, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:21.310, tt:1086.821\n",
      "Ep:51, loss:0.00004, loss_test:0.08387, lr:1.00e-02, fs:0.87432 (r=0.808,p=0.952),  time:21.356, tt:1110.488\n",
      "Ep:52, loss:0.00003, loss_test:0.08126, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:21.368, tt:1132.516\n",
      "Ep:53, loss:0.00003, loss_test:0.08262, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:21.384, tt:1154.735\n",
      "Ep:54, loss:0.00003, loss_test:0.08160, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:21.399, tt:1176.939\n",
      "Ep:55, loss:0.00003, loss_test:0.08243, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:21.386, tt:1197.595\n",
      "Ep:56, loss:0.00003, loss_test:0.08277, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:21.408, tt:1220.260\n",
      "Ep:57, loss:0.00003, loss_test:0.08001, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:21.447, tt:1243.919\n",
      "Ep:58, loss:0.00003, loss_test:0.08210, lr:9.90e-03, fs:0.81356 (r=0.727,p=0.923),  time:21.424, tt:1264.001\n",
      "Ep:59, loss:0.00002, loss_test:0.08235, lr:9.80e-03, fs:0.82222 (r=0.747,p=0.914),  time:21.419, tt:1285.165\n",
      "Ep:60, loss:0.00002, loss_test:0.08195, lr:9.70e-03, fs:0.78857 (r=0.697,p=0.908),  time:21.445, tt:1308.132\n",
      "Ep:61, loss:0.00002, loss_test:0.07984, lr:9.61e-03, fs:0.87097 (r=0.818,p=0.931),  time:21.520, tt:1334.224\n",
      "Ep:62, loss:0.00002, loss_test:0.08583, lr:9.51e-03, fs:0.80925 (r=0.707,p=0.946),  time:21.531, tt:1356.470\n",
      "Ep:63, loss:0.00002, loss_test:0.08271, lr:9.41e-03, fs:0.79310 (r=0.697,p=0.920),  time:21.530, tt:1377.920\n",
      "Ep:64, loss:0.00002, loss_test:0.08343, lr:9.32e-03, fs:0.80460 (r=0.707,p=0.933),  time:21.527, tt:1399.234\n",
      "Ep:65, loss:0.00002, loss_test:0.08354, lr:9.23e-03, fs:0.79070 (r=0.687,p=0.932),  time:21.529, tt:1420.885\n",
      "Ep:66, loss:0.00002, loss_test:0.08700, lr:9.14e-03, fs:0.79532 (r=0.687,p=0.944),  time:21.531, tt:1442.590\n",
      "Ep:67, loss:0.00002, loss_test:0.08630, lr:9.04e-03, fs:0.79532 (r=0.687,p=0.944),  time:21.556, tt:1465.785\n",
      "Ep:68, loss:0.00002, loss_test:0.08422, lr:8.95e-03, fs:0.82486 (r=0.737,p=0.936),  time:21.556, tt:1487.349\n",
      "Ep:69, loss:0.00002, loss_test:0.08709, lr:8.86e-03, fs:0.79532 (r=0.687,p=0.944),  time:21.555, tt:1508.829\n",
      "Ep:70, loss:0.00002, loss_test:0.08271, lr:8.78e-03, fs:0.82682 (r=0.747,p=0.925),  time:21.552, tt:1530.186\n",
      "Ep:71, loss:0.00002, loss_test:0.08523, lr:8.69e-03, fs:0.80233 (r=0.697,p=0.945),  time:21.545, tt:1551.268\n",
      "Ep:72, loss:0.00002, loss_test:0.08609, lr:8.60e-03, fs:0.81395 (r=0.707,p=0.959),  time:21.535, tt:1572.031\n",
      "Ep:73, loss:0.00002, loss_test:0.08678, lr:8.51e-03, fs:0.80233 (r=0.697,p=0.945),  time:21.521, tt:1592.544\n",
      "Ep:74, loss:0.00002, loss_test:0.08719, lr:8.43e-03, fs:0.79532 (r=0.687,p=0.944),  time:21.505, tt:1612.861\n",
      "Ep:75, loss:0.00001, loss_test:0.08207, lr:8.35e-03, fs:0.83799 (r=0.758,p=0.938),  time:21.519, tt:1635.431\n",
      "Ep:76, loss:0.00001, loss_test:0.08702, lr:8.26e-03, fs:0.83429 (r=0.737,p=0.961),  time:21.536, tt:1658.294\n",
      "Ep:77, loss:0.00001, loss_test:0.08349, lr:8.18e-03, fs:0.80925 (r=0.707,p=0.946),  time:21.525, tt:1678.972\n",
      "Ep:78, loss:0.00001, loss_test:0.08574, lr:8.10e-03, fs:0.80233 (r=0.697,p=0.945),  time:21.530, tt:1700.833\n",
      "Ep:79, loss:0.00001, loss_test:0.08584, lr:8.02e-03, fs:0.80233 (r=0.697,p=0.945),  time:21.512, tt:1720.999\n",
      "Ep:80, loss:0.00001, loss_test:0.08304, lr:7.94e-03, fs:0.83616 (r=0.747,p=0.949),  time:21.489, tt:1740.587\n",
      "Ep:81, loss:0.00001, loss_test:0.08612, lr:7.86e-03, fs:0.80702 (r=0.697,p=0.958),  time:21.480, tt:1761.362\n",
      "Ep:82, loss:0.00001, loss_test:0.08560, lr:7.78e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.494, tt:1784.010\n",
      "Ep:83, loss:0.00001, loss_test:0.08358, lr:7.70e-03, fs:0.80925 (r=0.707,p=0.946),  time:21.477, tt:1804.073\n",
      "Ep:84, loss:0.00001, loss_test:0.08566, lr:7.62e-03, fs:0.82081 (r=0.717,p=0.959),  time:21.496, tt:1827.188\n",
      "Ep:85, loss:0.00001, loss_test:0.08516, lr:7.55e-03, fs:0.80702 (r=0.697,p=0.958),  time:21.487, tt:1847.847\n",
      "Ep:86, loss:0.00001, loss_test:0.08723, lr:7.47e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.494, tt:1870.019\n",
      "Ep:87, loss:0.00001, loss_test:0.08634, lr:7.40e-03, fs:0.80702 (r=0.697,p=0.958),  time:21.477, tt:1889.936\n",
      "Ep:88, loss:0.00001, loss_test:0.08123, lr:7.32e-03, fs:0.80460 (r=0.707,p=0.933),  time:21.467, tt:1910.575\n",
      "Ep:89, loss:0.00001, loss_test:0.08847, lr:7.25e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.456, tt:1931.024\n",
      "Ep:90, loss:0.00001, loss_test:0.08587, lr:7.18e-03, fs:0.80702 (r=0.697,p=0.958),  time:21.450, tt:1951.991\n",
      "Ep:91, loss:0.00001, loss_test:0.08303, lr:7.11e-03, fs:0.80233 (r=0.697,p=0.945),  time:21.435, tt:1972.057\n",
      "Ep:92, loss:0.00001, loss_test:0.08641, lr:7.03e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.417, tt:1991.760\n",
      "Ep:93, loss:0.00001, loss_test:0.08586, lr:6.96e-03, fs:0.80233 (r=0.697,p=0.945),  time:21.397, tt:2011.316\n",
      "Ep:94, loss:0.00001, loss_test:0.08540, lr:6.89e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.390, tt:2032.008\n",
      "Ep:95, loss:0.00001, loss_test:0.08454, lr:6.83e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.378, tt:2052.259\n",
      "Ep:96, loss:0.00001, loss_test:0.08741, lr:6.76e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.378, tt:2073.656\n",
      "Ep:97, loss:0.00001, loss_test:0.08690, lr:6.69e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.373, tt:2094.508\n",
      "Ep:98, loss:0.00001, loss_test:0.08538, lr:6.62e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.359, tt:2114.548\n",
      "Ep:99, loss:0.00001, loss_test:0.08668, lr:6.56e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.371, tt:2137.059\n",
      "Ep:100, loss:0.00001, loss_test:0.08534, lr:6.49e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.373, tt:2158.635\n",
      "Ep:101, loss:0.00001, loss_test:0.08728, lr:6.43e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.401, tt:2182.876\n",
      "Ep:102, loss:0.00001, loss_test:0.08702, lr:6.36e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.402, tt:2204.429\n",
      "Ep:103, loss:0.00001, loss_test:0.08747, lr:6.30e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.421, tt:2227.828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:104, loss:0.00001, loss_test:0.08757, lr:6.24e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.416, tt:2248.710\n",
      "Ep:105, loss:0.00001, loss_test:0.08425, lr:6.17e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.421, tt:2270.616\n",
      "Ep:106, loss:0.00001, loss_test:0.08788, lr:6.11e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.406, tt:2290.390\n",
      "Ep:107, loss:0.00001, loss_test:0.08709, lr:6.05e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.396, tt:2310.774\n",
      "Ep:108, loss:0.00001, loss_test:0.08530, lr:5.99e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.381, tt:2330.538\n",
      "Ep:109, loss:0.00001, loss_test:0.08777, lr:5.93e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.400, tt:2354.033\n",
      "Ep:110, loss:0.00001, loss_test:0.08566, lr:5.87e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.394, tt:2374.745\n",
      "Ep:111, loss:0.00001, loss_test:0.08783, lr:5.81e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.409, tt:2397.818\n",
      "Ep:112, loss:0.00001, loss_test:0.08630, lr:5.75e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.402, tt:2418.442\n",
      "Ep:113, loss:0.00001, loss_test:0.08657, lr:5.70e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.398, tt:2439.358\n",
      "Ep:114, loss:0.00001, loss_test:0.08658, lr:5.64e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.374, tt:2457.982\n",
      "Ep:115, loss:0.00001, loss_test:0.08700, lr:5.58e-03, fs:0.78313 (r=0.657,p=0.970),  time:21.378, tt:2479.812\n",
      "Ep:116, loss:0.00001, loss_test:0.08577, lr:5.53e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.371, tt:2500.376\n",
      "Ep:117, loss:0.00001, loss_test:0.08691, lr:5.47e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.372, tt:2521.851\n",
      "Ep:118, loss:0.00001, loss_test:0.08728, lr:5.42e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.364, tt:2542.325\n",
      "Ep:119, loss:0.00001, loss_test:0.08670, lr:5.36e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.358, tt:2562.993\n",
      "Ep:120, loss:0.00001, loss_test:0.08835, lr:5.31e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.344, tt:2582.642\n",
      "Ep:121, loss:0.00000, loss_test:0.08706, lr:5.26e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.329, tt:2602.165\n",
      "Ep:122, loss:0.00000, loss_test:0.08668, lr:5.20e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.329, tt:2623.512\n",
      "Ep:123, loss:0.00000, loss_test:0.08536, lr:5.15e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.343, tt:2646.547\n",
      "Ep:124, loss:0.00000, loss_test:0.08775, lr:5.10e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.345, tt:2668.094\n",
      "Ep:125, loss:0.00000, loss_test:0.08845, lr:5.05e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.342, tt:2689.036\n",
      "Ep:126, loss:0.00000, loss_test:0.08603, lr:5.00e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.326, tt:2708.436\n",
      "Ep:127, loss:0.00000, loss_test:0.08787, lr:4.95e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.316, tt:2728.430\n",
      "Ep:128, loss:0.00000, loss_test:0.08812, lr:4.90e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.320, tt:2750.258\n",
      "Ep:129, loss:0.00000, loss_test:0.08667, lr:4.85e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.323, tt:2771.998\n",
      "Ep:130, loss:0.00000, loss_test:0.08691, lr:4.80e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.320, tt:2792.913\n",
      "Ep:131, loss:0.00000, loss_test:0.08780, lr:4.75e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.317, tt:2813.843\n",
      "Ep:132, loss:0.00000, loss_test:0.08737, lr:4.71e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.311, tt:2834.424\n",
      "Ep:133, loss:0.00000, loss_test:0.08754, lr:4.66e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.301, tt:2854.268\n",
      "Ep:134, loss:0.00000, loss_test:0.08723, lr:4.61e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.300, tt:2875.441\n",
      "Ep:135, loss:0.00000, loss_test:0.08633, lr:4.57e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.291, tt:2895.577\n",
      "Ep:136, loss:0.00000, loss_test:0.08906, lr:4.52e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.299, tt:2917.973\n",
      "Ep:137, loss:0.00000, loss_test:0.08801, lr:4.48e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.292, tt:2938.313\n",
      "Ep:138, loss:0.00000, loss_test:0.08644, lr:4.43e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.273, tt:2956.923\n",
      "Ep:139, loss:0.00000, loss_test:0.08763, lr:4.39e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.274, tt:2978.411\n",
      "Ep:140, loss:0.00000, loss_test:0.08926, lr:4.34e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.268, tt:2998.775\n",
      "Ep:141, loss:0.00000, loss_test:0.08733, lr:4.30e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.285, tt:3022.482\n",
      "Ep:142, loss:0.00000, loss_test:0.08774, lr:4.26e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.308, tt:3046.995\n",
      "Ep:143, loss:0.00000, loss_test:0.08915, lr:4.21e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.304, tt:3067.811\n",
      "Ep:144, loss:0.00000, loss_test:0.08773, lr:4.17e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.302, tt:3088.823\n",
      "Ep:145, loss:0.00000, loss_test:0.08722, lr:4.13e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.313, tt:3111.709\n",
      "Ep:146, loss:0.00000, loss_test:0.08800, lr:4.09e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.321, tt:3134.204\n",
      "Ep:147, loss:0.00000, loss_test:0.08807, lr:4.05e-03, fs:0.80473 (r=0.687,p=0.971),  time:21.323, tt:3155.859\n",
      "Ep:148, loss:0.00000, loss_test:0.08811, lr:4.01e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.326, tt:3177.580\n",
      "Ep:149, loss:0.00000, loss_test:0.08793, lr:3.97e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.339, tt:3200.819\n",
      "Ep:150, loss:0.00000, loss_test:0.08873, lr:3.93e-03, fs:0.76829 (r=0.636,p=0.969),  time:21.347, tt:3223.464\n",
      "Ep:151, loss:0.00000, loss_test:0.08795, lr:3.89e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.348, tt:3244.940\n",
      "Ep:152, loss:0.00000, loss_test:0.08958, lr:3.85e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.344, tt:3265.618\n",
      "Ep:153, loss:0.00000, loss_test:0.08925, lr:3.81e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.313, tt:3282.233\n",
      "Ep:154, loss:0.00000, loss_test:0.08750, lr:3.77e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.318, tt:3304.343\n",
      "Ep:155, loss:0.00000, loss_test:0.08926, lr:3.73e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.318, tt:3325.588\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14662, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.476, tt:20.476\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14584, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.808, tt:43.616\n",
      "Ep:2, loss:0.00028, loss_test:0.14448, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.290, tt:63.870\n",
      "Ep:3, loss:0.00028, loss_test:0.14226, lr:1.00e-02, fs:0.64605 (r=0.949,p=0.490),  time:21.402, tt:85.608\n",
      "Ep:4, loss:0.00027, loss_test:0.13854, lr:1.00e-02, fs:0.65233 (r=0.919,p=0.506),  time:21.305, tt:106.527\n",
      "Ep:5, loss:0.00026, loss_test:0.13480, lr:1.00e-02, fs:0.63359 (r=0.838,p=0.509),  time:21.397, tt:128.382\n",
      "Ep:6, loss:0.00024, loss_test:0.13260, lr:1.00e-02, fs:0.65517 (r=0.768,p=0.571),  time:21.686, tt:151.799\n",
      "Ep:7, loss:0.00023, loss_test:0.13235, lr:1.00e-02, fs:0.60963 (r=0.576,p=0.648),  time:21.539, tt:172.311\n",
      "Ep:8, loss:0.00022, loss_test:0.13255, lr:1.00e-02, fs:0.61957 (r=0.576,p=0.671),  time:21.448, tt:193.031\n",
      "Ep:9, loss:0.00021, loss_test:0.12797, lr:1.00e-02, fs:0.62802 (r=0.657,p=0.602),  time:21.339, tt:213.390\n",
      "Ep:10, loss:0.00021, loss_test:0.12604, lr:1.00e-02, fs:0.63415 (r=0.657,p=0.613),  time:21.388, tt:235.273\n",
      "Ep:11, loss:0.00020, loss_test:0.12809, lr:1.00e-02, fs:0.59783 (r=0.556,p=0.647),  time:21.439, tt:257.268\n",
      "Ep:12, loss:0.00019, loss_test:0.12296, lr:9.90e-03, fs:0.64211 (r=0.616,p=0.670),  time:21.425, tt:278.528\n",
      "Ep:13, loss:0.00018, loss_test:0.11810, lr:9.80e-03, fs:0.61458 (r=0.596,p=0.634),  time:21.430, tt:300.019\n",
      "Ep:14, loss:0.00018, loss_test:0.11708, lr:9.70e-03, fs:0.60870 (r=0.566,p=0.659),  time:21.453, tt:321.799\n",
      "Ep:15, loss:0.00017, loss_test:0.11423, lr:9.61e-03, fs:0.61622 (r=0.576,p=0.663),  time:21.394, tt:342.305\n",
      "Ep:16, loss:0.00016, loss_test:0.11111, lr:9.51e-03, fs:0.63102 (r=0.596,p=0.670),  time:21.403, tt:363.851\n",
      "Ep:17, loss:0.00016, loss_test:0.10962, lr:9.41e-03, fs:0.63636 (r=0.566,p=0.727),  time:21.450, tt:386.095\n",
      "Ep:18, loss:0.00015, loss_test:0.10617, lr:9.32e-03, fs:0.67033 (r=0.616,p=0.735),  time:21.391, tt:406.426\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:19, loss:0.00014, loss_test:0.10459, lr:9.32e-03, fs:0.70526 (r=0.677,p=0.736),  time:21.307, tt:426.131\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.10374, lr:9.32e-03, fs:0.69613 (r=0.636,p=0.768),  time:21.332, tt:447.969\n",
      "Ep:21, loss:0.00013, loss_test:0.10008, lr:9.32e-03, fs:0.74112 (r=0.737,p=0.745),  time:21.300, tt:468.590\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00013, loss_test:0.10017, lr:9.32e-03, fs:0.72043 (r=0.677,p=0.770),  time:21.283, tt:489.506\n",
      "Ep:23, loss:0.00012, loss_test:0.09748, lr:9.32e-03, fs:0.75758 (r=0.758,p=0.758),  time:21.232, tt:509.571\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00012, loss_test:0.09647, lr:9.32e-03, fs:0.74346 (r=0.717,p=0.772),  time:21.213, tt:530.319\n",
      "Ep:25, loss:0.00011, loss_test:0.09601, lr:9.32e-03, fs:0.75676 (r=0.707,p=0.814),  time:21.192, tt:550.990\n",
      "Ep:26, loss:0.00011, loss_test:0.09489, lr:9.32e-03, fs:0.74490 (r=0.737,p=0.753),  time:21.158, tt:571.261\n",
      "Ep:27, loss:0.00011, loss_test:0.09394, lr:9.32e-03, fs:0.75258 (r=0.737,p=0.768),  time:21.195, tt:593.472\n",
      "Ep:28, loss:0.00010, loss_test:0.09240, lr:9.32e-03, fs:0.78788 (r=0.788,p=0.788),  time:21.149, tt:613.323\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00010, loss_test:0.09235, lr:9.32e-03, fs:0.79602 (r=0.808,p=0.784),  time:21.140, tt:634.190\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00009, loss_test:0.09016, lr:9.32e-03, fs:0.81159 (r=0.848,p=0.778),  time:21.152, tt:655.718\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00009, loss_test:0.09049, lr:9.32e-03, fs:0.79803 (r=0.818,p=0.779),  time:21.135, tt:676.311\n",
      "Ep:32, loss:0.00009, loss_test:0.08888, lr:9.32e-03, fs:0.81731 (r=0.859,p=0.780),  time:21.104, tt:696.448\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00008, loss_test:0.08972, lr:9.32e-03, fs:0.77419 (r=0.727,p=0.828),  time:21.080, tt:716.714\n",
      "Ep:34, loss:0.00008, loss_test:0.08819, lr:9.32e-03, fs:0.83568 (r=0.899,p=0.781),  time:21.098, tt:738.445\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00008, loss_test:0.09055, lr:9.32e-03, fs:0.77596 (r=0.717,p=0.845),  time:21.108, tt:759.871\n",
      "Ep:36, loss:0.00008, loss_test:0.08644, lr:9.32e-03, fs:0.83568 (r=0.899,p=0.781),  time:21.061, tt:779.268\n",
      "Ep:37, loss:0.00007, loss_test:0.08996, lr:9.32e-03, fs:0.76923 (r=0.707,p=0.843),  time:21.034, tt:799.291\n",
      "Ep:38, loss:0.00007, loss_test:0.08595, lr:9.32e-03, fs:0.83810 (r=0.889,p=0.793),  time:20.997, tt:818.894\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00007, loss_test:0.08839, lr:9.32e-03, fs:0.80208 (r=0.778,p=0.828),  time:20.975, tt:839.009\n",
      "Ep:40, loss:0.00006, loss_test:0.08564, lr:9.32e-03, fs:0.84848 (r=0.848,p=0.848),  time:20.958, tt:859.273\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00006, loss_test:0.08752, lr:9.32e-03, fs:0.80628 (r=0.778,p=0.837),  time:20.939, tt:879.421\n",
      "Ep:42, loss:0.00006, loss_test:0.08500, lr:9.32e-03, fs:0.83938 (r=0.818,p=0.862),  time:20.948, tt:900.764\n",
      "Ep:43, loss:0.00006, loss_test:0.08651, lr:9.32e-03, fs:0.79365 (r=0.758,p=0.833),  time:20.954, tt:921.973\n",
      "Ep:44, loss:0.00005, loss_test:0.08598, lr:9.32e-03, fs:0.78689 (r=0.727,p=0.857),  time:20.957, tt:943.048\n",
      "Ep:45, loss:0.00005, loss_test:0.08486, lr:9.32e-03, fs:0.82412 (r=0.828,p=0.820),  time:20.957, tt:964.008\n",
      "Ep:46, loss:0.00005, loss_test:0.08629, lr:9.32e-03, fs:0.74860 (r=0.677,p=0.838),  time:20.969, tt:985.527\n",
      "Ep:47, loss:0.00005, loss_test:0.08469, lr:9.32e-03, fs:0.82828 (r=0.828,p=0.828),  time:20.946, tt:1005.404\n",
      "Ep:48, loss:0.00005, loss_test:0.08481, lr:9.32e-03, fs:0.77348 (r=0.707,p=0.854),  time:20.942, tt:1026.143\n",
      "Ep:49, loss:0.00005, loss_test:0.08559, lr:9.32e-03, fs:0.77348 (r=0.707,p=0.854),  time:20.912, tt:1045.624\n",
      "Ep:50, loss:0.00004, loss_test:0.08547, lr:9.32e-03, fs:0.77419 (r=0.727,p=0.828),  time:20.918, tt:1066.815\n",
      "Ep:51, loss:0.00004, loss_test:0.08921, lr:9.32e-03, fs:0.74419 (r=0.646,p=0.877),  time:20.917, tt:1087.666\n",
      "Ep:52, loss:0.00004, loss_test:0.08481, lr:9.23e-03, fs:0.79793 (r=0.778,p=0.819),  time:20.899, tt:1107.625\n",
      "Ep:53, loss:0.00004, loss_test:0.08629, lr:9.14e-03, fs:0.73563 (r=0.646,p=0.853),  time:20.941, tt:1130.836\n",
      "Ep:54, loss:0.00004, loss_test:0.08454, lr:9.04e-03, fs:0.75824 (r=0.697,p=0.831),  time:20.938, tt:1151.594\n",
      "Ep:55, loss:0.00004, loss_test:0.08368, lr:8.95e-03, fs:0.81283 (r=0.768,p=0.864),  time:20.970, tt:1174.298\n",
      "Ep:56, loss:0.00004, loss_test:0.08745, lr:8.86e-03, fs:0.74576 (r=0.667,p=0.846),  time:20.965, tt:1195.001\n",
      "Ep:57, loss:0.00003, loss_test:0.08351, lr:8.78e-03, fs:0.76503 (r=0.707,p=0.833),  time:20.942, tt:1214.629\n",
      "Ep:58, loss:0.00003, loss_test:0.08813, lr:8.69e-03, fs:0.72832 (r=0.636,p=0.851),  time:20.953, tt:1236.231\n",
      "Ep:59, loss:0.00003, loss_test:0.08456, lr:8.60e-03, fs:0.76923 (r=0.707,p=0.843),  time:20.953, tt:1257.186\n",
      "Ep:60, loss:0.00003, loss_test:0.08990, lr:8.51e-03, fs:0.73563 (r=0.646,p=0.853),  time:20.974, tt:1279.417\n",
      "Ep:61, loss:0.00003, loss_test:0.08327, lr:8.43e-03, fs:0.76923 (r=0.707,p=0.843),  time:20.972, tt:1300.283\n",
      "Ep:62, loss:0.00003, loss_test:0.09332, lr:8.35e-03, fs:0.76136 (r=0.677,p=0.870),  time:20.979, tt:1321.677\n",
      "Ep:63, loss:0.00003, loss_test:0.08788, lr:8.26e-03, fs:0.72093 (r=0.626,p=0.849),  time:20.964, tt:1341.705\n",
      "Ep:64, loss:0.00003, loss_test:0.08656, lr:8.18e-03, fs:0.76404 (r=0.687,p=0.861),  time:20.990, tt:1364.322\n",
      "Ep:65, loss:0.00003, loss_test:0.08892, lr:8.10e-03, fs:0.72093 (r=0.626,p=0.849),  time:21.016, tt:1387.049\n",
      "Ep:66, loss:0.00003, loss_test:0.08494, lr:8.02e-03, fs:0.75000 (r=0.667,p=0.857),  time:21.020, tt:1408.344\n",
      "Ep:67, loss:0.00002, loss_test:0.09022, lr:7.94e-03, fs:0.77095 (r=0.697,p=0.863),  time:21.018, tt:1429.216\n",
      "Ep:68, loss:0.00002, loss_test:0.08466, lr:7.86e-03, fs:0.75281 (r=0.677,p=0.848),  time:21.000, tt:1449.013\n",
      "Ep:69, loss:0.00002, loss_test:0.08834, lr:7.78e-03, fs:0.72515 (r=0.626,p=0.861),  time:21.016, tt:1471.089\n",
      "Ep:70, loss:0.00002, loss_test:0.08590, lr:7.70e-03, fs:0.75000 (r=0.667,p=0.857),  time:21.035, tt:1493.461\n",
      "Ep:71, loss:0.00002, loss_test:0.08797, lr:7.62e-03, fs:0.74576 (r=0.667,p=0.846),  time:21.029, tt:1514.083\n",
      "Ep:72, loss:0.00002, loss_test:0.08865, lr:7.55e-03, fs:0.73256 (r=0.636,p=0.863),  time:21.018, tt:1534.312\n",
      "Ep:73, loss:0.00002, loss_test:0.08617, lr:7.47e-03, fs:0.72093 (r=0.626,p=0.849),  time:21.006, tt:1554.448\n",
      "Ep:74, loss:0.00002, loss_test:0.08878, lr:7.40e-03, fs:0.73256 (r=0.636,p=0.863),  time:21.016, tt:1576.213\n",
      "Ep:75, loss:0.00002, loss_test:0.08898, lr:7.32e-03, fs:0.72941 (r=0.626,p=0.873),  time:21.013, tt:1596.965\n",
      "Ep:76, loss:0.00002, loss_test:0.08920, lr:7.25e-03, fs:0.72093 (r=0.626,p=0.849),  time:21.000, tt:1617.016\n",
      "Ep:77, loss:0.00002, loss_test:0.08729, lr:7.18e-03, fs:0.76404 (r=0.687,p=0.861),  time:20.991, tt:1637.336\n",
      "Ep:78, loss:0.00002, loss_test:0.08996, lr:7.11e-03, fs:0.72941 (r=0.626,p=0.873),  time:20.994, tt:1658.514\n",
      "Ep:79, loss:0.00002, loss_test:0.08835, lr:7.03e-03, fs:0.72515 (r=0.626,p=0.861),  time:21.012, tt:1680.996\n",
      "Ep:80, loss:0.00002, loss_test:0.08837, lr:6.96e-03, fs:0.74286 (r=0.657,p=0.855),  time:21.020, tt:1702.603\n",
      "Ep:81, loss:0.00002, loss_test:0.09007, lr:6.89e-03, fs:0.72941 (r=0.626,p=0.873),  time:21.018, tt:1723.450\n",
      "Ep:82, loss:0.00002, loss_test:0.09063, lr:6.83e-03, fs:0.72515 (r=0.626,p=0.861),  time:21.005, tt:1743.434\n",
      "Ep:83, loss:0.00002, loss_test:0.08694, lr:6.76e-03, fs:0.72941 (r=0.626,p=0.873),  time:20.996, tt:1763.637\n",
      "Ep:84, loss:0.00002, loss_test:0.09141, lr:6.69e-03, fs:0.72515 (r=0.626,p=0.861),  time:20.987, tt:1783.937\n",
      "Ep:85, loss:0.00002, loss_test:0.09122, lr:6.62e-03, fs:0.74118 (r=0.636,p=0.887),  time:20.988, tt:1804.976\n",
      "Ep:86, loss:0.00002, loss_test:0.09112, lr:6.56e-03, fs:0.72941 (r=0.626,p=0.873),  time:21.000, tt:1826.959\n",
      "Ep:87, loss:0.00002, loss_test:0.09225, lr:6.49e-03, fs:0.72619 (r=0.616,p=0.884),  time:20.990, tt:1847.090\n",
      "Ep:88, loss:0.00002, loss_test:0.09063, lr:6.43e-03, fs:0.73373 (r=0.626,p=0.886),  time:20.970, tt:1866.336\n",
      "Ep:89, loss:0.00001, loss_test:0.09262, lr:6.36e-03, fs:0.73373 (r=0.626,p=0.886),  time:20.992, tt:1889.255\n",
      "Ep:90, loss:0.00001, loss_test:0.09081, lr:6.30e-03, fs:0.73373 (r=0.626,p=0.886),  time:20.980, tt:1909.202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:91, loss:0.00001, loss_test:0.09249, lr:6.24e-03, fs:0.73373 (r=0.626,p=0.886),  time:20.993, tt:1931.317\n",
      "Ep:92, loss:0.00001, loss_test:0.09227, lr:6.17e-03, fs:0.73810 (r=0.626,p=0.899),  time:21.001, tt:1953.080\n",
      "Ep:93, loss:0.00001, loss_test:0.09003, lr:6.11e-03, fs:0.72941 (r=0.626,p=0.873),  time:20.994, tt:1973.416\n",
      "Ep:94, loss:0.00001, loss_test:0.09303, lr:6.05e-03, fs:0.73810 (r=0.626,p=0.899),  time:21.010, tt:1995.982\n",
      "Ep:95, loss:0.00001, loss_test:0.08944, lr:5.99e-03, fs:0.72941 (r=0.626,p=0.873),  time:21.019, tt:2017.842\n",
      "Ep:96, loss:0.00001, loss_test:0.09360, lr:5.93e-03, fs:0.73373 (r=0.626,p=0.886),  time:21.046, tt:2041.413\n",
      "Ep:97, loss:0.00001, loss_test:0.09101, lr:5.87e-03, fs:0.73810 (r=0.626,p=0.899),  time:21.047, tt:2062.568\n",
      "Ep:98, loss:0.00001, loss_test:0.09213, lr:5.81e-03, fs:0.73373 (r=0.626,p=0.886),  time:21.034, tt:2082.392\n",
      "Ep:99, loss:0.00001, loss_test:0.09288, lr:5.75e-03, fs:0.73810 (r=0.626,p=0.899),  time:21.046, tt:2104.566\n",
      "Ep:100, loss:0.00001, loss_test:0.09088, lr:5.70e-03, fs:0.73373 (r=0.626,p=0.886),  time:21.044, tt:2125.421\n",
      "Ep:101, loss:0.00001, loss_test:0.09208, lr:5.64e-03, fs:0.73810 (r=0.626,p=0.899),  time:21.050, tt:2147.131\n",
      "Ep:102, loss:0.00001, loss_test:0.09065, lr:5.58e-03, fs:0.73810 (r=0.626,p=0.899),  time:21.041, tt:2167.218\n",
      "Ep:103, loss:0.00001, loss_test:0.09345, lr:5.53e-03, fs:0.73810 (r=0.626,p=0.899),  time:21.022, tt:2186.336\n",
      "Ep:104, loss:0.00001, loss_test:0.09257, lr:5.47e-03, fs:0.73810 (r=0.626,p=0.899),  time:21.001, tt:2205.056\n",
      "Ep:105, loss:0.00001, loss_test:0.09293, lr:5.42e-03, fs:0.73810 (r=0.626,p=0.899),  time:20.969, tt:2222.707\n",
      "Ep:106, loss:0.00001, loss_test:0.09316, lr:5.36e-03, fs:0.73810 (r=0.626,p=0.899),  time:20.962, tt:2242.946\n",
      "Ep:107, loss:0.00001, loss_test:0.09320, lr:5.31e-03, fs:0.74251 (r=0.626,p=0.912),  time:20.965, tt:2264.252\n",
      "Ep:108, loss:0.00001, loss_test:0.09227, lr:5.26e-03, fs:0.74251 (r=0.626,p=0.912),  time:20.956, tt:2284.212\n",
      "Ep:109, loss:0.00001, loss_test:0.09333, lr:5.20e-03, fs:0.73810 (r=0.626,p=0.899),  time:20.932, tt:2302.484\n",
      "Ep:110, loss:0.00001, loss_test:0.09478, lr:5.15e-03, fs:0.70000 (r=0.566,p=0.918),  time:20.903, tt:2320.256\n",
      "Ep:111, loss:0.00001, loss_test:0.09261, lr:5.10e-03, fs:0.74251 (r=0.626,p=0.912),  time:20.906, tt:2341.488\n",
      "Ep:112, loss:0.00001, loss_test:0.09478, lr:5.05e-03, fs:0.73939 (r=0.616,p=0.924),  time:20.915, tt:2363.438\n",
      "Ep:113, loss:0.00001, loss_test:0.09425, lr:5.00e-03, fs:0.73494 (r=0.616,p=0.910),  time:20.902, tt:2382.879\n",
      "Ep:114, loss:0.00001, loss_test:0.09420, lr:4.95e-03, fs:0.74251 (r=0.626,p=0.912),  time:20.913, tt:2404.998\n",
      "Ep:115, loss:0.00001, loss_test:0.09412, lr:4.90e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.914, tt:2426.068\n",
      "Ep:116, loss:0.00001, loss_test:0.09409, lr:4.85e-03, fs:0.74251 (r=0.626,p=0.912),  time:20.911, tt:2446.620\n",
      "Ep:117, loss:0.00001, loss_test:0.09544, lr:4.80e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.901, tt:2466.342\n",
      "Ep:118, loss:0.00001, loss_test:0.09488, lr:4.75e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.891, tt:2486.017\n",
      "Ep:119, loss:0.00001, loss_test:0.09503, lr:4.71e-03, fs:0.73939 (r=0.616,p=0.924),  time:20.887, tt:2506.447\n",
      "Ep:120, loss:0.00001, loss_test:0.09421, lr:4.66e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.884, tt:2526.905\n",
      "Ep:121, loss:0.00001, loss_test:0.09577, lr:4.61e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.878, tt:2547.093\n",
      "Ep:122, loss:0.00001, loss_test:0.09444, lr:4.57e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.876, tt:2567.705\n",
      "Ep:123, loss:0.00001, loss_test:0.09577, lr:4.52e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.874, tt:2588.334\n",
      "Ep:124, loss:0.00001, loss_test:0.09610, lr:4.48e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.867, tt:2608.370\n",
      "Ep:125, loss:0.00001, loss_test:0.09494, lr:4.43e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.857, tt:2627.954\n",
      "Ep:126, loss:0.00001, loss_test:0.09558, lr:4.39e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.849, tt:2647.855\n",
      "Ep:127, loss:0.00001, loss_test:0.09381, lr:4.34e-03, fs:0.74251 (r=0.626,p=0.912),  time:20.855, tt:2669.414\n",
      "Ep:128, loss:0.00001, loss_test:0.09590, lr:4.30e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.858, tt:2690.719\n",
      "Ep:129, loss:0.00001, loss_test:0.09390, lr:4.26e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.848, tt:2710.187\n",
      "Ep:130, loss:0.00001, loss_test:0.09562, lr:4.21e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.841, tt:2730.198\n",
      "Ep:131, loss:0.00001, loss_test:0.09419, lr:4.17e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.841, tt:2751.021\n",
      "Ep:132, loss:0.00001, loss_test:0.09606, lr:4.13e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.839, tt:2771.540\n",
      "Ep:133, loss:0.00001, loss_test:0.09499, lr:4.09e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.836, tt:2792.087\n",
      "Ep:134, loss:0.00001, loss_test:0.09484, lr:4.05e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.841, tt:2813.473\n",
      "Ep:135, loss:0.00001, loss_test:0.09583, lr:4.01e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.833, tt:2833.286\n",
      "Ep:136, loss:0.00001, loss_test:0.09481, lr:3.97e-03, fs:0.74251 (r=0.626,p=0.912),  time:20.842, tt:2855.347\n",
      "Ep:137, loss:0.00001, loss_test:0.09707, lr:3.93e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.831, tt:2874.616\n",
      "Ep:138, loss:0.00001, loss_test:0.09516, lr:3.89e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.837, tt:2896.402\n",
      "Ep:139, loss:0.00001, loss_test:0.09624, lr:3.85e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.835, tt:2916.851\n",
      "Ep:140, loss:0.00001, loss_test:0.09678, lr:3.81e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.822, tt:2935.938\n",
      "Ep:141, loss:0.00001, loss_test:0.09458, lr:3.77e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.813, tt:2955.490\n",
      "Ep:142, loss:0.00001, loss_test:0.09607, lr:3.73e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.807, tt:2975.441\n",
      "Ep:143, loss:0.00001, loss_test:0.09507, lr:3.70e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.812, tt:2996.950\n",
      "Ep:144, loss:0.00001, loss_test:0.09664, lr:3.66e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.807, tt:3016.973\n",
      "Ep:145, loss:0.00001, loss_test:0.09853, lr:3.62e-03, fs:0.73939 (r=0.616,p=0.924),  time:20.821, tt:3039.904\n",
      "Ep:146, loss:0.00001, loss_test:0.09542, lr:3.59e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.818, tt:3060.180\n",
      "Ep:147, loss:0.00001, loss_test:0.09777, lr:3.55e-03, fs:0.73939 (r=0.616,p=0.924),  time:20.823, tt:3081.816\n",
      "Ep:148, loss:0.00001, loss_test:0.09835, lr:3.52e-03, fs:0.72393 (r=0.596,p=0.922),  time:20.830, tt:3103.628\n",
      "Ep:149, loss:0.00001, loss_test:0.09553, lr:3.48e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.827, tt:3124.123\n",
      "Ep:150, loss:0.00001, loss_test:0.09762, lr:3.45e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.838, tt:3146.582\n",
      "Ep:151, loss:0.00000, loss_test:0.09944, lr:3.41e-03, fs:0.72840 (r=0.596,p=0.937),  time:20.862, tt:3170.986\n",
      "Ep:152, loss:0.00001, loss_test:0.09627, lr:3.38e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.847, tt:3189.517\n",
      "Ep:153, loss:0.00000, loss_test:0.09651, lr:3.34e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.816, tt:3205.712\n",
      "Ep:154, loss:0.00000, loss_test:0.09796, lr:3.31e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.792, tt:3222.732\n",
      "Ep:155, loss:0.00000, loss_test:0.09644, lr:3.28e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.782, tt:3241.915\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14034, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.591, tt:25.591\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13831, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:25.422, tt:50.845\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:2, loss:0.00027, loss_test:0.13458, lr:1.00e-02, fs:0.66899 (r=0.970,p=0.511),  time:25.251, tt:75.754\n",
      "Ep:3, loss:0.00027, loss_test:0.12857, lr:1.00e-02, fs:0.66667 (r=0.929,p=0.520),  time:25.023, tt:100.092\n",
      "Ep:4, loss:0.00026, loss_test:0.12270, lr:1.00e-02, fs:0.68775 (r=0.879,p=0.565),  time:24.726, tt:123.632\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.11991, lr:1.00e-02, fs:0.67220 (r=0.818,p=0.570),  time:24.904, tt:149.423\n",
      "Ep:6, loss:0.00024, loss_test:0.11866, lr:1.00e-02, fs:0.68050 (r=0.828,p=0.577),  time:24.896, tt:174.272\n",
      "Ep:7, loss:0.00024, loss_test:0.11718, lr:1.00e-02, fs:0.69076 (r=0.869,p=0.573),  time:24.902, tt:199.219\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11412, lr:1.00e-02, fs:0.68313 (r=0.838,p=0.576),  time:24.881, tt:223.926\n",
      "Ep:9, loss:0.00022, loss_test:0.11131, lr:1.00e-02, fs:0.69124 (r=0.758,p=0.636),  time:24.686, tt:246.862\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.10921, lr:1.00e-02, fs:0.71498 (r=0.747,p=0.685),  time:24.772, tt:272.488\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.10574, lr:1.00e-02, fs:0.69036 (r=0.687,p=0.694),  time:24.747, tt:296.958\n",
      "Ep:12, loss:0.00019, loss_test:0.10376, lr:1.00e-02, fs:0.69430 (r=0.677,p=0.713),  time:24.798, tt:322.370\n",
      "Ep:13, loss:0.00018, loss_test:0.10131, lr:1.00e-02, fs:0.70103 (r=0.687,p=0.716),  time:24.891, tt:348.477\n",
      "Ep:14, loss:0.00017, loss_test:0.09940, lr:1.00e-02, fs:0.72917 (r=0.707,p=0.753),  time:24.951, tt:374.260\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.09698, lr:1.00e-02, fs:0.77157 (r=0.768,p=0.776),  time:24.972, tt:399.546\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.09584, lr:1.00e-02, fs:0.74737 (r=0.717,p=0.780),  time:24.955, tt:424.232\n",
      "Ep:17, loss:0.00015, loss_test:0.09526, lr:1.00e-02, fs:0.74346 (r=0.717,p=0.772),  time:24.905, tt:448.282\n",
      "Ep:18, loss:0.00015, loss_test:0.09371, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:24.917, tt:473.431\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.09314, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:24.922, tt:498.444\n",
      "Ep:20, loss:0.00013, loss_test:0.09170, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:24.863, tt:522.128\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.09125, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:24.976, tt:549.471\n",
      "Ep:22, loss:0.00012, loss_test:0.09096, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:24.953, tt:573.930\n",
      "Ep:23, loss:0.00012, loss_test:0.09037, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:25.019, tt:600.457\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.08949, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:25.175, tt:629.368\n",
      "Ep:25, loss:0.00011, loss_test:0.08945, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:25.186, tt:654.826\n",
      "Ep:26, loss:0.00010, loss_test:0.08929, lr:1.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:25.213, tt:680.754\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00010, loss_test:0.08989, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:25.246, tt:706.896\n",
      "Ep:28, loss:0.00010, loss_test:0.08748, lr:1.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:25.236, tt:731.858\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00009, loss_test:0.09072, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:25.270, tt:758.092\n",
      "Ep:30, loss:0.00009, loss_test:0.08648, lr:1.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:25.264, tt:783.175\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00009, loss_test:0.08881, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:25.277, tt:808.857\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00008, loss_test:0.08678, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:25.250, tt:833.256\n",
      "Ep:33, loss:0.00008, loss_test:0.08483, lr:1.00e-02, fs:0.85572 (r=0.869,p=0.843),  time:25.281, tt:859.547\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00008, loss_test:0.08920, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:25.218, tt:882.618\n",
      "Ep:35, loss:0.00007, loss_test:0.08242, lr:1.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:25.219, tt:907.883\n",
      "Ep:36, loss:0.00007, loss_test:0.09003, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:25.264, tt:934.764\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00007, loss_test:0.08210, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:25.234, tt:958.887\n",
      "Ep:38, loss:0.00007, loss_test:0.08475, lr:1.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:25.207, tt:983.091\n",
      "Ep:39, loss:0.00006, loss_test:0.08336, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:25.169, tt:1006.763\n",
      "Ep:40, loss:0.00006, loss_test:0.07985, lr:1.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:25.203, tt:1033.332\n",
      "Ep:41, loss:0.00006, loss_test:0.08358, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:25.210, tt:1058.808\n",
      "Ep:42, loss:0.00006, loss_test:0.07768, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:25.206, tt:1083.849\n",
      "Ep:43, loss:0.00005, loss_test:0.08341, lr:1.00e-02, fs:0.88083 (r=0.859,p=0.904),  time:25.181, tt:1107.970\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00005, loss_test:0.07825, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:25.158, tt:1132.094\n",
      "Ep:45, loss:0.00005, loss_test:0.08026, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:25.170, tt:1157.830\n",
      "Ep:46, loss:0.00005, loss_test:0.07991, lr:1.00e-02, fs:0.86813 (r=0.798,p=0.952),  time:25.214, tt:1185.054\n",
      "Ep:47, loss:0.00005, loss_test:0.07664, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:25.189, tt:1209.073\n",
      "Ep:48, loss:0.00004, loss_test:0.08310, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:25.185, tt:1234.084\n",
      "Ep:49, loss:0.00004, loss_test:0.07544, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:25.182, tt:1259.124\n",
      "Ep:50, loss:0.00004, loss_test:0.08278, lr:1.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:25.160, tt:1283.140\n",
      "Ep:51, loss:0.00004, loss_test:0.07483, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:25.145, tt:1307.544\n",
      "Ep:52, loss:0.00004, loss_test:0.08290, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:25.130, tt:1331.915\n",
      "Ep:53, loss:0.00004, loss_test:0.08216, lr:1.00e-02, fs:0.81395 (r=0.707,p=0.959),  time:25.109, tt:1355.903\n",
      "Ep:54, loss:0.00004, loss_test:0.07461, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:25.088, tt:1379.863\n",
      "Ep:55, loss:0.00004, loss_test:0.08581, lr:9.90e-03, fs:0.82558 (r=0.717,p=0.973),  time:25.106, tt:1405.938\n",
      "Ep:56, loss:0.00004, loss_test:0.07639, lr:9.80e-03, fs:0.85083 (r=0.778,p=0.939),  time:25.097, tt:1430.522\n",
      "Ep:57, loss:0.00003, loss_test:0.07714, lr:9.70e-03, fs:0.85106 (r=0.808,p=0.899),  time:25.074, tt:1454.290\n",
      "Ep:58, loss:0.00003, loss_test:0.08088, lr:9.61e-03, fs:0.80702 (r=0.697,p=0.958),  time:25.068, tt:1479.014\n",
      "Ep:59, loss:0.00003, loss_test:0.07430, lr:9.51e-03, fs:0.85714 (r=0.818,p=0.900),  time:25.090, tt:1505.422\n",
      "Ep:60, loss:0.00003, loss_test:0.07720, lr:9.41e-03, fs:0.84270 (r=0.758,p=0.949),  time:25.099, tt:1531.020\n",
      "Ep:61, loss:0.00003, loss_test:0.08095, lr:9.32e-03, fs:0.87432 (r=0.808,p=0.952),  time:25.059, tt:1553.657\n",
      "Ep:62, loss:0.00003, loss_test:0.07530, lr:9.23e-03, fs:0.84615 (r=0.778,p=0.928),  time:25.018, tt:1576.132\n",
      "Ep:63, loss:0.00003, loss_test:0.07819, lr:9.14e-03, fs:0.86170 (r=0.818,p=0.910),  time:25.009, tt:1600.600\n",
      "Ep:64, loss:0.00003, loss_test:0.07725, lr:9.04e-03, fs:0.85556 (r=0.778,p=0.951),  time:25.031, tt:1626.991\n",
      "Ep:65, loss:0.00003, loss_test:0.07673, lr:8.95e-03, fs:0.86170 (r=0.818,p=0.910),  time:25.025, tt:1651.622\n",
      "Ep:66, loss:0.00002, loss_test:0.07615, lr:8.86e-03, fs:0.85227 (r=0.758,p=0.974),  time:25.004, tt:1675.261\n",
      "Ep:67, loss:0.00002, loss_test:0.07827, lr:8.78e-03, fs:0.87097 (r=0.818,p=0.931),  time:25.000, tt:1700.013\n",
      "Ep:68, loss:0.00002, loss_test:0.07587, lr:8.69e-03, fs:0.86034 (r=0.778,p=0.963),  time:25.015, tt:1726.037\n",
      "Ep:69, loss:0.00002, loss_test:0.07849, lr:8.60e-03, fs:0.87568 (r=0.818,p=0.942),  time:25.001, tt:1750.098\n",
      "Ep:70, loss:0.00002, loss_test:0.07745, lr:8.51e-03, fs:0.83237 (r=0.727,p=0.973),  time:24.994, tt:1774.609\n",
      "Ep:71, loss:0.00002, loss_test:0.07786, lr:8.43e-03, fs:0.87097 (r=0.818,p=0.931),  time:24.997, tt:1799.752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:72, loss:0.00002, loss_test:0.07706, lr:8.35e-03, fs:0.83908 (r=0.737,p=0.973),  time:25.063, tt:1829.613\n",
      "Ep:73, loss:0.00002, loss_test:0.07907, lr:8.26e-03, fs:0.87568 (r=0.818,p=0.942),  time:25.045, tt:1853.348\n",
      "Ep:74, loss:0.00002, loss_test:0.07630, lr:8.18e-03, fs:0.84571 (r=0.747,p=0.974),  time:25.029, tt:1877.211\n",
      "Ep:75, loss:0.00002, loss_test:0.08097, lr:8.10e-03, fs:0.87912 (r=0.808,p=0.964),  time:25.035, tt:1902.673\n",
      "Ep:76, loss:0.00002, loss_test:0.07821, lr:8.02e-03, fs:0.83908 (r=0.737,p=0.973),  time:25.022, tt:1926.701\n",
      "Ep:77, loss:0.00002, loss_test:0.07968, lr:7.94e-03, fs:0.88525 (r=0.818,p=0.964),  time:25.019, tt:1951.496\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00002, loss_test:0.07866, lr:7.94e-03, fs:0.83908 (r=0.737,p=0.973),  time:25.001, tt:1975.065\n",
      "Ep:79, loss:0.00002, loss_test:0.08050, lr:7.94e-03, fs:0.83908 (r=0.737,p=0.973),  time:24.997, tt:1999.783\n",
      "Ep:80, loss:0.00002, loss_test:0.07883, lr:7.94e-03, fs:0.85227 (r=0.758,p=0.974),  time:24.996, tt:2024.663\n",
      "Ep:81, loss:0.00002, loss_test:0.07941, lr:7.94e-03, fs:0.83237 (r=0.727,p=0.973),  time:24.987, tt:2048.955\n",
      "Ep:82, loss:0.00002, loss_test:0.08100, lr:7.94e-03, fs:0.83237 (r=0.727,p=0.973),  time:24.991, tt:2074.290\n",
      "Ep:83, loss:0.00002, loss_test:0.07876, lr:7.94e-03, fs:0.83908 (r=0.737,p=0.973),  time:24.997, tt:2099.721\n",
      "Ep:84, loss:0.00001, loss_test:0.08049, lr:7.94e-03, fs:0.83237 (r=0.727,p=0.973),  time:24.983, tt:2123.581\n",
      "Ep:85, loss:0.00001, loss_test:0.08023, lr:7.94e-03, fs:0.81871 (r=0.707,p=0.972),  time:24.948, tt:2145.564\n",
      "Ep:86, loss:0.00001, loss_test:0.07961, lr:7.94e-03, fs:0.83908 (r=0.737,p=0.973),  time:24.921, tt:2168.117\n",
      "Ep:87, loss:0.00001, loss_test:0.08051, lr:7.94e-03, fs:0.82558 (r=0.717,p=0.973),  time:24.885, tt:2189.881\n",
      "Ep:88, loss:0.00001, loss_test:0.08094, lr:7.94e-03, fs:0.83237 (r=0.727,p=0.973),  time:24.842, tt:2210.901\n",
      "Ep:89, loss:0.00001, loss_test:0.07903, lr:7.86e-03, fs:0.82558 (r=0.717,p=0.973),  time:24.810, tt:2232.900\n",
      "Ep:90, loss:0.00001, loss_test:0.08298, lr:7.78e-03, fs:0.82558 (r=0.717,p=0.973),  time:24.796, tt:2256.407\n",
      "Ep:91, loss:0.00001, loss_test:0.08090, lr:7.70e-03, fs:0.81871 (r=0.707,p=0.972),  time:24.752, tt:2277.189\n",
      "Ep:92, loss:0.00001, loss_test:0.08028, lr:7.62e-03, fs:0.81871 (r=0.707,p=0.972),  time:24.727, tt:2299.623\n",
      "Ep:93, loss:0.00001, loss_test:0.08176, lr:7.55e-03, fs:0.81871 (r=0.707,p=0.972),  time:24.724, tt:2324.046\n",
      "Ep:94, loss:0.00001, loss_test:0.08052, lr:7.47e-03, fs:0.81871 (r=0.707,p=0.972),  time:24.736, tt:2349.892\n",
      "Ep:95, loss:0.00001, loss_test:0.08118, lr:7.40e-03, fs:0.81871 (r=0.707,p=0.972),  time:24.734, tt:2374.499\n",
      "Ep:96, loss:0.00001, loss_test:0.08137, lr:7.32e-03, fs:0.81871 (r=0.707,p=0.972),  time:24.729, tt:2398.707\n",
      "Ep:97, loss:0.00001, loss_test:0.08018, lr:7.25e-03, fs:0.81871 (r=0.707,p=0.972),  time:24.719, tt:2422.477\n",
      "Ep:98, loss:0.00001, loss_test:0.08184, lr:7.18e-03, fs:0.82353 (r=0.707,p=0.986),  time:24.723, tt:2447.617\n",
      "Ep:99, loss:0.00001, loss_test:0.08168, lr:7.11e-03, fs:0.81395 (r=0.707,p=0.959),  time:24.707, tt:2470.739\n",
      "Ep:100, loss:0.00001, loss_test:0.08254, lr:7.03e-03, fs:0.82353 (r=0.707,p=0.986),  time:24.703, tt:2494.962\n",
      "Ep:101, loss:0.00001, loss_test:0.08207, lr:6.96e-03, fs:0.81871 (r=0.707,p=0.972),  time:24.705, tt:2519.885\n",
      "Ep:102, loss:0.00001, loss_test:0.08221, lr:6.89e-03, fs:0.82353 (r=0.707,p=0.986),  time:24.715, tt:2545.660\n",
      "Ep:103, loss:0.00001, loss_test:0.08292, lr:6.83e-03, fs:0.82353 (r=0.707,p=0.986),  time:24.730, tt:2571.951\n",
      "Ep:104, loss:0.00001, loss_test:0.08311, lr:6.76e-03, fs:0.82353 (r=0.707,p=0.986),  time:24.742, tt:2597.870\n",
      "Ep:105, loss:0.00001, loss_test:0.08230, lr:6.69e-03, fs:0.81871 (r=0.707,p=0.972),  time:24.739, tt:2622.304\n",
      "Ep:106, loss:0.00001, loss_test:0.08272, lr:6.62e-03, fs:0.81871 (r=0.707,p=0.972),  time:24.784, tt:2651.881\n",
      "Ep:107, loss:0.00001, loss_test:0.08334, lr:6.56e-03, fs:0.82353 (r=0.707,p=0.986),  time:24.790, tt:2677.279\n",
      "Ep:108, loss:0.00001, loss_test:0.08262, lr:6.49e-03, fs:0.81871 (r=0.707,p=0.972),  time:24.789, tt:2701.978\n",
      "Ep:109, loss:0.00001, loss_test:0.08325, lr:6.43e-03, fs:0.81657 (r=0.697,p=0.986),  time:24.792, tt:2727.066\n",
      "Ep:110, loss:0.00001, loss_test:0.08359, lr:6.36e-03, fs:0.82353 (r=0.707,p=0.986),  time:24.774, tt:2749.955\n",
      "Ep:111, loss:0.00001, loss_test:0.08362, lr:6.30e-03, fs:0.82353 (r=0.707,p=0.986),  time:24.772, tt:2774.483\n",
      "Ep:112, loss:0.00001, loss_test:0.08448, lr:6.24e-03, fs:0.82353 (r=0.707,p=0.986),  time:24.753, tt:2797.136\n",
      "Ep:113, loss:0.00001, loss_test:0.08442, lr:6.17e-03, fs:0.82353 (r=0.707,p=0.986),  time:24.765, tt:2823.232\n",
      "Ep:114, loss:0.00001, loss_test:0.08394, lr:6.11e-03, fs:0.82353 (r=0.707,p=0.986),  time:24.751, tt:2846.331\n",
      "Ep:115, loss:0.00001, loss_test:0.08531, lr:6.05e-03, fs:0.82353 (r=0.707,p=0.986),  time:24.759, tt:2872.000\n",
      "Ep:116, loss:0.00001, loss_test:0.08523, lr:5.99e-03, fs:0.81657 (r=0.697,p=0.986),  time:24.761, tt:2897.028\n",
      "Ep:117, loss:0.00001, loss_test:0.08451, lr:5.93e-03, fs:0.82353 (r=0.707,p=0.986),  time:24.767, tt:2922.500\n",
      "Ep:118, loss:0.00001, loss_test:0.08638, lr:5.87e-03, fs:0.81657 (r=0.697,p=0.986),  time:24.777, tt:2948.451\n",
      "Ep:119, loss:0.00001, loss_test:0.08510, lr:5.81e-03, fs:0.82353 (r=0.707,p=0.986),  time:24.767, tt:2972.025\n",
      "Ep:120, loss:0.00001, loss_test:0.08610, lr:5.75e-03, fs:0.81657 (r=0.697,p=0.986),  time:24.761, tt:2996.026\n",
      "Ep:121, loss:0.00001, loss_test:0.08608, lr:5.70e-03, fs:0.82353 (r=0.707,p=0.986),  time:24.752, tt:3019.704\n",
      "Ep:122, loss:0.00001, loss_test:0.08603, lr:5.64e-03, fs:0.81657 (r=0.697,p=0.986),  time:24.748, tt:3044.038\n",
      "Ep:123, loss:0.00001, loss_test:0.08524, lr:5.58e-03, fs:0.82353 (r=0.707,p=0.986),  time:24.740, tt:3067.725\n",
      "Ep:124, loss:0.00001, loss_test:0.08794, lr:5.53e-03, fs:0.82143 (r=0.697,p=1.000),  time:24.750, tt:3093.799\n",
      "Ep:125, loss:0.00001, loss_test:0.08644, lr:5.47e-03, fs:0.82353 (r=0.707,p=0.986),  time:24.751, tt:3118.668\n",
      "Ep:126, loss:0.00001, loss_test:0.08541, lr:5.42e-03, fs:0.81657 (r=0.697,p=0.986),  time:24.753, tt:3143.579\n",
      "Ep:127, loss:0.00001, loss_test:0.08716, lr:5.36e-03, fs:0.81657 (r=0.697,p=0.986),  time:24.768, tt:3170.358\n",
      "Ep:128, loss:0.00001, loss_test:0.08661, lr:5.31e-03, fs:0.82353 (r=0.707,p=0.986),  time:24.772, tt:3195.587\n",
      "Ep:129, loss:0.00001, loss_test:0.08643, lr:5.26e-03, fs:0.82143 (r=0.697,p=1.000),  time:24.765, tt:3219.406\n",
      "Ep:130, loss:0.00001, loss_test:0.08674, lr:5.20e-03, fs:0.82353 (r=0.707,p=0.986),  time:24.756, tt:3243.014\n",
      "Ep:131, loss:0.00001, loss_test:0.08697, lr:5.15e-03, fs:0.82143 (r=0.697,p=1.000),  time:24.756, tt:3267.852\n",
      "Ep:132, loss:0.00001, loss_test:0.08754, lr:5.10e-03, fs:0.82353 (r=0.707,p=0.986),  time:24.758, tt:3292.819\n",
      "Ep:133, loss:0.00001, loss_test:0.08876, lr:5.05e-03, fs:0.82143 (r=0.697,p=1.000),  time:24.773, tt:3319.596\n",
      "Ep:134, loss:0.00001, loss_test:0.08600, lr:5.00e-03, fs:0.82353 (r=0.707,p=0.986),  time:24.780, tt:3345.287\n",
      "Ep:135, loss:0.00001, loss_test:0.08693, lr:4.95e-03, fs:0.81657 (r=0.697,p=0.986),  time:24.795, tt:3372.119\n",
      "Ep:136, loss:0.00001, loss_test:0.08758, lr:4.90e-03, fs:0.82143 (r=0.697,p=1.000),  time:24.790, tt:3396.178\n",
      "Ep:137, loss:0.00001, loss_test:0.08640, lr:4.85e-03, fs:0.81871 (r=0.707,p=0.972),  time:24.785, tt:3420.272\n",
      "Ep:138, loss:0.00001, loss_test:0.08729, lr:4.80e-03, fs:0.82143 (r=0.697,p=1.000),  time:24.784, tt:3444.998\n",
      "Ep:139, loss:0.00001, loss_test:0.08694, lr:4.75e-03, fs:0.82353 (r=0.707,p=0.986),  time:24.795, tt:3471.351\n",
      "Ep:140, loss:0.00001, loss_test:0.08805, lr:4.71e-03, fs:0.82143 (r=0.697,p=1.000),  time:24.782, tt:3494.208\n",
      "Ep:141, loss:0.00001, loss_test:0.08733, lr:4.66e-03, fs:0.82143 (r=0.697,p=1.000),  time:24.797, tt:3521.148\n",
      "Ep:142, loss:0.00001, loss_test:0.08648, lr:4.61e-03, fs:0.81657 (r=0.697,p=0.986),  time:24.795, tt:3545.680\n",
      "Ep:143, loss:0.00001, loss_test:0.08838, lr:4.57e-03, fs:0.82143 (r=0.697,p=1.000),  time:24.811, tt:3572.723\n",
      "Ep:144, loss:0.00001, loss_test:0.08832, lr:4.52e-03, fs:0.81657 (r=0.697,p=0.986),  time:24.810, tt:3597.462\n",
      "Ep:145, loss:0.00000, loss_test:0.08714, lr:4.48e-03, fs:0.82143 (r=0.697,p=1.000),  time:24.802, tt:3621.031\n",
      "Ep:146, loss:0.00000, loss_test:0.08793, lr:4.43e-03, fs:0.82143 (r=0.697,p=1.000),  time:24.791, tt:3644.228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:147, loss:0.00000, loss_test:0.08767, lr:4.39e-03, fs:0.82143 (r=0.697,p=1.000),  time:24.788, tt:3668.686\n",
      "Ep:148, loss:0.00000, loss_test:0.08752, lr:4.34e-03, fs:0.82143 (r=0.697,p=1.000),  time:24.788, tt:3693.342\n",
      "Ep:149, loss:0.00000, loss_test:0.08786, lr:4.30e-03, fs:0.81657 (r=0.697,p=0.986),  time:24.779, tt:3716.858\n",
      "Ep:150, loss:0.00000, loss_test:0.08792, lr:4.26e-03, fs:0.82143 (r=0.697,p=1.000),  time:24.783, tt:3742.271\n",
      "Ep:151, loss:0.00000, loss_test:0.08723, lr:4.21e-03, fs:0.82143 (r=0.697,p=1.000),  time:24.773, tt:3765.535\n",
      "Ep:152, loss:0.00000, loss_test:0.08868, lr:4.17e-03, fs:0.81657 (r=0.697,p=0.986),  time:24.763, tt:3788.777\n",
      "Ep:153, loss:0.00000, loss_test:0.08894, lr:4.13e-03, fs:0.81437 (r=0.687,p=1.000),  time:24.753, tt:3812.038\n",
      "Ep:154, loss:0.00000, loss_test:0.08726, lr:4.09e-03, fs:0.82143 (r=0.697,p=1.000),  time:24.721, tt:3831.826\n",
      "Ep:155, loss:0.00000, loss_test:0.08741, lr:4.05e-03, fs:0.82143 (r=0.697,p=1.000),  time:24.709, tt:3854.681\n",
      "Ep:156, loss:0.00000, loss_test:0.08891, lr:4.01e-03, fs:0.81437 (r=0.687,p=1.000),  time:24.707, tt:3879.037\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.14271, lr:1.00e-02, fs:0.65052 (r=0.949,p=0.495),  time:25.749, tt:25.749\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14047, lr:1.00e-02, fs:0.65714 (r=0.929,p=0.508),  time:25.706, tt:51.412\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.13670, lr:1.00e-02, fs:0.64662 (r=0.869,p=0.515),  time:25.919, tt:77.756\n",
      "Ep:3, loss:0.00025, loss_test:0.13606, lr:1.00e-02, fs:0.62295 (r=0.768,p=0.524),  time:25.977, tt:103.909\n",
      "Ep:4, loss:0.00024, loss_test:0.13708, lr:1.00e-02, fs:0.63111 (r=0.717,p=0.563),  time:25.370, tt:126.848\n",
      "Ep:5, loss:0.00024, loss_test:0.13529, lr:1.00e-02, fs:0.63927 (r=0.707,p=0.583),  time:25.427, tt:152.564\n",
      "Ep:6, loss:0.00024, loss_test:0.12726, lr:1.00e-02, fs:0.64889 (r=0.737,p=0.579),  time:25.420, tt:177.938\n",
      "Ep:7, loss:0.00023, loss_test:0.12268, lr:1.00e-02, fs:0.66379 (r=0.778,p=0.579),  time:25.604, tt:204.835\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.12001, lr:1.00e-02, fs:0.65158 (r=0.727,p=0.590),  time:25.559, tt:230.027\n",
      "Ep:9, loss:0.00021, loss_test:0.12021, lr:1.00e-02, fs:0.66337 (r=0.677,p=0.650),  time:25.499, tt:254.991\n",
      "Ep:10, loss:0.00020, loss_test:0.11946, lr:1.00e-02, fs:0.63959 (r=0.636,p=0.643),  time:25.250, tt:277.751\n",
      "Ep:11, loss:0.00019, loss_test:0.11409, lr:1.00e-02, fs:0.67317 (r=0.697,p=0.651),  time:25.138, tt:301.654\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.11267, lr:1.00e-02, fs:0.67327 (r=0.687,p=0.660),  time:25.164, tt:327.130\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.11182, lr:1.00e-02, fs:0.68041 (r=0.667,p=0.695),  time:25.268, tt:353.748\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.10863, lr:1.00e-02, fs:0.72195 (r=0.747,p=0.698),  time:25.351, tt:380.272\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.10598, lr:1.00e-02, fs:0.73786 (r=0.768,p=0.710),  time:25.295, tt:404.725\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.10385, lr:1.00e-02, fs:0.74112 (r=0.737,p=0.745),  time:25.172, tt:427.916\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.10165, lr:1.00e-02, fs:0.74000 (r=0.747,p=0.733),  time:25.106, tt:451.909\n",
      "Ep:18, loss:0.00015, loss_test:0.10050, lr:1.00e-02, fs:0.73846 (r=0.727,p=0.750),  time:25.108, tt:477.048\n",
      "Ep:19, loss:0.00014, loss_test:0.09948, lr:1.00e-02, fs:0.74112 (r=0.737,p=0.745),  time:24.975, tt:499.508\n",
      "Ep:20, loss:0.00014, loss_test:0.09764, lr:1.00e-02, fs:0.75377 (r=0.758,p=0.750),  time:25.008, tt:525.172\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.09565, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:24.964, tt:549.211\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00013, loss_test:0.09489, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:24.941, tt:573.648\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.09475, lr:1.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:24.872, tt:596.933\n",
      "Ep:24, loss:0.00012, loss_test:0.09382, lr:1.00e-02, fs:0.78818 (r=0.808,p=0.769),  time:24.812, tt:620.312\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00011, loss_test:0.09418, lr:1.00e-02, fs:0.77487 (r=0.747,p=0.804),  time:24.764, tt:643.874\n",
      "Ep:26, loss:0.00011, loss_test:0.09288, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:24.729, tt:667.682\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00010, loss_test:0.09185, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:24.808, tt:694.619\n",
      "Ep:28, loss:0.00010, loss_test:0.09002, lr:1.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:24.808, tt:719.423\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00010, loss_test:0.08951, lr:1.00e-02, fs:0.83000 (r=0.838,p=0.822),  time:24.842, tt:745.249\n",
      "Ep:30, loss:0.00009, loss_test:0.08976, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:24.802, tt:768.873\n",
      "Ep:31, loss:0.00009, loss_test:0.08778, lr:1.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:24.747, tt:791.910\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00009, loss_test:0.08762, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:24.688, tt:814.691\n",
      "Ep:33, loss:0.00008, loss_test:0.08679, lr:1.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:24.786, tt:842.718\n",
      "Ep:34, loss:0.00008, loss_test:0.08547, lr:1.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:24.753, tt:866.369\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00008, loss_test:0.08543, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:24.764, tt:891.500\n",
      "Ep:36, loss:0.00008, loss_test:0.08427, lr:1.00e-02, fs:0.85577 (r=0.899,p=0.817),  time:24.724, tt:914.775\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00007, loss_test:0.08400, lr:1.00e-02, fs:0.83077 (r=0.818,p=0.844),  time:24.760, tt:940.874\n",
      "Ep:38, loss:0.00007, loss_test:0.08332, lr:1.00e-02, fs:0.85714 (r=0.879,p=0.837),  time:24.704, tt:963.465\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00007, loss_test:0.08510, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:24.663, tt:986.525\n",
      "Ep:40, loss:0.00007, loss_test:0.08100, lr:1.00e-02, fs:0.85990 (r=0.899,p=0.824),  time:24.656, tt:1010.912\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00006, loss_test:0.08451, lr:1.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:24.584, tt:1032.519\n",
      "Ep:42, loss:0.00006, loss_test:0.08054, lr:1.00e-02, fs:0.86408 (r=0.899,p=0.832),  time:24.599, tt:1057.743\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00006, loss_test:0.08464, lr:1.00e-02, fs:0.83673 (r=0.828,p=0.845),  time:24.571, tt:1081.106\n",
      "Ep:44, loss:0.00006, loss_test:0.08082, lr:1.00e-02, fs:0.87255 (r=0.899,p=0.848),  time:24.536, tt:1104.125\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00005, loss_test:0.08385, lr:1.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:24.555, tt:1129.535\n",
      "Ep:46, loss:0.00005, loss_test:0.08053, lr:1.00e-02, fs:0.86700 (r=0.889,p=0.846),  time:24.539, tt:1153.324\n",
      "Ep:47, loss:0.00005, loss_test:0.08655, lr:1.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:24.518, tt:1176.844\n",
      "Ep:48, loss:0.00005, loss_test:0.07978, lr:1.00e-02, fs:0.87255 (r=0.899,p=0.848),  time:24.489, tt:1199.941\n",
      "Ep:49, loss:0.00005, loss_test:0.08490, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:24.473, tt:1223.666\n",
      "Ep:50, loss:0.00005, loss_test:0.08409, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:24.478, tt:1248.353\n",
      "Ep:51, loss:0.00004, loss_test:0.07829, lr:1.00e-02, fs:0.88350 (r=0.919,p=0.850),  time:24.523, tt:1275.197\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:52, loss:0.00004, loss_test:0.08907, lr:1.00e-02, fs:0.74157 (r=0.667,p=0.835),  time:24.533, tt:1300.229\n",
      "Ep:53, loss:0.00004, loss_test:0.07868, lr:1.00e-02, fs:0.88350 (r=0.919,p=0.850),  time:24.517, tt:1323.894\n",
      "Ep:54, loss:0.00004, loss_test:0.08407, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:24.564, tt:1350.996\n",
      "Ep:55, loss:0.00004, loss_test:0.08153, lr:1.00e-02, fs:0.87000 (r=0.879,p=0.861),  time:24.569, tt:1375.875\n",
      "Ep:56, loss:0.00004, loss_test:0.08149, lr:1.00e-02, fs:0.85714 (r=0.879,p=0.837),  time:24.552, tt:1399.460\n",
      "Ep:57, loss:0.00004, loss_test:0.08155, lr:1.00e-02, fs:0.85427 (r=0.859,p=0.850),  time:24.569, tt:1424.992\n",
      "Ep:58, loss:0.00004, loss_test:0.08030, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:24.609, tt:1451.931\n",
      "Ep:59, loss:0.00003, loss_test:0.08403, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:24.626, tt:1477.540\n",
      "Ep:60, loss:0.00003, loss_test:0.07957, lr:1.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:24.622, tt:1501.933\n",
      "Ep:61, loss:0.00003, loss_test:0.08219, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:24.602, tt:1525.300\n",
      "Ep:62, loss:0.00003, loss_test:0.07885, lr:1.00e-02, fs:0.87000 (r=0.879,p=0.861),  time:24.589, tt:1549.104\n",
      "Ep:63, loss:0.00003, loss_test:0.08253, lr:9.90e-03, fs:0.83077 (r=0.818,p=0.844),  time:24.590, tt:1573.753\n",
      "Ep:64, loss:0.00003, loss_test:0.08304, lr:9.80e-03, fs:0.80000 (r=0.768,p=0.835),  time:24.613, tt:1599.821\n",
      "Ep:65, loss:0.00003, loss_test:0.08019, lr:9.70e-03, fs:0.85279 (r=0.848,p=0.857),  time:24.615, tt:1624.571\n",
      "Ep:66, loss:0.00003, loss_test:0.08450, lr:9.61e-03, fs:0.80435 (r=0.747,p=0.871),  time:24.654, tt:1651.851\n",
      "Ep:67, loss:0.00003, loss_test:0.08185, lr:9.51e-03, fs:0.79365 (r=0.758,p=0.833),  time:24.669, tt:1677.524\n",
      "Ep:68, loss:0.00003, loss_test:0.08177, lr:9.41e-03, fs:0.81283 (r=0.768,p=0.864),  time:24.666, tt:1701.961\n",
      "Ep:69, loss:0.00003, loss_test:0.08723, lr:9.32e-03, fs:0.79781 (r=0.737,p=0.869),  time:24.681, tt:1727.640\n",
      "Ep:70, loss:0.00002, loss_test:0.07971, lr:9.23e-03, fs:0.85279 (r=0.848,p=0.857),  time:24.675, tt:1751.910\n",
      "Ep:71, loss:0.00002, loss_test:0.08486, lr:9.14e-03, fs:0.79348 (r=0.737,p=0.859),  time:24.665, tt:1775.897\n",
      "Ep:72, loss:0.00002, loss_test:0.08338, lr:9.04e-03, fs:0.78613 (r=0.687,p=0.919),  time:24.639, tt:1798.628\n",
      "Ep:73, loss:0.00002, loss_test:0.08127, lr:8.95e-03, fs:0.80000 (r=0.747,p=0.860),  time:24.655, tt:1824.452\n",
      "Ep:74, loss:0.00002, loss_test:0.08582, lr:8.86e-03, fs:0.77273 (r=0.687,p=0.883),  time:24.646, tt:1848.469\n",
      "Ep:75, loss:0.00002, loss_test:0.08220, lr:8.78e-03, fs:0.80899 (r=0.727,p=0.911),  time:24.647, tt:1873.182\n",
      "Ep:76, loss:0.00002, loss_test:0.08308, lr:8.69e-03, fs:0.78161 (r=0.687,p=0.907),  time:24.639, tt:1897.207\n",
      "Ep:77, loss:0.00002, loss_test:0.08403, lr:8.60e-03, fs:0.78161 (r=0.687,p=0.907),  time:24.643, tt:1922.149\n",
      "Ep:78, loss:0.00002, loss_test:0.08175, lr:8.51e-03, fs:0.76836 (r=0.687,p=0.872),  time:24.636, tt:1946.211\n",
      "Ep:79, loss:0.00002, loss_test:0.08365, lr:8.43e-03, fs:0.78161 (r=0.687,p=0.907),  time:24.646, tt:1971.683\n",
      "Ep:80, loss:0.00002, loss_test:0.08376, lr:8.35e-03, fs:0.78161 (r=0.687,p=0.907),  time:24.645, tt:1996.252\n",
      "Ep:81, loss:0.00002, loss_test:0.08202, lr:8.26e-03, fs:0.78161 (r=0.687,p=0.907),  time:24.664, tt:2022.423\n",
      "Ep:82, loss:0.00002, loss_test:0.08356, lr:8.18e-03, fs:0.78161 (r=0.687,p=0.907),  time:24.658, tt:2046.585\n",
      "Ep:83, loss:0.00002, loss_test:0.08471, lr:8.10e-03, fs:0.78161 (r=0.687,p=0.907),  time:24.659, tt:2071.357\n",
      "Ep:84, loss:0.00002, loss_test:0.08255, lr:8.02e-03, fs:0.78161 (r=0.687,p=0.907),  time:24.637, tt:2094.137\n",
      "Ep:85, loss:0.00002, loss_test:0.08511, lr:7.94e-03, fs:0.76301 (r=0.667,p=0.892),  time:24.638, tt:2118.872\n",
      "Ep:86, loss:0.00002, loss_test:0.08364, lr:7.86e-03, fs:0.78161 (r=0.687,p=0.907),  time:24.619, tt:2141.851\n",
      "Ep:87, loss:0.00002, loss_test:0.08439, lr:7.78e-03, fs:0.78161 (r=0.687,p=0.907),  time:24.622, tt:2166.713\n",
      "Ep:88, loss:0.00002, loss_test:0.08456, lr:7.70e-03, fs:0.78161 (r=0.687,p=0.907),  time:24.619, tt:2191.119\n",
      "Ep:89, loss:0.00001, loss_test:0.08297, lr:7.62e-03, fs:0.78161 (r=0.687,p=0.907),  time:24.600, tt:2214.015\n",
      "Ep:90, loss:0.00001, loss_test:0.08496, lr:7.55e-03, fs:0.78161 (r=0.687,p=0.907),  time:24.595, tt:2238.107\n",
      "Ep:91, loss:0.00001, loss_test:0.08513, lr:7.47e-03, fs:0.77714 (r=0.687,p=0.895),  time:24.586, tt:2261.875\n",
      "Ep:92, loss:0.00001, loss_test:0.08339, lr:7.40e-03, fs:0.78161 (r=0.687,p=0.907),  time:24.604, tt:2288.138\n",
      "Ep:93, loss:0.00001, loss_test:0.08702, lr:7.32e-03, fs:0.75740 (r=0.646,p=0.914),  time:24.608, tt:2313.198\n",
      "Ep:94, loss:0.00001, loss_test:0.08384, lr:7.25e-03, fs:0.77714 (r=0.687,p=0.895),  time:24.619, tt:2338.789\n",
      "Ep:95, loss:0.00001, loss_test:0.08528, lr:7.18e-03, fs:0.78161 (r=0.687,p=0.907),  time:24.601, tt:2361.727\n",
      "Ep:96, loss:0.00001, loss_test:0.08779, lr:7.11e-03, fs:0.75740 (r=0.646,p=0.914),  time:24.596, tt:2385.843\n",
      "Ep:97, loss:0.00001, loss_test:0.08330, lr:7.03e-03, fs:0.78161 (r=0.687,p=0.907),  time:24.578, tt:2408.600\n",
      "Ep:98, loss:0.00001, loss_test:0.08681, lr:6.96e-03, fs:0.76190 (r=0.646,p=0.928),  time:24.570, tt:2432.451\n",
      "Ep:99, loss:0.00001, loss_test:0.08745, lr:6.89e-03, fs:0.74251 (r=0.626,p=0.912),  time:24.566, tt:2456.603\n",
      "Ep:100, loss:0.00001, loss_test:0.08461, lr:6.83e-03, fs:0.78161 (r=0.687,p=0.907),  time:24.572, tt:2481.730\n",
      "Ep:101, loss:0.00001, loss_test:0.08817, lr:6.76e-03, fs:0.74251 (r=0.626,p=0.912),  time:24.562, tt:2505.333\n",
      "Ep:102, loss:0.00001, loss_test:0.08701, lr:6.69e-03, fs:0.75000 (r=0.636,p=0.913),  time:24.546, tt:2528.268\n",
      "Ep:103, loss:0.00001, loss_test:0.08597, lr:6.62e-03, fs:0.78613 (r=0.687,p=0.919),  time:24.553, tt:2553.524\n",
      "Ep:104, loss:0.00001, loss_test:0.08651, lr:6.56e-03, fs:0.74251 (r=0.626,p=0.912),  time:24.539, tt:2576.640\n",
      "Ep:105, loss:0.00001, loss_test:0.08626, lr:6.49e-03, fs:0.77907 (r=0.677,p=0.918),  time:24.543, tt:2601.517\n",
      "Ep:106, loss:0.00001, loss_test:0.08804, lr:6.43e-03, fs:0.79070 (r=0.687,p=0.932),  time:24.542, tt:2626.040\n",
      "Ep:107, loss:0.00001, loss_test:0.08784, lr:6.36e-03, fs:0.73939 (r=0.616,p=0.924),  time:24.528, tt:2649.064\n",
      "Ep:108, loss:0.00001, loss_test:0.08750, lr:6.30e-03, fs:0.77647 (r=0.667,p=0.930),  time:24.513, tt:2671.908\n",
      "Ep:109, loss:0.00001, loss_test:0.08615, lr:6.24e-03, fs:0.78363 (r=0.677,p=0.931),  time:24.504, tt:2695.492\n",
      "Ep:110, loss:0.00001, loss_test:0.08909, lr:6.17e-03, fs:0.74699 (r=0.626,p=0.925),  time:24.487, tt:2718.087\n",
      "Ep:111, loss:0.00001, loss_test:0.08793, lr:6.11e-03, fs:0.76923 (r=0.657,p=0.929),  time:24.486, tt:2742.451\n",
      "Ep:112, loss:0.00001, loss_test:0.08746, lr:6.05e-03, fs:0.74699 (r=0.626,p=0.925),  time:24.496, tt:2768.010\n",
      "Ep:113, loss:0.00001, loss_test:0.08867, lr:5.99e-03, fs:0.74699 (r=0.626,p=0.925),  time:24.504, tt:2793.438\n",
      "Ep:114, loss:0.00001, loss_test:0.08802, lr:5.93e-03, fs:0.74699 (r=0.626,p=0.925),  time:24.513, tt:2818.949\n",
      "Ep:115, loss:0.00001, loss_test:0.08889, lr:5.87e-03, fs:0.73939 (r=0.616,p=0.924),  time:24.523, tt:2844.672\n",
      "Ep:116, loss:0.00001, loss_test:0.09153, lr:5.81e-03, fs:0.73939 (r=0.616,p=0.924),  time:24.522, tt:2869.060\n",
      "Ep:117, loss:0.00001, loss_test:0.08803, lr:5.75e-03, fs:0.74699 (r=0.626,p=0.925),  time:24.525, tt:2893.974\n",
      "Ep:118, loss:0.00001, loss_test:0.08959, lr:5.70e-03, fs:0.73939 (r=0.616,p=0.924),  time:24.526, tt:2918.546\n",
      "Ep:119, loss:0.00001, loss_test:0.09104, lr:5.64e-03, fs:0.73939 (r=0.616,p=0.924),  time:24.515, tt:2941.778\n",
      "Ep:120, loss:0.00001, loss_test:0.08995, lr:5.58e-03, fs:0.73939 (r=0.616,p=0.924),  time:24.518, tt:2966.671\n",
      "Ep:121, loss:0.00001, loss_test:0.09105, lr:5.53e-03, fs:0.73939 (r=0.616,p=0.924),  time:24.532, tt:2992.848\n",
      "Ep:122, loss:0.00001, loss_test:0.09046, lr:5.47e-03, fs:0.73939 (r=0.616,p=0.924),  time:24.536, tt:3017.938\n",
      "Ep:123, loss:0.00001, loss_test:0.09194, lr:5.42e-03, fs:0.73939 (r=0.616,p=0.924),  time:24.561, tt:3045.619\n",
      "Ep:124, loss:0.00001, loss_test:0.09236, lr:5.36e-03, fs:0.73939 (r=0.616,p=0.924),  time:24.571, tt:3071.313\n",
      "Ep:125, loss:0.00001, loss_test:0.09063, lr:5.31e-03, fs:0.73939 (r=0.616,p=0.924),  time:24.584, tt:3097.557\n",
      "Ep:126, loss:0.00001, loss_test:0.09385, lr:5.26e-03, fs:0.73939 (r=0.616,p=0.924),  time:24.590, tt:3122.927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:127, loss:0.00001, loss_test:0.09290, lr:5.20e-03, fs:0.73939 (r=0.616,p=0.924),  time:24.605, tt:3149.450\n",
      "Ep:128, loss:0.00001, loss_test:0.09146, lr:5.15e-03, fs:0.73939 (r=0.616,p=0.924),  time:24.600, tt:3173.338\n",
      "Ep:129, loss:0.00001, loss_test:0.09347, lr:5.10e-03, fs:0.74390 (r=0.616,p=0.938),  time:24.601, tt:3198.095\n",
      "Ep:130, loss:0.00001, loss_test:0.09189, lr:5.05e-03, fs:0.73939 (r=0.616,p=0.924),  time:24.591, tt:3221.465\n",
      "Ep:131, loss:0.00001, loss_test:0.09166, lr:5.00e-03, fs:0.74390 (r=0.616,p=0.938),  time:24.596, tt:3246.708\n",
      "Ep:132, loss:0.00001, loss_test:0.09495, lr:4.95e-03, fs:0.74390 (r=0.616,p=0.938),  time:24.596, tt:3271.221\n",
      "Ep:133, loss:0.00001, loss_test:0.09516, lr:4.90e-03, fs:0.74390 (r=0.616,p=0.938),  time:24.592, tt:3295.312\n",
      "Ep:134, loss:0.00001, loss_test:0.09287, lr:4.85e-03, fs:0.74390 (r=0.616,p=0.938),  time:24.585, tt:3318.909\n",
      "Ep:135, loss:0.00001, loss_test:0.09462, lr:4.80e-03, fs:0.74390 (r=0.616,p=0.938),  time:24.570, tt:3341.537\n",
      "Ep:136, loss:0.00001, loss_test:0.09370, lr:4.75e-03, fs:0.74390 (r=0.616,p=0.938),  time:24.576, tt:3366.936\n",
      "Ep:137, loss:0.00001, loss_test:0.09406, lr:4.71e-03, fs:0.74390 (r=0.616,p=0.938),  time:24.569, tt:3390.495\n",
      "Ep:138, loss:0.00001, loss_test:0.09538, lr:4.66e-03, fs:0.74390 (r=0.616,p=0.938),  time:24.571, tt:3415.363\n",
      "Ep:139, loss:0.00001, loss_test:0.09448, lr:4.61e-03, fs:0.74390 (r=0.616,p=0.938),  time:24.554, tt:3437.502\n",
      "Ep:140, loss:0.00001, loss_test:0.09527, lr:4.57e-03, fs:0.74390 (r=0.616,p=0.938),  time:24.552, tt:3461.872\n",
      "Ep:141, loss:0.00001, loss_test:0.09630, lr:4.52e-03, fs:0.74390 (r=0.616,p=0.938),  time:24.557, tt:3487.026\n",
      "Ep:142, loss:0.00001, loss_test:0.09430, lr:4.48e-03, fs:0.74390 (r=0.616,p=0.938),  time:24.557, tt:3511.625\n",
      "Ep:143, loss:0.00001, loss_test:0.09510, lr:4.43e-03, fs:0.74390 (r=0.616,p=0.938),  time:24.553, tt:3535.704\n",
      "Ep:144, loss:0.00001, loss_test:0.09549, lr:4.39e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.546, tt:3559.165\n",
      "Ep:145, loss:0.00001, loss_test:0.09528, lr:4.34e-03, fs:0.74390 (r=0.616,p=0.938),  time:24.541, tt:3582.936\n",
      "Ep:146, loss:0.00001, loss_test:0.09601, lr:4.30e-03, fs:0.74390 (r=0.616,p=0.938),  time:24.540, tt:3607.427\n",
      "Ep:147, loss:0.00001, loss_test:0.09513, lr:4.26e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.534, tt:3630.995\n",
      "Ep:148, loss:0.00000, loss_test:0.09480, lr:4.21e-03, fs:0.74390 (r=0.616,p=0.938),  time:24.528, tt:3654.630\n",
      "Ep:149, loss:0.00000, loss_test:0.09547, lr:4.17e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.537, tt:3680.486\n",
      "Ep:150, loss:0.00000, loss_test:0.09560, lr:4.13e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.526, tt:3703.429\n",
      "Ep:151, loss:0.00000, loss_test:0.09570, lr:4.09e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.518, tt:3726.696\n",
      "Ep:152, loss:0.00000, loss_test:0.09391, lr:4.05e-03, fs:0.74390 (r=0.616,p=0.938),  time:24.513, tt:3750.440\n",
      "Ep:153, loss:0.00000, loss_test:0.09577, lr:4.01e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.510, tt:3774.469\n",
      "Ep:154, loss:0.00000, loss_test:0.09549, lr:3.97e-03, fs:0.74390 (r=0.616,p=0.938),  time:24.476, tt:3793.796\n",
      "Ep:155, loss:0.00000, loss_test:0.09578, lr:3.93e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.444, tt:3813.226\n",
      "Ep:156, loss:0.00000, loss_test:0.09601, lr:3.89e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.409, tt:3832.289\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14401, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.401, tt:40.401\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14253, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:40.459, tt:80.918\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13981, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:39.283, tt:117.848\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.13488, lr:1.00e-02, fs:0.67128 (r=0.980,p=0.511),  time:39.833, tt:159.333\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.12623, lr:1.00e-02, fs:0.64151 (r=0.859,p=0.512),  time:40.273, tt:201.367\n",
      "Ep:5, loss:0.00024, loss_test:0.11743, lr:1.00e-02, fs:0.65502 (r=0.758,p=0.577),  time:40.745, tt:244.470\n",
      "Ep:6, loss:0.00023, loss_test:0.11381, lr:1.00e-02, fs:0.65741 (r=0.717,p=0.607),  time:40.993, tt:286.953\n",
      "Ep:7, loss:0.00022, loss_test:0.11141, lr:1.00e-02, fs:0.66981 (r=0.717,p=0.628),  time:41.124, tt:328.989\n",
      "Ep:8, loss:0.00022, loss_test:0.10991, lr:1.00e-02, fs:0.68932 (r=0.717,p=0.664),  time:40.754, tt:366.782\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.10804, lr:1.00e-02, fs:0.67619 (r=0.717,p=0.640),  time:40.892, tt:408.918\n",
      "Ep:10, loss:0.00020, loss_test:0.10608, lr:1.00e-02, fs:0.68269 (r=0.717,p=0.651),  time:40.812, tt:448.937\n",
      "Ep:11, loss:0.00020, loss_test:0.10396, lr:1.00e-02, fs:0.72897 (r=0.788,p=0.678),  time:41.202, tt:494.424\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.10258, lr:1.00e-02, fs:0.73832 (r=0.798,p=0.687),  time:41.270, tt:536.514\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.10093, lr:1.00e-02, fs:0.73077 (r=0.768,p=0.697),  time:41.290, tt:578.053\n",
      "Ep:14, loss:0.00018, loss_test:0.09952, lr:1.00e-02, fs:0.73786 (r=0.768,p=0.710),  time:41.437, tt:621.561\n",
      "Ep:15, loss:0.00018, loss_test:0.09804, lr:1.00e-02, fs:0.73267 (r=0.747,p=0.718),  time:41.664, tt:666.618\n",
      "Ep:16, loss:0.00017, loss_test:0.09694, lr:1.00e-02, fs:0.74627 (r=0.758,p=0.735),  time:41.636, tt:707.817\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.09636, lr:1.00e-02, fs:0.73171 (r=0.758,p=0.708),  time:41.700, tt:750.600\n",
      "Ep:18, loss:0.00017, loss_test:0.09571, lr:1.00e-02, fs:0.75377 (r=0.758,p=0.750),  time:41.619, tt:790.770\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.09521, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:41.614, tt:832.286\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.09480, lr:1.00e-02, fs:0.76617 (r=0.778,p=0.755),  time:41.468, tt:870.833\n",
      "Ep:21, loss:0.00015, loss_test:0.09451, lr:1.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:41.444, tt:911.760\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.09450, lr:1.00e-02, fs:0.76382 (r=0.768,p=0.760),  time:41.549, tt:955.631\n",
      "Ep:23, loss:0.00015, loss_test:0.09337, lr:1.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:41.659, tt:999.818\n",
      "Ep:24, loss:0.00014, loss_test:0.09357, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:41.627, tt:1040.685\n",
      "Ep:25, loss:0.00014, loss_test:0.09243, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:41.622, tt:1082.160\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.09212, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:41.606, tt:1123.364\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.09125, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:41.543, tt:1163.196\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.09113, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:41.533, tt:1204.456\n",
      "Ep:29, loss:0.00013, loss_test:0.09009, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:41.452, tt:1243.552\n",
      "Ep:30, loss:0.00013, loss_test:0.09078, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:41.453, tt:1285.057\n",
      "Ep:31, loss:0.00012, loss_test:0.08966, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:41.402, tt:1324.869\n",
      "Ep:32, loss:0.00012, loss_test:0.09015, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:41.360, tt:1364.881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:33, loss:0.00012, loss_test:0.09000, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:41.385, tt:1407.105\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00012, loss_test:0.08822, lr:1.00e-02, fs:0.82902 (r=0.808,p=0.851),  time:41.313, tt:1445.964\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.09052, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:41.277, tt:1485.979\n",
      "Ep:36, loss:0.00011, loss_test:0.08768, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:41.288, tt:1527.647\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00011, loss_test:0.09208, lr:1.00e-02, fs:0.77005 (r=0.727,p=0.818),  time:41.302, tt:1569.474\n",
      "Ep:38, loss:0.00011, loss_test:0.08786, lr:1.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:41.342, tt:1612.346\n",
      "Ep:39, loss:0.00011, loss_test:0.09265, lr:1.00e-02, fs:0.75132 (r=0.717,p=0.789),  time:41.365, tt:1654.597\n",
      "Ep:40, loss:0.00010, loss_test:0.08861, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:41.345, tt:1695.160\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00011, loss_test:0.09441, lr:1.00e-02, fs:0.74346 (r=0.717,p=0.772),  time:41.351, tt:1736.756\n",
      "Ep:42, loss:0.00010, loss_test:0.08773, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:41.365, tt:1778.700\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00010, loss_test:0.09316, lr:1.00e-02, fs:0.75556 (r=0.687,p=0.840),  time:41.357, tt:1819.698\n",
      "Ep:44, loss:0.00010, loss_test:0.08927, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:41.328, tt:1859.766\n",
      "Ep:45, loss:0.00010, loss_test:0.09231, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:41.391, tt:1903.998\n",
      "Ep:46, loss:0.00009, loss_test:0.08786, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:41.388, tt:1945.230\n",
      "Ep:47, loss:0.00009, loss_test:0.08967, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:41.387, tt:1986.574\n",
      "Ep:48, loss:0.00009, loss_test:0.08879, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:41.415, tt:2029.346\n",
      "Ep:49, loss:0.00009, loss_test:0.08722, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:41.409, tt:2070.446\n",
      "Ep:50, loss:0.00008, loss_test:0.08784, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:41.399, tt:2111.358\n",
      "Ep:51, loss:0.00008, loss_test:0.08843, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:41.415, tt:2153.601\n",
      "Ep:52, loss:0.00008, loss_test:0.08640, lr:1.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:41.403, tt:2194.344\n",
      "Ep:53, loss:0.00008, loss_test:0.08958, lr:1.00e-02, fs:0.80000 (r=0.747,p=0.860),  time:41.398, tt:2235.487\n",
      "Ep:54, loss:0.00008, loss_test:0.08727, lr:9.90e-03, fs:0.85128 (r=0.838,p=0.865),  time:41.354, tt:2274.466\n",
      "Ep:55, loss:0.00007, loss_test:0.09166, lr:9.80e-03, fs:0.76923 (r=0.707,p=0.843),  time:41.330, tt:2314.468\n",
      "Ep:56, loss:0.00007, loss_test:0.08663, lr:9.70e-03, fs:0.84974 (r=0.828,p=0.872),  time:41.295, tt:2353.792\n",
      "Ep:57, loss:0.00007, loss_test:0.08806, lr:9.61e-03, fs:0.81053 (r=0.778,p=0.846),  time:41.268, tt:2393.566\n",
      "Ep:58, loss:0.00007, loss_test:0.08850, lr:9.51e-03, fs:0.82796 (r=0.778,p=0.885),  time:41.271, tt:2434.986\n",
      "Ep:59, loss:0.00007, loss_test:0.08810, lr:9.41e-03, fs:0.81319 (r=0.747,p=0.892),  time:41.279, tt:2476.733\n",
      "Ep:60, loss:0.00007, loss_test:0.08948, lr:9.32e-03, fs:0.79144 (r=0.747,p=0.841),  time:41.278, tt:2517.930\n",
      "Ep:61, loss:0.00007, loss_test:0.08846, lr:9.23e-03, fs:0.84946 (r=0.798,p=0.908),  time:41.274, tt:2558.994\n",
      "Ep:62, loss:0.00007, loss_test:0.08999, lr:9.14e-03, fs:0.78261 (r=0.727,p=0.847),  time:41.258, tt:2599.238\n",
      "Ep:63, loss:0.00008, loss_test:0.09249, lr:9.04e-03, fs:0.80788 (r=0.828,p=0.788),  time:41.278, tt:2641.782\n",
      "Ep:64, loss:0.00008, loss_test:0.09660, lr:8.95e-03, fs:0.75789 (r=0.727,p=0.791),  time:41.308, tt:2685.004\n",
      "Ep:65, loss:0.00008, loss_test:0.08706, lr:8.86e-03, fs:0.85263 (r=0.818,p=0.890),  time:41.314, tt:2726.702\n",
      "Ep:66, loss:0.00008, loss_test:0.09012, lr:8.78e-03, fs:0.77966 (r=0.697,p=0.885),  time:41.345, tt:2770.102\n",
      "Ep:67, loss:0.00007, loss_test:0.08893, lr:8.69e-03, fs:0.81522 (r=0.758,p=0.882),  time:41.365, tt:2812.790\n",
      "Ep:68, loss:0.00007, loss_test:0.08874, lr:8.60e-03, fs:0.80000 (r=0.768,p=0.835),  time:41.398, tt:2856.434\n",
      "Ep:69, loss:0.00007, loss_test:0.08730, lr:8.51e-03, fs:0.80447 (r=0.727,p=0.900),  time:41.423, tt:2899.630\n",
      "Ep:70, loss:0.00006, loss_test:0.09156, lr:8.43e-03, fs:0.80214 (r=0.758,p=0.852),  time:41.433, tt:2941.721\n",
      "Ep:71, loss:0.00006, loss_test:0.08898, lr:8.35e-03, fs:0.78022 (r=0.717,p=0.855),  time:41.451, tt:2984.489\n",
      "Ep:72, loss:0.00006, loss_test:0.08971, lr:8.26e-03, fs:0.82418 (r=0.758,p=0.904),  time:41.491, tt:3028.852\n",
      "Ep:73, loss:0.00006, loss_test:0.08813, lr:8.18e-03, fs:0.77273 (r=0.687,p=0.883),  time:41.538, tt:3073.834\n",
      "Ep:74, loss:0.00006, loss_test:0.08761, lr:8.10e-03, fs:0.83871 (r=0.788,p=0.897),  time:41.546, tt:3115.928\n",
      "Ep:75, loss:0.00005, loss_test:0.08673, lr:8.02e-03, fs:0.76571 (r=0.677,p=0.882),  time:41.602, tt:3161.766\n",
      "Ep:76, loss:0.00005, loss_test:0.08743, lr:7.94e-03, fs:0.84324 (r=0.788,p=0.907),  time:41.660, tt:3207.854\n",
      "Ep:77, loss:0.00005, loss_test:0.08694, lr:7.86e-03, fs:0.76571 (r=0.677,p=0.882),  time:41.717, tt:3253.950\n",
      "Ep:78, loss:0.00005, loss_test:0.08683, lr:7.78e-03, fs:0.82222 (r=0.747,p=0.914),  time:41.753, tt:3298.503\n",
      "Ep:79, loss:0.00005, loss_test:0.08595, lr:7.70e-03, fs:0.77528 (r=0.697,p=0.873),  time:41.796, tt:3343.680\n",
      "Ep:80, loss:0.00005, loss_test:0.08853, lr:7.62e-03, fs:0.84492 (r=0.798,p=0.898),  time:41.838, tt:3388.847\n",
      "Ep:81, loss:0.00005, loss_test:0.08730, lr:7.55e-03, fs:0.78652 (r=0.707,p=0.886),  time:41.849, tt:3431.628\n",
      "Ep:82, loss:0.00004, loss_test:0.08673, lr:7.47e-03, fs:0.86631 (r=0.818,p=0.920),  time:41.858, tt:3474.220\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00004, loss_test:0.08561, lr:7.47e-03, fs:0.80663 (r=0.737,p=0.890),  time:41.883, tt:3518.166\n",
      "Ep:84, loss:0.00004, loss_test:0.08706, lr:7.47e-03, fs:0.85870 (r=0.798,p=0.929),  time:41.905, tt:3561.913\n",
      "Ep:85, loss:0.00004, loss_test:0.08716, lr:7.47e-03, fs:0.85405 (r=0.798,p=0.919),  time:41.902, tt:3603.609\n",
      "Ep:86, loss:0.00004, loss_test:0.08567, lr:7.47e-03, fs:0.84615 (r=0.778,p=0.928),  time:41.949, tt:3649.603\n",
      "Ep:87, loss:0.00004, loss_test:0.08740, lr:7.47e-03, fs:0.85405 (r=0.798,p=0.919),  time:41.947, tt:3691.375\n",
      "Ep:88, loss:0.00004, loss_test:0.08563, lr:7.47e-03, fs:0.83978 (r=0.768,p=0.927),  time:41.977, tt:3735.927\n",
      "Ep:89, loss:0.00004, loss_test:0.08613, lr:7.47e-03, fs:0.84444 (r=0.768,p=0.938),  time:42.022, tt:3781.949\n",
      "Ep:90, loss:0.00004, loss_test:0.08584, lr:7.47e-03, fs:0.87097 (r=0.818,p=0.931),  time:42.065, tt:3827.927\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00004, loss_test:0.08596, lr:7.47e-03, fs:0.86170 (r=0.818,p=0.910),  time:42.105, tt:3873.634\n",
      "Ep:92, loss:0.00004, loss_test:0.08726, lr:7.47e-03, fs:0.84444 (r=0.768,p=0.938),  time:42.125, tt:3917.627\n",
      "Ep:93, loss:0.00004, loss_test:0.08572, lr:7.47e-03, fs:0.86486 (r=0.808,p=0.930),  time:42.142, tt:3961.305\n",
      "Ep:94, loss:0.00003, loss_test:0.08677, lr:7.47e-03, fs:0.87568 (r=0.818,p=0.942),  time:42.134, tt:4002.687\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00003, loss_test:0.08565, lr:7.47e-03, fs:0.83978 (r=0.768,p=0.927),  time:42.134, tt:4044.892\n",
      "Ep:96, loss:0.00003, loss_test:0.08746, lr:7.47e-03, fs:0.87432 (r=0.808,p=0.952),  time:42.163, tt:4089.763\n",
      "Ep:97, loss:0.00003, loss_test:0.08525, lr:7.47e-03, fs:0.86486 (r=0.808,p=0.930),  time:42.184, tt:4134.058\n",
      "Ep:98, loss:0.00003, loss_test:0.08594, lr:7.47e-03, fs:0.84444 (r=0.768,p=0.938),  time:42.202, tt:4178.046\n",
      "Ep:99, loss:0.00003, loss_test:0.08625, lr:7.47e-03, fs:0.87568 (r=0.818,p=0.942),  time:42.225, tt:4222.469\n",
      "Ep:100, loss:0.00003, loss_test:0.08676, lr:7.47e-03, fs:0.86631 (r=0.818,p=0.920),  time:42.219, tt:4264.164\n",
      "Ep:101, loss:0.00003, loss_test:0.08739, lr:7.47e-03, fs:0.87432 (r=0.808,p=0.952),  time:42.222, tt:4306.651\n",
      "Ep:102, loss:0.00003, loss_test:0.08489, lr:7.47e-03, fs:0.87568 (r=0.818,p=0.942),  time:42.228, tt:4349.467\n",
      "Ep:103, loss:0.00003, loss_test:0.08624, lr:7.47e-03, fs:0.87097 (r=0.818,p=0.931),  time:42.230, tt:4391.945\n",
      "Ep:104, loss:0.00003, loss_test:0.08775, lr:7.47e-03, fs:0.87432 (r=0.808,p=0.952),  time:42.216, tt:4432.657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:105, loss:0.00003, loss_test:0.08508, lr:7.47e-03, fs:0.87097 (r=0.818,p=0.931),  time:42.212, tt:4474.505\n",
      "Ep:106, loss:0.00003, loss_test:0.08487, lr:7.40e-03, fs:0.87568 (r=0.818,p=0.942),  time:42.245, tt:4520.252\n",
      "Ep:107, loss:0.00003, loss_test:0.08611, lr:7.32e-03, fs:0.87432 (r=0.808,p=0.952),  time:42.254, tt:4563.426\n",
      "Ep:108, loss:0.00003, loss_test:0.08783, lr:7.25e-03, fs:0.86170 (r=0.818,p=0.910),  time:42.251, tt:4605.344\n",
      "Ep:109, loss:0.00003, loss_test:0.08532, lr:7.18e-03, fs:0.86339 (r=0.798,p=0.940),  time:42.245, tt:4646.948\n",
      "Ep:110, loss:0.00003, loss_test:0.08785, lr:7.11e-03, fs:0.87097 (r=0.818,p=0.931),  time:42.232, tt:4687.753\n",
      "Ep:111, loss:0.00003, loss_test:0.08790, lr:7.03e-03, fs:0.87568 (r=0.818,p=0.942),  time:42.237, tt:4730.572\n",
      "Ep:112, loss:0.00003, loss_test:0.08497, lr:6.96e-03, fs:0.85083 (r=0.778,p=0.939),  time:42.240, tt:4773.156\n",
      "Ep:113, loss:0.00003, loss_test:0.08727, lr:6.89e-03, fs:0.87568 (r=0.818,p=0.942),  time:42.217, tt:4812.731\n",
      "Ep:114, loss:0.00003, loss_test:0.08510, lr:6.83e-03, fs:0.81564 (r=0.737,p=0.912),  time:42.203, tt:4853.390\n",
      "Ep:115, loss:0.00003, loss_test:0.09076, lr:6.76e-03, fs:0.87097 (r=0.818,p=0.931),  time:42.193, tt:4894.363\n",
      "Ep:116, loss:0.00003, loss_test:0.08498, lr:6.69e-03, fs:0.82873 (r=0.758,p=0.915),  time:42.197, tt:4937.091\n",
      "Ep:117, loss:0.00003, loss_test:0.08840, lr:6.62e-03, fs:0.87568 (r=0.818,p=0.942),  time:42.200, tt:4979.544\n",
      "Ep:118, loss:0.00003, loss_test:0.08554, lr:6.56e-03, fs:0.80682 (r=0.717,p=0.922),  time:42.219, tt:5024.075\n",
      "Ep:119, loss:0.00003, loss_test:0.08860, lr:6.49e-03, fs:0.87097 (r=0.818,p=0.931),  time:42.217, tt:5066.002\n",
      "Ep:120, loss:0.00003, loss_test:0.08454, lr:6.43e-03, fs:0.80682 (r=0.717,p=0.922),  time:42.221, tt:5108.712\n",
      "Ep:121, loss:0.00003, loss_test:0.09203, lr:6.36e-03, fs:0.87097 (r=0.818,p=0.931),  time:42.217, tt:5150.436\n",
      "Ep:122, loss:0.00003, loss_test:0.08574, lr:6.30e-03, fs:0.80226 (r=0.717,p=0.910),  time:42.213, tt:5192.203\n",
      "Ep:123, loss:0.00003, loss_test:0.08937, lr:6.24e-03, fs:0.87568 (r=0.818,p=0.942),  time:42.207, tt:5233.610\n",
      "Ep:124, loss:0.00003, loss_test:0.08591, lr:6.17e-03, fs:0.81143 (r=0.717,p=0.934),  time:42.209, tt:5276.073\n",
      "Ep:125, loss:0.00002, loss_test:0.08913, lr:6.11e-03, fs:0.87568 (r=0.818,p=0.942),  time:42.192, tt:5316.244\n",
      "Ep:126, loss:0.00002, loss_test:0.08559, lr:6.05e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.199, tt:5359.244\n",
      "Ep:127, loss:0.00002, loss_test:0.08868, lr:5.99e-03, fs:0.85714 (r=0.788,p=0.940),  time:42.203, tt:5401.929\n",
      "Ep:128, loss:0.00002, loss_test:0.08481, lr:5.93e-03, fs:0.86188 (r=0.788,p=0.951),  time:42.204, tt:5444.339\n",
      "Ep:129, loss:0.00002, loss_test:0.08640, lr:5.87e-03, fs:0.88525 (r=0.818,p=0.964),  time:42.192, tt:5484.995\n",
      "##########Best model found so far##########\n",
      "Ep:130, loss:0.00002, loss_test:0.08785, lr:5.87e-03, fs:0.86813 (r=0.798,p=0.952),  time:42.203, tt:5528.611\n",
      "Ep:131, loss:0.00002, loss_test:0.08519, lr:5.87e-03, fs:0.84746 (r=0.758,p=0.962),  time:42.209, tt:5571.599\n",
      "Ep:132, loss:0.00002, loss_test:0.08777, lr:5.87e-03, fs:0.87568 (r=0.818,p=0.942),  time:42.202, tt:5612.850\n",
      "Ep:133, loss:0.00002, loss_test:0.08625, lr:5.87e-03, fs:0.82558 (r=0.717,p=0.973),  time:42.202, tt:5655.046\n",
      "Ep:134, loss:0.00002, loss_test:0.08836, lr:5.87e-03, fs:0.87568 (r=0.818,p=0.942),  time:42.170, tt:5692.925\n",
      "Ep:135, loss:0.00002, loss_test:0.08497, lr:5.87e-03, fs:0.84746 (r=0.758,p=0.962),  time:42.170, tt:5735.160\n",
      "Ep:136, loss:0.00002, loss_test:0.08794, lr:5.87e-03, fs:0.86188 (r=0.788,p=0.951),  time:42.146, tt:5774.026\n",
      "Ep:137, loss:0.00002, loss_test:0.08660, lr:5.87e-03, fs:0.86667 (r=0.788,p=0.963),  time:42.141, tt:5815.490\n",
      "Ep:138, loss:0.00002, loss_test:0.08493, lr:5.87e-03, fs:0.84571 (r=0.747,p=0.974),  time:42.153, tt:5859.221\n",
      "Ep:139, loss:0.00002, loss_test:0.08658, lr:5.87e-03, fs:0.87432 (r=0.808,p=0.952),  time:42.153, tt:5901.370\n",
      "Ep:140, loss:0.00002, loss_test:0.08496, lr:5.87e-03, fs:0.82759 (r=0.727,p=0.960),  time:42.154, tt:5943.776\n",
      "Ep:141, loss:0.00002, loss_test:0.08852, lr:5.81e-03, fs:0.87432 (r=0.808,p=0.952),  time:42.154, tt:5985.808\n",
      "Ep:142, loss:0.00002, loss_test:0.08558, lr:5.75e-03, fs:0.84091 (r=0.747,p=0.961),  time:42.156, tt:6028.241\n",
      "Ep:143, loss:0.00002, loss_test:0.08736, lr:5.70e-03, fs:0.86667 (r=0.788,p=0.963),  time:42.146, tt:6069.017\n",
      "Ep:144, loss:0.00002, loss_test:0.08720, lr:5.64e-03, fs:0.84746 (r=0.758,p=0.962),  time:42.148, tt:6111.444\n",
      "Ep:145, loss:0.00002, loss_test:0.08724, lr:5.58e-03, fs:0.84091 (r=0.747,p=0.961),  time:42.150, tt:6153.956\n",
      "Ep:146, loss:0.00002, loss_test:0.08731, lr:5.53e-03, fs:0.86034 (r=0.778,p=0.963),  time:42.160, tt:6197.512\n",
      "Ep:147, loss:0.00002, loss_test:0.08588, lr:5.47e-03, fs:0.84746 (r=0.758,p=0.962),  time:42.156, tt:6239.062\n",
      "Ep:148, loss:0.00002, loss_test:0.08634, lr:5.42e-03, fs:0.84746 (r=0.758,p=0.962),  time:42.140, tt:6278.854\n",
      "Ep:149, loss:0.00002, loss_test:0.08695, lr:5.36e-03, fs:0.86667 (r=0.788,p=0.963),  time:42.144, tt:6321.629\n",
      "Ep:150, loss:0.00002, loss_test:0.08665, lr:5.31e-03, fs:0.84746 (r=0.758,p=0.962),  time:42.141, tt:6363.304\n",
      "Ep:151, loss:0.00002, loss_test:0.08768, lr:5.26e-03, fs:0.84091 (r=0.747,p=0.961),  time:42.144, tt:6405.827\n",
      "Ep:152, loss:0.00002, loss_test:0.08636, lr:5.20e-03, fs:0.84091 (r=0.747,p=0.961),  time:42.133, tt:6446.425\n",
      "Ep:153, loss:0.00002, loss_test:0.08664, lr:5.15e-03, fs:0.83429 (r=0.737,p=0.961),  time:42.126, tt:6487.365\n",
      "Ep:154, loss:0.00002, loss_test:0.08748, lr:5.10e-03, fs:0.83429 (r=0.737,p=0.961),  time:42.083, tt:6522.864\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14643, lr:1.00e-02, fs:0.64384 (r=0.949,p=0.487),  time:39.582, tt:39.582\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14522, lr:1.00e-02, fs:0.64138 (r=0.939,p=0.487),  time:41.432, tt:82.864\n",
      "Ep:2, loss:0.00027, loss_test:0.14283, lr:1.00e-02, fs:0.65018 (r=0.929,p=0.500),  time:41.821, tt:125.464\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.13920, lr:1.00e-02, fs:0.65918 (r=0.889,p=0.524),  time:41.737, tt:166.947\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.13538, lr:1.00e-02, fs:0.63866 (r=0.768,p=0.547),  time:41.676, tt:208.378\n",
      "Ep:5, loss:0.00023, loss_test:0.13431, lr:1.00e-02, fs:0.63964 (r=0.717,p=0.577),  time:41.601, tt:249.606\n",
      "Ep:6, loss:0.00022, loss_test:0.13833, lr:1.00e-02, fs:0.60784 (r=0.626,p=0.590),  time:41.484, tt:290.389\n",
      "Ep:7, loss:0.00021, loss_test:0.13871, lr:1.00e-02, fs:0.59794 (r=0.586,p=0.611),  time:41.684, tt:333.469\n",
      "Ep:8, loss:0.00021, loss_test:0.13504, lr:1.00e-02, fs:0.64706 (r=0.667,p=0.629),  time:41.382, tt:372.441\n",
      "Ep:9, loss:0.00020, loss_test:0.13275, lr:1.00e-02, fs:0.65366 (r=0.677,p=0.632),  time:41.648, tt:416.476\n",
      "Ep:10, loss:0.00019, loss_test:0.13289, lr:1.00e-02, fs:0.64249 (r=0.626,p=0.660),  time:41.769, tt:459.463\n",
      "Ep:11, loss:0.00019, loss_test:0.13211, lr:1.00e-02, fs:0.65979 (r=0.646,p=0.674),  time:41.831, tt:501.967\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.13071, lr:1.00e-02, fs:0.64615 (r=0.636,p=0.656),  time:41.912, tt:544.853\n",
      "Ep:13, loss:0.00018, loss_test:0.12955, lr:1.00e-02, fs:0.61458 (r=0.596,p=0.634),  time:41.917, tt:586.840\n",
      "Ep:14, loss:0.00017, loss_test:0.12741, lr:1.00e-02, fs:0.60417 (r=0.586,p=0.624),  time:41.733, tt:625.997\n",
      "Ep:15, loss:0.00017, loss_test:0.12703, lr:1.00e-02, fs:0.59893 (r=0.566,p=0.636),  time:41.709, tt:667.338\n",
      "Ep:16, loss:0.00016, loss_test:0.12697, lr:1.00e-02, fs:0.60215 (r=0.566,p=0.644),  time:41.758, tt:709.881\n",
      "Ep:17, loss:0.00016, loss_test:0.12532, lr:1.00e-02, fs:0.60317 (r=0.576,p=0.633),  time:41.849, tt:753.285\n",
      "Ep:18, loss:0.00016, loss_test:0.12458, lr:1.00e-02, fs:0.59574 (r=0.566,p=0.629),  time:41.965, tt:797.332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:19, loss:0.00015, loss_test:0.12567, lr:1.00e-02, fs:0.60870 (r=0.566,p=0.659),  time:42.056, tt:841.120\n",
      "Ep:20, loss:0.00015, loss_test:0.12383, lr:1.00e-02, fs:0.59783 (r=0.556,p=0.647),  time:42.019, tt:882.399\n",
      "Ep:21, loss:0.00015, loss_test:0.12231, lr:1.00e-02, fs:0.59783 (r=0.556,p=0.647),  time:42.019, tt:924.422\n",
      "Ep:22, loss:0.00014, loss_test:0.12340, lr:1.00e-02, fs:0.60000 (r=0.545,p=0.667),  time:42.058, tt:967.330\n",
      "Ep:23, loss:0.00014, loss_test:0.12266, lr:9.90e-03, fs:0.59218 (r=0.535,p=0.662),  time:42.157, tt:1011.776\n",
      "Ep:24, loss:0.00014, loss_test:0.12219, lr:9.80e-03, fs:0.58889 (r=0.535,p=0.654),  time:42.224, tt:1055.611\n",
      "Ep:25, loss:0.00013, loss_test:0.12231, lr:9.70e-03, fs:0.58889 (r=0.535,p=0.654),  time:42.268, tt:1098.963\n",
      "Ep:26, loss:0.00013, loss_test:0.12240, lr:9.61e-03, fs:0.59218 (r=0.535,p=0.662),  time:42.304, tt:1142.215\n",
      "Ep:27, loss:0.00013, loss_test:0.12388, lr:9.51e-03, fs:0.56647 (r=0.495,p=0.662),  time:42.310, tt:1184.678\n",
      "Ep:28, loss:0.00012, loss_test:0.12048, lr:9.41e-03, fs:0.58242 (r=0.535,p=0.639),  time:42.337, tt:1227.774\n",
      "Ep:29, loss:0.00012, loss_test:0.12289, lr:9.32e-03, fs:0.55491 (r=0.485,p=0.649),  time:42.378, tt:1271.325\n",
      "Ep:30, loss:0.00012, loss_test:0.12203, lr:9.23e-03, fs:0.56818 (r=0.505,p=0.649),  time:42.401, tt:1314.436\n",
      "Ep:31, loss:0.00012, loss_test:0.12111, lr:9.14e-03, fs:0.57778 (r=0.525,p=0.642),  time:42.441, tt:1358.125\n",
      "Ep:32, loss:0.00011, loss_test:0.12188, lr:9.04e-03, fs:0.57471 (r=0.505,p=0.667),  time:42.434, tt:1400.328\n",
      "Ep:33, loss:0.00011, loss_test:0.12092, lr:8.95e-03, fs:0.58427 (r=0.525,p=0.658),  time:42.572, tt:1447.452\n",
      "Ep:34, loss:0.00011, loss_test:0.12307, lr:8.86e-03, fs:0.56471 (r=0.485,p=0.676),  time:42.581, tt:1490.346\n",
      "Ep:35, loss:0.00011, loss_test:0.12023, lr:8.78e-03, fs:0.57627 (r=0.515,p=0.654),  time:42.608, tt:1533.882\n",
      "Ep:36, loss:0.00010, loss_test:0.11999, lr:8.69e-03, fs:0.58286 (r=0.515,p=0.671),  time:42.623, tt:1577.058\n",
      "Ep:37, loss:0.00010, loss_test:0.12125, lr:8.60e-03, fs:0.55814 (r=0.485,p=0.658),  time:42.628, tt:1619.849\n",
      "Ep:38, loss:0.00010, loss_test:0.11975, lr:8.51e-03, fs:0.55491 (r=0.485,p=0.649),  time:42.640, tt:1662.952\n",
      "Ep:39, loss:0.00010, loss_test:0.12064, lr:8.43e-03, fs:0.56977 (r=0.495,p=0.671),  time:42.601, tt:1704.051\n",
      "Ep:40, loss:0.00010, loss_test:0.11979, lr:8.35e-03, fs:0.56805 (r=0.485,p=0.686),  time:42.625, tt:1747.627\n",
      "Ep:41, loss:0.00009, loss_test:0.11796, lr:8.26e-03, fs:0.61878 (r=0.566,p=0.683),  time:42.687, tt:1792.855\n",
      "Ep:42, loss:0.00009, loss_test:0.11975, lr:8.18e-03, fs:0.59302 (r=0.515,p=0.699),  time:42.714, tt:1836.686\n",
      "Ep:43, loss:0.00009, loss_test:0.11796, lr:8.10e-03, fs:0.61714 (r=0.545,p=0.711),  time:42.762, tt:1881.517\n",
      "Ep:44, loss:0.00009, loss_test:0.11888, lr:8.02e-03, fs:0.61798 (r=0.556,p=0.696),  time:42.810, tt:1926.453\n",
      "Ep:45, loss:0.00009, loss_test:0.12032, lr:7.94e-03, fs:0.59172 (r=0.505,p=0.714),  time:42.834, tt:1970.377\n",
      "Ep:46, loss:0.00008, loss_test:0.11848, lr:7.86e-03, fs:0.61798 (r=0.556,p=0.696),  time:42.904, tt:2016.471\n",
      "Ep:47, loss:0.00008, loss_test:0.11823, lr:7.78e-03, fs:0.60819 (r=0.525,p=0.722),  time:42.894, tt:2058.905\n",
      "Ep:48, loss:0.00008, loss_test:0.11834, lr:7.70e-03, fs:0.64444 (r=0.586,p=0.716),  time:42.921, tt:2103.114\n",
      "Ep:49, loss:0.00008, loss_test:0.11877, lr:7.62e-03, fs:0.60819 (r=0.525,p=0.722),  time:42.921, tt:2146.045\n",
      "Ep:50, loss:0.00008, loss_test:0.11930, lr:7.55e-03, fs:0.64368 (r=0.566,p=0.747),  time:42.949, tt:2190.389\n",
      "Ep:51, loss:0.00008, loss_test:0.11670, lr:7.47e-03, fs:0.65934 (r=0.606,p=0.723),  time:42.968, tt:2234.316\n",
      "Ep:52, loss:0.00007, loss_test:0.11782, lr:7.40e-03, fs:0.64740 (r=0.566,p=0.757),  time:42.930, tt:2275.307\n",
      "Ep:53, loss:0.00007, loss_test:0.11704, lr:7.32e-03, fs:0.63218 (r=0.556,p=0.733),  time:42.930, tt:2318.231\n",
      "Ep:54, loss:0.00007, loss_test:0.11704, lr:7.25e-03, fs:0.66286 (r=0.586,p=0.763),  time:42.939, tt:2361.655\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00007, loss_test:0.11897, lr:7.25e-03, fs:0.62722 (r=0.535,p=0.757),  time:42.930, tt:2404.068\n",
      "Ep:56, loss:0.00007, loss_test:0.11567, lr:7.25e-03, fs:0.66292 (r=0.596,p=0.747),  time:42.931, tt:2447.087\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00007, loss_test:0.11840, lr:7.25e-03, fs:0.63905 (r=0.545,p=0.771),  time:42.927, tt:2489.764\n",
      "Ep:58, loss:0.00007, loss_test:0.11845, lr:7.25e-03, fs:0.64740 (r=0.566,p=0.757),  time:42.929, tt:2532.791\n",
      "Ep:59, loss:0.00007, loss_test:0.11557, lr:7.25e-03, fs:0.67045 (r=0.596,p=0.766),  time:42.903, tt:2574.194\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00006, loss_test:0.11558, lr:7.25e-03, fs:0.65896 (r=0.576,p=0.770),  time:42.919, tt:2618.042\n",
      "Ep:61, loss:0.00006, loss_test:0.11746, lr:7.25e-03, fs:0.64706 (r=0.556,p=0.775),  time:42.917, tt:2660.882\n",
      "Ep:62, loss:0.00006, loss_test:0.11426, lr:7.25e-03, fs:0.67403 (r=0.616,p=0.744),  time:42.918, tt:2703.848\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00006, loss_test:0.11612, lr:7.25e-03, fs:0.65116 (r=0.566,p=0.767),  time:42.919, tt:2746.791\n",
      "Ep:64, loss:0.00006, loss_test:0.11851, lr:7.25e-03, fs:0.62722 (r=0.535,p=0.757),  time:42.932, tt:2790.602\n",
      "Ep:65, loss:0.00006, loss_test:0.11284, lr:7.25e-03, fs:0.69613 (r=0.636,p=0.768),  time:42.940, tt:2834.069\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00006, loss_test:0.11676, lr:7.25e-03, fs:0.65116 (r=0.566,p=0.767),  time:42.881, tt:2872.996\n",
      "Ep:67, loss:0.00006, loss_test:0.11657, lr:7.25e-03, fs:0.66272 (r=0.566,p=0.800),  time:42.790, tt:2909.737\n",
      "Ep:68, loss:0.00005, loss_test:0.11603, lr:7.25e-03, fs:0.66286 (r=0.586,p=0.763),  time:42.677, tt:2944.715\n",
      "Ep:69, loss:0.00005, loss_test:0.11479, lr:7.25e-03, fs:0.67816 (r=0.596,p=0.787),  time:42.642, tt:2984.922\n",
      "Ep:70, loss:0.00005, loss_test:0.11585, lr:7.25e-03, fs:0.68208 (r=0.596,p=0.797),  time:42.662, tt:3028.982\n",
      "Ep:71, loss:0.00005, loss_test:0.11632, lr:7.25e-03, fs:0.67059 (r=0.576,p=0.803),  time:42.683, tt:3073.205\n",
      "Ep:72, loss:0.00005, loss_test:0.11945, lr:7.25e-03, fs:0.64242 (r=0.535,p=0.803),  time:42.708, tt:3117.681\n",
      "Ep:73, loss:0.00005, loss_test:0.11403, lr:7.25e-03, fs:0.70787 (r=0.636,p=0.797),  time:42.739, tt:3162.687\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00005, loss_test:0.11841, lr:7.25e-03, fs:0.65089 (r=0.556,p=0.786),  time:42.767, tt:3207.559\n",
      "Ep:75, loss:0.00005, loss_test:0.11446, lr:7.25e-03, fs:0.72414 (r=0.636,p=0.840),  time:42.773, tt:3250.747\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00005, loss_test:0.11613, lr:7.25e-03, fs:0.69318 (r=0.616,p=0.792),  time:42.768, tt:3293.107\n",
      "Ep:77, loss:0.00005, loss_test:0.11549, lr:7.25e-03, fs:0.72093 (r=0.626,p=0.849),  time:42.836, tt:3341.214\n",
      "Ep:78, loss:0.00005, loss_test:0.11727, lr:7.25e-03, fs:0.66667 (r=0.576,p=0.792),  time:42.816, tt:3382.430\n",
      "Ep:79, loss:0.00005, loss_test:0.11084, lr:7.25e-03, fs:0.72727 (r=0.646,p=0.831),  time:42.814, tt:3425.112\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00005, loss_test:0.11727, lr:7.25e-03, fs:0.67836 (r=0.586,p=0.806),  time:42.788, tt:3465.812\n",
      "Ep:81, loss:0.00005, loss_test:0.11747, lr:7.25e-03, fs:0.67066 (r=0.566,p=0.824),  time:42.784, tt:3508.285\n",
      "Ep:82, loss:0.00004, loss_test:0.11672, lr:7.25e-03, fs:0.70930 (r=0.616,p=0.836),  time:42.785, tt:3551.129\n",
      "Ep:83, loss:0.00004, loss_test:0.11462, lr:7.25e-03, fs:0.70520 (r=0.616,p=0.824),  time:42.793, tt:3594.648\n",
      "Ep:84, loss:0.00004, loss_test:0.11550, lr:7.25e-03, fs:0.71264 (r=0.626,p=0.827),  time:42.795, tt:3637.588\n",
      "Ep:85, loss:0.00004, loss_test:0.11536, lr:7.25e-03, fs:0.71345 (r=0.616,p=0.847),  time:42.786, tt:3679.577\n",
      "Ep:86, loss:0.00004, loss_test:0.11621, lr:7.25e-03, fs:0.70520 (r=0.616,p=0.824),  time:42.777, tt:3721.560\n",
      "Ep:87, loss:0.00004, loss_test:0.11465, lr:7.25e-03, fs:0.70175 (r=0.606,p=0.833),  time:42.773, tt:3764.039\n",
      "Ep:88, loss:0.00004, loss_test:0.11518, lr:7.25e-03, fs:0.71676 (r=0.626,p=0.838),  time:42.761, tt:3805.741\n",
      "Ep:89, loss:0.00004, loss_test:0.11353, lr:7.25e-03, fs:0.72832 (r=0.636,p=0.851),  time:42.774, tt:3849.693\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00004, loss_test:0.11752, lr:7.25e-03, fs:0.67066 (r=0.566,p=0.824),  time:42.763, tt:3891.392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:91, loss:0.00004, loss_test:0.11201, lr:7.25e-03, fs:0.73563 (r=0.646,p=0.853),  time:42.757, tt:3933.604\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00004, loss_test:0.11978, lr:7.25e-03, fs:0.67470 (r=0.566,p=0.836),  time:42.765, tt:3977.110\n",
      "Ep:93, loss:0.00004, loss_test:0.11047, lr:7.25e-03, fs:0.74033 (r=0.677,p=0.817),  time:42.774, tt:4020.752\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00004, loss_test:0.12034, lr:7.25e-03, fs:0.66258 (r=0.545,p=0.844),  time:42.762, tt:4062.362\n",
      "Ep:95, loss:0.00004, loss_test:0.11620, lr:7.25e-03, fs:0.72832 (r=0.636,p=0.851),  time:42.749, tt:4103.867\n",
      "Ep:96, loss:0.00004, loss_test:0.11492, lr:7.25e-03, fs:0.72515 (r=0.626,p=0.861),  time:42.751, tt:4146.844\n",
      "Ep:97, loss:0.00004, loss_test:0.11643, lr:7.25e-03, fs:0.70588 (r=0.606,p=0.845),  time:42.749, tt:4189.356\n",
      "Ep:98, loss:0.00003, loss_test:0.11792, lr:7.25e-03, fs:0.73256 (r=0.636,p=0.863),  time:42.766, tt:4233.859\n",
      "Ep:99, loss:0.00003, loss_test:0.11655, lr:7.25e-03, fs:0.72093 (r=0.626,p=0.849),  time:42.773, tt:4277.297\n",
      "Ep:100, loss:0.00003, loss_test:0.11452, lr:7.25e-03, fs:0.72832 (r=0.636,p=0.851),  time:42.765, tt:4319.248\n",
      "Ep:101, loss:0.00003, loss_test:0.11747, lr:7.25e-03, fs:0.70588 (r=0.606,p=0.845),  time:42.755, tt:4361.048\n",
      "Ep:102, loss:0.00003, loss_test:0.11870, lr:7.25e-03, fs:0.69461 (r=0.586,p=0.853),  time:42.751, tt:4403.329\n",
      "Ep:103, loss:0.00003, loss_test:0.11693, lr:7.25e-03, fs:0.73256 (r=0.636,p=0.863),  time:42.774, tt:4448.476\n",
      "Ep:104, loss:0.00003, loss_test:0.11372, lr:7.25e-03, fs:0.72414 (r=0.636,p=0.840),  time:42.772, tt:4491.096\n",
      "Ep:105, loss:0.00003, loss_test:0.11772, lr:7.18e-03, fs:0.71006 (r=0.606,p=0.857),  time:42.792, tt:4535.987\n",
      "Ep:106, loss:0.00003, loss_test:0.11730, lr:7.11e-03, fs:0.68293 (r=0.566,p=0.862),  time:42.782, tt:4577.627\n",
      "Ep:107, loss:0.00003, loss_test:0.11755, lr:7.03e-03, fs:0.71006 (r=0.606,p=0.857),  time:42.773, tt:4619.471\n",
      "Ep:108, loss:0.00003, loss_test:0.11743, lr:6.96e-03, fs:0.70238 (r=0.596,p=0.855),  time:42.766, tt:4661.542\n",
      "Ep:109, loss:0.00003, loss_test:0.11825, lr:6.89e-03, fs:0.70238 (r=0.596,p=0.855),  time:42.776, tt:4705.392\n",
      "Ep:110, loss:0.00003, loss_test:0.11604, lr:6.83e-03, fs:0.73256 (r=0.636,p=0.863),  time:42.777, tt:4748.232\n",
      "Ep:111, loss:0.00003, loss_test:0.11612, lr:6.76e-03, fs:0.72093 (r=0.626,p=0.849),  time:42.770, tt:4790.246\n",
      "Ep:112, loss:0.00003, loss_test:0.11810, lr:6.69e-03, fs:0.67073 (r=0.556,p=0.846),  time:42.770, tt:4833.006\n",
      "Ep:113, loss:0.00003, loss_test:0.11839, lr:6.62e-03, fs:0.66667 (r=0.556,p=0.833),  time:42.752, tt:4873.765\n",
      "Ep:114, loss:0.00003, loss_test:0.11605, lr:6.56e-03, fs:0.73256 (r=0.636,p=0.863),  time:42.746, tt:4915.820\n",
      "Ep:115, loss:0.00003, loss_test:0.12051, lr:6.49e-03, fs:0.66667 (r=0.545,p=0.857),  time:42.745, tt:4958.461\n",
      "Ep:116, loss:0.00003, loss_test:0.12090, lr:6.43e-03, fs:0.67901 (r=0.556,p=0.873),  time:42.755, tt:5002.345\n",
      "Ep:117, loss:0.00003, loss_test:0.11829, lr:6.36e-03, fs:0.72189 (r=0.616,p=0.871),  time:42.758, tt:5045.396\n",
      "Ep:118, loss:0.00003, loss_test:0.12486, lr:6.30e-03, fs:0.64968 (r=0.515,p=0.879),  time:42.746, tt:5086.816\n",
      "Ep:119, loss:0.00003, loss_test:0.11672, lr:6.24e-03, fs:0.73256 (r=0.636,p=0.863),  time:42.738, tt:5128.595\n",
      "Ep:120, loss:0.00003, loss_test:0.12087, lr:6.17e-03, fs:0.66667 (r=0.556,p=0.833),  time:42.733, tt:5170.677\n",
      "Ep:121, loss:0.00003, loss_test:0.12020, lr:6.11e-03, fs:0.65839 (r=0.535,p=0.855),  time:42.740, tt:5214.305\n",
      "Ep:122, loss:0.00002, loss_test:0.11945, lr:6.05e-03, fs:0.68263 (r=0.576,p=0.838),  time:42.757, tt:5259.120\n",
      "Ep:123, loss:0.00002, loss_test:0.11715, lr:5.99e-03, fs:0.73684 (r=0.636,p=0.875),  time:42.760, tt:5302.198\n",
      "Ep:124, loss:0.00002, loss_test:0.12120, lr:5.93e-03, fs:0.66667 (r=0.556,p=0.833),  time:42.765, tt:5345.642\n",
      "Ep:125, loss:0.00002, loss_test:0.11965, lr:5.87e-03, fs:0.71429 (r=0.606,p=0.870),  time:42.807, tt:5393.721\n",
      "Ep:126, loss:0.00003, loss_test:0.12288, lr:5.81e-03, fs:0.64968 (r=0.515,p=0.879),  time:42.812, tt:5437.096\n",
      "Ep:127, loss:0.00003, loss_test:0.12357, lr:5.75e-03, fs:0.64557 (r=0.515,p=0.864),  time:42.818, tt:5480.659\n",
      "Ep:128, loss:0.00002, loss_test:0.11973, lr:5.70e-03, fs:0.65839 (r=0.535,p=0.855),  time:42.820, tt:5523.770\n",
      "Ep:129, loss:0.00002, loss_test:0.12358, lr:5.64e-03, fs:0.66667 (r=0.545,p=0.857),  time:42.808, tt:5565.016\n",
      "Ep:130, loss:0.00002, loss_test:0.11943, lr:5.58e-03, fs:0.67485 (r=0.556,p=0.859),  time:42.804, tt:5607.335\n",
      "Ep:131, loss:0.00002, loss_test:0.12348, lr:5.53e-03, fs:0.64968 (r=0.515,p=0.879),  time:42.817, tt:5651.897\n",
      "Ep:132, loss:0.00002, loss_test:0.11841, lr:5.47e-03, fs:0.73256 (r=0.636,p=0.863),  time:42.810, tt:5693.786\n",
      "Ep:133, loss:0.00002, loss_test:0.12433, lr:5.42e-03, fs:0.64968 (r=0.515,p=0.879),  time:42.816, tt:5737.388\n",
      "Ep:134, loss:0.00002, loss_test:0.12019, lr:5.36e-03, fs:0.70303 (r=0.586,p=0.879),  time:42.814, tt:5779.931\n",
      "Ep:135, loss:0.00002, loss_test:0.12255, lr:5.31e-03, fs:0.64557 (r=0.515,p=0.864),  time:42.811, tt:5822.315\n",
      "Ep:136, loss:0.00002, loss_test:0.12181, lr:5.26e-03, fs:0.65409 (r=0.525,p=0.867),  time:42.817, tt:5865.903\n",
      "Ep:137, loss:0.00002, loss_test:0.12342, lr:5.20e-03, fs:0.63750 (r=0.515,p=0.836),  time:42.827, tt:5910.119\n",
      "Ep:138, loss:0.00002, loss_test:0.12043, lr:5.15e-03, fs:0.64151 (r=0.515,p=0.850),  time:42.819, tt:5951.855\n",
      "Ep:139, loss:0.00002, loss_test:0.12344, lr:5.10e-03, fs:0.63750 (r=0.515,p=0.836),  time:42.825, tt:5995.534\n",
      "Ep:140, loss:0.00002, loss_test:0.12124, lr:5.05e-03, fs:0.64557 (r=0.515,p=0.864),  time:42.828, tt:6038.755\n",
      "Ep:141, loss:0.00002, loss_test:0.12181, lr:5.00e-03, fs:0.64151 (r=0.515,p=0.850),  time:42.839, tt:6083.189\n",
      "Ep:142, loss:0.00002, loss_test:0.12254, lr:4.95e-03, fs:0.64151 (r=0.515,p=0.850),  time:42.844, tt:6126.703\n",
      "Ep:143, loss:0.00002, loss_test:0.12058, lr:4.90e-03, fs:0.64151 (r=0.515,p=0.850),  time:42.849, tt:6170.327\n",
      "Ep:144, loss:0.00002, loss_test:0.12370, lr:4.85e-03, fs:0.64151 (r=0.515,p=0.850),  time:42.859, tt:6214.605\n",
      "Ep:145, loss:0.00002, loss_test:0.12268, lr:4.80e-03, fs:0.64151 (r=0.515,p=0.850),  time:42.871, tt:6259.097\n",
      "Ep:146, loss:0.00002, loss_test:0.12252, lr:4.75e-03, fs:0.64151 (r=0.515,p=0.850),  time:42.877, tt:6302.850\n",
      "Ep:147, loss:0.00002, loss_test:0.12342, lr:4.71e-03, fs:0.64151 (r=0.515,p=0.850),  time:42.892, tt:6348.034\n",
      "Ep:148, loss:0.00002, loss_test:0.12318, lr:4.66e-03, fs:0.64557 (r=0.515,p=0.864),  time:42.899, tt:6391.957\n",
      "Ep:149, loss:0.00002, loss_test:0.12331, lr:4.61e-03, fs:0.64557 (r=0.515,p=0.864),  time:42.898, tt:6434.681\n",
      "Ep:150, loss:0.00002, loss_test:0.12128, lr:4.57e-03, fs:0.64557 (r=0.515,p=0.864),  time:42.905, tt:6478.725\n",
      "Ep:151, loss:0.00002, loss_test:0.12270, lr:4.52e-03, fs:0.65409 (r=0.525,p=0.867),  time:42.930, tt:6525.293\n",
      "Ep:152, loss:0.00002, loss_test:0.12314, lr:4.48e-03, fs:0.64968 (r=0.515,p=0.879),  time:42.934, tt:6568.861\n",
      "Ep:153, loss:0.00002, loss_test:0.12344, lr:4.43e-03, fs:0.64968 (r=0.515,p=0.879),  time:42.912, tt:6608.437\n",
      "Ep:154, loss:0.00002, loss_test:0.12227, lr:4.39e-03, fs:0.65839 (r=0.535,p=0.855),  time:42.904, tt:6650.080\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13668, lr:1.00e-02, fs:0.65965 (r=0.949,p=0.505),  time:21.055, tt:21.055\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13364, lr:1.00e-02, fs:0.66667 (r=0.939,p=0.517),  time:20.134, tt:40.268\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:2, loss:0.00027, loss_test:0.12964, lr:1.00e-02, fs:0.67433 (r=0.889,p=0.543),  time:19.161, tt:57.484\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12556, lr:1.00e-02, fs:0.65323 (r=0.818,p=0.544),  time:19.467, tt:77.867\n",
      "Ep:4, loss:0.00025, loss_test:0.12362, lr:1.00e-02, fs:0.64655 (r=0.758,p=0.564),  time:19.038, tt:95.191\n",
      "Ep:5, loss:0.00025, loss_test:0.12226, lr:1.00e-02, fs:0.64317 (r=0.737,p=0.570),  time:19.092, tt:114.551\n",
      "Ep:6, loss:0.00024, loss_test:0.12065, lr:1.00e-02, fs:0.66376 (r=0.768,p=0.585),  time:18.830, tt:131.812\n",
      "Ep:7, loss:0.00023, loss_test:0.11820, lr:1.00e-02, fs:0.65778 (r=0.747,p=0.587),  time:18.483, tt:147.865\n",
      "Ep:8, loss:0.00023, loss_test:0.11558, lr:1.00e-02, fs:0.67273 (r=0.747,p=0.612),  time:18.447, tt:166.024\n",
      "Ep:9, loss:0.00022, loss_test:0.11298, lr:1.00e-02, fs:0.67290 (r=0.727,p=0.626),  time:18.612, tt:186.120\n",
      "Ep:10, loss:0.00021, loss_test:0.11083, lr:1.00e-02, fs:0.67290 (r=0.727,p=0.626),  time:18.429, tt:202.714\n",
      "Ep:11, loss:0.00021, loss_test:0.10809, lr:1.00e-02, fs:0.71154 (r=0.747,p=0.679),  time:18.230, tt:218.760\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.10616, lr:1.00e-02, fs:0.71498 (r=0.747,p=0.685),  time:18.122, tt:235.584\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.10426, lr:1.00e-02, fs:0.71498 (r=0.747,p=0.685),  time:18.032, tt:252.452\n",
      "Ep:14, loss:0.00019, loss_test:0.10307, lr:1.00e-02, fs:0.73096 (r=0.727,p=0.735),  time:17.943, tt:269.151\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.10129, lr:1.00e-02, fs:0.73737 (r=0.737,p=0.737),  time:17.967, tt:287.467\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.09947, lr:1.00e-02, fs:0.73737 (r=0.737,p=0.737),  time:17.875, tt:303.875\n",
      "Ep:17, loss:0.00017, loss_test:0.09808, lr:1.00e-02, fs:0.75000 (r=0.727,p=0.774),  time:17.725, tt:319.050\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00016, loss_test:0.09709, lr:1.00e-02, fs:0.75393 (r=0.727,p=0.783),  time:17.784, tt:337.894\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.09523, lr:1.00e-02, fs:0.76042 (r=0.737,p=0.785),  time:17.789, tt:355.787\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00015, loss_test:0.09645, lr:1.00e-02, fs:0.75532 (r=0.717,p=0.798),  time:17.801, tt:373.811\n",
      "Ep:21, loss:0.00015, loss_test:0.09532, lr:1.00e-02, fs:0.75393 (r=0.727,p=0.783),  time:17.802, tt:391.646\n",
      "Ep:22, loss:0.00015, loss_test:0.09702, lr:1.00e-02, fs:0.76757 (r=0.717,p=0.826),  time:17.746, tt:408.156\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.09661, lr:1.00e-02, fs:0.75936 (r=0.717,p=0.807),  time:17.792, tt:427.016\n",
      "Ep:24, loss:0.00014, loss_test:0.09588, lr:1.00e-02, fs:0.75936 (r=0.717,p=0.807),  time:17.794, tt:444.850\n",
      "Ep:25, loss:0.00013, loss_test:0.09783, lr:1.00e-02, fs:0.75410 (r=0.697,p=0.821),  time:17.785, tt:462.421\n",
      "Ep:26, loss:0.00013, loss_test:0.09832, lr:1.00e-02, fs:0.77596 (r=0.717,p=0.845),  time:17.874, tt:482.596\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00012, loss_test:0.09570, lr:1.00e-02, fs:0.75269 (r=0.707,p=0.805),  time:17.898, tt:501.131\n",
      "Ep:28, loss:0.00012, loss_test:0.10094, lr:1.00e-02, fs:0.76571 (r=0.677,p=0.882),  time:18.016, tt:522.459\n",
      "Ep:29, loss:0.00012, loss_test:0.09399, lr:1.00e-02, fs:0.77487 (r=0.747,p=0.804),  time:18.015, tt:540.455\n",
      "Ep:30, loss:0.00011, loss_test:0.10287, lr:1.00e-02, fs:0.77457 (r=0.677,p=0.905),  time:18.049, tt:559.518\n",
      "Ep:31, loss:0.00011, loss_test:0.09283, lr:1.00e-02, fs:0.75897 (r=0.747,p=0.771),  time:18.130, tt:580.170\n",
      "Ep:32, loss:0.00011, loss_test:0.10076, lr:1.00e-02, fs:0.78613 (r=0.687,p=0.919),  time:18.116, tt:597.842\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00010, loss_test:0.09205, lr:1.00e-02, fs:0.76842 (r=0.737,p=0.802),  time:18.107, tt:615.647\n",
      "Ep:34, loss:0.00010, loss_test:0.09811, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:18.133, tt:634.658\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00009, loss_test:0.09266, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:18.150, tt:653.403\n",
      "Ep:36, loss:0.00009, loss_test:0.09598, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:18.123, tt:670.546\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00009, loss_test:0.09533, lr:1.00e-02, fs:0.76571 (r=0.677,p=0.882),  time:18.063, tt:686.406\n",
      "Ep:38, loss:0.00009, loss_test:0.09274, lr:1.00e-02, fs:0.81967 (r=0.758,p=0.893),  time:18.091, tt:705.534\n",
      "Ep:39, loss:0.00008, loss_test:0.09450, lr:1.00e-02, fs:0.77011 (r=0.677,p=0.893),  time:18.119, tt:724.750\n",
      "Ep:40, loss:0.00008, loss_test:0.09044, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:18.114, tt:742.666\n",
      "Ep:41, loss:0.00008, loss_test:0.09636, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:18.112, tt:760.699\n",
      "Ep:42, loss:0.00008, loss_test:0.09274, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:18.075, tt:777.230\n",
      "Ep:43, loss:0.00007, loss_test:0.09142, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:18.087, tt:795.838\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00007, loss_test:0.09132, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:18.102, tt:814.568\n",
      "Ep:45, loss:0.00007, loss_test:0.09136, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:18.054, tt:830.484\n",
      "Ep:46, loss:0.00007, loss_test:0.09284, lr:1.00e-02, fs:0.79545 (r=0.707,p=0.909),  time:18.038, tt:847.800\n",
      "Ep:47, loss:0.00006, loss_test:0.09493, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:18.034, tt:865.643\n",
      "Ep:48, loss:0.00006, loss_test:0.10074, lr:1.00e-02, fs:0.83799 (r=0.758,p=0.938),  time:18.059, tt:884.893\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00006, loss_test:0.08652, lr:1.00e-02, fs:0.79787 (r=0.758,p=0.843),  time:18.066, tt:903.304\n",
      "Ep:50, loss:0.00006, loss_test:0.10023, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:18.053, tt:920.725\n",
      "Ep:51, loss:0.00006, loss_test:0.09411, lr:1.00e-02, fs:0.80925 (r=0.707,p=0.946),  time:18.062, tt:939.223\n",
      "Ep:52, loss:0.00006, loss_test:0.08822, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:18.123, tt:960.501\n",
      "Ep:53, loss:0.00007, loss_test:0.10209, lr:1.00e-02, fs:0.80447 (r=0.727,p=0.900),  time:18.211, tt:983.401\n",
      "Ep:54, loss:0.00006, loss_test:0.08492, lr:1.00e-02, fs:0.78495 (r=0.737,p=0.839),  time:18.199, tt:1000.947\n",
      "Ep:55, loss:0.00006, loss_test:0.09918, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:18.196, tt:1018.954\n",
      "Ep:56, loss:0.00006, loss_test:0.09366, lr:1.00e-02, fs:0.80925 (r=0.707,p=0.946),  time:18.205, tt:1037.670\n",
      "Ep:57, loss:0.00005, loss_test:0.09031, lr:1.00e-02, fs:0.80226 (r=0.717,p=0.910),  time:18.196, tt:1055.350\n",
      "Ep:58, loss:0.00005, loss_test:0.09565, lr:1.00e-02, fs:0.80460 (r=0.707,p=0.933),  time:18.209, tt:1074.329\n",
      "Ep:59, loss:0.00005, loss_test:0.08835, lr:1.00e-02, fs:0.80226 (r=0.717,p=0.910),  time:18.217, tt:1093.050\n",
      "Ep:60, loss:0.00005, loss_test:0.10280, lr:9.90e-03, fs:0.85556 (r=0.778,p=0.951),  time:18.232, tt:1112.125\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00005, loss_test:0.08366, lr:9.90e-03, fs:0.78652 (r=0.707,p=0.886),  time:18.220, tt:1129.643\n",
      "Ep:62, loss:0.00004, loss_test:0.09692, lr:9.90e-03, fs:0.80925 (r=0.707,p=0.946),  time:18.179, tt:1145.297\n",
      "Ep:63, loss:0.00004, loss_test:0.08685, lr:9.90e-03, fs:0.79545 (r=0.707,p=0.909),  time:18.189, tt:1164.072\n",
      "Ep:64, loss:0.00004, loss_test:0.09109, lr:9.90e-03, fs:0.80925 (r=0.707,p=0.946),  time:18.183, tt:1181.872\n",
      "Ep:65, loss:0.00004, loss_test:0.09412, lr:9.90e-03, fs:0.80925 (r=0.707,p=0.946),  time:18.142, tt:1197.363\n",
      "Ep:66, loss:0.00004, loss_test:0.08892, lr:9.90e-03, fs:0.80925 (r=0.707,p=0.946),  time:18.123, tt:1214.244\n",
      "Ep:67, loss:0.00004, loss_test:0.09504, lr:9.90e-03, fs:0.84270 (r=0.758,p=0.949),  time:18.101, tt:1230.836\n",
      "Ep:68, loss:0.00004, loss_test:0.09178, lr:9.90e-03, fs:0.80925 (r=0.707,p=0.946),  time:18.098, tt:1248.748\n",
      "Ep:69, loss:0.00003, loss_test:0.09200, lr:9.90e-03, fs:0.84270 (r=0.758,p=0.949),  time:18.096, tt:1266.742\n",
      "Ep:70, loss:0.00004, loss_test:0.08273, lr:9.90e-03, fs:0.79096 (r=0.707,p=0.897),  time:18.064, tt:1282.514\n",
      "Ep:71, loss:0.00003, loss_test:0.10045, lr:9.90e-03, fs:0.86034 (r=0.778,p=0.963),  time:18.066, tt:1300.758\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:72, loss:0.00003, loss_test:0.07987, lr:9.90e-03, fs:0.79545 (r=0.707,p=0.909),  time:18.063, tt:1318.580\n",
      "Ep:73, loss:0.00003, loss_test:0.09905, lr:9.90e-03, fs:0.86034 (r=0.778,p=0.963),  time:18.057, tt:1336.185\n",
      "Ep:74, loss:0.00003, loss_test:0.08660, lr:9.90e-03, fs:0.80460 (r=0.707,p=0.933),  time:18.065, tt:1354.900\n",
      "Ep:75, loss:0.00003, loss_test:0.09209, lr:9.90e-03, fs:0.82759 (r=0.727,p=0.960),  time:18.041, tt:1371.127\n",
      "Ep:76, loss:0.00003, loss_test:0.08676, lr:9.90e-03, fs:0.80925 (r=0.707,p=0.946),  time:18.043, tt:1389.310\n",
      "Ep:77, loss:0.00003, loss_test:0.08954, lr:9.90e-03, fs:0.81609 (r=0.717,p=0.947),  time:18.048, tt:1407.757\n",
      "Ep:78, loss:0.00003, loss_test:0.08783, lr:9.90e-03, fs:0.80925 (r=0.707,p=0.946),  time:18.015, tt:1423.161\n",
      "Ep:79, loss:0.00003, loss_test:0.08786, lr:9.90e-03, fs:0.81395 (r=0.707,p=0.959),  time:18.039, tt:1443.156\n",
      "Ep:80, loss:0.00003, loss_test:0.08949, lr:9.90e-03, fs:0.80925 (r=0.707,p=0.946),  time:18.025, tt:1459.988\n",
      "Ep:81, loss:0.00003, loss_test:0.09102, lr:9.90e-03, fs:0.85083 (r=0.778,p=0.939),  time:18.014, tt:1477.121\n",
      "Ep:82, loss:0.00003, loss_test:0.08837, lr:9.90e-03, fs:0.81395 (r=0.707,p=0.959),  time:18.009, tt:1494.763\n",
      "Ep:83, loss:0.00003, loss_test:0.08816, lr:9.80e-03, fs:0.80925 (r=0.707,p=0.946),  time:17.996, tt:1511.659\n",
      "Ep:84, loss:0.00002, loss_test:0.09516, lr:9.70e-03, fs:0.85083 (r=0.778,p=0.939),  time:18.010, tt:1530.867\n",
      "Ep:85, loss:0.00002, loss_test:0.08651, lr:9.61e-03, fs:0.80925 (r=0.707,p=0.946),  time:18.000, tt:1548.009\n",
      "Ep:86, loss:0.00002, loss_test:0.09572, lr:9.51e-03, fs:0.85083 (r=0.778,p=0.939),  time:17.996, tt:1565.648\n",
      "Ep:87, loss:0.00003, loss_test:0.08782, lr:9.41e-03, fs:0.81395 (r=0.707,p=0.959),  time:18.018, tt:1585.603\n",
      "Ep:88, loss:0.00002, loss_test:0.09173, lr:9.32e-03, fs:0.81395 (r=0.707,p=0.959),  time:17.987, tt:1600.844\n",
      "Ep:89, loss:0.00002, loss_test:0.08717, lr:9.23e-03, fs:0.81395 (r=0.707,p=0.959),  time:17.995, tt:1619.507\n",
      "Ep:90, loss:0.00002, loss_test:0.09317, lr:9.14e-03, fs:0.81818 (r=0.727,p=0.935),  time:17.981, tt:1636.304\n",
      "Ep:91, loss:0.00002, loss_test:0.08717, lr:9.04e-03, fs:0.81395 (r=0.707,p=0.959),  time:17.982, tt:1654.351\n",
      "Ep:92, loss:0.00002, loss_test:0.09182, lr:8.95e-03, fs:0.84916 (r=0.768,p=0.950),  time:17.981, tt:1672.233\n",
      "Ep:93, loss:0.00002, loss_test:0.08551, lr:8.86e-03, fs:0.80925 (r=0.707,p=0.946),  time:17.957, tt:1687.915\n",
      "Ep:94, loss:0.00002, loss_test:0.09486, lr:8.78e-03, fs:0.85556 (r=0.778,p=0.951),  time:17.961, tt:1706.254\n",
      "Ep:95, loss:0.00002, loss_test:0.08778, lr:8.69e-03, fs:0.81395 (r=0.707,p=0.959),  time:17.947, tt:1722.868\n",
      "Ep:96, loss:0.00002, loss_test:0.09118, lr:8.60e-03, fs:0.82081 (r=0.717,p=0.959),  time:17.939, tt:1740.068\n",
      "Ep:97, loss:0.00002, loss_test:0.08872, lr:8.51e-03, fs:0.81395 (r=0.707,p=0.959),  time:17.931, tt:1757.197\n",
      "Ep:98, loss:0.00002, loss_test:0.09356, lr:8.43e-03, fs:0.81609 (r=0.717,p=0.947),  time:17.907, tt:1772.820\n",
      "Ep:99, loss:0.00002, loss_test:0.08939, lr:8.35e-03, fs:0.84746 (r=0.758,p=0.962),  time:17.928, tt:1792.763\n",
      "Ep:100, loss:0.00002, loss_test:0.09261, lr:8.26e-03, fs:0.81609 (r=0.717,p=0.947),  time:17.938, tt:1811.786\n",
      "Ep:101, loss:0.00002, loss_test:0.08957, lr:8.18e-03, fs:0.81395 (r=0.707,p=0.959),  time:17.916, tt:1827.417\n",
      "Ep:102, loss:0.00002, loss_test:0.09082, lr:8.10e-03, fs:0.86034 (r=0.778,p=0.963),  time:17.938, tt:1847.605\n",
      "Ep:103, loss:0.00002, loss_test:0.09011, lr:8.02e-03, fs:0.81395 (r=0.707,p=0.959),  time:17.924, tt:1864.099\n",
      "Ep:104, loss:0.00002, loss_test:0.09308, lr:7.94e-03, fs:0.84270 (r=0.758,p=0.949),  time:17.932, tt:1882.879\n",
      "Ep:105, loss:0.00002, loss_test:0.08771, lr:7.86e-03, fs:0.83429 (r=0.737,p=0.961),  time:17.957, tt:1903.470\n",
      "Ep:106, loss:0.00002, loss_test:0.09230, lr:7.78e-03, fs:0.81395 (r=0.707,p=0.959),  time:17.985, tt:1924.351\n",
      "Ep:107, loss:0.00002, loss_test:0.09143, lr:7.70e-03, fs:0.82081 (r=0.717,p=0.959),  time:18.052, tt:1949.634\n",
      "Ep:108, loss:0.00002, loss_test:0.09151, lr:7.62e-03, fs:0.81395 (r=0.707,p=0.959),  time:18.066, tt:1969.181\n",
      "Ep:109, loss:0.00002, loss_test:0.09442, lr:7.55e-03, fs:0.81609 (r=0.717,p=0.947),  time:18.079, tt:1988.704\n",
      "Ep:110, loss:0.00002, loss_test:0.09186, lr:7.47e-03, fs:0.81395 (r=0.707,p=0.959),  time:18.082, tt:2007.079\n",
      "Ep:111, loss:0.00002, loss_test:0.09211, lr:7.40e-03, fs:0.81609 (r=0.717,p=0.947),  time:18.100, tt:2027.215\n",
      "Ep:112, loss:0.00001, loss_test:0.09285, lr:7.32e-03, fs:0.84746 (r=0.758,p=0.962),  time:18.114, tt:2046.867\n",
      "Ep:113, loss:0.00001, loss_test:0.09234, lr:7.25e-03, fs:0.80925 (r=0.707,p=0.946),  time:18.119, tt:2065.546\n",
      "Ep:114, loss:0.00001, loss_test:0.09146, lr:7.18e-03, fs:0.84571 (r=0.747,p=0.974),  time:18.141, tt:2086.221\n",
      "Ep:115, loss:0.00001, loss_test:0.09570, lr:7.11e-03, fs:0.82955 (r=0.737,p=0.948),  time:18.132, tt:2103.294\n",
      "Ep:116, loss:0.00001, loss_test:0.08915, lr:7.03e-03, fs:0.81395 (r=0.707,p=0.959),  time:18.138, tt:2122.149\n",
      "Ep:117, loss:0.00001, loss_test:0.09557, lr:6.96e-03, fs:0.86034 (r=0.778,p=0.963),  time:18.138, tt:2140.342\n",
      "Ep:118, loss:0.00001, loss_test:0.09095, lr:6.89e-03, fs:0.81395 (r=0.707,p=0.959),  time:18.140, tt:2158.711\n",
      "Ep:119, loss:0.00001, loss_test:0.09385, lr:6.83e-03, fs:0.82081 (r=0.717,p=0.959),  time:18.136, tt:2176.378\n",
      "Ep:120, loss:0.00001, loss_test:0.09100, lr:6.76e-03, fs:0.81395 (r=0.707,p=0.959),  time:18.127, tt:2193.409\n",
      "Ep:121, loss:0.00001, loss_test:0.09541, lr:6.69e-03, fs:0.81395 (r=0.707,p=0.959),  time:18.130, tt:2211.827\n",
      "Ep:122, loss:0.00001, loss_test:0.09305, lr:6.62e-03, fs:0.85393 (r=0.768,p=0.962),  time:18.134, tt:2230.426\n",
      "Ep:123, loss:0.00001, loss_test:0.09336, lr:6.56e-03, fs:0.80925 (r=0.707,p=0.946),  time:18.122, tt:2247.155\n",
      "Ep:124, loss:0.00001, loss_test:0.09591, lr:6.49e-03, fs:0.83429 (r=0.737,p=0.961),  time:18.118, tt:2264.804\n",
      "Ep:125, loss:0.00001, loss_test:0.09279, lr:6.43e-03, fs:0.84091 (r=0.747,p=0.961),  time:18.109, tt:2281.731\n",
      "Ep:126, loss:0.00001, loss_test:0.09481, lr:6.36e-03, fs:0.81395 (r=0.707,p=0.959),  time:18.112, tt:2300.195\n",
      "Ep:127, loss:0.00001, loss_test:0.09463, lr:6.30e-03, fs:0.81395 (r=0.707,p=0.959),  time:18.112, tt:2318.357\n",
      "Ep:128, loss:0.00001, loss_test:0.09282, lr:6.24e-03, fs:0.82081 (r=0.717,p=0.959),  time:18.102, tt:2335.191\n",
      "Ep:129, loss:0.00001, loss_test:0.09463, lr:6.17e-03, fs:0.82759 (r=0.727,p=0.960),  time:18.089, tt:2351.579\n",
      "Ep:130, loss:0.00001, loss_test:0.09318, lr:6.11e-03, fs:0.82081 (r=0.717,p=0.959),  time:18.080, tt:2368.477\n",
      "Ep:131, loss:0.00001, loss_test:0.09390, lr:6.05e-03, fs:0.84746 (r=0.758,p=0.962),  time:18.071, tt:2385.308\n",
      "Ep:132, loss:0.00001, loss_test:0.09419, lr:5.99e-03, fs:0.81395 (r=0.707,p=0.959),  time:18.072, tt:2403.620\n",
      "Ep:133, loss:0.00001, loss_test:0.09418, lr:5.93e-03, fs:0.83429 (r=0.737,p=0.961),  time:18.064, tt:2420.635\n",
      "Ep:134, loss:0.00001, loss_test:0.09349, lr:5.87e-03, fs:0.81395 (r=0.707,p=0.959),  time:18.063, tt:2438.448\n",
      "Ep:135, loss:0.00001, loss_test:0.09520, lr:5.81e-03, fs:0.81395 (r=0.707,p=0.959),  time:18.062, tt:2456.372\n",
      "Ep:136, loss:0.00001, loss_test:0.09425, lr:5.75e-03, fs:0.82081 (r=0.717,p=0.959),  time:18.054, tt:2473.368\n",
      "Ep:137, loss:0.00001, loss_test:0.09354, lr:5.70e-03, fs:0.82081 (r=0.717,p=0.959),  time:18.058, tt:2492.046\n",
      "Ep:138, loss:0.00001, loss_test:0.09734, lr:5.64e-03, fs:0.83616 (r=0.747,p=0.949),  time:18.054, tt:2509.550\n",
      "Ep:139, loss:0.00001, loss_test:0.09329, lr:5.58e-03, fs:0.81395 (r=0.707,p=0.959),  time:18.066, tt:2529.194\n",
      "Ep:140, loss:0.00001, loss_test:0.09685, lr:5.53e-03, fs:0.82955 (r=0.737,p=0.948),  time:18.062, tt:2546.744\n",
      "Ep:141, loss:0.00001, loss_test:0.09320, lr:5.47e-03, fs:0.81395 (r=0.707,p=0.959),  time:18.051, tt:2563.264\n",
      "Ep:142, loss:0.00001, loss_test:0.09688, lr:5.42e-03, fs:0.82081 (r=0.717,p=0.959),  time:18.053, tt:2581.611\n",
      "Ep:143, loss:0.00001, loss_test:0.09484, lr:5.36e-03, fs:0.81395 (r=0.707,p=0.959),  time:18.041, tt:2597.835\n",
      "Ep:144, loss:0.00001, loss_test:0.09626, lr:5.31e-03, fs:0.84091 (r=0.747,p=0.961),  time:18.054, tt:2617.863\n",
      "Ep:145, loss:0.00001, loss_test:0.09571, lr:5.26e-03, fs:0.81395 (r=0.707,p=0.959),  time:18.046, tt:2634.754\n",
      "Ep:146, loss:0.00001, loss_test:0.09502, lr:5.20e-03, fs:0.82081 (r=0.717,p=0.959),  time:18.033, tt:2650.798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:147, loss:0.00001, loss_test:0.09566, lr:5.15e-03, fs:0.82081 (r=0.717,p=0.959),  time:18.023, tt:2667.404\n",
      "Ep:148, loss:0.00001, loss_test:0.09550, lr:5.10e-03, fs:0.82081 (r=0.717,p=0.959),  time:18.006, tt:2682.964\n",
      "Ep:149, loss:0.00001, loss_test:0.09778, lr:5.05e-03, fs:0.81609 (r=0.717,p=0.947),  time:18.005, tt:2700.799\n",
      "Ep:150, loss:0.00001, loss_test:0.09431, lr:5.00e-03, fs:0.81395 (r=0.707,p=0.959),  time:18.012, tt:2719.879\n",
      "Ep:151, loss:0.00001, loss_test:0.09813, lr:4.95e-03, fs:0.81395 (r=0.707,p=0.959),  time:18.012, tt:2737.806\n",
      "Ep:152, loss:0.00001, loss_test:0.09723, lr:4.90e-03, fs:0.81395 (r=0.707,p=0.959),  time:17.997, tt:2753.598\n",
      "Ep:153, loss:0.00001, loss_test:0.09325, lr:4.85e-03, fs:0.81395 (r=0.707,p=0.959),  time:17.974, tt:2768.049\n",
      "Ep:154, loss:0.00001, loss_test:0.10013, lr:4.80e-03, fs:0.84270 (r=0.758,p=0.949),  time:17.974, tt:2785.956\n",
      "Ep:155, loss:0.00001, loss_test:0.09455, lr:4.75e-03, fs:0.81395 (r=0.707,p=0.959),  time:17.974, tt:2803.932\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.14014, lr:1.00e-02, fs:0.63197 (r=0.859,p=0.500),  time:17.502, tt:17.502\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.13858, lr:1.00e-02, fs:0.64093 (r=0.838,p=0.519),  time:16.676, tt:33.352\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.13709, lr:1.00e-02, fs:0.62903 (r=0.788,p=0.523),  time:17.325, tt:51.976\n",
      "Ep:3, loss:0.00025, loss_test:0.13553, lr:1.00e-02, fs:0.62762 (r=0.758,p=0.536),  time:17.924, tt:71.697\n",
      "Ep:4, loss:0.00024, loss_test:0.13354, lr:1.00e-02, fs:0.62009 (r=0.717,p=0.546),  time:18.047, tt:90.233\n",
      "Ep:5, loss:0.00024, loss_test:0.13121, lr:1.00e-02, fs:0.60090 (r=0.677,p=0.540),  time:18.065, tt:108.392\n",
      "Ep:6, loss:0.00023, loss_test:0.12917, lr:1.00e-02, fs:0.62162 (r=0.697,p=0.561),  time:17.920, tt:125.442\n",
      "Ep:7, loss:0.00023, loss_test:0.12667, lr:1.00e-02, fs:0.61682 (r=0.667,p=0.574),  time:18.147, tt:145.179\n",
      "Ep:8, loss:0.00022, loss_test:0.12512, lr:1.00e-02, fs:0.63415 (r=0.657,p=0.613),  time:18.449, tt:166.039\n",
      "Ep:9, loss:0.00021, loss_test:0.12453, lr:1.00e-02, fs:0.63317 (r=0.636,p=0.630),  time:18.299, tt:182.991\n",
      "Ep:10, loss:0.00021, loss_test:0.12311, lr:1.00e-02, fs:0.64677 (r=0.657,p=0.637),  time:18.306, tt:201.363\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.12115, lr:1.00e-02, fs:0.65025 (r=0.667,p=0.635),  time:18.137, tt:217.649\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.11943, lr:1.00e-02, fs:0.64286 (r=0.636,p=0.649),  time:18.019, tt:234.242\n",
      "Ep:13, loss:0.00019, loss_test:0.11707, lr:1.00e-02, fs:0.65990 (r=0.657,p=0.663),  time:17.912, tt:250.774\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.11490, lr:1.00e-02, fs:0.66667 (r=0.667,p=0.667),  time:17.663, tt:264.941\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.11317, lr:1.00e-02, fs:0.65979 (r=0.646,p=0.674),  time:17.682, tt:282.919\n",
      "Ep:16, loss:0.00017, loss_test:0.11132, lr:1.00e-02, fs:0.68041 (r=0.667,p=0.695),  time:17.625, tt:299.632\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.10887, lr:1.00e-02, fs:0.68041 (r=0.667,p=0.695),  time:17.659, tt:317.861\n",
      "Ep:18, loss:0.00016, loss_test:0.10769, lr:1.00e-02, fs:0.68063 (r=0.657,p=0.707),  time:17.643, tt:335.216\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.10644, lr:1.00e-02, fs:0.66316 (r=0.636,p=0.692),  time:17.631, tt:352.630\n",
      "Ep:20, loss:0.00015, loss_test:0.10528, lr:1.00e-02, fs:0.62637 (r=0.576,p=0.687),  time:17.662, tt:370.897\n",
      "Ep:21, loss:0.00015, loss_test:0.10389, lr:1.00e-02, fs:0.63784 (r=0.596,p=0.686),  time:17.592, tt:387.033\n",
      "Ep:22, loss:0.00014, loss_test:0.10333, lr:1.00e-02, fs:0.64516 (r=0.606,p=0.690),  time:17.629, tt:405.473\n",
      "Ep:23, loss:0.00014, loss_test:0.10222, lr:1.00e-02, fs:0.64481 (r=0.596,p=0.702),  time:17.569, tt:421.667\n",
      "Ep:24, loss:0.00014, loss_test:0.10179, lr:1.00e-02, fs:0.65574 (r=0.606,p=0.714),  time:17.628, tt:440.699\n",
      "Ep:25, loss:0.00013, loss_test:0.10027, lr:1.00e-02, fs:0.70157 (r=0.677,p=0.728),  time:17.782, tt:462.345\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.10093, lr:1.00e-02, fs:0.70899 (r=0.677,p=0.744),  time:17.782, tt:480.121\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00012, loss_test:0.09938, lr:1.00e-02, fs:0.71579 (r=0.687,p=0.747),  time:17.913, tt:501.560\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00012, loss_test:0.09935, lr:1.00e-02, fs:0.72539 (r=0.707,p=0.745),  time:17.919, tt:519.661\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00011, loss_test:0.09840, lr:1.00e-02, fs:0.73846 (r=0.727,p=0.750),  time:17.894, tt:536.819\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00011, loss_test:0.09822, lr:1.00e-02, fs:0.71277 (r=0.677,p=0.753),  time:17.932, tt:555.892\n",
      "Ep:31, loss:0.00011, loss_test:0.09674, lr:1.00e-02, fs:0.74747 (r=0.747,p=0.747),  time:18.030, tt:576.959\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00010, loss_test:0.09525, lr:1.00e-02, fs:0.75258 (r=0.737,p=0.768),  time:18.077, tt:596.528\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00010, loss_test:0.09602, lr:1.00e-02, fs:0.74611 (r=0.727,p=0.766),  time:18.051, tt:613.722\n",
      "Ep:34, loss:0.00010, loss_test:0.09682, lr:1.00e-02, fs:0.74257 (r=0.758,p=0.728),  time:18.036, tt:631.269\n",
      "Ep:35, loss:0.00009, loss_test:0.09362, lr:1.00e-02, fs:0.74372 (r=0.747,p=0.740),  time:18.014, tt:648.497\n",
      "Ep:36, loss:0.00009, loss_test:0.09552, lr:1.00e-02, fs:0.74074 (r=0.707,p=0.778),  time:18.035, tt:667.293\n",
      "Ep:37, loss:0.00009, loss_test:0.09448, lr:1.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:17.993, tt:683.720\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00008, loss_test:0.09423, lr:1.00e-02, fs:0.74074 (r=0.707,p=0.778),  time:17.962, tt:700.516\n",
      "Ep:39, loss:0.00008, loss_test:0.09707, lr:1.00e-02, fs:0.76056 (r=0.818,p=0.711),  time:18.000, tt:720.014\n",
      "Ep:40, loss:0.00008, loss_test:0.09190, lr:1.00e-02, fs:0.75410 (r=0.697,p=0.821),  time:18.072, tt:740.933\n",
      "Ep:41, loss:0.00008, loss_test:0.09512, lr:1.00e-02, fs:0.76498 (r=0.838,p=0.703),  time:18.046, tt:757.914\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00008, loss_test:0.09178, lr:1.00e-02, fs:0.74576 (r=0.667,p=0.846),  time:18.033, tt:775.431\n",
      "Ep:43, loss:0.00007, loss_test:0.09248, lr:1.00e-02, fs:0.79452 (r=0.879,p=0.725),  time:18.070, tt:795.095\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00007, loss_test:0.09447, lr:1.00e-02, fs:0.73626 (r=0.677,p=0.807),  time:18.104, tt:814.693\n",
      "Ep:45, loss:0.00007, loss_test:0.08856, lr:1.00e-02, fs:0.79817 (r=0.879,p=0.731),  time:18.156, tt:835.169\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00007, loss_test:0.09589, lr:1.00e-02, fs:0.70056 (r=0.626,p=0.795),  time:18.211, tt:855.930\n",
      "Ep:47, loss:0.00006, loss_test:0.08739, lr:1.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:18.290, tt:877.936\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00006, loss_test:0.09646, lr:1.00e-02, fs:0.73864 (r=0.657,p=0.844),  time:18.377, tt:900.484\n",
      "Ep:49, loss:0.00006, loss_test:0.09345, lr:1.00e-02, fs:0.74146 (r=0.768,p=0.717),  time:18.371, tt:918.540\n",
      "Ep:50, loss:0.00006, loss_test:0.08694, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:18.375, tt:937.100\n",
      "Ep:51, loss:0.00006, loss_test:0.09495, lr:1.00e-02, fs:0.72043 (r=0.677,p=0.770),  time:18.396, tt:956.567\n",
      "Ep:52, loss:0.00006, loss_test:0.08797, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:18.419, tt:976.192\n",
      "Ep:53, loss:0.00005, loss_test:0.09725, lr:1.00e-02, fs:0.68539 (r=0.616,p=0.772),  time:18.409, tt:994.099\n",
      "Ep:54, loss:0.00005, loss_test:0.08974, lr:1.00e-02, fs:0.73797 (r=0.697,p=0.784),  time:18.408, tt:1012.440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:55, loss:0.00005, loss_test:0.09259, lr:1.00e-02, fs:0.73224 (r=0.677,p=0.798),  time:18.425, tt:1031.825\n",
      "Ep:56, loss:0.00005, loss_test:0.09354, lr:1.00e-02, fs:0.72826 (r=0.677,p=0.788),  time:18.433, tt:1050.686\n",
      "Ep:57, loss:0.00005, loss_test:0.08946, lr:1.00e-02, fs:0.74595 (r=0.697,p=0.802),  time:18.454, tt:1070.342\n",
      "Ep:58, loss:0.00005, loss_test:0.09267, lr:1.00e-02, fs:0.74033 (r=0.677,p=0.817),  time:18.428, tt:1087.273\n",
      "Ep:59, loss:0.00005, loss_test:0.09089, lr:9.90e-03, fs:0.74595 (r=0.697,p=0.802),  time:18.387, tt:1103.248\n",
      "Ep:60, loss:0.00004, loss_test:0.09172, lr:9.80e-03, fs:0.73446 (r=0.657,p=0.833),  time:18.396, tt:1122.171\n",
      "Ep:61, loss:0.00004, loss_test:0.09064, lr:9.70e-03, fs:0.74595 (r=0.697,p=0.802),  time:18.394, tt:1140.430\n",
      "Ep:62, loss:0.00004, loss_test:0.09550, lr:9.61e-03, fs:0.72000 (r=0.636,p=0.829),  time:18.392, tt:1158.696\n",
      "Ep:63, loss:0.00004, loss_test:0.08954, lr:9.51e-03, fs:0.74595 (r=0.697,p=0.802),  time:18.376, tt:1176.058\n",
      "Ep:64, loss:0.00004, loss_test:0.09020, lr:9.41e-03, fs:0.74286 (r=0.657,p=0.855),  time:18.382, tt:1194.842\n",
      "Ep:65, loss:0.00004, loss_test:0.09493, lr:9.32e-03, fs:0.73333 (r=0.667,p=0.815),  time:18.371, tt:1212.474\n",
      "Ep:66, loss:0.00004, loss_test:0.08770, lr:9.23e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.365, tt:1230.469\n",
      "Ep:67, loss:0.00004, loss_test:0.09786, lr:9.14e-03, fs:0.69364 (r=0.606,p=0.811),  time:18.366, tt:1248.880\n",
      "Ep:68, loss:0.00004, loss_test:0.08530, lr:9.04e-03, fs:0.74194 (r=0.697,p=0.793),  time:18.354, tt:1266.399\n",
      "Ep:69, loss:0.00004, loss_test:0.09595, lr:8.95e-03, fs:0.70115 (r=0.616,p=0.813),  time:18.340, tt:1283.810\n",
      "Ep:70, loss:0.00004, loss_test:0.08737, lr:8.86e-03, fs:0.71186 (r=0.636,p=0.808),  time:18.352, tt:1302.959\n",
      "Ep:71, loss:0.00004, loss_test:0.09409, lr:8.78e-03, fs:0.71038 (r=0.657,p=0.774),  time:18.355, tt:1321.562\n",
      "Ep:72, loss:0.00004, loss_test:0.09008, lr:8.69e-03, fs:0.73256 (r=0.636,p=0.863),  time:18.367, tt:1340.790\n",
      "Ep:73, loss:0.00004, loss_test:0.09054, lr:8.60e-03, fs:0.73797 (r=0.697,p=0.784),  time:18.354, tt:1358.205\n",
      "Ep:74, loss:0.00004, loss_test:0.09124, lr:8.51e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.376, tt:1378.172\n",
      "Ep:75, loss:0.00003, loss_test:0.09239, lr:8.43e-03, fs:0.76836 (r=0.687,p=0.872),  time:18.389, tt:1397.539\n",
      "Ep:76, loss:0.00003, loss_test:0.09127, lr:8.35e-03, fs:0.75410 (r=0.697,p=0.821),  time:18.392, tt:1416.214\n",
      "Ep:77, loss:0.00003, loss_test:0.09013, lr:8.26e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.399, tt:1435.116\n",
      "Ep:78, loss:0.00003, loss_test:0.09244, lr:8.18e-03, fs:0.76667 (r=0.697,p=0.852),  time:18.380, tt:1452.027\n",
      "Ep:79, loss:0.00003, loss_test:0.08831, lr:8.10e-03, fs:0.76667 (r=0.697,p=0.852),  time:18.368, tt:1469.444\n",
      "Ep:80, loss:0.00003, loss_test:0.09445, lr:8.02e-03, fs:0.75000 (r=0.667,p=0.857),  time:18.361, tt:1487.248\n",
      "Ep:81, loss:0.00003, loss_test:0.08808, lr:7.94e-03, fs:0.76243 (r=0.697,p=0.841),  time:18.354, tt:1505.026\n",
      "Ep:82, loss:0.00003, loss_test:0.09188, lr:7.86e-03, fs:0.76836 (r=0.687,p=0.872),  time:18.375, tt:1525.084\n",
      "Ep:83, loss:0.00003, loss_test:0.08924, lr:7.78e-03, fs:0.76243 (r=0.697,p=0.841),  time:18.401, tt:1545.707\n",
      "Ep:84, loss:0.00003, loss_test:0.08999, lr:7.70e-03, fs:0.76243 (r=0.697,p=0.841),  time:18.427, tt:1566.337\n",
      "Ep:85, loss:0.00003, loss_test:0.09017, lr:7.62e-03, fs:0.75000 (r=0.667,p=0.857),  time:18.429, tt:1584.937\n",
      "Ep:86, loss:0.00003, loss_test:0.08912, lr:7.55e-03, fs:0.76667 (r=0.697,p=0.852),  time:18.419, tt:1602.478\n",
      "Ep:87, loss:0.00003, loss_test:0.08930, lr:7.47e-03, fs:0.77095 (r=0.697,p=0.863),  time:18.461, tt:1624.561\n",
      "Ep:88, loss:0.00003, loss_test:0.09098, lr:7.40e-03, fs:0.77966 (r=0.697,p=0.885),  time:18.495, tt:1646.072\n",
      "Ep:89, loss:0.00002, loss_test:0.08787, lr:7.32e-03, fs:0.75410 (r=0.697,p=0.821),  time:18.491, tt:1664.163\n",
      "Ep:90, loss:0.00002, loss_test:0.08990, lr:7.25e-03, fs:0.78409 (r=0.697,p=0.896),  time:18.500, tt:1683.462\n",
      "Ep:91, loss:0.00002, loss_test:0.09071, lr:7.18e-03, fs:0.75978 (r=0.687,p=0.850),  time:18.505, tt:1702.470\n",
      "Ep:92, loss:0.00002, loss_test:0.08867, lr:7.11e-03, fs:0.75000 (r=0.667,p=0.857),  time:18.532, tt:1723.435\n",
      "Ep:93, loss:0.00002, loss_test:0.09260, lr:7.03e-03, fs:0.77966 (r=0.697,p=0.885),  time:18.547, tt:1743.458\n",
      "Ep:94, loss:0.00002, loss_test:0.08687, lr:6.96e-03, fs:0.75824 (r=0.697,p=0.831),  time:18.542, tt:1761.518\n",
      "Ep:95, loss:0.00002, loss_test:0.09028, lr:6.89e-03, fs:0.77095 (r=0.697,p=0.863),  time:18.551, tt:1780.897\n",
      "Ep:96, loss:0.00002, loss_test:0.08897, lr:6.83e-03, fs:0.77966 (r=0.697,p=0.885),  time:18.560, tt:1800.332\n",
      "Ep:97, loss:0.00002, loss_test:0.08926, lr:6.76e-03, fs:0.75556 (r=0.687,p=0.840),  time:18.570, tt:1819.896\n",
      "Ep:98, loss:0.00002, loss_test:0.08800, lr:6.69e-03, fs:0.77528 (r=0.697,p=0.873),  time:18.581, tt:1839.511\n",
      "Ep:99, loss:0.00002, loss_test:0.08836, lr:6.62e-03, fs:0.75556 (r=0.687,p=0.840),  time:18.582, tt:1858.237\n",
      "Ep:100, loss:0.00002, loss_test:0.08727, lr:6.56e-03, fs:0.77095 (r=0.697,p=0.863),  time:18.606, tt:1879.177\n",
      "Ep:101, loss:0.00002, loss_test:0.08820, lr:6.49e-03, fs:0.72941 (r=0.626,p=0.873),  time:18.629, tt:1900.184\n",
      "Ep:102, loss:0.00002, loss_test:0.08897, lr:6.43e-03, fs:0.76667 (r=0.697,p=0.852),  time:18.640, tt:1919.942\n",
      "Ep:103, loss:0.00002, loss_test:0.08747, lr:6.36e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.636, tt:1938.176\n",
      "Ep:104, loss:0.00002, loss_test:0.08852, lr:6.30e-03, fs:0.76667 (r=0.697,p=0.852),  time:18.660, tt:1959.339\n",
      "Ep:105, loss:0.00002, loss_test:0.08734, lr:6.24e-03, fs:0.77966 (r=0.697,p=0.885),  time:18.659, tt:1977.843\n",
      "Ep:106, loss:0.00002, loss_test:0.09015, lr:6.17e-03, fs:0.71765 (r=0.616,p=0.859),  time:18.660, tt:1996.603\n",
      "Ep:107, loss:0.00002, loss_test:0.08718, lr:6.11e-03, fs:0.77095 (r=0.697,p=0.863),  time:18.668, tt:2016.124\n",
      "Ep:108, loss:0.00002, loss_test:0.08828, lr:6.05e-03, fs:0.76836 (r=0.687,p=0.872),  time:18.672, tt:2035.233\n",
      "Ep:109, loss:0.00002, loss_test:0.08814, lr:5.99e-03, fs:0.77966 (r=0.697,p=0.885),  time:18.670, tt:2053.695\n",
      "Ep:110, loss:0.00002, loss_test:0.08680, lr:5.93e-03, fs:0.73333 (r=0.667,p=0.815),  time:18.682, tt:2073.680\n",
      "Ep:111, loss:0.00002, loss_test:0.08729, lr:5.87e-03, fs:0.78409 (r=0.697,p=0.896),  time:18.677, tt:2091.839\n",
      "Ep:112, loss:0.00002, loss_test:0.09016, lr:5.81e-03, fs:0.71765 (r=0.616,p=0.859),  time:18.678, tt:2110.620\n",
      "Ep:113, loss:0.00002, loss_test:0.08512, lr:5.75e-03, fs:0.77095 (r=0.697,p=0.863),  time:18.683, tt:2129.815\n",
      "Ep:114, loss:0.00002, loss_test:0.08908, lr:5.70e-03, fs:0.72515 (r=0.626,p=0.861),  time:18.682, tt:2148.395\n",
      "Ep:115, loss:0.00002, loss_test:0.08762, lr:5.64e-03, fs:0.77528 (r=0.697,p=0.873),  time:18.674, tt:2166.178\n",
      "Ep:116, loss:0.00002, loss_test:0.08687, lr:5.58e-03, fs:0.73256 (r=0.636,p=0.863),  time:18.691, tt:2186.889\n",
      "Ep:117, loss:0.00002, loss_test:0.08866, lr:5.53e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.712, tt:2208.033\n",
      "Ep:118, loss:0.00002, loss_test:0.08706, lr:5.47e-03, fs:0.72941 (r=0.626,p=0.873),  time:18.735, tt:2229.440\n",
      "Ep:119, loss:0.00002, loss_test:0.08718, lr:5.42e-03, fs:0.74860 (r=0.677,p=0.838),  time:18.732, tt:2247.795\n",
      "Ep:120, loss:0.00002, loss_test:0.08802, lr:5.36e-03, fs:0.72515 (r=0.626,p=0.861),  time:18.725, tt:2265.673\n",
      "Ep:121, loss:0.00002, loss_test:0.08833, lr:5.31e-03, fs:0.75862 (r=0.667,p=0.880),  time:18.732, tt:2285.257\n",
      "Ep:122, loss:0.00002, loss_test:0.08631, lr:5.26e-03, fs:0.73256 (r=0.636,p=0.863),  time:18.768, tt:2308.468\n",
      "Ep:123, loss:0.00002, loss_test:0.08942, lr:5.20e-03, fs:0.69091 (r=0.576,p=0.864),  time:18.789, tt:2329.778\n",
      "Ep:124, loss:0.00002, loss_test:0.08832, lr:5.15e-03, fs:0.73684 (r=0.636,p=0.875),  time:18.810, tt:2351.258\n",
      "Ep:125, loss:0.00002, loss_test:0.08779, lr:5.10e-03, fs:0.70659 (r=0.596,p=0.868),  time:18.831, tt:2372.753\n",
      "Ep:126, loss:0.00002, loss_test:0.08817, lr:5.05e-03, fs:0.75145 (r=0.657,p=0.878),  time:18.858, tt:2394.970\n",
      "Ep:127, loss:0.00002, loss_test:0.08720, lr:5.00e-03, fs:0.71006 (r=0.606,p=0.857),  time:18.878, tt:2416.341\n",
      "Ep:128, loss:0.00002, loss_test:0.08856, lr:4.95e-03, fs:0.72189 (r=0.616,p=0.871),  time:18.874, tt:2434.786\n",
      "Ep:129, loss:0.00002, loss_test:0.08763, lr:4.90e-03, fs:0.70659 (r=0.596,p=0.868),  time:18.874, tt:2453.645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:130, loss:0.00002, loss_test:0.08799, lr:4.85e-03, fs:0.74556 (r=0.636,p=0.900),  time:18.884, tt:2473.761\n",
      "Ep:131, loss:0.00002, loss_test:0.08734, lr:4.80e-03, fs:0.70659 (r=0.596,p=0.868),  time:18.886, tt:2492.930\n",
      "Ep:132, loss:0.00002, loss_test:0.08774, lr:4.75e-03, fs:0.69880 (r=0.586,p=0.866),  time:18.895, tt:2513.038\n",
      "Ep:133, loss:0.00001, loss_test:0.08792, lr:4.71e-03, fs:0.73810 (r=0.626,p=0.899),  time:18.904, tt:2533.145\n",
      "Ep:134, loss:0.00001, loss_test:0.08768, lr:4.66e-03, fs:0.69880 (r=0.586,p=0.866),  time:18.891, tt:2550.337\n",
      "Ep:135, loss:0.00001, loss_test:0.08749, lr:4.61e-03, fs:0.74118 (r=0.636,p=0.887),  time:18.878, tt:2567.360\n",
      "Ep:136, loss:0.00001, loss_test:0.08929, lr:4.57e-03, fs:0.67485 (r=0.556,p=0.859),  time:18.868, tt:2584.898\n",
      "Ep:137, loss:0.00001, loss_test:0.08813, lr:4.52e-03, fs:0.70732 (r=0.586,p=0.892),  time:18.869, tt:2603.965\n",
      "Ep:138, loss:0.00001, loss_test:0.08814, lr:4.48e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.852, tt:2620.472\n",
      "Ep:139, loss:0.00001, loss_test:0.08865, lr:4.43e-03, fs:0.67901 (r=0.556,p=0.873),  time:18.853, tt:2639.359\n",
      "Ep:140, loss:0.00001, loss_test:0.08843, lr:4.39e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.858, tt:2658.951\n",
      "Ep:141, loss:0.00001, loss_test:0.08959, lr:4.34e-03, fs:0.67901 (r=0.556,p=0.873),  time:18.849, tt:2676.534\n",
      "Ep:142, loss:0.00001, loss_test:0.08771, lr:4.30e-03, fs:0.71166 (r=0.586,p=0.906),  time:18.830, tt:2692.712\n",
      "Ep:143, loss:0.00001, loss_test:0.08841, lr:4.26e-03, fs:0.67901 (r=0.556,p=0.873),  time:18.815, tt:2709.408\n",
      "Ep:144, loss:0.00001, loss_test:0.08971, lr:4.21e-03, fs:0.68323 (r=0.556,p=0.887),  time:18.795, tt:2725.220\n",
      "Ep:145, loss:0.00001, loss_test:0.08801, lr:4.17e-03, fs:0.71951 (r=0.596,p=0.908),  time:18.782, tt:2742.102\n",
      "Ep:146, loss:0.00001, loss_test:0.08924, lr:4.13e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.775, tt:2759.881\n",
      "Ep:147, loss:0.00001, loss_test:0.09019, lr:4.09e-03, fs:0.68323 (r=0.556,p=0.887),  time:18.767, tt:2777.464\n",
      "Ep:148, loss:0.00001, loss_test:0.08946, lr:4.05e-03, fs:0.69620 (r=0.556,p=0.932),  time:18.772, tt:2797.012\n",
      "Ep:149, loss:0.00001, loss_test:0.09014, lr:4.01e-03, fs:0.67901 (r=0.556,p=0.873),  time:18.765, tt:2814.816\n",
      "Ep:150, loss:0.00001, loss_test:0.08841, lr:3.97e-03, fs:0.69182 (r=0.556,p=0.917),  time:18.771, tt:2834.479\n",
      "Ep:151, loss:0.00001, loss_test:0.09055, lr:3.93e-03, fs:0.69182 (r=0.556,p=0.917),  time:18.740, tt:2848.476\n",
      "Ep:152, loss:0.00001, loss_test:0.08985, lr:3.89e-03, fs:0.68750 (r=0.556,p=0.902),  time:18.710, tt:2862.683\n",
      "Ep:153, loss:0.00001, loss_test:0.08964, lr:3.85e-03, fs:0.68323 (r=0.556,p=0.887),  time:18.674, tt:2875.830\n",
      "Ep:154, loss:0.00001, loss_test:0.08969, lr:3.81e-03, fs:0.69182 (r=0.556,p=0.917),  time:18.662, tt:2892.661\n",
      "Ep:155, loss:0.00001, loss_test:0.09012, lr:3.77e-03, fs:0.68750 (r=0.556,p=0.902),  time:18.662, tt:2911.328\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13985, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:18.740, tt:18.740\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13770, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:20.009, tt:40.017\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00028, loss_test:0.13412, lr:1.00e-02, fs:0.67820 (r=0.990,p=0.516),  time:20.471, tt:61.412\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.12926, lr:1.00e-02, fs:0.66667 (r=0.939,p=0.517),  time:21.497, tt:85.987\n",
      "Ep:4, loss:0.00026, loss_test:0.12407, lr:1.00e-02, fs:0.66409 (r=0.869,p=0.537),  time:21.399, tt:106.993\n",
      "Ep:5, loss:0.00025, loss_test:0.12034, lr:1.00e-02, fs:0.67742 (r=0.848,p=0.564),  time:21.324, tt:127.942\n",
      "Ep:6, loss:0.00025, loss_test:0.11916, lr:1.00e-02, fs:0.67769 (r=0.828,p=0.573),  time:21.201, tt:148.409\n",
      "Ep:7, loss:0.00024, loss_test:0.11816, lr:1.00e-02, fs:0.69388 (r=0.859,p=0.582),  time:21.255, tt:170.040\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11642, lr:1.00e-02, fs:0.69421 (r=0.848,p=0.587),  time:21.215, tt:190.939\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.11376, lr:1.00e-02, fs:0.68142 (r=0.778,p=0.606),  time:21.222, tt:212.216\n",
      "Ep:10, loss:0.00021, loss_test:0.11292, lr:1.00e-02, fs:0.68807 (r=0.758,p=0.630),  time:20.895, tt:229.843\n",
      "Ep:11, loss:0.00020, loss_test:0.11200, lr:1.00e-02, fs:0.68750 (r=0.778,p=0.616),  time:20.792, tt:249.508\n",
      "Ep:12, loss:0.00019, loss_test:0.10984, lr:1.00e-02, fs:0.70642 (r=0.778,p=0.647),  time:20.415, tt:265.399\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.10753, lr:1.00e-02, fs:0.72986 (r=0.778,p=0.688),  time:20.201, tt:282.810\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.10511, lr:1.00e-02, fs:0.74775 (r=0.838,p=0.675),  time:20.111, tt:301.658\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.10313, lr:1.00e-02, fs:0.74766 (r=0.808,p=0.696),  time:20.167, tt:322.668\n",
      "Ep:16, loss:0.00016, loss_test:0.10249, lr:1.00e-02, fs:0.74766 (r=0.808,p=0.696),  time:20.241, tt:344.092\n",
      "Ep:17, loss:0.00015, loss_test:0.10163, lr:1.00e-02, fs:0.75248 (r=0.768,p=0.738),  time:20.321, tt:365.776\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.09916, lr:1.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:20.364, tt:386.916\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.09891, lr:1.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:20.373, tt:407.460\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.09893, lr:1.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:20.349, tt:427.320\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.09685, lr:1.00e-02, fs:0.80392 (r=0.828,p=0.781),  time:20.348, tt:447.656\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00012, loss_test:0.09664, lr:1.00e-02, fs:0.78846 (r=0.828,p=0.752),  time:20.305, tt:467.015\n",
      "Ep:23, loss:0.00012, loss_test:0.09567, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:20.390, tt:489.368\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.09372, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:20.384, tt:509.599\n",
      "Ep:25, loss:0.00011, loss_test:0.09308, lr:1.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:20.434, tt:531.275\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00010, loss_test:0.09434, lr:1.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:20.398, tt:550.733\n",
      "Ep:27, loss:0.00010, loss_test:0.09040, lr:1.00e-02, fs:0.82126 (r=0.859,p=0.787),  time:20.491, tt:573.750\n",
      "Ep:28, loss:0.00010, loss_test:0.09184, lr:1.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:20.604, tt:597.524\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00009, loss_test:0.09159, lr:1.00e-02, fs:0.85000 (r=0.859,p=0.842),  time:20.735, tt:622.040\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00009, loss_test:0.08891, lr:1.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:20.763, tt:643.666\n",
      "Ep:31, loss:0.00009, loss_test:0.09006, lr:1.00e-02, fs:0.85000 (r=0.859,p=0.842),  time:20.860, tt:667.507\n",
      "Ep:32, loss:0.00008, loss_test:0.08998, lr:1.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:20.930, tt:690.690\n",
      "Ep:33, loss:0.00008, loss_test:0.08707, lr:1.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:20.921, tt:711.300\n",
      "Ep:34, loss:0.00008, loss_test:0.08945, lr:1.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:20.868, tt:730.377\n",
      "Ep:35, loss:0.00007, loss_test:0.08648, lr:1.00e-02, fs:0.85000 (r=0.859,p=0.842),  time:20.856, tt:750.821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:36, loss:0.00007, loss_test:0.08385, lr:1.00e-02, fs:0.85572 (r=0.869,p=0.843),  time:20.801, tt:769.640\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00007, loss_test:0.08657, lr:1.00e-02, fs:0.85427 (r=0.859,p=0.850),  time:20.868, tt:792.996\n",
      "Ep:38, loss:0.00007, loss_test:0.09623, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:20.899, tt:815.058\n",
      "Ep:39, loss:0.00007, loss_test:0.08307, lr:1.00e-02, fs:0.86432 (r=0.869,p=0.860),  time:20.991, tt:839.621\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00007, loss_test:0.08307, lr:1.00e-02, fs:0.86432 (r=0.869,p=0.860),  time:21.026, tt:862.055\n",
      "Ep:41, loss:0.00006, loss_test:0.08799, lr:1.00e-02, fs:0.82474 (r=0.808,p=0.842),  time:21.024, tt:883.007\n",
      "Ep:42, loss:0.00006, loss_test:0.08667, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:21.009, tt:903.386\n",
      "Ep:43, loss:0.00006, loss_test:0.08145, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:20.987, tt:923.440\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00006, loss_test:0.08433, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:20.978, tt:944.016\n",
      "Ep:45, loss:0.00005, loss_test:0.08448, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:21.016, tt:966.742\n",
      "Ep:46, loss:0.00005, loss_test:0.08177, lr:1.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:21.020, tt:987.939\n",
      "Ep:47, loss:0.00005, loss_test:0.08116, lr:1.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:21.010, tt:1008.499\n",
      "Ep:48, loss:0.00005, loss_test:0.07898, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:21.062, tt:1032.046\n",
      "Ep:49, loss:0.00005, loss_test:0.08361, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:21.050, tt:1052.478\n",
      "Ep:50, loss:0.00005, loss_test:0.09119, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:21.031, tt:1072.606\n",
      "Ep:51, loss:0.00005, loss_test:0.08383, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:21.029, tt:1093.523\n",
      "Ep:52, loss:0.00005, loss_test:0.07735, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:21.033, tt:1114.741\n",
      "Ep:53, loss:0.00005, loss_test:0.07834, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:21.072, tt:1137.899\n",
      "Ep:54, loss:0.00004, loss_test:0.08754, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:21.085, tt:1159.694\n",
      "Ep:55, loss:0.00004, loss_test:0.07843, lr:9.90e-03, fs:0.86010 (r=0.838,p=0.883),  time:21.066, tt:1179.711\n",
      "Ep:56, loss:0.00004, loss_test:0.08127, lr:9.80e-03, fs:0.84656 (r=0.808,p=0.889),  time:21.055, tt:1200.112\n",
      "Ep:57, loss:0.00004, loss_test:0.08650, lr:9.70e-03, fs:0.85263 (r=0.818,p=0.890),  time:21.069, tt:1221.994\n",
      "Ep:58, loss:0.00004, loss_test:0.07651, lr:9.61e-03, fs:0.88325 (r=0.879,p=0.888),  time:21.074, tt:1243.362\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00004, loss_test:0.07775, lr:9.61e-03, fs:0.88776 (r=0.879,p=0.897),  time:21.078, tt:1264.697\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00004, loss_test:0.07974, lr:9.61e-03, fs:0.85263 (r=0.818,p=0.890),  time:21.093, tt:1286.670\n",
      "Ep:61, loss:0.00004, loss_test:0.08398, lr:9.61e-03, fs:0.85263 (r=0.818,p=0.890),  time:21.064, tt:1305.998\n",
      "Ep:62, loss:0.00004, loss_test:0.07788, lr:9.61e-03, fs:0.85263 (r=0.818,p=0.890),  time:21.121, tt:1330.606\n",
      "Ep:63, loss:0.00004, loss_test:0.08557, lr:9.61e-03, fs:0.85263 (r=0.818,p=0.890),  time:21.106, tt:1350.777\n",
      "Ep:64, loss:0.00003, loss_test:0.07964, lr:9.61e-03, fs:0.85714 (r=0.818,p=0.900),  time:21.115, tt:1372.444\n",
      "Ep:65, loss:0.00003, loss_test:0.07714, lr:9.61e-03, fs:0.86911 (r=0.838,p=0.902),  time:21.153, tt:1396.127\n",
      "Ep:66, loss:0.00003, loss_test:0.08840, lr:9.61e-03, fs:0.85263 (r=0.818,p=0.890),  time:21.162, tt:1417.867\n",
      "Ep:67, loss:0.00004, loss_test:0.08331, lr:9.61e-03, fs:0.85714 (r=0.818,p=0.900),  time:21.164, tt:1439.140\n",
      "Ep:68, loss:0.00003, loss_test:0.07671, lr:9.61e-03, fs:0.85263 (r=0.818,p=0.890),  time:21.222, tt:1464.295\n",
      "Ep:69, loss:0.00003, loss_test:0.08793, lr:9.61e-03, fs:0.85263 (r=0.818,p=0.890),  time:21.266, tt:1488.601\n",
      "Ep:70, loss:0.00003, loss_test:0.07732, lr:9.61e-03, fs:0.85263 (r=0.818,p=0.890),  time:21.299, tt:1512.240\n",
      "Ep:71, loss:0.00003, loss_test:0.08345, lr:9.51e-03, fs:0.85263 (r=0.818,p=0.890),  time:21.308, tt:1534.194\n",
      "Ep:72, loss:0.00003, loss_test:0.08317, lr:9.41e-03, fs:0.86170 (r=0.818,p=0.910),  time:21.327, tt:1556.841\n",
      "Ep:73, loss:0.00003, loss_test:0.07875, lr:9.32e-03, fs:0.85714 (r=0.818,p=0.900),  time:21.343, tt:1579.358\n",
      "Ep:74, loss:0.00003, loss_test:0.08245, lr:9.23e-03, fs:0.85263 (r=0.818,p=0.890),  time:21.365, tt:1602.340\n",
      "Ep:75, loss:0.00003, loss_test:0.07895, lr:9.14e-03, fs:0.85714 (r=0.818,p=0.900),  time:21.391, tt:1625.712\n",
      "Ep:76, loss:0.00003, loss_test:0.08203, lr:9.04e-03, fs:0.85263 (r=0.818,p=0.890),  time:21.380, tt:1646.259\n",
      "Ep:77, loss:0.00003, loss_test:0.08062, lr:8.95e-03, fs:0.85714 (r=0.818,p=0.900),  time:21.355, tt:1665.726\n",
      "Ep:78, loss:0.00003, loss_test:0.08043, lr:8.86e-03, fs:0.86170 (r=0.818,p=0.910),  time:21.335, tt:1685.482\n",
      "Ep:79, loss:0.00002, loss_test:0.08281, lr:8.78e-03, fs:0.85714 (r=0.818,p=0.900),  time:21.319, tt:1705.550\n",
      "Ep:80, loss:0.00002, loss_test:0.07848, lr:8.69e-03, fs:0.85714 (r=0.818,p=0.900),  time:21.301, tt:1725.390\n",
      "Ep:81, loss:0.00002, loss_test:0.08106, lr:8.60e-03, fs:0.86170 (r=0.818,p=0.910),  time:21.282, tt:1745.124\n",
      "Ep:82, loss:0.00002, loss_test:0.08154, lr:8.51e-03, fs:0.86170 (r=0.818,p=0.910),  time:21.271, tt:1765.532\n",
      "Ep:83, loss:0.00002, loss_test:0.07832, lr:8.43e-03, fs:0.86170 (r=0.818,p=0.910),  time:21.252, tt:1785.183\n",
      "Ep:84, loss:0.00002, loss_test:0.08297, lr:8.35e-03, fs:0.86170 (r=0.818,p=0.910),  time:21.238, tt:1805.194\n",
      "Ep:85, loss:0.00002, loss_test:0.08030, lr:8.26e-03, fs:0.85714 (r=0.818,p=0.900),  time:21.221, tt:1825.030\n",
      "Ep:86, loss:0.00002, loss_test:0.07981, lr:8.18e-03, fs:0.86170 (r=0.818,p=0.910),  time:21.241, tt:1847.985\n",
      "Ep:87, loss:0.00002, loss_test:0.08382, lr:8.10e-03, fs:0.85714 (r=0.818,p=0.900),  time:21.230, tt:1868.224\n",
      "Ep:88, loss:0.00002, loss_test:0.08025, lr:8.02e-03, fs:0.86170 (r=0.818,p=0.910),  time:21.228, tt:1889.325\n",
      "Ep:89, loss:0.00002, loss_test:0.07998, lr:7.94e-03, fs:0.86631 (r=0.818,p=0.920),  time:21.246, tt:1912.172\n",
      "Ep:90, loss:0.00002, loss_test:0.08425, lr:7.86e-03, fs:0.85263 (r=0.818,p=0.890),  time:21.271, tt:1935.659\n",
      "Ep:91, loss:0.00002, loss_test:0.07843, lr:7.78e-03, fs:0.86631 (r=0.818,p=0.920),  time:21.284, tt:1958.088\n",
      "Ep:92, loss:0.00002, loss_test:0.08616, lr:7.70e-03, fs:0.86631 (r=0.818,p=0.920),  time:21.276, tt:1978.675\n",
      "Ep:93, loss:0.00002, loss_test:0.07975, lr:7.62e-03, fs:0.86170 (r=0.818,p=0.910),  time:21.297, tt:2001.919\n",
      "Ep:94, loss:0.00002, loss_test:0.08580, lr:7.55e-03, fs:0.86631 (r=0.818,p=0.920),  time:21.293, tt:2022.806\n",
      "Ep:95, loss:0.00002, loss_test:0.07857, lr:7.47e-03, fs:0.86631 (r=0.818,p=0.920),  time:21.291, tt:2043.970\n",
      "Ep:96, loss:0.00002, loss_test:0.08498, lr:7.40e-03, fs:0.86631 (r=0.818,p=0.920),  time:21.265, tt:2062.738\n",
      "Ep:97, loss:0.00002, loss_test:0.08076, lr:7.32e-03, fs:0.86631 (r=0.818,p=0.920),  time:21.274, tt:2084.861\n",
      "Ep:98, loss:0.00002, loss_test:0.08338, lr:7.25e-03, fs:0.86631 (r=0.818,p=0.920),  time:21.279, tt:2106.657\n",
      "Ep:99, loss:0.00002, loss_test:0.08117, lr:7.18e-03, fs:0.87097 (r=0.818,p=0.931),  time:21.280, tt:2128.001\n",
      "Ep:100, loss:0.00002, loss_test:0.08535, lr:7.11e-03, fs:0.86631 (r=0.818,p=0.920),  time:21.282, tt:2149.444\n",
      "Ep:101, loss:0.00002, loss_test:0.07828, lr:7.03e-03, fs:0.86631 (r=0.818,p=0.920),  time:21.270, tt:2169.510\n",
      "Ep:102, loss:0.00002, loss_test:0.08819, lr:6.96e-03, fs:0.86631 (r=0.818,p=0.920),  time:21.256, tt:2189.347\n",
      "Ep:103, loss:0.00002, loss_test:0.07980, lr:6.89e-03, fs:0.87097 (r=0.818,p=0.931),  time:21.238, tt:2208.731\n",
      "Ep:104, loss:0.00002, loss_test:0.08575, lr:6.83e-03, fs:0.86170 (r=0.818,p=0.910),  time:21.228, tt:2228.953\n",
      "Ep:105, loss:0.00002, loss_test:0.07832, lr:6.76e-03, fs:0.87097 (r=0.818,p=0.931),  time:21.222, tt:2249.526\n",
      "Ep:106, loss:0.00002, loss_test:0.09057, lr:6.69e-03, fs:0.86170 (r=0.818,p=0.910),  time:21.215, tt:2270.017\n",
      "Ep:107, loss:0.00002, loss_test:0.07974, lr:6.62e-03, fs:0.87097 (r=0.818,p=0.931),  time:21.200, tt:2289.549\n",
      "Ep:108, loss:0.00002, loss_test:0.09249, lr:6.56e-03, fs:0.86170 (r=0.818,p=0.910),  time:21.204, tt:2311.232\n",
      "Ep:109, loss:0.00002, loss_test:0.07977, lr:6.49e-03, fs:0.89362 (r=0.848,p=0.944),  time:21.222, tt:2334.416\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:110, loss:0.00002, loss_test:0.09162, lr:6.49e-03, fs:0.85263 (r=0.818,p=0.890),  time:21.225, tt:2356.022\n",
      "Ep:111, loss:0.00002, loss_test:0.08132, lr:6.49e-03, fs:0.88525 (r=0.818,p=0.964),  time:21.237, tt:2378.566\n",
      "Ep:112, loss:0.00002, loss_test:0.08660, lr:6.49e-03, fs:0.86631 (r=0.818,p=0.920),  time:21.264, tt:2402.822\n",
      "Ep:113, loss:0.00002, loss_test:0.08654, lr:6.49e-03, fs:0.85714 (r=0.818,p=0.900),  time:21.262, tt:2423.917\n",
      "Ep:114, loss:0.00002, loss_test:0.08044, lr:6.49e-03, fs:0.88043 (r=0.818,p=0.953),  time:21.256, tt:2444.392\n",
      "Ep:115, loss:0.00002, loss_test:0.08934, lr:6.49e-03, fs:0.86170 (r=0.818,p=0.910),  time:21.257, tt:2465.835\n",
      "Ep:116, loss:0.00002, loss_test:0.08506, lr:6.49e-03, fs:0.87097 (r=0.818,p=0.931),  time:21.276, tt:2489.235\n",
      "Ep:117, loss:0.00002, loss_test:0.08112, lr:6.49e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.267, tt:2509.542\n",
      "Ep:118, loss:0.00002, loss_test:0.08771, lr:6.49e-03, fs:0.86170 (r=0.818,p=0.910),  time:21.275, tt:2531.736\n",
      "Ep:119, loss:0.00002, loss_test:0.08335, lr:6.49e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.280, tt:2553.547\n",
      "Ep:120, loss:0.00002, loss_test:0.08288, lr:6.49e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.270, tt:2573.625\n",
      "Ep:121, loss:0.00002, loss_test:0.08564, lr:6.43e-03, fs:0.87097 (r=0.818,p=0.931),  time:21.268, tt:2594.652\n",
      "Ep:122, loss:0.00002, loss_test:0.08438, lr:6.36e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.279, tt:2617.351\n",
      "Ep:123, loss:0.00001, loss_test:0.08605, lr:6.30e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.277, tt:2638.398\n",
      "Ep:124, loss:0.00001, loss_test:0.08429, lr:6.24e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.280, tt:2660.039\n",
      "Ep:125, loss:0.00001, loss_test:0.08466, lr:6.17e-03, fs:0.87097 (r=0.818,p=0.931),  time:21.287, tt:2682.219\n",
      "Ep:126, loss:0.00001, loss_test:0.08526, lr:6.11e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.272, tt:2701.547\n",
      "Ep:127, loss:0.00001, loss_test:0.08422, lr:6.05e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.276, tt:2723.286\n",
      "Ep:128, loss:0.00001, loss_test:0.08699, lr:5.99e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.261, tt:2742.674\n",
      "Ep:129, loss:0.00001, loss_test:0.08627, lr:5.93e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.261, tt:2763.951\n",
      "Ep:130, loss:0.00001, loss_test:0.08467, lr:5.87e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.264, tt:2785.598\n",
      "Ep:131, loss:0.00001, loss_test:0.08786, lr:5.81e-03, fs:0.87097 (r=0.818,p=0.931),  time:21.261, tt:2806.497\n",
      "Ep:132, loss:0.00001, loss_test:0.08511, lr:5.75e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.265, tt:2828.297\n",
      "Ep:133, loss:0.00001, loss_test:0.08623, lr:5.70e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.260, tt:2848.872\n",
      "Ep:134, loss:0.00001, loss_test:0.08663, lr:5.64e-03, fs:0.87097 (r=0.818,p=0.931),  time:21.275, tt:2872.148\n",
      "Ep:135, loss:0.00001, loss_test:0.08492, lr:5.58e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.275, tt:2893.407\n",
      "Ep:136, loss:0.00001, loss_test:0.08670, lr:5.53e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.276, tt:2914.839\n",
      "Ep:137, loss:0.00001, loss_test:0.08544, lr:5.47e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.275, tt:2935.941\n",
      "Ep:138, loss:0.00001, loss_test:0.08686, lr:5.42e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.289, tt:2959.169\n",
      "Ep:139, loss:0.00001, loss_test:0.08637, lr:5.36e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.285, tt:2979.866\n",
      "Ep:140, loss:0.00001, loss_test:0.08515, lr:5.31e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.295, tt:3002.643\n",
      "Ep:141, loss:0.00001, loss_test:0.08739, lr:5.26e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.306, tt:3025.518\n",
      "Ep:142, loss:0.00001, loss_test:0.08544, lr:5.20e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.301, tt:3045.992\n",
      "Ep:143, loss:0.00001, loss_test:0.08657, lr:5.15e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.300, tt:3067.224\n",
      "Ep:144, loss:0.00001, loss_test:0.08561, lr:5.10e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.304, tt:3089.139\n",
      "Ep:145, loss:0.00001, loss_test:0.08663, lr:5.05e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.302, tt:3110.062\n",
      "Ep:146, loss:0.00001, loss_test:0.08538, lr:5.00e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.307, tt:3132.146\n",
      "Ep:147, loss:0.00001, loss_test:0.08672, lr:4.95e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.307, tt:3153.509\n",
      "Ep:148, loss:0.00001, loss_test:0.08706, lr:4.90e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.319, tt:3176.562\n",
      "Ep:149, loss:0.00001, loss_test:0.08602, lr:4.85e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.336, tt:3200.418\n",
      "Ep:150, loss:0.00001, loss_test:0.08648, lr:4.80e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.344, tt:3222.932\n",
      "Ep:151, loss:0.00001, loss_test:0.08612, lr:4.75e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.353, tt:3245.597\n",
      "Ep:152, loss:0.00001, loss_test:0.08674, lr:4.71e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.360, tt:3268.032\n",
      "Ep:153, loss:0.00001, loss_test:0.08567, lr:4.66e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.336, tt:3285.761\n",
      "Ep:154, loss:0.00001, loss_test:0.08669, lr:4.61e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.320, tt:3304.569\n",
      "Ep:155, loss:0.00001, loss_test:0.08618, lr:4.57e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.330, tt:3327.464\n",
      "Ep:156, loss:0.00001, loss_test:0.08687, lr:4.52e-03, fs:0.87568 (r=0.818,p=0.942),  time:21.348, tt:3351.607\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.14278, lr:1.00e-02, fs:0.65052 (r=0.949,p=0.495),  time:18.691, tt:18.691\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14009, lr:1.00e-02, fs:0.66667 (r=0.939,p=0.517),  time:20.386, tt:40.772\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.13591, lr:1.00e-02, fs:0.63670 (r=0.859,p=0.506),  time:20.232, tt:60.696\n",
      "Ep:3, loss:0.00025, loss_test:0.13360, lr:1.00e-02, fs:0.62810 (r=0.768,p=0.531),  time:20.845, tt:83.381\n",
      "Ep:4, loss:0.00025, loss_test:0.13358, lr:1.00e-02, fs:0.62338 (r=0.727,p=0.545),  time:21.394, tt:106.972\n",
      "Ep:5, loss:0.00024, loss_test:0.13325, lr:1.00e-02, fs:0.63111 (r=0.717,p=0.563),  time:21.199, tt:127.192\n",
      "Ep:6, loss:0.00024, loss_test:0.13048, lr:1.00e-02, fs:0.61947 (r=0.707,p=0.551),  time:21.159, tt:148.116\n",
      "Ep:7, loss:0.00023, loss_test:0.12850, lr:1.00e-02, fs:0.62009 (r=0.717,p=0.546),  time:21.493, tt:171.943\n",
      "Ep:8, loss:0.00023, loss_test:0.12728, lr:1.00e-02, fs:0.63063 (r=0.707,p=0.569),  time:21.592, tt:194.325\n",
      "Ep:9, loss:0.00022, loss_test:0.12644, lr:1.00e-02, fs:0.64455 (r=0.687,p=0.607),  time:21.576, tt:215.759\n",
      "Ep:10, loss:0.00021, loss_test:0.12162, lr:1.00e-02, fs:0.64423 (r=0.677,p=0.615),  time:21.717, tt:238.888\n",
      "Ep:11, loss:0.00020, loss_test:0.11880, lr:1.00e-02, fs:0.65025 (r=0.667,p=0.635),  time:21.626, tt:259.511\n",
      "Ep:12, loss:0.00019, loss_test:0.11785, lr:1.00e-02, fs:0.64646 (r=0.646,p=0.646),  time:21.315, tt:277.098\n",
      "Ep:13, loss:0.00018, loss_test:0.11633, lr:9.90e-03, fs:0.64322 (r=0.646,p=0.640),  time:21.079, tt:295.101\n",
      "Ep:14, loss:0.00018, loss_test:0.11424, lr:9.80e-03, fs:0.60825 (r=0.596,p=0.621),  time:20.668, tt:310.013\n",
      "Ep:15, loss:0.00017, loss_test:0.11149, lr:9.70e-03, fs:0.61780 (r=0.596,p=0.641),  time:20.356, tt:325.688\n",
      "Ep:16, loss:0.00016, loss_test:0.10855, lr:9.61e-03, fs:0.65672 (r=0.667,p=0.647),  time:20.070, tt:341.187\n",
      "Ep:17, loss:0.00016, loss_test:0.10761, lr:9.51e-03, fs:0.67692 (r=0.667,p=0.688),  time:19.868, tt:357.615\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.10479, lr:9.51e-03, fs:0.69072 (r=0.677,p=0.705),  time:19.578, tt:371.981\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.10128, lr:9.51e-03, fs:0.70769 (r=0.697,p=0.719),  time:19.344, tt:386.878\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.09963, lr:9.51e-03, fs:0.72081 (r=0.717,p=0.724),  time:19.160, tt:402.349\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.09732, lr:9.51e-03, fs:0.72251 (r=0.697,p=0.750),  time:18.980, tt:417.556\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:22, loss:0.00012, loss_test:0.09445, lr:9.51e-03, fs:0.77949 (r=0.768,p=0.792),  time:18.798, tt:432.347\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.09382, lr:9.51e-03, fs:0.77720 (r=0.758,p=0.798),  time:18.655, tt:447.714\n",
      "Ep:24, loss:0.00011, loss_test:0.09220, lr:9.51e-03, fs:0.77720 (r=0.758,p=0.798),  time:18.536, tt:463.410\n",
      "Ep:25, loss:0.00011, loss_test:0.09035, lr:9.51e-03, fs:0.76190 (r=0.727,p=0.800),  time:18.380, tt:477.872\n",
      "Ep:26, loss:0.00011, loss_test:0.09025, lr:9.51e-03, fs:0.79397 (r=0.798,p=0.790),  time:18.239, tt:492.444\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00010, loss_test:0.08969, lr:9.51e-03, fs:0.75532 (r=0.717,p=0.798),  time:18.100, tt:506.790\n",
      "Ep:28, loss:0.00010, loss_test:0.08868, lr:9.51e-03, fs:0.80583 (r=0.838,p=0.776),  time:17.991, tt:521.731\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00010, loss_test:0.08652, lr:9.51e-03, fs:0.80208 (r=0.778,p=0.828),  time:17.930, tt:537.892\n",
      "Ep:30, loss:0.00009, loss_test:0.08736, lr:9.51e-03, fs:0.79592 (r=0.788,p=0.804),  time:17.803, tt:551.897\n",
      "Ep:31, loss:0.00009, loss_test:0.08332, lr:9.51e-03, fs:0.82412 (r=0.828,p=0.820),  time:17.704, tt:566.529\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00008, loss_test:0.08513, lr:9.51e-03, fs:0.81026 (r=0.798,p=0.823),  time:17.612, tt:581.188\n",
      "Ep:33, loss:0.00008, loss_test:0.08240, lr:9.51e-03, fs:0.84158 (r=0.859,p=0.825),  time:17.551, tt:596.740\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00008, loss_test:0.08363, lr:9.51e-03, fs:0.80208 (r=0.778,p=0.828),  time:17.480, tt:611.792\n",
      "Ep:35, loss:0.00008, loss_test:0.08101, lr:9.51e-03, fs:0.85437 (r=0.889,p=0.822),  time:17.414, tt:626.902\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00007, loss_test:0.08224, lr:9.51e-03, fs:0.82902 (r=0.808,p=0.851),  time:17.346, tt:641.802\n",
      "Ep:37, loss:0.00007, loss_test:0.08140, lr:9.51e-03, fs:0.84729 (r=0.869,p=0.827),  time:17.275, tt:656.446\n",
      "Ep:38, loss:0.00007, loss_test:0.08290, lr:9.51e-03, fs:0.81026 (r=0.798,p=0.823),  time:17.206, tt:671.031\n",
      "Ep:39, loss:0.00007, loss_test:0.08067, lr:9.51e-03, fs:0.82828 (r=0.828,p=0.828),  time:17.153, tt:686.135\n",
      "Ep:40, loss:0.00007, loss_test:0.08468, lr:9.51e-03, fs:0.81218 (r=0.808,p=0.816),  time:17.094, tt:700.842\n",
      "Ep:41, loss:0.00006, loss_test:0.07859, lr:9.51e-03, fs:0.82723 (r=0.798,p=0.859),  time:17.029, tt:715.198\n",
      "Ep:42, loss:0.00006, loss_test:0.08411, lr:9.51e-03, fs:0.81905 (r=0.869,p=0.775),  time:16.984, tt:730.332\n",
      "Ep:43, loss:0.00006, loss_test:0.08218, lr:9.51e-03, fs:0.78261 (r=0.727,p=0.847),  time:16.937, tt:745.214\n",
      "Ep:44, loss:0.00006, loss_test:0.08112, lr:9.51e-03, fs:0.84158 (r=0.859,p=0.825),  time:16.891, tt:760.105\n",
      "Ep:45, loss:0.00006, loss_test:0.08453, lr:9.51e-03, fs:0.76087 (r=0.707,p=0.824),  time:16.840, tt:774.645\n",
      "Ep:46, loss:0.00006, loss_test:0.08120, lr:9.51e-03, fs:0.84422 (r=0.848,p=0.840),  time:16.805, tt:789.856\n",
      "Ep:47, loss:0.00006, loss_test:0.08445, lr:9.41e-03, fs:0.77895 (r=0.747,p=0.813),  time:16.752, tt:804.111\n",
      "Ep:48, loss:0.00005, loss_test:0.08142, lr:9.32e-03, fs:0.79787 (r=0.758,p=0.843),  time:16.712, tt:818.893\n",
      "Ep:49, loss:0.00005, loss_test:0.08439, lr:9.23e-03, fs:0.80597 (r=0.818,p=0.794),  time:16.687, tt:834.370\n",
      "Ep:50, loss:0.00005, loss_test:0.08109, lr:9.14e-03, fs:0.78919 (r=0.737,p=0.849),  time:16.654, tt:849.333\n",
      "Ep:51, loss:0.00005, loss_test:0.08473, lr:9.04e-03, fs:0.79397 (r=0.798,p=0.790),  time:16.615, tt:863.983\n",
      "Ep:52, loss:0.00005, loss_test:0.07996, lr:8.95e-03, fs:0.78495 (r=0.737,p=0.839),  time:16.582, tt:878.851\n",
      "Ep:53, loss:0.00005, loss_test:0.08499, lr:8.86e-03, fs:0.77320 (r=0.758,p=0.789),  time:16.552, tt:893.822\n",
      "Ep:54, loss:0.00005, loss_test:0.07923, lr:8.78e-03, fs:0.82292 (r=0.798,p=0.849),  time:16.558, tt:910.715\n",
      "Ep:55, loss:0.00005, loss_test:0.08761, lr:8.69e-03, fs:0.75532 (r=0.717,p=0.798),  time:16.543, tt:926.421\n",
      "Ep:56, loss:0.00005, loss_test:0.07991, lr:8.60e-03, fs:0.82474 (r=0.808,p=0.842),  time:16.512, tt:941.196\n",
      "Ep:57, loss:0.00004, loss_test:0.08633, lr:8.51e-03, fs:0.76344 (r=0.717,p=0.816),  time:16.484, tt:956.084\n",
      "Ep:58, loss:0.00004, loss_test:0.08009, lr:8.43e-03, fs:0.80829 (r=0.788,p=0.830),  time:16.477, tt:972.150\n",
      "Ep:59, loss:0.00004, loss_test:0.08330, lr:8.35e-03, fs:0.78534 (r=0.758,p=0.815),  time:16.474, tt:988.451\n",
      "Ep:60, loss:0.00004, loss_test:0.08036, lr:8.26e-03, fs:0.80851 (r=0.768,p=0.854),  time:16.465, tt:1004.367\n",
      "Ep:61, loss:0.00004, loss_test:0.08528, lr:8.18e-03, fs:0.78125 (r=0.758,p=0.806),  time:16.439, tt:1019.230\n",
      "Ep:62, loss:0.00004, loss_test:0.08122, lr:8.10e-03, fs:0.80214 (r=0.758,p=0.852),  time:16.413, tt:1034.034\n",
      "Ep:63, loss:0.00004, loss_test:0.08668, lr:8.02e-03, fs:0.72527 (r=0.667,p=0.795),  time:16.376, tt:1048.054\n",
      "Ep:64, loss:0.00004, loss_test:0.08040, lr:7.94e-03, fs:0.83770 (r=0.808,p=0.870),  time:16.348, tt:1062.610\n",
      "Ep:65, loss:0.00004, loss_test:0.08676, lr:7.86e-03, fs:0.74866 (r=0.707,p=0.795),  time:16.311, tt:1076.505\n",
      "Ep:66, loss:0.00004, loss_test:0.08041, lr:7.78e-03, fs:0.80214 (r=0.758,p=0.852),  time:16.289, tt:1091.396\n",
      "Ep:67, loss:0.00004, loss_test:0.08895, lr:7.70e-03, fs:0.74866 (r=0.707,p=0.795),  time:16.265, tt:1106.017\n",
      "Ep:68, loss:0.00004, loss_test:0.08132, lr:7.62e-03, fs:0.80000 (r=0.747,p=0.860),  time:16.239, tt:1120.508\n",
      "Ep:69, loss:0.00004, loss_test:0.08400, lr:7.55e-03, fs:0.75000 (r=0.697,p=0.812),  time:16.221, tt:1135.440\n",
      "Ep:70, loss:0.00003, loss_test:0.08617, lr:7.47e-03, fs:0.75000 (r=0.697,p=0.812),  time:16.190, tt:1149.486\n",
      "Ep:71, loss:0.00003, loss_test:0.08145, lr:7.40e-03, fs:0.80000 (r=0.747,p=0.860),  time:16.165, tt:1163.908\n",
      "Ep:72, loss:0.00003, loss_test:0.08925, lr:7.32e-03, fs:0.73913 (r=0.687,p=0.800),  time:16.138, tt:1178.056\n",
      "Ep:73, loss:0.00003, loss_test:0.08111, lr:7.25e-03, fs:0.81283 (r=0.768,p=0.864),  time:16.129, tt:1193.557\n",
      "Ep:74, loss:0.00003, loss_test:0.08761, lr:7.18e-03, fs:0.73913 (r=0.687,p=0.800),  time:16.108, tt:1208.078\n",
      "Ep:75, loss:0.00003, loss_test:0.08159, lr:7.11e-03, fs:0.79121 (r=0.727,p=0.867),  time:16.086, tt:1222.527\n",
      "Ep:76, loss:0.00003, loss_test:0.08752, lr:7.03e-03, fs:0.74866 (r=0.707,p=0.795),  time:16.085, tt:1238.552\n",
      "Ep:77, loss:0.00003, loss_test:0.08440, lr:6.96e-03, fs:0.76404 (r=0.687,p=0.861),  time:16.087, tt:1254.764\n",
      "Ep:78, loss:0.00003, loss_test:0.08390, lr:6.89e-03, fs:0.74033 (r=0.677,p=0.817),  time:16.083, tt:1270.548\n",
      "Ep:79, loss:0.00003, loss_test:0.08556, lr:6.83e-03, fs:0.75410 (r=0.697,p=0.821),  time:16.071, tt:1285.663\n",
      "Ep:80, loss:0.00003, loss_test:0.08497, lr:6.76e-03, fs:0.73864 (r=0.657,p=0.844),  time:16.052, tt:1300.242\n",
      "Ep:81, loss:0.00003, loss_test:0.08431, lr:6.69e-03, fs:0.76087 (r=0.707,p=0.824),  time:16.038, tt:1315.081\n",
      "Ep:82, loss:0.00003, loss_test:0.08449, lr:6.62e-03, fs:0.76667 (r=0.697,p=0.852),  time:16.018, tt:1329.459\n",
      "Ep:83, loss:0.00003, loss_test:0.08627, lr:6.56e-03, fs:0.72626 (r=0.657,p=0.812),  time:16.010, tt:1344.866\n",
      "Ep:84, loss:0.00003, loss_test:0.08446, lr:6.49e-03, fs:0.75824 (r=0.697,p=0.831),  time:16.006, tt:1360.503\n",
      "Ep:85, loss:0.00003, loss_test:0.08392, lr:6.43e-03, fs:0.75281 (r=0.677,p=0.848),  time:15.988, tt:1374.978\n",
      "Ep:86, loss:0.00003, loss_test:0.08465, lr:6.36e-03, fs:0.74444 (r=0.677,p=0.827),  time:15.977, tt:1390.043\n",
      "Ep:87, loss:0.00003, loss_test:0.08509, lr:6.30e-03, fs:0.75706 (r=0.677,p=0.859),  time:15.978, tt:1406.070\n",
      "Ep:88, loss:0.00003, loss_test:0.08663, lr:6.24e-03, fs:0.73333 (r=0.667,p=0.815),  time:15.978, tt:1422.053\n",
      "Ep:89, loss:0.00002, loss_test:0.08361, lr:6.17e-03, fs:0.76404 (r=0.687,p=0.861),  time:15.965, tt:1436.883\n",
      "Ep:90, loss:0.00002, loss_test:0.08819, lr:6.11e-03, fs:0.71910 (r=0.646,p=0.810),  time:15.958, tt:1452.139\n",
      "Ep:91, loss:0.00002, loss_test:0.08372, lr:6.05e-03, fs:0.75978 (r=0.687,p=0.850),  time:15.950, tt:1467.362\n",
      "Ep:92, loss:0.00002, loss_test:0.08715, lr:5.99e-03, fs:0.72928 (r=0.667,p=0.805),  time:15.943, tt:1482.745\n",
      "Ep:93, loss:0.00002, loss_test:0.08216, lr:5.93e-03, fs:0.74157 (r=0.667,p=0.835),  time:15.943, tt:1498.639\n",
      "Ep:94, loss:0.00002, loss_test:0.08812, lr:5.87e-03, fs:0.74317 (r=0.687,p=0.810),  time:15.931, tt:1513.408\n",
      "Ep:95, loss:0.00002, loss_test:0.08455, lr:5.81e-03, fs:0.74713 (r=0.657,p=0.867),  time:15.923, tt:1528.588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:96, loss:0.00002, loss_test:0.08427, lr:5.75e-03, fs:0.73864 (r=0.657,p=0.844),  time:15.908, tt:1543.084\n",
      "Ep:97, loss:0.00002, loss_test:0.08729, lr:5.70e-03, fs:0.74725 (r=0.687,p=0.819),  time:15.899, tt:1558.131\n",
      "Ep:98, loss:0.00002, loss_test:0.08528, lr:5.64e-03, fs:0.72832 (r=0.636,p=0.851),  time:15.884, tt:1572.549\n",
      "Ep:99, loss:0.00002, loss_test:0.08564, lr:5.58e-03, fs:0.73864 (r=0.657,p=0.844),  time:15.867, tt:1586.670\n",
      "Ep:100, loss:0.00002, loss_test:0.08469, lr:5.53e-03, fs:0.75138 (r=0.687,p=0.829),  time:15.851, tt:1600.958\n",
      "Ep:101, loss:0.00002, loss_test:0.08687, lr:5.47e-03, fs:0.72626 (r=0.657,p=0.812),  time:15.848, tt:1616.525\n",
      "Ep:102, loss:0.00002, loss_test:0.08568, lr:5.42e-03, fs:0.73864 (r=0.657,p=0.844),  time:15.842, tt:1631.734\n",
      "Ep:103, loss:0.00002, loss_test:0.08535, lr:5.36e-03, fs:0.73446 (r=0.657,p=0.833),  time:15.830, tt:1646.358\n",
      "Ep:104, loss:0.00002, loss_test:0.08657, lr:5.31e-03, fs:0.74576 (r=0.667,p=0.846),  time:15.828, tt:1661.930\n",
      "Ep:105, loss:0.00002, loss_test:0.08552, lr:5.26e-03, fs:0.72727 (r=0.646,p=0.831),  time:15.819, tt:1676.860\n",
      "Ep:106, loss:0.00002, loss_test:0.08449, lr:5.20e-03, fs:0.72727 (r=0.646,p=0.831),  time:15.804, tt:1691.081\n",
      "Ep:107, loss:0.00002, loss_test:0.08847, lr:5.15e-03, fs:0.72316 (r=0.646,p=0.821),  time:15.790, tt:1705.349\n",
      "Ep:108, loss:0.00002, loss_test:0.08486, lr:5.10e-03, fs:0.74157 (r=0.667,p=0.835),  time:15.781, tt:1720.117\n",
      "Ep:109, loss:0.00002, loss_test:0.08577, lr:5.05e-03, fs:0.71676 (r=0.626,p=0.838),  time:15.771, tt:1734.845\n",
      "Ep:110, loss:0.00002, loss_test:0.08811, lr:5.00e-03, fs:0.73864 (r=0.657,p=0.844),  time:15.767, tt:1750.096\n",
      "Ep:111, loss:0.00002, loss_test:0.08568, lr:4.95e-03, fs:0.74157 (r=0.667,p=0.835),  time:15.762, tt:1765.396\n",
      "Ep:112, loss:0.00002, loss_test:0.08428, lr:4.90e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.751, tt:1779.848\n",
      "Ep:113, loss:0.00002, loss_test:0.08757, lr:4.85e-03, fs:0.74286 (r=0.657,p=0.855),  time:15.743, tt:1794.685\n",
      "Ep:114, loss:0.00002, loss_test:0.08603, lr:4.80e-03, fs:0.72316 (r=0.646,p=0.821),  time:15.736, tt:1809.671\n",
      "Ep:115, loss:0.00002, loss_test:0.08534, lr:4.75e-03, fs:0.73446 (r=0.657,p=0.833),  time:15.729, tt:1824.514\n",
      "Ep:116, loss:0.00002, loss_test:0.08754, lr:4.71e-03, fs:0.72414 (r=0.636,p=0.840),  time:15.724, tt:1839.660\n",
      "Ep:117, loss:0.00002, loss_test:0.08519, lr:4.66e-03, fs:0.72414 (r=0.636,p=0.840),  time:15.722, tt:1855.151\n",
      "Ep:118, loss:0.00002, loss_test:0.08605, lr:4.61e-03, fs:0.73864 (r=0.657,p=0.844),  time:15.724, tt:1871.202\n",
      "Ep:119, loss:0.00002, loss_test:0.08482, lr:4.57e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.716, tt:1885.879\n",
      "Ep:120, loss:0.00002, loss_test:0.08812, lr:4.52e-03, fs:0.72000 (r=0.636,p=0.829),  time:15.707, tt:1900.564\n",
      "Ep:121, loss:0.00002, loss_test:0.08417, lr:4.48e-03, fs:0.72727 (r=0.646,p=0.831),  time:15.697, tt:1915.040\n",
      "Ep:122, loss:0.00002, loss_test:0.08684, lr:4.43e-03, fs:0.72414 (r=0.636,p=0.840),  time:15.691, tt:1930.017\n",
      "Ep:123, loss:0.00002, loss_test:0.08689, lr:4.39e-03, fs:0.72414 (r=0.636,p=0.840),  time:15.683, tt:1944.643\n",
      "Ep:124, loss:0.00002, loss_test:0.08500, lr:4.34e-03, fs:0.71264 (r=0.626,p=0.827),  time:15.679, tt:1959.851\n",
      "Ep:125, loss:0.00002, loss_test:0.08641, lr:4.30e-03, fs:0.72414 (r=0.636,p=0.840),  time:15.667, tt:1974.071\n",
      "Ep:126, loss:0.00002, loss_test:0.08612, lr:4.26e-03, fs:0.73446 (r=0.657,p=0.833),  time:15.662, tt:1989.063\n",
      "Ep:127, loss:0.00002, loss_test:0.08680, lr:4.21e-03, fs:0.71676 (r=0.626,p=0.838),  time:15.656, tt:2004.028\n",
      "Ep:128, loss:0.00002, loss_test:0.08579, lr:4.17e-03, fs:0.72414 (r=0.636,p=0.840),  time:15.652, tt:2019.153\n",
      "Ep:129, loss:0.00002, loss_test:0.08643, lr:4.13e-03, fs:0.71676 (r=0.626,p=0.838),  time:15.651, tt:2034.690\n",
      "Ep:130, loss:0.00002, loss_test:0.08658, lr:4.09e-03, fs:0.71676 (r=0.626,p=0.838),  time:15.642, tt:2049.113\n",
      "Ep:131, loss:0.00002, loss_test:0.08750, lr:4.05e-03, fs:0.72000 (r=0.636,p=0.829),  time:15.636, tt:2063.888\n",
      "Ep:132, loss:0.00002, loss_test:0.08535, lr:4.01e-03, fs:0.70857 (r=0.626,p=0.816),  time:15.626, tt:2078.206\n",
      "Ep:133, loss:0.00002, loss_test:0.08704, lr:3.97e-03, fs:0.71264 (r=0.626,p=0.827),  time:15.621, tt:2093.244\n",
      "Ep:134, loss:0.00002, loss_test:0.08710, lr:3.93e-03, fs:0.71676 (r=0.626,p=0.838),  time:15.618, tt:2108.396\n",
      "Ep:135, loss:0.00002, loss_test:0.08700, lr:3.89e-03, fs:0.71676 (r=0.626,p=0.838),  time:15.612, tt:2123.201\n",
      "Ep:136, loss:0.00002, loss_test:0.08509, lr:3.85e-03, fs:0.71264 (r=0.626,p=0.827),  time:15.606, tt:2138.011\n",
      "Ep:137, loss:0.00002, loss_test:0.08899, lr:3.81e-03, fs:0.71676 (r=0.626,p=0.838),  time:15.600, tt:2152.754\n",
      "Ep:138, loss:0.00002, loss_test:0.08675, lr:3.77e-03, fs:0.71264 (r=0.626,p=0.827),  time:15.594, tt:2167.610\n",
      "Ep:139, loss:0.00002, loss_test:0.08573, lr:3.73e-03, fs:0.70857 (r=0.626,p=0.816),  time:15.590, tt:2182.641\n",
      "Ep:140, loss:0.00002, loss_test:0.08821, lr:3.70e-03, fs:0.71264 (r=0.626,p=0.827),  time:15.585, tt:2197.442\n",
      "Ep:141, loss:0.00002, loss_test:0.08648, lr:3.66e-03, fs:0.71264 (r=0.626,p=0.827),  time:15.582, tt:2212.667\n",
      "Ep:142, loss:0.00002, loss_test:0.08690, lr:3.62e-03, fs:0.71676 (r=0.626,p=0.838),  time:15.581, tt:2228.136\n",
      "Ep:143, loss:0.00002, loss_test:0.08607, lr:3.59e-03, fs:0.71676 (r=0.626,p=0.838),  time:15.577, tt:2243.156\n",
      "Ep:144, loss:0.00002, loss_test:0.08706, lr:3.55e-03, fs:0.71676 (r=0.626,p=0.838),  time:15.571, tt:2257.819\n",
      "Ep:145, loss:0.00002, loss_test:0.08843, lr:3.52e-03, fs:0.71676 (r=0.626,p=0.838),  time:15.567, tt:2272.717\n",
      "Ep:146, loss:0.00002, loss_test:0.08537, lr:3.48e-03, fs:0.71264 (r=0.626,p=0.827),  time:15.565, tt:2288.064\n",
      "Ep:147, loss:0.00002, loss_test:0.08887, lr:3.45e-03, fs:0.71676 (r=0.626,p=0.838),  time:15.560, tt:2302.925\n",
      "Ep:148, loss:0.00002, loss_test:0.08721, lr:3.41e-03, fs:0.71264 (r=0.626,p=0.827),  time:15.558, tt:2318.208\n",
      "Ep:149, loss:0.00002, loss_test:0.08573, lr:3.38e-03, fs:0.70857 (r=0.626,p=0.816),  time:15.558, tt:2333.646\n",
      "Ep:150, loss:0.00002, loss_test:0.08853, lr:3.34e-03, fs:0.71676 (r=0.626,p=0.838),  time:15.552, tt:2348.379\n",
      "Ep:151, loss:0.00002, loss_test:0.08846, lr:3.31e-03, fs:0.71264 (r=0.626,p=0.827),  time:15.547, tt:2363.101\n",
      "Ep:152, loss:0.00002, loss_test:0.08651, lr:3.28e-03, fs:0.71264 (r=0.626,p=0.827),  time:15.543, tt:2378.104\n",
      "Ep:153, loss:0.00002, loss_test:0.08686, lr:3.24e-03, fs:0.71264 (r=0.626,p=0.827),  time:15.539, tt:2392.967\n",
      "Ep:154, loss:0.00002, loss_test:0.08779, lr:3.21e-03, fs:0.71264 (r=0.626,p=0.827),  time:15.517, tt:2405.129\n",
      "Ep:155, loss:0.00002, loss_test:0.08934, lr:3.18e-03, fs:0.71264 (r=0.626,p=0.827),  time:15.493, tt:2416.984\n",
      "Ep:156, loss:0.00002, loss_test:0.08665, lr:3.15e-03, fs:0.71676 (r=0.626,p=0.838),  time:15.470, tt:2428.834\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"7-8\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_NEW\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,155,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,156,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_SHORT\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,2,False)\n",
    "\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_NEW\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,155,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,156,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_SHORT\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #train new model and specify parameters\n",
    "# training_object = gcn_training.Training()\n",
    "# training_object.set_training(\n",
    "#             net_name= gcn_nn.get_option_name(),  #_of_option for NN architecture\n",
    "#             batch_splits= ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "#             lr= , #learning rate for training (e.g. 1e-3 )\n",
    "#             loss_name=gcn_loss.get_option_name(), #_of_option for loss \n",
    "#             loss_parameters= ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "#             optimizer_name= ) #adam or sgd, default adam\n",
    "\n",
    "##cross_validation(training_object,num_of_training_iterations_per_fold,nsample[opt],create_split[opt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results <br>\n",
    "\n",
    "<p>This will plot charts of loss/accuracy for all the results that match the parameters options under the /results folder</p>\n",
    "\n",
    "#### Parameters options\n",
    "\n",
    "<p> Choose one of each and pass it to the corresponding plot function in the following order:\n",
    "\n",
    "<b>1) neg_sample</b> = [1,2,3,4...etc] <br>\n",
    "<b>2) db_name</b> = [\"openml_203ds_datasets_matching\"] <br>\n",
    "<b>3) strategy</b> = [\"isolation\",\"random\"] <br>\n",
    "<b>4) archi</b> = [\"Fasttext_150\",\"Fasttext_300\",\"Bert_300\",\"Bert_768\"] <br>\n",
    "<b>5) optimizer</b> = [\"adam\",\"sgd\"] <br>\n",
    "<b>6) loss_functions</b> = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"] <br>\n",
    "\n",
    "#### Type of chart\n",
    "<b>plot_by_loss_parameters:</b> groups in one chart the different results for loss functions parameters (margin) <br>\n",
    "<b>plot_by_split </b>: groups in one chart the different results for size of batch splits <br>\n",
    "<b>plot_cv </b>: plot the result of cross validation runs that were found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot individual runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [2]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [4]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [8]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [16]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [24]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISOLATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [2]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [4]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [8]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [16]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [24]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(4,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISOLATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(4,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"FasttextSum_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"FasttextSum_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_364\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
